<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Semidefinite Optimization | Semidefinite Optimization and Relaxation</title>
  <meta name="description" content="Lecture notes for Harvard ES 257 Semidefinite Optimization and Relaxation." />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Semidefinite Optimization | Semidefinite Optimization and Relaxation" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture notes for Harvard ES 257 Semidefinite Optimization and Relaxation." />
  <meta name="github-repo" content="hankyang94/Semidefinite" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Semidefinite Optimization | Semidefinite Optimization and Relaxation" />
  
  <meta name="twitter:description" content="Lecture notes for Harvard ES 257 Semidefinite Optimization and Relaxation." />
  

<meta name="author" content="Heng Yang" />


<meta name="date" content="2024-02-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="background.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Semidefinite Optimization and Relaxation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#feedback"><i class="fa fa-check"></i>Feedback</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#offerings"><i class="fa fa-check"></i>Offerings</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="notation.html"><a href="notation.html"><i class="fa fa-check"></i>Notation</a></li>
<li class="chapter" data-level="1" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>1</b> Mathematical Background</a>
<ul>
<li class="chapter" data-level="1.1" data-path="background.html"><a href="background.html#background:convexity"><i class="fa fa-check"></i><b>1.1</b> Convexity</a></li>
<li class="chapter" data-level="1.2" data-path="background.html"><a href="background.html#background:convex:geometry"><i class="fa fa-check"></i><b>1.2</b> Convex Geometry</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="background.html"><a href="background.html#basic-facts"><i class="fa fa-check"></i><b>1.2.1</b> Basic Facts</a></li>
<li class="chapter" data-level="1.2.2" data-path="background.html"><a href="background.html#cones-duality-polarity"><i class="fa fa-check"></i><b>1.2.2</b> Cones, Duality, Polarity</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="background.html"><a href="background.html#background:convex:optimization"><i class="fa fa-check"></i><b>1.3</b> Convex Optimization</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="background.html"><a href="background.html#minimax-theorem"><i class="fa fa-check"></i><b>1.3.1</b> Minimax Theorem</a></li>
<li class="chapter" data-level="1.3.2" data-path="background.html"><a href="background.html#background:convex:optimization:Lagrangian"><i class="fa fa-check"></i><b>1.3.2</b> Lagrangian Duality</a></li>
<li class="chapter" data-level="1.3.3" data-path="background.html"><a href="background.html#kkt-optimality-conditions"><i class="fa fa-check"></i><b>1.3.3</b> KKT Optimality Conditions</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="background.html"><a href="background.html#background:linear:optimization"><i class="fa fa-check"></i><b>1.4</b> Linear Optimization</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="background.html"><a href="background.html#polyhedra"><i class="fa fa-check"></i><b>1.4.1</b> Polyhedra</a></li>
<li class="chapter" data-level="1.4.2" data-path="background.html"><a href="background.html#linear-program"><i class="fa fa-check"></i><b>1.4.2</b> Linear Program</a></li>
<li class="chapter" data-level="1.4.3" data-path="background.html"><a href="background.html#farkas-lemma"><i class="fa fa-check"></i><b>1.4.3</b> Farkas Lemma</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="sdp.html"><a href="sdp.html"><i class="fa fa-check"></i><b>2</b> Semidefinite Optimization</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sdp.html"><a href="sdp.html#positive-semidefinite-matrices"><i class="fa fa-check"></i><b>2.1</b> Positive Semidefinite Matrices</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="sdp.html"><a href="sdp.html#geometric-properties"><i class="fa fa-check"></i><b>2.1.1</b> Geometric Properties</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="sdp.html"><a href="sdp.html#semidefinite-programming"><i class="fa fa-check"></i><b>2.2</b> Semidefinite Programming</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="sdp.html"><a href="sdp.html#spectrahedra"><i class="fa fa-check"></i><b>2.2.1</b> Spectrahedra</a></li>
<li class="chapter" data-level="2.2.2" data-path="sdp.html"><a href="sdp.html#formulation-and-duality"><i class="fa fa-check"></i><b>2.2.2</b> Formulation and Duality</a></li>
<li class="chapter" data-level="2.2.3" data-path="sdp.html"><a href="sdp.html#geometric-properties-1"><i class="fa fa-check"></i><b>2.2.3</b> Geometric Properties</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="sdp.html"><a href="sdp.html#software-for-conic-optimization"><i class="fa fa-check"></i><b>2.3</b> Software for Conic Optimization</a></li>
<li class="chapter" data-level="2.4" data-path="sdp.html"><a href="sdp.html#interior-point-algorithm"><i class="fa fa-check"></i><b>2.4</b> Interior Point Algorithm</a></li>
<li class="chapter" data-level="2.5" data-path="sdp.html"><a href="sdp.html#applications"><i class="fa fa-check"></i><b>2.5</b> Applications</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="sdp.html"><a href="sdp.html#lyapunov-stability"><i class="fa fa-check"></i><b>2.5.1</b> Lyapunov Stability</a></li>
<li class="chapter" data-level="2.5.2" data-path="sdp.html"><a href="sdp.html#linear-quadratic-regulator"><i class="fa fa-check"></i><b>2.5.2</b> Linear Quadratic Regulator</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Semidefinite Optimization and Relaxation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sdp" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Semidefinite Optimization<a href="sdp.html#sdp" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="positive-semidefinite-matrices" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Positive Semidefinite Matrices<a href="sdp.html#positive-semidefinite-matrices" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A real matrix <span class="math inline">\(A = (A_{ij}) \in \mathbb{R}^{n \times n}\)</span> is symmetric if <span class="math inline">\(A = A^\top\)</span>, i.e., <span class="math inline">\(A_{ij} = A_{ji}\)</span> for all <span class="math inline">\(i,j\)</span>. Let <span class="math inline">\(\mathbb{S}^{n}\)</span> be the space of all real symmetric matrices.</p>
<p>Any symmetric matrix <span class="math inline">\(A\)</span> defines a <strong>quadratic form</strong> <span class="math inline">\(x^\top A x\)</span>. A matrix <span class="math inline">\(A\)</span> is said to be <strong>positive semidefinite</strong> (PSD) if and only if its associated quadratic form is nonnegative, i.e.,
<span class="math display">\[
x^\top A x \geq 0, \quad \forall x \in \mathbb{R}^{n}.
\]</span>
We use <span class="math inline">\(\mathbb{S}^{n}_{+}\)</span> to denote the set of <span class="math inline">\(n\times n\)</span> PSD matrices. We also write <span class="math inline">\(A \succeq 0\)</span> to denote positive semidefiniteness when the dimension is clear.</p>
<p>There are several equivalent characterizations of positive semidefiniteness.</p>
<div class="theorembox">
<div class="lemma">
<p><span id="lem:PositiveSemidefinite" class="lemma"><strong>Lemma 2.1  (Positive Semidefinite Matrices) </strong></span>Let <span class="math inline">\(A \in \mathbb{S}^{n}\)</span> be a symmetric matrix, the following statements are equivalent:</p>
<ol style="list-style-type: decimal">
<li><p>A is positive semidefinite.</p></li>
<li><p><span class="math inline">\(x^\top A x \geq 0, \forall x \in \mathbb{R}^{n}\)</span>.</p></li>
<li><p>All eigenvalues of <span class="math inline">\(A\)</span> are nonnegative.</p></li>
<li><p>All <span class="math inline">\(2^n-1\)</span> principal minors of <span class="math inline">\(A\)</span> are nonnegative.</p></li>
<li><p>The coefficients of <span class="math inline">\(p_A(\lambda)\)</span> weakly alternate in sign, i.e., <span class="math inline">\((-1)^{n-k} p_k \geq 0\)</span> for <span class="math inline">\(k=0,\dots,n-1\)</span>, where <span class="math inline">\(p_A(\lambda) = \det (A - \lambda \mathrm{I}_n)\)</span> is the characteristics polynomial of <span class="math inline">\(A\)</span>.</p></li>
<li><p>There exists a factorization <span class="math inline">\(A = BB^\top\)</span>, where <span class="math inline">\(B \in \mathbb{R}^{n \times r}\)</span> with <span class="math inline">\(r\)</span> the rank of <span class="math inline">\(A\)</span>.</p></li>
</ol>
</div>
</div>
<p>Among the equivalent characterizations of PSD matrices, (5) is less well-known, but it can be very useful when we want to convert a PSD constraint into multiple scalar constraints. For example, consider the following subset of <span class="math inline">\(\mathbb{R}^{3}\)</span>:
<span class="math display">\[
\left\{ z \in \mathbb{R}^{3} \ \middle\vert\ X(z) = \begin{bmatrix} 1 &amp; z_1 &amp; z_2 \\ z_1 &amp; z_2 &amp; z_3 \\ z_2 &amp; z_3 &amp; 5 z_2 - 4  \end{bmatrix} \succeq 0  \right\} .
\]</span>
We can first form the characteristic polynomial of <span class="math inline">\(X(z)\)</span> –whose coefficients will be functions of <span class="math inline">\(z\)</span>– and then invoking (5) to obtain a finite number scalar inequality constraints. We can then pass these scalar constraints to Mathematica and plot the set as in the following figure <span class="citation">(<a href="#ref-yang22mp-inexact" role="doc-biblioref">Yang et al. 2022</a>)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:SpectrahedronStride"></span>
<img src="images/spectrahedron-stride.png" alt="An example spectrahedron." width="50%" />
<p class="caption">
Figure 2.1: An example spectrahedron.
</p>
</div>
<p>Similarly, we say a matrix <span class="math inline">\(A \in \mathbb{S}^{n}\)</span> is <strong>positive definite</strong> (PD) is its associated quadratic form is always positive, i.e.,
<span class="math display">\[
x^\top A x &gt; 0, \quad \forall x \in \mathbb{R}^{n}.
\]</span>
We use <span class="math inline">\(\mathbb{S}^{n}_{++}\)</span> to denote the set of <span class="math inline">\(n \times n\)</span> PD matrices, and also write <span class="math inline">\(A \succ 0\)</span> when the dimension is clear.</p>
<p>Below is set of equivalent characterizations of positive definite matrices.</p>
<div class="theorembox">
<div class="lemma">
<p><span id="lem:PositiveDefinite" class="lemma"><strong>Lemma 2.2  (Positive Definite Matrices) </strong></span>Let <span class="math inline">\(A \in \mathbb{S}^{n}\)</span> be a symmetric matrix, the following statements are equivalent:</p>
<ol style="list-style-type: decimal">
<li><p>A is positive definite.</p></li>
<li><p><span class="math inline">\(x^\top A x &gt; 0, \forall x \in \mathbb{R}^{n}\)</span>.</p></li>
<li><p>All eigenvalues of <span class="math inline">\(A\)</span> are strictly positive.</p></li>
<li><p>All <span class="math inline">\(n\)</span> leading principal minors of <span class="math inline">\(A\)</span> are strictly positive.</p></li>
<li><p>The coefficients of <span class="math inline">\(p_A(\lambda)\)</span> strictly alternate in sign, i.e., <span class="math inline">\((-1)^{n-k} p_k &gt; 0\)</span> for <span class="math inline">\(k=0,\dots,n-1\)</span>, where <span class="math inline">\(p_A(\lambda) = \det (A - \lambda \mathrm{I}_n)\)</span> is the characteristics polynomial of <span class="math inline">\(A\)</span>.</p></li>
<li><p>There exists a factorization <span class="math inline">\(A = BB^\top\)</span> with <span class="math inline">\(B\)</span> square and nonsingular (full-rank).</p></li>
</ol>
</div>
</div>
<p><strong>Schur Complements</strong>. A useful technique to check whether a matrix is positive (semi-)definite is to use the Schur Complements. Consider a block-partitioned matrix
<span class="math display" id="eq:block-mat-M">\[\begin{equation}
M = \begin{bmatrix} A &amp; B \\ B^\top&amp; C \end{bmatrix},
\tag{2.1}
\end{equation}\]</span>
where <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span> are symmetric matrices.
If <span class="math inline">\(A\)</span> is invertible, then the Schur complement of <span class="math inline">\(A\)</span> is
<span class="math display">\[
M / A = C - B^\top A^{-1}B.
\]</span>
Similarly, if <span class="math inline">\(C\)</span> is invertible, then the Schur complement of <span class="math inline">\(C\)</span> is
<span class="math display">\[
M / C = A - B C^{-1}B^\top.
\]</span></p>
<p>We have the following result relating the Schur Complements to positive (semi-)definiteness.</p>
<div class="theorembox">
<div class="proposition">
<p><span id="prp:SchurPSD" class="proposition"><strong>Proposition 2.1  (Schur Complements and PSD) </strong></span>Consider the block-partitioned matrix <span class="math inline">\(M\)</span> in <a href="sdp.html#eq:block-mat-M">(2.1)</a>,</p>
<ul>
<li><p><span class="math inline">\(M\)</span> is positive definite if and only if both <span class="math inline">\(A\)</span> and <span class="math inline">\(M/A\)</span> are positive definite:
<span class="math display">\[
M \succ 0 \Leftrightarrow A \succ 0, M/A = C - B^\top A^{-1}B \succ 0.
\]</span></p></li>
<li><p><span class="math inline">\(M\)</span> is positive definite if and only if both <span class="math inline">\(C\)</span> and <span class="math inline">\(M/C\)</span> are positive definite:
<span class="math display">\[
M \succ 0 \Leftrightarrow C \succ 0, M/C = A - B C^{-1}B^\top\succ 0.
\]</span></p></li>
<li><p>If <span class="math inline">\(A\)</span> is positive definite, then <span class="math inline">\(M\)</span> is positive semidefinite if and only if <span class="math inline">\(M/A\)</span> is positive semidefinite:
<span class="math display">\[
\text{If } A \succ 0, \text{ then } M \succeq 0 \Leftrightarrow M / A \succeq 0.
\]</span></p></li>
<li><p>If <span class="math inline">\(C\)</span> is positive definite, then <span class="math inline">\(M\)</span> is positive semidefinite if and only if <span class="math inline">\(M/C\)</span> is positive semidefinite:
<span class="math display">\[
\text{If } C \succ 0, \text{ then } M \succeq 0 \Leftrightarrow M / C \succeq 0.
\]</span></p></li>
</ul>
</div>
</div>
<div id="geometric-properties" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Geometric Properties<a href="sdp.html#geometric-properties" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The set <span class="math inline">\(\mathbb{S}^{n}_{+}\)</span> is a proper cone (cf. Definition <a href="background.html#def:ProperCone">1.3</a>). Its interior is <span class="math inline">\(\mathbb{S}^{n}_{++}\)</span>. Under the inner product
<span class="math display">\[
\langle A, B \rangle = \mathrm{tr}(AB^\top), \quad A,B \in \mathbb{R}^{n \times n},
\]</span>
the PSD cone <span class="math inline">\(\mathbb{S}^{n}_{+}\)</span> is self-dual.</p>
<p>Next we want to characterize the face of the PSD cone. We first present the following lemma which will turn out to be useful afterwards.</p>
<div class="theorembox">
<div class="lemma">
<p><span id="lem:PSDRange" class="lemma"><strong>Lemma 2.3  (Range of PSD Matrices) </strong></span>Let <span class="math inline">\(A,B \in \mathbb{S}^{n}_{+}\)</span>, then we have
<span class="math display" id="eq:Range-PSD">\[\begin{equation}
\mathrm{Range}(A) \subseteq \mathrm{Range}(A + B),
\tag{2.2}
\end{equation}\]</span>
where <span class="math inline">\(\mathrm{Range}(A)\)</span> denotes the span of the column vectors of <span class="math inline">\(A\)</span>.</p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-6" class="proof"><em>Proof</em>. </span>For any symmetric matrix <span class="math inline">\(S\)</span>, we know
<span class="math display">\[
\mathrm{Range}(S) = \mathrm{ker}(S)^{\perp}.
\]</span>
Therefore, to prove <a href="sdp.html#eq:Range-PSD">(2.2)</a>, it is equivalent to prove
<span class="math display">\[
\mathrm{ker}(A) \supseteq \mathrm{ker}(A + B).
\]</span>
Pick any <span class="math inline">\(u \in \mathrm{ker}(A + B)\)</span>, we have
<span class="math display">\[
(A + B) u = 0 \Rightarrow u ^\top(A + B) u = 0 \Rightarrow u^\top A u + u^\top B u = 0 \Rightarrow u^\top A u = u^\top B u = 0,
\]</span>
where the last derivation is due to <span class="math inline">\(A, B \succeq 0\)</span>. Now that we have <span class="math inline">\(u^\top A u = 0\)</span>, we claim that <span class="math inline">\(Au = 0\)</span> must hold, i.e., <span class="math inline">\(u \in \mathrm{ker}(A)\)</span>. To see this, write
<span class="math display">\[
u = \sum_{i=1}^n a_i v_i,
\]</span>
where <span class="math inline">\(a_i = \langle u, v_i \rangle\)</span> and <span class="math inline">\(v_i,i=1,\dots,n\)</span> are the eigenvectors of <span class="math inline">\(A\)</span> corresponding to eigenvalues <span class="math inline">\(\lambda_i,i=1,\dots,n\)</span>. Then we have
<span class="math display">\[
Au = \sum_{i=1}^n a_i A v_i = \sum_{i=1}^n a_i \lambda_i v_i,
\]</span>
and
<span class="math display">\[
u^\top A u = \sum_{i=1}^n \lambda_i a_i^2 = 0.
\]</span>
Since <span class="math inline">\(\lambda_i \geq 0, a_i^2 \geq 0\)</span>, we have
<span class="math display">\[
\lambda_i a_i^2 = 0, \forall i = 1,\dots,n.
\]</span>
This indicates that if <span class="math inline">\(\lambda_i &gt; 0\)</span>, then <span class="math inline">\(a_i = 0\)</span>. Therefore, <span class="math inline">\(a_i\)</span> can only be nonzero for <span class="math inline">\(\lambda_i = 0\)</span>, which leads to
<span class="math display">\[
Au = \sum_{i=1}^n a_i \lambda_i v_i = 0.
\]</span>
Therefore, <span class="math inline">\(u \in \mathrm{ker}(A)\)</span>, proving the result.</p>
</div>
</div>
<p>Lemma <a href="sdp.html#lem:PSDRange">2.3</a> indicates that if <span class="math inline">\(A \succeq B\)</span>, then <span class="math inline">\(\mathrm{Range}(B) \subseteq \mathrm{Range}(A)\)</span>. What about the reverse?</p>
<div class="theorembox">
<div class="lemma">
<p><span id="lem:Extension" class="lemma"><strong>Lemma 2.4  (Extend Line Segment) </strong></span>Let <span class="math inline">\(A,B \in \mathbb{S}^{n}_{+}\)</span>, if <span class="math inline">\(\mathrm{Range}(B) \subseteq \mathrm{Range}(A)\)</span>, then there must exist <span class="math inline">\(C \in \mathbb{S}^{n}_{+}\)</span> such that
<span class="math display">\[
A \in (B,C),
\]</span>
i.e., the line segment from <span class="math inline">\(B\)</span> to <span class="math inline">\(A\)</span> can be extended past <span class="math inline">\(A\)</span> within <span class="math inline">\(\mathbb{S}^{n}_{+}\)</span>.</p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-7" class="proof"><em>Proof</em>. </span>Since <span class="math inline">\(\mathrm{Range}(B) \subseteq \mathrm{Range}(A)\)</span>, we have
<span class="math display">\[
\mathrm{ker}(A) \subseteq \mathrm{ker}(B).
\]</span>
Now consider extending the line segment past <span class="math inline">\(A\)</span> to
<span class="math display">\[
C_{\alpha} = A + \alpha(A - B) = (1+\alpha) A - \alpha B,
\]</span>
with some <span class="math inline">\(\alpha &gt; 0\)</span>. We want to show that there exists <span class="math inline">\(\alpha &gt; 0\)</span> such that <span class="math inline">\(C_{\alpha} \succeq 0\)</span>.</p>
<p>Pick <span class="math inline">\(u \in \mathbb{R}^{n}\)</span>, then either <span class="math inline">\(u \in \mathrm{ker}(B)\)</span> or <span class="math inline">\(u \not\in \mathrm{ker}(B)\)</span>. If <span class="math inline">\(u \in \mathrm{ker}(B)\)</span>, then
<span class="math display">\[
u^\top C_{\alpha} u = (1+\alpha) u^\top A u - \alpha u^\top B u = (1+\alpha) u^\top A u \geq 0.
\]</span>
If <span class="math inline">\(u \not\in \mathrm{ker}(B)\)</span>, then due to <span class="math inline">\(\mathrm{ker}(A) \subseteq \mathrm{ker}(B)\)</span>, we have <span class="math inline">\(u \not\in \mathrm{ker}(A)\)</span> as well. As a result, we have
<span class="math display" id="eq:prove-extension-1">\[\begin{equation}
u^\top C_{\alpha} u = (1+\alpha) u^\top A u - \alpha u^\top B u = (1+\alpha) u^\top A u \lparen{ 1- \frac{\alpha}{1+\alpha} \frac{u^\top B u}{u^\top A u} }.
\tag{2.3}
\end{equation}\]</span>
Since
<span class="math display">\[
\max_{u: u \not\in \mathrm{ker}(A)} \frac{u^\top B u}{u^\top A u} \leq \frac{\lambda_{\max}(B)}{\lambda_{\min,&gt;0}(A)},
\]</span>
where <span class="math inline">\(\lambda_{\min,&gt;0}(A)\)</span> denotes the minimum positive eigenvalue of <span class="math inline">\(A\)</span>, we can always choose <span class="math inline">\(\alpha\)</span> sufficiently small to make <a href="sdp.html#eq:prove-extension-1">(2.3)</a> nonnegative. Therefore, there exists <span class="math inline">\(\alpha &gt; 0\)</span> such that <span class="math inline">\(C_{\alpha} \succeq 0\)</span>.</p>
</div>
</div>
<p>In fact, from Lemma <a href="sdp.html#lem:PSDRange">2.3</a> we can induce a corollary.</p>
<div class="theorembox">
<div class="corollary">
<p><span id="cor:PSDRange" class="corollary"><strong>Corollary 2.1  (Range of PSD Matrices) </strong></span>Let <span class="math inline">\(A, B \in \mathbb{S}^{n}_{+}\)</span>, then we have
<span class="math display">\[
\mathrm{Range}(A + B) = \mathrm{Range}(A) + \mathrm{Range}(B),
\]</span>
with “<span class="math inline">\(+\)</span>” the Minkowski sum.</p>
</div>
</div>
<div class="exercisebox">
<div class="exercise">
<p><span id="exr:unlabeled-div-8" class="exercise"><strong>Exercise 2.1  </strong></span>Let <span class="math inline">\(A,B \in \mathbb{S}^{n}_{+}\)</span>, show that <span class="math inline">\(\langle A, B \rangle = 0\)</span> if and only if <span class="math inline">\(\mathrm{Range}(A) \perp \mathrm{Range}(B)\)</span>.</p>
</div>
</div>
<p>For a subset <span class="math inline">\(T \subseteq \mathbb{S}^{n}_{+}\)</span>, we use <span class="math inline">\(\mathrm{face}(T,\mathbb{S}^{n}_{+})\)</span> to denote the smallest face of <span class="math inline">\(\mathbb{S}^{n}_{+}\)</span> that contains <span class="math inline">\(T\)</span>. We first characterize the smallest face that contains a given PSD matrix, i.e., <span class="math inline">\(\mathrm{face}(A,\mathbb{S}^{n}_{+})\)</span> for <span class="math inline">\(A\succeq 0\)</span>. Clearly, if <span class="math inline">\(A\)</span> is PD, then <span class="math inline">\(\mathrm{face}(A, \mathbb{S}^{n}_{+}) = \mathbb{S}^{n}_{+}\)</span> is the entire cone. If <span class="math inline">\(A\)</span> is PSD but singular with rank <span class="math inline">\(r &lt; n\)</span>, then <span class="math inline">\(A\)</span> has the following spectral decomposition
<span class="math display">\[
Q^\top A Q = \begin{bmatrix} \Lambda &amp; 0 \\ 0 &amp; 0 \end{bmatrix},
\]</span>
where <span class="math inline">\(\Lambda \in \mathbb{S}^{r}_{++}\)</span> is a diagonal matrix with the <span class="math inline">\(r\)</span> nonzero eigenvalues of <span class="math inline">\(A\)</span>, and <span class="math inline">\(Q \in \mathrm{O}(n)\)</span> is orthogonal. If
<span class="math display">\[
A = \lambda B + (1-\lambda)C, \quad B,C \in \mathbb{S}^{n}_{+},\lambda \in (0,1),
\]</span>
then multiplying both sides by <span class="math inline">\(Q^\top\)</span> and <span class="math inline">\(Q\)</span> we have
<span class="math display">\[
\begin{bmatrix} \Lambda &amp; 0 \\ 0 &amp; 0 \end{bmatrix} = Q^\top A Q = \lambda Q^\top B Q + (1-\lambda) Q^\top C Q.
\]</span>
Therefore, it must hold that
<span class="math display">\[
Q^\top B Q = \begin{bmatrix} B_1 &amp; 0 \\ 0 &amp; 0 \end{bmatrix}, \quad Q^\top C Q = \begin{bmatrix} C_1 &amp; 0 \\ 0 &amp; 0 \end{bmatrix}, \quad B_1 \in \mathbb{S}^{r}_{+}, C_1 \in \mathbb{S}^{r}_{+},
\]</span>
which is equivalent to
<span class="math display">\[
B = Q \begin{bmatrix} B_1 &amp; 0 \\ 0 &amp; 0 \end{bmatrix} Q^\top, C = Q \begin{bmatrix} C_1 &amp; 0 \\ 0 &amp; 0 \end{bmatrix} Q^\top, \quad B_1 \in \mathbb{S}^{r}_{+}, C_1 \in \mathbb{S}^{r}_{+}.
\]</span>
We conclude that <span class="math inline">\(\mathrm{face}(A,\mathbb{S}^{n}_{+})\)</span> must contain the set
<span class="math display" id="eq:face-of-A-psd">\[\begin{equation}
G:=  \left\{ Q \begin{bmatrix} X &amp; 0 \\ 0 &amp; 0 \end{bmatrix} Q^\top\ \middle\vert\ X \in \mathbb{S}^{r}_{+} \right\} .
\tag{2.4}
\end{equation}\]</span></p>
<div class="exercisebox">
<div class="exercise">
<p><span id="exr:unlabeled-div-9" class="exercise"><strong>Exercise 2.2  </strong></span>Show that <span class="math inline">\(G\)</span> in <a href="sdp.html#eq:face-of-A-psd">(2.4)</a> is a face of <span class="math inline">\(\mathbb{S}^{n}_{+}\)</span>, i.e., (i) <span class="math inline">\(G\)</span> is convex; (ii) <span class="math inline">\(u \in (x,y), u \in G, x,y \in \mathbb{S}^{n}_{+} \Rightarrow x,y \in G\)</span>.</p>
</div>
</div>
<p>As a result, we have <span class="math inline">\(\mathrm{face}(A,\mathbb{S}^{n}_{+}) = G\)</span>.</p>
<p>More general faces of the PSD cone <span class="math inline">\(\mathbb{S}^{n}_{+}\)</span> can be characterized as follows (Theorem 3.7.1 in <span class="citation">(<a href="#ref-wolkowicz12book-sdp" role="doc-biblioref">Wolkowicz, Saigal, and Vandenberghe 2000</a>)</span>).</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:FacePSD" class="theorem"><strong>Theorem 2.1  (Faces of the PSD Cone) </strong></span>A set <span class="math inline">\(F \subseteq \mathbb{S}^{n}_{+}\)</span> is a face if and only if there exists a subspace <span class="math inline">\(L \subseteq \mathbb{R}^{n}\)</span> such that
<span class="math display">\[
F = \{ X \in \mathbb{S}^{n}_{+} \mid \mathrm{Range}(X) \subseteq L \}.
\]</span></p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-10" class="proof"><em>Proof</em>. </span>It is easy to prove the “<strong>If</strong>” direction using Lemma <a href="sdp.html#lem:PSDRange">2.3</a>.</p>
<p>First we show <span class="math inline">\(F\)</span> is convex. Pick <span class="math inline">\(A,B \in F\)</span>. We have <span class="math inline">\(\mathrm{Range}(A) \subseteq L\)</span> and <span class="math inline">\(\mathrm{Range}(B) \subseteq L\)</span>. Let <span class="math inline">\(v_1,\dots,v_m\)</span> be a set of basis spanning <span class="math inline">\(L\)</span>. We have that, for any <span class="math inline">\(u \in \mathbb{R}^{n}\)</span>,
<span class="math display">\[\begin{equation}
\begin{split}
A u \in L &amp; \Rightarrow Au = \sum_{i=1}^m a_i v_i, \\
B u \in L &amp; \Rightarrow Bu = \sum_{i=1}^m b_i v_i.
\end{split}
\end{equation}\]</span>
So for any <span class="math inline">\(\lambda \in [0,1]\)</span>, we have
<span class="math display">\[
(\lambda A + (1-\lambda) B) u = \lambda Au + (1-\lambda) Bu = \sum_{i=1}^m (\lambda a_i + (1-\lambda) b_i ) v_i \in L,
\]</span>
implying <span class="math inline">\(\lambda A + (1-\lambda) B \in F\)</span> for any <span class="math inline">\(\lambda \in [0,1]\)</span>.</p>
<p>Now we show that:
<span class="math display">\[
X \in (A,B), X \in F, A,B \in \mathbb{S}^{n}_{+} \Rightarrow A, B \in F.
\]</span>
From <span class="math inline">\(X = \lambda A + (1-\lambda) B\)</span> for some <span class="math inline">\(\lambda \in (0,1)\)</span>, and invoking Lemma <a href="sdp.html#lem:PSDRange">2.3</a>, we have
<span class="math display">\[\begin{equation}
\begin{split}
\mathrm{Range}(X) &amp; = \mathrm{Range}(\lambda A + (1-\lambda) B) \supseteq \mathrm{Range}(\lambda A) = \mathrm{Range}(A) \\
\mathrm{Range}(X) &amp; = \mathrm{Range}(\lambda A + (1-\lambda) B) \supseteq \mathrm{Range}((1-\lambda) B) = \mathrm{Range}(B).
\end{split}
\end{equation}\]</span>
Since <span class="math inline">\(\mathrm{Range}(X) \subseteq L\)</span> due to <span class="math inline">\(X \in F\)</span>, we have
<span class="math display">\[
\mathrm{Range}(A) \subseteq L, \quad \mathrm{Range}(B) \subseteq L,
\]</span>
leading to <span class="math inline">\(A,B \in F\)</span>.</p>
<p>The proof for the “<strong>Only If</strong>” direction can be found in Theorem 3.7.1 of <span class="citation">(<a href="#ref-wolkowicz12book-sdp" role="doc-biblioref">Wolkowicz, Saigal, and Vandenberghe 2000</a>)</span>.</p>
</div>
</div>
</div>
</div>
<div id="semidefinite-programming" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Semidefinite Programming<a href="sdp.html#semidefinite-programming" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="spectrahedra" class="section level3 hasAnchor" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Spectrahedra<a href="sdp.html#spectrahedra" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall the definition of a polyhedron in <a href="background.html#eq:polyhedron">(1.12)</a>, i.e., a vector <span class="math inline">\(x\)</span> constrained by finitely many linear inequalities. The feasible set of a Linear Program is a polyhedron.</p>
<p>Similarly, we define a <strong>spectrahedron</strong> as a set defined by finitely many <strong>linear matrix inequalities</strong> (LMIs). Spectrahedra are the feasible sets of Semidefinite Programs (SDPs).</p>
<p>A linear matrix inequality has the form
<span class="math display">\[
A_0 + \sum_{i=1}^m A_i x_i \succeq 0,
\]</span>
where <span class="math inline">\(A_i \in \mathbb{S}^{n},i=0,\dots,m\)</span> are given symmetric matrices. Correspondingly, a spectrahedron is defined by finitely many LMIs.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:Spectrahedron" class="definition"><strong>Definition 2.1  (Spectrahedron) </strong></span>A set <span class="math inline">\(S \subseteq \mathbb{R}^{m}\)</span> is a spectrahedron if it has the form
<span class="math display">\[
S =  \left\{ x \in \mathbb{R}^{m} \ \middle\vert\ A_0 + \sum_{i=1}^m x_i A_i \succeq 0 \right\} ,
\]</span>
for given symmetric matrices <span class="math inline">\(A_0,A_1,\dots,A_m \in \mathbb{S}^{n}\)</span>.</p>
</div>
</div>
<p>Note that there is no less of generality in defining a spectrahedron using a single LMI. For example, in the case of a set defined by two LMIs:
<span class="math display">\[
S =  \left\{ x \in \mathbb{R}^{m} \ \middle\vert\ A_0 + \sum_{i=1}^m x_i A_i \succeq 0, B_0 + \sum_{i=1}^m x_i B_i \succeq 0  \right\} , A_i \in \mathbb{S}^{n}, B_i \in \mathbb{S}^{d},
\]</span>
we can compress the two LMIs into a single LMI by putting <span class="math inline">\(A_i\)</span> and <span class="math inline">\(B_i\)</span> along the diagonal:
<span class="math display">\[
S =  \left\{ x \in \mathbb{R}^{m} \ \middle\vert\ \begin{bmatrix} A_0 &amp; \\ &amp; B_0 \end{bmatrix} + \sum_{i=1}^m x_i \begin{bmatrix} A_i &amp; \\ &amp; B_i \end{bmatrix} \succeq 0  \right\} .
\]</span></p>
<p>Leveraging (5) of Lemma <a href="sdp.html#lem:PositiveSemidefinite">2.1</a>, we know that a PSD constraint is equivalent to weakly alternating signs of the characteristic polynomial of the given matrix. Therefore, a spectrahedron is defined by finitely many polynomial inequalities, i.e., a spectrahedron is a (convex) <strong>basic semialgebraic set</strong>, as seen in the following example <span class="citation">(<a href="#ref-blekherman12book-semidefinite" role="doc-biblioref">Blekherman, Parrilo, and Thomas 2012</a>)</span>.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:EllipticCurve" class="example"><strong>Example 2.1  (Elliptic Curve) </strong></span>Consider the spectrahedron in <span class="math inline">\(\mathbb{R}^{2}\)</span> defined by
<span class="math display">\[
\left\{ (x,y) \in \mathbb{R}^{2} \ \middle\vert\ A(x,y) = \begin{bmatrix} x+1 &amp; 0 &amp; y \\ 0 &amp; 2 &amp; -x-1 \\ y &amp; -x-1 &amp; 2 \end{bmatrix} \succeq 0  \right\} .
\]</span>
To obtain scalar inequalities defining the set, let
<span class="math display">\[
p_A(\lambda) = \det (\lambda I - A(x,y)) = \lambda^3 + p_2 \lambda^2 + p_1 \lambda + p_0
\]</span>
be the characteristic polynomial of <span class="math inline">\(A(x,y)\)</span>. <span class="math inline">\(A(x,y) \succeq 0\)</span> is then equivalent to the coefficients weakly alternating in sign:
<span class="math display">\[\begin{equation}
\begin{split}
p_2 &amp; = -(x+5) \leq 0, \\
p_1 &amp; = -x^2 + 2x - y^2 + 7 \geq 0, \\
p_0 &amp; = -(3+ x -x^3 -3x^2 - 2y^2) \leq 0.
\end{split}
\end{equation}\]</span>
We can use the following Matlab script to plot the set shown in Fig. <a href="sdp.html#fig:EllipticCurve">2.2</a>. (The code is also available at <a href="https://github.com/ComputationalRobotics/Semidefinite-Examples">here</a>.) As we can see, the spectrahedron is convex, but it is not a polyhedron.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span id="cb1-1"><a href="sdp.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="va">x</span> <span class="op">=</span> <span class="op">-</span><span class="fl">2</span><span class="op">:</span><span class="fl">0.01</span><span class="op">:</span><span class="fl">2</span><span class="op">;</span> </span>
<span id="cb1-2"><a href="sdp.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="va">y</span> <span class="op">=</span> <span class="op">-</span><span class="fl">2</span><span class="op">:</span><span class="fl">0.01</span><span class="op">:</span><span class="fl">2</span><span class="op">;</span> </span>
<span id="cb1-3"><a href="sdp.html#cb1-3" aria-hidden="true" tabindex="-1"></a>[<span class="va">X</span><span class="op">,</span><span class="va">Y</span>] <span class="op">=</span> <span class="va">meshgrid</span>(<span class="va">x</span><span class="op">,</span><span class="va">y</span>)<span class="op">;</span></span>
<span id="cb1-4"><a href="sdp.html#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="sdp.html#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="va">ineq</span> <span class="op">=</span> (<span class="op">-</span><span class="va">X</span> <span class="op">-</span> <span class="fl">5</span> <span class="op">&lt;=</span> <span class="fl">0</span>) <span class="op">&amp;</span> <span class="op">...</span></span>
<span id="cb1-6"><a href="sdp.html#cb1-6" aria-hidden="true" tabindex="-1"></a>    (<span class="op">-</span><span class="va">X</span><span class="op">.^</span><span class="fl">2</span> <span class="op">+</span> <span class="fl">2</span><span class="op">*</span><span class="va">X</span> <span class="op">-</span> <span class="va">Y</span><span class="op">.^</span><span class="fl">2</span> <span class="op">+</span> <span class="fl">7</span> <span class="op">&gt;=</span><span class="fl">0</span>) <span class="op">&amp;</span> <span class="op">...</span></span>
<span id="cb1-7"><a href="sdp.html#cb1-7" aria-hidden="true" tabindex="-1"></a>    (<span class="fl">3</span> <span class="op">+</span> <span class="va">X</span> <span class="op">-</span> <span class="va">X</span><span class="op">.^</span><span class="fl">3</span> <span class="op">-</span> <span class="fl">3</span><span class="op">*</span><span class="va">X</span><span class="op">.^</span><span class="fl">2</span> <span class="op">-</span> <span class="fl">2</span><span class="op">*</span><span class="va">Y</span><span class="op">.^</span><span class="fl">2</span> <span class="op">&gt;=</span> <span class="fl">0</span>)<span class="op">;</span></span>
<span id="cb1-8"><a href="sdp.html#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="sdp.html#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="va">h</span> <span class="op">=</span> <span class="va">pcolor</span>(<span class="va">X</span><span class="op">,</span><span class="va">Y</span><span class="op">,</span><span class="va">double</span>(<span class="va">ineq</span>)) <span class="op">;</span></span>
<span id="cb1-10"><a href="sdp.html#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="va">h</span>.<span class="va">EdgeColor</span> <span class="op">=</span> <span class="ss">&#39;none&#39;</span> <span class="op">;</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:EllipticCurve"></span>
<img src="images/elliptic_curve.png" alt="Elliptic Curve." width="60%" />
<p class="caption">
Figure 2.2: Elliptic Curve.
</p>
</div>
</div>
</div>
<p>We can use the same technique to visualize the elliptope, a spectrahedron that we will see again later when we study the MAXCUT problem.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:Elliptope" class="example"><strong>Example 2.2  (Elliptope) </strong></span>Consider the 3D elliptope defined by
<span class="math display">\[
\left\{ (x,y,z) \in \mathbb{R}^{3} \ \middle\vert\ A(x,y,z) = \begin{bmatrix} 1 &amp; x &amp; y \\ x &amp; 1 &amp; z \\ y &amp; z &amp; 1 \end{bmatrix} \succeq 0 \right\} .
\]</span>
The characteristic polynomial of <span class="math inline">\(A(x,y,z)\)</span> is
<span class="math display">\[
p_A(\lambda) = \lambda^3 - 3 \lambda^2 + (-x^2 - y^2 - z^2 + 3) \lambda + x^2 - 2 xyz + y^2 + z^2 -1.
\]</span>
The coefficients need to weakly alternative in sign, we have the inequalities
<span class="math display">\[\begin{equation}
\begin{split}
-x^2 - y^2 - z^2 + 3 &amp; \geq 0 \\
x^2 - 2 xyz + y^2 + z^2 -1 &amp; \leq 0
\end{split}
\end{equation}\]</span></p>
<p>Using the Matlab script <a href="https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/elliptope.m">here</a>, we generate the following plot.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Elliptope"></span>
<img src="images/elliptope.png" alt="Elliptope." width="80%" />
<p class="caption">
Figure 2.3: Elliptope.
</p>
</div>
</div>
</div>
<p>Another example is provided in Fig. <a href="sdp.html#fig:SpectrahedronStride">2.1</a>.</p>
</div>
<div id="formulation-and-duality" class="section level3 hasAnchor" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Formulation and Duality<a href="sdp.html#formulation-and-duality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Semidefinite programs (SDPs) are linear optimization problems over spectrahedra. A standard SDP in <strong>primal</strong> form is written as
<span class="math display" id="eq:SDP-P">\[\begin{equation}
\boxed{
\begin{split}
p^\star = \min_{X \in \mathbb{S}^{n}} &amp; \quad \langle C, X \rangle \\
\mathrm{s.t.}&amp; \quad \mathcal{A}(X) = b, \\
&amp; \quad X \succeq 0
\end{split}
}
\tag{2.5}
\end{equation}\]</span>
where <span class="math inline">\(C \in \mathbb{S}^{n}\)</span>, <span class="math inline">\(b \in \mathbb{R}^{m}\)</span>, and the linear map <span class="math inline">\(\mathcal{A}: \mathbb{S}^{n} \rightarrow \mathbb{R}^{m}\)</span> is defined as
<span class="math display">\[
\mathcal{A}(X) := \begin{bmatrix} \langle A_1, X \rangle \\
\vdots \\ \langle A_i, X \rangle \\ \langle A_m, X \rangle \end{bmatrix}.
\]</span>
Recall that <span class="math inline">\(\langle C, X \rangle = \mathrm{tr}(CX)\)</span>. The feasible set of <a href="sdp.html#eq:SDP-P">(2.5)</a> is the intersection of the PSD cone (<span class="math inline">\(\mathbb{S}^{n}_{+}\)</span>) and the affine subspace defined by <span class="math inline">\(\mathcal{A}(X) = b\)</span>.</p>
<p>Closely related to the primal SDP <a href="sdp.html#eq:SDP-P">(2.5)</a> is the <strong>dual</strong> problem
<span class="math display" id="eq:SDP-D">\[\begin{equation}
\boxed{
\begin{split}
d^\star = \max_{y \in \mathbb{R}^{m}} &amp; \quad \langle b, y \rangle \\
\mathrm{s.t.}&amp; \quad C - \mathcal{A}^* (y) \succeq 0
\end{split}
}
\tag{2.6}
\end{equation}\]</span>
where <span class="math inline">\(\mathcal{A}^{*}: \mathbb{R}^{m} \rightarrow \mathbb{S}^{n}\)</span> is the <strong>adjoint</strong> map defined as
<span class="math display">\[
\mathcal{A}^*(y) := \sum_{i=1}^m y_i A_i.
\]</span>
Observe how the primal-dual SDP pair <a href="sdp.html#eq:SDP-P">(2.5)</a>-<a href="sdp.html#eq:SDP-D">(2.6)</a> parallels the primal-dual LP pair <a href="background.html#eq:primal-lp">(1.15)</a>-<a href="background.html#eq:dual-lp">(1.16)</a>.</p>
<p><strong>Weak duality</strong>. We have a similar weak duality between the primal and dual. Pick any <span class="math inline">\(X\)</span> that is feasible for the primal <a href="sdp.html#eq:SDP-P">(2.5)</a> and <span class="math inline">\(y\)</span> that is feasible for the dual <a href="sdp.html#eq:SDP-D">(2.6)</a>, we have
<span class="math display">\[
\boxed{\langle C, X \rangle - \langle b, y \rangle = \langle C, X \rangle - \langle \mathcal{A}(X), y \rangle = \langle C - \mathcal{A}^* (y), X \rangle \geq 0,}
\]</span>
where the last inequality holds because both <span class="math inline">\(C - \mathcal{A}^*(y)\)</span> and <span class="math inline">\(X\)</span> are positive semidefinite. As a result, we have the weak duality
<span class="math display">\[
d^\star \leq p^\star.
\]</span></p>
<p>Similar to the LP case, we will denote <span class="math inline">\(p^\star = +\infty\)</span> if the primal is infeasible, <span class="math inline">\(p^\star = - \infty\)</span> if the primal is unbounded below. We will denote <span class="math inline">\(d^\star = +\infty\)</span> if the dual is unbounded above, and <span class="math inline">\(d^\star = -\infty\)</span> if the dual is infeasible. We say the primal (or the dual) is <strong>solvable</strong> if it admits optimizers. We denote <span class="math inline">\(p^\star - d^\star\)</span> as the <strong>duality gap</strong>.</p>
<p>Recall Theorem <a href="background.html#thm:LPStrongDuality">1.9</a> states that in LP, if at least one of the primal and dual is feasible, then strong duality holds (i.e., <span class="math inline">\(p^\star = d^\star = \{\pm \infty, \text{finite} \}\)</span>). Unfortunately, this does not carry over to SDPs. Let us provide several examples.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:FailureSDPDuality" class="example"><strong>Example 2.3  (Failure of SDP Strong Duality) </strong></span>The first example, from <span class="citation">(<a href="#ref-ramana97mp-exact" role="doc-biblioref">Ramana 1997</a>)</span>, shows that even if both primal and dual are feasible, there could exist a nonzero duality gap. Consider the following SDP pair for some <span class="math inline">\(\alpha \geq 0\)</span>
<span class="math display">\[
\begin{cases}
\min_{X \in \mathbb{S}^{3}} &amp; \alpha X_{11} \\
\mathrm{s.t.}&amp; X_{22} = 0 \\
&amp; X_{11} + 2 X_{23} = 1 \\
&amp; \begin{bmatrix} X_{11} &amp; X_{12} &amp; X_{13} \\
* &amp; X_{22} &amp; X_{23} \\
* &amp; * &amp; X_{33} \end{bmatrix} \succeq 0
\end{cases},
\begin{cases}
\max_{y \in \mathbb{R}^{2}} &amp; y_2 \\
\mathrm{s.t.}&amp; \begin{bmatrix} \alpha &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{bmatrix} \succeq \begin{bmatrix} y_2 &amp; 0 &amp; 0 \\ 0 &amp; y_1 &amp; y_2 \\ 0 &amp; y_2 &amp; 0 \end{bmatrix}
\end{cases}
\]</span>
To examine the primal feasible set, let us pick the bottom-right <span class="math inline">\(2\times 2\)</span> submatrix of <span class="math inline">\(X\)</span>. The determinant of this submatrix needs to be nonnegative (due to (4) of Lemma <a href="sdp.html#lem:PositiveSemidefinite">2.1</a>):
<span class="math display">\[
X_{22} X_{33} - X_{23}^2 \geq 0.
\]</span>
Because <span class="math inline">\(X_{22} = 0\)</span>, we have <span class="math inline">\(X_{23} = 0\)</span> and hence <span class="math inline">\(X_{11} = 1\)</span>. Therefore, <span class="math inline">\(p^\star = \alpha\)</span> is attained.</p>
<p>To examine the dual feasible set, pick the bottom-right <span class="math inline">\(2 \times 2\)</span> submatrix of
<span class="math display">\[
\begin{bmatrix} \alpha - y_2 &amp; 0 &amp; 0 \\ 0 &amp; - y_1 &amp; -y_2 \\ 0 &amp; -y_2 &amp; 0 \end{bmatrix} \succeq 0,
\]</span>
we have <span class="math inline">\(y_2 = 0\)</span>. As a result, <span class="math inline">\(d^\star = 0\)</span>, and strong duality fails.</p>
<p>The second example, from <span class="citation">(<a href="#ref-todd01an-semidefinite" role="doc-biblioref">Todd 2001</a>)</span>, shows that the duality gap can even be infinite. Consider the primal-dual SDP
<span class="math display">\[
\begin{cases}
\min_{X \in \mathbb{S}^{2}} &amp; 0 \\
\mathrm{s.t.}&amp; X_{11} = 0 \\
&amp; X_{12} = 1 \\
&amp; \begin{bmatrix} X_{11} &amp; X_{12} \\ * &amp; X_{22} \end{bmatrix} \succeq 0
\end{cases},
\begin{cases}
\max_{y \in \mathbb{R}^{2}} &amp; 2 y_2 \\
\mathrm{s.t.}&amp; \begin{bmatrix} - y_1 &amp; - y_2 \\ - y_2 &amp; 0 \end{bmatrix} \succeq 0
\end{cases}
\]</span>
Clearly, the primal is infeasible because
<span class="math display">\[
\begin{bmatrix} 0 &amp; 1 \\ 1 &amp; X_{22} \end{bmatrix}
\]</span>
can never be PSD. So <span class="math inline">\(p^\star = + \infty\)</span>. The dual problem, however, is feasible. From the PSD constraint we have <span class="math inline">\(y_2 = 0\)</span> and <span class="math inline">\(d^\star = 0\)</span>. Therefore, the duality gap is infinite.</p>
<p>The third example, from <span class="citation">(<a href="#ref-todd01an-semidefinite" role="doc-biblioref">Todd 2001</a>)</span>, shows that even when the duality gap is zero, the primal or dual problem may not admit optimizers. Consider the primal-dual SDP
<span class="math display">\[
\begin{cases}
\min_{X \in \mathbb{S}^{2}} &amp; 2 X_{12} \\
\mathrm{s.t.}&amp; - X_{11} = -1 \\
&amp; - X_{22} = 0 \\
&amp; \begin{bmatrix} X_{11} &amp; X_{12} \\ * &amp; X_{22} \end{bmatrix} \succeq 0
\end{cases},
\begin{cases}
\max_{y \in \mathbb{R}^{2}} &amp; - y_1 \\
\mathrm{s.t.}&amp; \begin{bmatrix} y_1 &amp; 1 \\ 1 &amp; y_2 \end{bmatrix} \succeq 0
\end{cases}
\]</span>
To examine the primal feasible set, we have
<span class="math display">\[
\begin{bmatrix} 1 &amp; X_{12} \\ X_{12} &amp; 0 \end{bmatrix} \succeq 0
\]</span>
implies <span class="math inline">\(X_{12} = 0\)</span>. Hence the primal feasible set only has one point and <span class="math inline">\(p^\star = 0\)</span>. The dual feasible set reads
<span class="math display">\[
y_1 y_2 \geq 1,\quad  y_1 \geq 0, \quad y_2 \geq 0,
\]</span>
and we want to minimize <span class="math inline">\(y_1\)</span>. Clearly, <span class="math inline">\(d^\star = 0\)</span> but it is not attainable. Therefore, strong duality holds but the dual problem is not solvable.</p>
<p>A Matlab script that passes these three examples to SDP solvers can be found <a href="https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/failure_strong_duality.m">here</a>.</p>
</div>
</div>
<p>The examples above are somewhat “pathological” and they show that SDPs in general can be more complicated that LPs. It turns out, with the addition of <strong>Slater’s condition</strong>, i.e., <strong>strict feasibility</strong> of the primal and dual, we can recover nice results parallel to those of LP.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:SDPStrongDuality" class="theorem"><strong>Theorem 2.2  (SDP Strong Duality) </strong></span>Assume both the primal SDP <a href="sdp.html#eq:SDP-P">(2.5)</a> and the dual SDP <a href="sdp.html#eq:SDP-D">(2.6)</a> are <em>strictly feasible</em>, i.e., there exists <span class="math inline">\(X \succ 0\)</span> such that <span class="math inline">\(\mathcal{A}(X)=b\)</span> for the primal and there exists <span class="math inline">\(y \in \mathbb{R}^{m}\)</span> such that <span class="math inline">\(C - \mathcal{A}^* (y) \succ 0\)</span> for the dual, then strong duality holds, i.e., both problems are solvable and admit optimizers, and <span class="math inline">\(p^\star = d^\star\)</span> equals to some finite number.</p>
<p>Further, a pair of primal-dual feasible points <span class="math inline">\((X,y)\)</span> is optimal if and only if
<span class="math display">\[
\langle C, X \rangle = \langle b, y \rangle \Leftrightarrow \langle C - \mathcal{A}^* (y), X \rangle = 0 \Leftrightarrow (C - \mathcal{A}^* (y)) X = 0.
\]</span></p>
</div>
</div>
<p>One can relax the requirement of both primal and dual being strictly feasible to only one of them being strictly feasible, and similar results would hold. Precisely, if the primal is bounded below and strictly feasible, then <span class="math inline">\(p^\star = d^\star\)</span> and the dual is solvable. If the dual is bounded above and strictly feasible, then <span class="math inline">\(p^\star = d^\star\)</span> and the primal is solvable <span class="citation">(<a href="#ref-nie23book-moment" role="doc-biblioref">Nie 2023</a>)</span>.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:SuccessSDPDuality" class="example"><strong>Example 2.4  (SDP Strong Duality) </strong></span>Consider the following primal-dual SDP pair
<span class="math display">\[
\begin{cases}
\min_{X \in \mathbb{S}^{2}} &amp; 2 X_{11} + 2 X_{12} \\
\mathrm{s.t.}&amp; X_{11} + X_{22} = 1 \\
&amp; \begin{bmatrix} X_{11} &amp; X_{12} \\ * &amp; X_{22} \end{bmatrix} \succeq 0
\end{cases},
\begin{cases}
\max_{y \in \mathbb{R}^{}} &amp; y \\
\mathrm{s.t.}&amp; \begin{bmatrix} 2 - y &amp; 1 \\ 1 &amp; - y \end{bmatrix} \succeq 0
\end{cases}
\]</span>
Choose
<span class="math display">\[
X = \begin{bmatrix} 0.5 &amp; 0 \\ 0 &amp; 0.5 \end{bmatrix} \succ 0
\]</span>
we see the primal is strictly feasible.
Choose <span class="math inline">\(y = -1\)</span>, we have
<span class="math display">\[
\begin{bmatrix} 3 &amp; 1 \\ 1 &amp; 1 \end{bmatrix} \succ 0
\]</span>
and the dual is strictly feasible. Therefore, strong duality holds.</p>
<p>In this case, pick the pair of primal-dual feasible points
<span class="math display">\[
X^\star = \begin{bmatrix} \frac{2 - \sqrt{2}}{4} &amp; - \frac{1}{2 \sqrt{2}} \\ - \frac{1}{2 \sqrt{2}} &amp; \frac{2 + \sqrt{2}}{4} \end{bmatrix}, \quad y^\star = 1 - \sqrt{2},
\]</span>
we have
<span class="math display">\[
\langle C, X^\star \rangle = 1-\sqrt{2} = \langle b, y^\star \rangle,
\]</span>
and both <span class="math inline">\(X^\star\)</span> and <span class="math inline">\(y^\star\)</span> are optimal.</p>
</div>
</div>
</div>
<div id="geometric-properties-1" class="section level3 hasAnchor" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Geometric Properties<a href="sdp.html#geometric-properties-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
</div>
<div id="software-for-conic-optimization" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Software for Conic Optimization<a href="sdp.html#software-for-conic-optimization" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Linear optimization over the nonnegative orthant (<span class="math inline">\(\mathbb{R}^{n}_{+}\)</span>), the second-order cone (<span class="math inline">\(\mathcal{Q}_{n}\)</span>), and the positive semidefinite cone (<span class="math inline">\(\mathbb{S}^{n}_{+}\)</span>) forms the foundation of modern convex optimization, commonly referred to as conic optimization. These three types of cones are self-dual, and there exist efficient algorithms to solve the convex optimization problems. Popular solvers include SDPT3, SeDuMi, MOSEK, and SDPNAL+.</p>
<p>In this section, we introduce how we should “talk to” the numerical solvers for conic optimization, i.e., how should we pass a mathematically written conic optimization to a numerical solver. Note that in many cases, this “transcription” can be done by programming packages such as CVX, CVXPY, YALMIP etc., but I think it is important to understand the standard interface of numerical solvers because (i) it reinforces our understanding of the mathematical basics, (ii) it gets us closer to designing custom numerical solvers for specific problems, (iii) if you are a heavy convex optimization user you will realize that many of the programming packages are not “efficient” in transcribing the original optimization problem (but they are indeed very general). I have had cases where solving the conic optimization takes a few minutes but transcribing the problem to the solver takes half an hour.</p>
<p>We will use the SeDuMi format as an example. Consider the following general linear convex optimization problem
<span class="math display" id="eq:general-convex-sedumi">\[\begin{equation}
\begin{split}
\max_{y \in \mathbb{R}^{m}} &amp; \quad b^\top y \\
\mathrm{s.t.}&amp; \quad Fy = g \\
&amp; \quad f \geq Gy \\
&amp; \quad h_i^\top y + \tau_i \geq \Vert H_i y + p_i \Vert_2, i=1,\dots,r \\
&amp; \quad B_{j,0} + \sum_{k=1}^m y_k B_{j,k} \succeq 0, j=1,\dots,s,
\end{split}
\tag{2.7}
\end{equation}\]</span>
for given matrices and vectors
<span class="math display">\[
F \in \mathbb{R}^{\ell_1 \times m},G \in \mathbb{R}^{\ell_2 \times m},H_i \in \mathbb{R}^{l_i \times m}, B_{j,k} \in \mathbb{S}^{n_j}, h_i \in \mathbb{R}^{m}, p_i \in \mathbb{R}^{l_i}, \tau_i \in \mathbb{R}^{}, g \in \mathbb{R}^{\ell_1},f \in \mathbb{R}^{\ell_2}.
\]</span>
Define the linear function
<span class="math display">\[
\phi(y):= \left(Fy, Gy, \begin{bmatrix} - h_1^\top y \\ - H_1 y \end{bmatrix}, \dots, \begin{bmatrix} - h_r^\top y \\ - H_r y \end{bmatrix}, - \sum_{k=1}^m y_k B_{1,k}, \dots,- \sum_{k=1}^m y_k B_{s,k} \right),
\]</span>
which is a linear map from <span class="math inline">\(\mathbb{R}^{m}\)</span> to the vector space of Cartesian products
<span class="math display">\[
V:= \mathbb{R}^{\ell_1} \times \mathbb{R}^{\ell_2} \times \mathbb{R}^{l_1+1} \times \dots \times \mathbb{R}^{l_r + 1} \times \mathbb{S}^{n_1}\times \dots \times \mathbb{S}^{n_s}.
\]</span>
A vector <span class="math inline">\(X \in V\)</span> can be written as a tuple
<span class="math display">\[
X = (x_1,x_2,\mathrm{x}_1,\dots,\mathrm{x}_r,X_1,\dots,X_s).
\]</span>
Given another vector <span class="math inline">\(Y \in V\)</span>
<span class="math display">\[
X = (y_1,y_2,\mathrm{y}_1,\dots,\mathrm{y}_r,Y_1,\dots,Y_s),
\]</span>
the inner product between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is defined as
<span class="math display">\[
\langle X, Y \rangle = \langle x_1, y_2 \rangle + \langle x_2, y_2 \rangle + \sum_{i=1}^r \langle \mathrm{x}_i, \mathrm{y}_i \rangle + \sum_{j=1}^s \langle X_j, Y_j \rangle.
\]</span></p>
<p>Let <span class="math inline">\(\mathcal{K}\)</span> be the Cartesian product of the free cone, the nonnegative orthant, the second-order cone, and the PSD cone
<span class="math display">\[
\mathcal{K}:= \mathbb{R}^{\ell_1} \times \mathbb{R}^{\ell_2}_{+} \times \mathcal{Q}_{l_1} \times \dots \times \mathcal{Q}_{l_r} \times \mathbb{S}^{n_1}_{+} \times \dots \times \mathbb{S}^{n_s}_{+}.
\]</span>
Its dual cone is
<span class="math display">\[
\mathcal{K}^* = \{0\}^{\ell_1} \times \times \mathbb{R}^{\ell_2}_{+} \times \mathcal{Q}_{l_1} \times \dots \times \mathcal{Q}_{l_r} \times \mathbb{S}^{n_1}_{+} \times \dots \times \mathbb{S}^{n_s}_{+}.
\]</span>
Note that all the cones there are self-dual except the free cone whose dual is the zero point. Then denote
<span class="math display">\[
C := \left( g,f,\begin{bmatrix} \tau_1 \\ p_1 \end{bmatrix},\dots,\begin{bmatrix} \tau_r \\ p_r \end{bmatrix},B_{1,0},\dots,B_{s,0} \right) \in V,
\]</span>
we have that the original optimization <a href="sdp.html#eq:general-convex-sedumi">(2.7)</a> is simply the following dual conic problem
<span class="math display" id="eq:dual-conic">\[\begin{equation}
\max_{y \in \mathbb{R}^{m}} \{ b^\top y \mid C - \phi(y) \in \mathcal{K}^* \}.
\tag{2.8}
\end{equation}\]</span>
The linear map <span class="math inline">\(\phi(y)\)</span> can be written as
<span class="math display">\[
\phi(y) = y_1 A_1 + \dots, y_m A_m
\]</span>
for vectors <span class="math inline">\(A_1,\dots,A_m\)</span> in the space <span class="math inline">\(V\)</span>. Therefore, the primal problem to <a href="sdp.html#eq:dual-conic">(2.8)</a> is
<span class="math display" id="eq:primal-conic">\[\begin{equation}
\min_{X \in V} \{ \langle C, X \rangle \mid \langle A_i, X \rangle=b_i,i=1,\dots,m,X \in \mathcal{K} \}.
\tag{2.9}
\end{equation}\]</span></p>
<p>Let us practice an example from <span class="citation">(<a href="#ref-nie23book-moment" role="doc-biblioref">Nie 2023</a>)</span>.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:SeDuMiExample" class="example"><strong>Example 2.5  (SeDuMi Example) </strong></span>Consider the following optimization problem as an instance of <a href="sdp.html#eq:general-convex-sedumi">(2.7)</a>:
<span class="math display" id="eq:sedumi-example">\[\begin{equation}
\begin{split}
\max_{y \in \mathbb{R}^{3}} &amp; \quad y_3 - y_1 \\
\mathrm{s.t.}&amp; \quad y_1 + y_2 + y_3 = 3\\
&amp; \quad -1 \geq -y_1 - y_2 \\
&amp; \quad -1 \geq -y_2 - y_3 \\
&amp; \quad y_1 + y_3 \geq \sqrt{(y_1-1)^2 + y_2^2 + (y_3 -1)^2} \\
&amp; \quad \begin{bmatrix} 1 &amp; y_1 &amp; y_2 \\ y_1 &amp; 2 &amp; y_3 \\ y_2 &amp; y_3 &amp; 3 \end{bmatrix} \succeq 0
\end{split}
\tag{2.10}
\end{equation}\]</span>
Clearly we have <span class="math inline">\(b = (-1,0,1)\)</span>. The linear map <span class="math inline">\(\phi(y)\)</span> is
<span class="math display">\[
\phi(y) = \left( y_1+y_2+y_3,\begin{bmatrix} -y_1 - y_2 \\ - y_2 - y_3 \end{bmatrix}, \begin{bmatrix} - y_1 - y_3 \\ -y_1 \\ -y_2 \\ -y_3 \end{bmatrix}, \begin{bmatrix} 0 &amp; -y_1 &amp; -y_2 \\ -y_1 &amp; 0 &amp; -y_3 \\ -y_2 &amp; -y_3 &amp; 0 \end{bmatrix} \right).
\]</span>
The vector space <span class="math inline">\(V=\mathbb{R}^{} \times \mathbb{R}^{2} \times \mathbb{R}^{4} \times \mathbb{S}^{3}\)</span>, and the cone <span class="math inline">\(\mathcal{K}\)</span> is
<span class="math display">\[
\mathcal{K}= \mathbb{R}^{} \times \mathbb{R}^{2}_{+} \times \mathcal{Q}_3 \times \mathbb{S}^{3}_{+}.
\]</span>
The vectors <span class="math inline">\(A_1,A_2,A_3\)</span> are
<span class="math display">\[\begin{equation}
\begin{split}
A_1 &amp;= \left( 1,\begin{bmatrix}-1\\0\end{bmatrix}, \begin{bmatrix}-1\\-1\\0\\0\end{bmatrix},\begin{bmatrix}0&amp;-1&amp;0\\-1&amp;0&amp;0\\0&amp;0&amp;0\end{bmatrix} \right)\\
A_2 &amp;= \left( 1,\begin{bmatrix}-1\\-1\end{bmatrix}, \begin{bmatrix}0\\0\\-1\\0\end{bmatrix},\begin{bmatrix}0&amp;0&amp;-1\\0&amp;0&amp;0\\-1&amp;0&amp;0\end{bmatrix} \right)\\
A_3 &amp;= \left( 1,\begin{bmatrix}0\\-1\end{bmatrix}, \begin{bmatrix}-1\\0\\0\\-1\end{bmatrix},\begin{bmatrix}0&amp;0&amp;0\\0&amp;0&amp;-1\\0&amp;-1&amp;0\end{bmatrix} \right).
\end{split}
\end{equation}\]</span>
The vector <span class="math inline">\(C\)</span> is
<span class="math display">\[
C = \left( 3,\begin{bmatrix}-1\\-1\end{bmatrix}, \begin{bmatrix}0\\-1\\0\\-1\end{bmatrix},\begin{bmatrix}1&amp;0&amp;0\\0&amp;2&amp;0\\0&amp;0&amp;3\end{bmatrix} \right).
\]</span></p>
<p>To input this problem to SeDuMi, we only need to provide the data <span class="math inline">\((A,b,C)\)</span> together with the description of the cones <span class="math inline">\(\mathcal{K}\)</span>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span id="cb2-1"><a href="sdp.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">% describe dimensions of the cones</span></span>
<span id="cb2-2"><a href="sdp.html#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="va">K</span>.<span class="va">f</span> <span class="op">=</span> <span class="fl">1</span><span class="op">;</span> <span class="co">% free cone</span></span>
<span id="cb2-3"><a href="sdp.html#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="va">K</span>.<span class="va">l</span> <span class="op">=</span> <span class="fl">2</span><span class="op">;</span> <span class="co">% nonnegative orthant</span></span>
<span id="cb2-4"><a href="sdp.html#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="va">K</span>.<span class="va">q</span> <span class="op">=</span> <span class="fl">4</span><span class="op">;</span> <span class="co">% second order cone</span></span>
<span id="cb2-5"><a href="sdp.html#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="va">K</span>.<span class="va">s</span> <span class="op">=</span> <span class="fl">3</span><span class="op">;</span> <span class="co">% psd cone</span></span>
<span id="cb2-6"><a href="sdp.html#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="sdp.html#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">% provide A,b,c</span></span>
<span id="cb2-8"><a href="sdp.html#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="va">c</span> <span class="op">=</span> [<span class="fl">3</span><span class="op">,-</span><span class="fl">1</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">2</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">3</span>]<span class="op">;</span></span>
<span id="cb2-9"><a href="sdp.html#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="va">b</span> <span class="op">=</span> [<span class="op">-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">1</span>]<span class="op">;</span></span>
<span id="cb2-10"><a href="sdp.html#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="va">A</span> <span class="op">=</span> [</span>
<span id="cb2-11"><a href="sdp.html#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="fl">1</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,-</span><span class="fl">1</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">;</span></span>
<span id="cb2-12"><a href="sdp.html#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="fl">1</span><span class="op">,-</span><span class="fl">1</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">;</span></span>
<span id="cb2-13"><a href="sdp.html#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,-</span><span class="fl">1</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,</span><span class="fl">0</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span><span class="op">,-</span><span class="fl">1</span><span class="op">,</span><span class="fl">0</span></span>
<span id="cb2-14"><a href="sdp.html#cb2-14" aria-hidden="true" tabindex="-1"></a>    ]<span class="op">;</span></span>
<span id="cb2-15"><a href="sdp.html#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="sdp.html#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">% solve using sedumi</span></span>
<span id="cb2-17"><a href="sdp.html#cb2-17" aria-hidden="true" tabindex="-1"></a>[<span class="va">xopt</span><span class="op">,</span><span class="va">yopt</span><span class="op">,</span><span class="va">info</span>] <span class="op">=</span> <span class="va">sedumi</span>(<span class="va">A</span><span class="op">,</span><span class="va">b</span><span class="op">,</span><span class="va">c</span><span class="op">,</span><span class="va">K</span>)<span class="op">;</span></span></code></pre></div>
<p>Note that in providing <span class="math inline">\(A\)</span>, we vectorize each <span class="math inline">\(A_i\)</span> and place it along the <span class="math inline">\(i\)</span>-th row of the matrix <span class="math inline">\(A\)</span>.
The above Matlab script gives us the optimal solution
<span class="math display">\[
y^\star = (0,1,2).
\]</span>
To run the <a href="https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/sedumi_example.m">code</a>, make sure you download <a href="https://github.com/sqlp/sedumi">SeDuMi</a> and add that to your Matlab path.</p>
</div>
</div>
</div>
<div id="interior-point-algorithm" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Interior Point Algorithm<a href="sdp.html#interior-point-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="applications" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Applications<a href="sdp.html#applications" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="lyapunov-stability" class="section level3 hasAnchor" number="2.5.1">
<h3><span class="header-section-number">2.5.1</span> Lyapunov Stability<a href="sdp.html#lyapunov-stability" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One of the earliest and most important applications of semidefinite optimization is in the context of dynamical systems and control theory. The main reason is that it is possible to characterize the dynamical properties of a system (e.g., stability, contraction) in terms of algebraic statements such as the feasibility of specific forms of inequalities. We provide a simple example in the case of Lyapunov stability for linear dynamical systems. For a comprehensive overview, see <span class="citation">(<a href="#ref-boyd94book-lmi" role="doc-biblioref">S. Boyd et al. 1994</a>)</span>.</p>
<p>Consider a discrete-time linear dynamical system
<span class="math display" id="eq:dt-linear-system">\[\begin{equation}
x_{k+1} = A x_k,\quad k=0,\dots
\tag{2.11}
\end{equation}\]</span>
where <span class="math inline">\(x \in \mathbb{R}^{n}\)</span> is called the state of the system, and <span class="math inline">\(k\)</span> indexes the time. An important property that one wants to understand about the system <a href="sdp.html#eq:dt-linear-system">(2.11)</a> is whether it is <strong>stable</strong>, i.e., given an initial state <span class="math inline">\(x_0\)</span>, does <span class="math inline">\(x_k\)</span> tend to zero as <span class="math inline">\(k\)</span> tends to infinity.</p>
<p>It is well-known that <span class="math inline">\(x_k\)</span> tends to zero for all initial conditions <span class="math inline">\(x_0\)</span> if and only if <span class="math inline">\(|\lambda_i(A)| &lt; 1, \forall i=1,\dots,n\)</span>, i.e., all the eigenvalues of the transition matrix <span class="math inline">\(A\)</span> lies inside the unit circle.</p>
<p>Equivalently, one can also <strong>certify</strong> the stability of the system if a <strong>Lyapunov function</strong>
<span class="math display" id="eq:Lyapunov-function">\[\begin{equation}
V(x_k) = x_k^\top P x_k
\tag{2.12}
\end{equation}\]</span>
is given that satisfies the following matrix inequalities.</p>
<div class="theorembox">
<div class="lemma">
<p><span id="lem:LyapunovStability" class="lemma"><strong>Lemma 2.5  (Lyapunov Stability) </strong></span>Given <span class="math inline">\(A \in \mathbb{R}^{n \times n}\)</span>, the following statements are equivalent:</p>
<ol style="list-style-type: decimal">
<li><p>All eigenvalues of <span class="math inline">\(A\)</span> lie strictly inside the unit circle, i.e., <span class="math inline">\(|\lambda_i(A)| &lt; 1, i=1,\dots,n\)</span></p></li>
<li><p>There exists a matrix <span class="math inline">\(P \in \mathbb{S}^{n}\)</span> such that
<span class="math display">\[
P \succ 0, \quad A^\top P A - P \prec 0.
\]</span></p></li>
</ol>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-11" class="proof"><em>Proof</em>. </span>2 <span class="math inline">\(\Rightarrow\)</span> 1: Let <span class="math inline">\(\lambda \in \mathbb{C}^{}\)</span> and <span class="math inline">\(v \neq 0 \in \mathbb{C}^{n}\)</span> be a pair of eigenvalue and eigenvector of <span class="math inline">\(A\)</span> such that <span class="math inline">\(A v = \lambda v\)</span>. Since <span class="math inline">\(A^\top P A - P \prec 0\)</span>, we have
<span class="math display">\[
v^* (A^\top P A - P) v &lt; 0 \Rightarrow (\lambda v)^* P (\lambda v) - v^* P v &lt; 0 \Rightarrow (|\lambda|^2 - 1) (v^* P v) &lt; 0.
\]</span>
Since <span class="math inline">\(P \succ 0\)</span>, we have <span class="math inline">\(v^* P v &gt; 0\)</span>. Hence, <span class="math inline">\(|\lambda|^2 - 1 &lt; 0\)</span> and <span class="math inline">\(|\lambda| &lt; 1\)</span>.</p>
<p>1 <span class="math inline">\(\Rightarrow\)</span> 2: Construct
<span class="math display">\[
P := \sum_{k=0}^{\infty} (A^k)^\top A^k.
\]</span>
The sum converges by the condition that <span class="math inline">\(|\lambda_i(A)| &lt; 1,\forall i\)</span> and <span class="math inline">\(P \succ 0\)</span>. Then we have
<span class="math display">\[
A^\top P A - P = \sum_{k=1}^{\infty} (A^k)^\top A^k - \sum_{k=0}^{\infty} (A^k)^\top A^k = - \mathrm{I}\prec 0,
\]</span>
proving the result.</p>
</div>
</div>
<p>Intuitively, the Lyapunov function <a href="sdp.html#eq:Lyapunov-function">(2.12)</a> defines a positive definite energy function. The fact that <span class="math inline">\(P \succ 0\)</span> implies <span class="math inline">\(V(0) = 0\)</span> and <span class="math inline">\(V(x) &gt; 0\)</span> for any <span class="math inline">\(x\)</span> that is nonzero. The condition <span class="math inline">\(A^\top P A - P \prec 0\)</span> guarantees that the system’s energy strictly decreases along any possible system trajectory. To see this, write
<span class="math display">\[
V(x_{k+1}) - V(x_k) = V(Ax_k) - V(x_k) = x_k^\top(A^\top P A - P) x_k &lt; 0, \forall x_k \neq 0.
\]</span>
Therefore, the existence of a Lyapunov function guarantees any system trajectory will converge to the origin.</p>
<p>The nice property of constructing such a Lyapunov function is that it goes beyond linear systems and can be similarly generalized to nonlinear systems, where one can compute a stability certificate from semidefinite optimization. See for example <a href="https://hankyang.seas.harvard.edu/OptimalControlEstimation/stability.html#lyapunov-analysis">this lecture notes</a>.</p>
<p><strong>Control Design</strong>. Consider now the case where <span class="math inline">\(A\)</span> is not stable, but we can use a linear <strong>feedback controller</strong> to stabilize the system, i.e.,
<span class="math display">\[
u_k = K x_k, \quad x_{k+1} = A x_k + B u_k = (A+ BK) x_k,
\]</span>
where the matrix <span class="math inline">\(K \in \mathbb{R}^{m \times n}\)</span> is the feedback law we wish to design. We wish to design <span class="math inline">\(K\)</span> using convex optimization, in particular semidefinite optimization.</p>
<p>Involving Lemma~<a href="sdp.html#lem:LyapunovStability">2.5</a>, we see that designing <span class="math inline">\(K\)</span> to stabilize <span class="math inline">\(A + BK\)</span> is equivalent to finding
<span class="math display" id="eq:control-stability">\[\begin{equation}
P \succ 0, \quad (A + BK)^\top P (A + BK) - P \prec 0.
\tag{2.13}
\end{equation}\]</span>
Using the Schur complement technique in Proposition <a href="sdp.html#prp:SchurPSD">2.1</a>, we know <a href="sdp.html#eq:control-stability">(2.13)</a> is equivalent to
<span class="math display">\[
\begin{bmatrix}
P &amp; (A + BK)^\top P \\
P(A+BK) &amp; P \end{bmatrix} \succ 0.
\]</span>
This matrix inequality is, however, not jointly convex in the unknowns <span class="math inline">\((P,A)\)</span>. To address this issue, we can pre-multiply and post-multiply the equation by <span class="math inline">\(\mathrm{BlkDiag}(P^{-1}, P^{-1})\)</span>, which leads to
<span class="math display">\[\begin{equation}
\begin{split}
\begin{bmatrix} P^{-1}&amp; \\
&amp; P^{-1}\end{bmatrix}
\begin{bmatrix}
P &amp; (A + BK)^\top P \\
P(A+BK) &amp; P \end{bmatrix}
\begin{bmatrix} P^{-1}&amp; \\
&amp; P^{-1}\end{bmatrix} \succ 0  \Leftrightarrow \\
\begin{bmatrix} P^{-1}&amp; P^{-1}(A + BK)^\top\\ (A+BK)P^{-1}&amp; P^{-1}\end{bmatrix} \succ 0.
\end{split}
\end{equation}\]</span>
Now with a change of variable <span class="math inline">\(Q:= P^{-1}\)</span>, <span class="math inline">\(Y = K P^{-1}\)</span>, we have
<span class="math display">\[
\begin{bmatrix} Q &amp; Q A^\top+ Y^\top B^\top\\
A Q + BY &amp; Q \end{bmatrix} \succ 0,
\]</span>
which is indeed a linear matrix inequality in the unknowns <span class="math inline">\((Q,Y)\)</span>. Solving the LMI, we can recover
<span class="math display">\[
P = Q^{-1}, K = Y Q^{-1}.
\]</span></p>
</div>
<div id="linear-quadratic-regulator" class="section level3 hasAnchor" number="2.5.2">
<h3><span class="header-section-number">2.5.2</span> Linear Quadratic Regulator<a href="sdp.html#linear-quadratic-regulator" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Another (somewhat surprising) application of semidefinite optimization is that it can be used to convexify the direct optimization of the linear quadratic regulator problem (one of the cornerstones in modern optimal control). In fact, such a convex formulation is the key to prove why <strong>policy optimization</strong> works in reinforcement learning, as least in the linear quadratic case <span class="citation">(<a href="#ref-hu23review-toward" role="doc-biblioref">Hu et al. 2023</a>)</span> <span class="citation">(<a href="#ref-mohammadi21tac-convergence" role="doc-biblioref">Mohammadi et al. 2021</a>)</span>.</p>
<p>Consider a continuous-time linear dynamical system
<span class="math display" id="eq:ct-linear-dynamical">\[\begin{equation}
\dot{x} = A x + B u, \quad x \in \mathbb{R}^{n}, u \in \mathbb{R}^{m}, A \in \mathbb{R}^{n \times n}, B \in \mathbb{R}^{n \times m},
\tag{2.14}
\end{equation}\]</span>
where <span class="math inline">\(x\)</span> denotes the state and <span class="math inline">\(u\)</span> denotes the control. Consider the following optimal control problem
<span class="math display" id="eq:linear-quadratic-regulator">\[\begin{equation}
\begin{split}
\min_{u(t)}  &amp; \quad \mathbb{E} \left\{  \int_{t=0}^{\infty} x(t)^\top Q x(t) + u(t)^\top R u(t) dt  \right\}  \\
\mathrm{s.t.}&amp; \quad \dot{x} = A x + Bu, \quad x(0) \sim \mathcal{N}(0,\Omega)
\end{split}
\tag{2.15}
\end{equation}\]</span>
where <span class="math inline">\(Q,R\succ 0\)</span> are known cost matrices, and <span class="math inline">\(x(0)\)</span> is supposed to satisfy the zero-mean Gaussian distribution with covariance <span class="math inline">\(\Omega \succ 0\)</span>. In the case where <span class="math inline">\(A,B,Q,R\)</span> are perfectly known to the control designer, and <span class="math inline">\((A,B)\)</span> is controllable (to be defined soon), problem <a href="sdp.html#eq:linear-quadratic-regulator">(2.15)</a> can be solved exactly and optimally, with the optimal controller being a linear feedback controller of the form
<span class="math display">\[
u(t) = -Kx(t),
\]</span>
where
<span class="math display">\[
K = R^{-1}B^\top S,
\]</span>
with <span class="math inline">\(S\)</span> the unique positive definite solution to the continuous-time <strong>algebraic Riccati equation</strong> (ARE)
<span class="math display">\[
SA + A^\top S - SBR^{-1}B^\top S + Q = 0.
\]</span></p>
<p><strong>Policy Optimization</strong>. The control and reinforcement learning community are interested in whether it is possible to directly find the optimal feedback policy <span class="math inline">\(K\)</span>, i.e., directly solving
<span class="math display" id="eq:linear-quadratic-regulator-directK">\[\begin{equation}
\begin{split}
\min_{K \in \mathcal{S}}  &amp; \quad \mathbb{E} \left\{  \int_{t=0}^{\infty} x(t)^\top Q x(t) + u(t)^\top R u(t) dt  \right\}  \\
\mathrm{s.t.}&amp; \quad \dot{x} = A x + Bu, \quad u = -Kx, \quad x(0) \sim \mathcal{N}(0,\Omega).
\end{split}
\tag{2.16}
\end{equation}\]</span>
Note that problem <a href="sdp.html#eq:linear-quadratic-regulator-directK">(2.16)</a> is different from the original problem <a href="sdp.html#eq:linear-quadratic-regulator">(2.15)</a> in the sense that we assume the knowledge that the optimal controller is linear and directly optimize <span class="math inline">\(K\)</span>. The feasible set <span class="math inline">\(\mathcal{S}\)</span> contains the set of <strong>stabilizing controllers</strong>, i.e.,
<span class="math display" id="eq:stabilizing-K">\[\begin{equation}
\mathcal{S}= \{ K \in \mathbb{R}^{m \times n} \mid A - BK \text{ is Hurwitz} \},
\tag{2.17}
\end{equation}\]</span>
where a matrix <span class="math inline">\(A\)</span> is Hurwitz means <span class="math inline">\(\mathrm{Re}(\lambda_i(A)) &lt; 0\)</span> for all <span class="math inline">\(i=1,\dots,n\)</span>, i.e., all the eigenvalues of <span class="math inline">\(A\)</span> have strictly negative real parts. When <span class="math inline">\(A - BK\)</span> is Hurwitz, the closed-loop system is stable and the integral in <a href="sdp.html#eq:linear-quadratic-regulator-directK">(2.16)</a> will not blow up (so it is sufficient to consider the class of stabilizing controllers).</p>
<p>We will first observe that the direct optimization <a href="sdp.html#eq:linear-quadratic-regulator-directK">(2.16)</a> is nonconvex, because the feasible set <span class="math inline">\(\mathcal{S}\)</span> is nonconvex. The following example is adapted from <span class="citation">(<a href="#ref-fazel18icml-global" role="doc-biblioref">Fazel et al. 2018</a>)</span>.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:NonconvexStabilizingController" class="example"><strong>Example 2.6  (Nonconvex Set of Stabilizing Controllers) </strong></span>Consider the dynamical system <a href="sdp.html#eq:ct-linear-dynamical">(2.14)</a> with
<span class="math display">\[
A = 0_{3 \times 3}, \quad B = \mathrm{I}_3.
\]</span>
It is easy to show that both
<span class="math display">\[
K_1 = \begin{bmatrix} 1 &amp; 0 &amp; -10 \\ -1 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{bmatrix}, \quad K_2 = \begin{bmatrix} 1 &amp; -10 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ -1 &amp; 0 &amp; 1 \end{bmatrix}
\]</span>
are stabilizing controllers, as
<span class="math display">\[
\lambda(A - BK_1) = (-1,-1,-1), \quad \lambda(A - BK_2) = (-1,-1,-1).
\]</span>
However, pick
<span class="math display">\[
K = \frac{K_1 + K_2}{2} = \begin{bmatrix} 1 &amp; -5 &amp; -5 \\ -0.5 &amp; 1 &amp; 0 \\ -0.5 &amp; 0 &amp; 1 \end{bmatrix},
\]</span>
we have
<span class="math display">\[
\lambda(A - BK) = (-3.2361, 1.2361, -1)
\]</span>
and <span class="math inline">\(K\)</span> does not stabilize the closed-loop system.</p>
</div>
</div>
<p><strong>Convex Parameterization with Semidefinite Optimization</strong>. We will now show that it is possible to reparameterize problem <a href="sdp.html#eq:linear-quadratic-regulator-directK">(2.16)</a> as a semidefinite optimization so it becomes convex. To do so, we note
<span class="math display">\[
x^\top Q x + u^\top R u = x^\top Q x + x^\top K^\top R K x = x^\top(Q + K^\top R K)x^\top= \mathrm{tr}((Q + K^\top R K)xx^\top),
\]</span>
and therefore the objective of <a href="sdp.html#eq:linear-quadratic-regulator-directK">(2.16)</a> can be written as
<span class="math display">\[\begin{equation}
\mathbb{E} \left\{ \int_{0}^{\infty} \mathrm{tr}((Q + K^\top R K) xx^\top) dt  \right\}  = \mathrm{tr}\left( (Q + K^\top R K) \mathbb{E} \left\{  \int_{0}^{\infty} xx^\top dt  \right\}    \right).
\end{equation}\]</span>
For any given initial condition, the solution of the closed-loop dynamics is given by the matrix exponential
<span class="math display">\[
x(t) = e^{(A-BK)t} x(0).
\]</span>
For the distribution of initial conditions, we have
<span class="math display">\[
\mathbb{E} \left\{ x(t)x(t)^\top \right\}  = e^{(A-BK)t} \mathbb{E}\{ x(0)x(0)^\top \}  e^{(A-BK)^\top t} = e^{(A-BK)t} \Omega  e^{(A-BK)^\top t}.
\]</span>
The integral of this function, call it <span class="math inline">\(X\)</span>, represents the expected energy of the closed-loop response
<span class="math display">\[
X = \mathbb{E} \left\{ \int_{0}^{\infty} xx^\top dt \right\} .
\]</span>
For every <span class="math inline">\(K \in \mathcal{S}\)</span> that is stabilizing, <span class="math inline">\(X\)</span> can be computed as the solution to the Lyapunov equation
<span class="math display" id="eq:Lyapunov-equation">\[\begin{equation}
(A - BK) X + X(A - BK)^\top+ \Omega = 0.
\tag{2.18}
\end{equation}\]</span>
As a result, the objective of <a href="sdp.html#eq:linear-quadratic-regulator-directK">(2.16)</a> is simplied as
<span class="math display">\[
\mathrm{tr}((Q + K^\top R K) X),
\]</span>
with <span class="math inline">\(X\)</span> solves <a href="sdp.html#eq:Lyapunov-equation">(2.18)</a>. We arrive at an optimization problem
<span class="math display" id="eq:lqr-directK-toX">\[\begin{equation}
\begin{split}
\min_{X,K} &amp; \quad \mathrm{tr}(QX) + \mathrm{tr}(K^\top R K X) \\
\mathrm{s.t.}&amp; \quad (A-BK) X + X (A - BK)^\top+ \Omega = 0 \\
&amp; \quad X \succ 0
\end{split},
\tag{2.19}
\end{equation}\]</span>
which is still nonconvex. We do a change of variable <span class="math inline">\(Y = KX\)</span>, so <span class="math inline">\(K = Y X ^{-1}\)</span> and obtain
<span class="math display" id="eq:lqr-directK-toX-1">\[\begin{equation}
\begin{split}
\min_{X,Y} &amp; \quad \mathrm{tr}(QX) + \mathrm{tr}(X^{-1}Y^\top R Y) \\
\mathrm{s.t.}&amp; \quad AX - BY + XA^\top- Y^\top B^\top+ \Omega = 0 \\
&amp; \quad X \succ 0
\end{split}.
\tag{2.20}
\end{equation}\]</span>
The second term in the objective is still nonconvex, but we can use the Schur complement technique again, and arrive at the final optimization
<span class="math display" id="eq:lqr-directK-toX-2">\[\begin{equation}
\begin{split}
\min_{X,Y,Z} &amp; \quad \mathrm{tr}(QX) + \mathrm{tr}(Z) \\
\mathrm{s.t.}&amp; \quad AX - BY + XA^\top- Y^\top B^\top+ \Omega = 0 \\
&amp; \quad X \succ 0 \\
&amp; \quad \begin{bmatrix} Z &amp; R^{1/2} Y &amp; \\ Y^\top R^{1/2} &amp; X \end{bmatrix} \succeq 0
\end{split}.
\tag{2.21}
\end{equation}\]</span>
Note that the last two matrix inequalities of <a href="sdp.html#eq:lqr-directK-toX-2">(2.21)</a> implies, by Schur complement
<span class="math display">\[
Z - R^{1/2}Y X^{-1}Y^\top R^{1/2} \succeq 0 \Rightarrow \mathrm{tr}(Z - R^{1/2}Y X^{-1}Y^\top R^{1/2}) \geq 0.
\]</span>
Since the optimization is trying to minimize <span class="math inline">\(\mathrm{tr}(Z)\)</span>, it will push the equality to hold
<span class="math display">\[
Z - R^{1/2}Y X^{-1}Y^\top R^{1/2} = 0,
\]</span>
and thus
<span class="math display">\[
\mathrm{tr}(Z) = \mathrm{tr}(R^{1/2}Y X^{-1}Y^\top R^{1/2}) = \mathrm{tr}(X^{-1}Y^\top R Y).
\]</span></p>
<div class="examplebox">
<div class="example">
<p><span id="exm:ConvexLQR" class="example"><strong>Example 2.7  (Convex LQR) </strong></span>For the same linear system as in Example <a href="sdp.html#exm:NonconvexStabilizingController">2.6</a>, let <span class="math inline">\(Q = R = \mathrm{I}_3\)</span>.</p>
<p>If we solve the optimal feedback controller <span class="math inline">\(K\)</span> by solving the ARE, we get the optimal controller is <span class="math inline">\(K^\star = \mathrm{I}_3\)</span>.</p>
<p>If we implement the SDP in <a href="sdp.html#eq:lqr-directK-toX-2">(2.21)</a>, we also get <span class="math inline">\(K^\star = \mathrm{I}_3\)</span>, confirming the correctness of the convex parameterization. The implementation is shown below and can be found <a href="https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/lqr_sdp.m">here</a>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span id="cb3-1"><a href="sdp.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">%% Show the feasible set is nonconvex</span></span>
<span id="cb3-2"><a href="sdp.html#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="va">A</span> <span class="op">=</span> <span class="va">zeros</span>(<span class="fl">3</span><span class="op">,</span><span class="fl">3</span>)<span class="op">;</span></span>
<span id="cb3-3"><a href="sdp.html#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="va">B</span> <span class="op">=</span> <span class="va">eye</span>(<span class="fl">3</span>)<span class="op">;</span></span>
<span id="cb3-4"><a href="sdp.html#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="va">K1</span> <span class="op">=</span> [<span class="fl">1</span><span class="op">,</span> <span class="fl">0</span><span class="op">,</span> <span class="op">-</span><span class="fl">10</span><span class="op">;</span> <span class="op">-</span><span class="fl">1</span><span class="op">,</span> <span class="fl">1</span><span class="op">,</span> <span class="fl">0</span><span class="op">;</span> <span class="fl">0</span><span class="op">,</span> <span class="fl">0</span><span class="op">,</span> <span class="fl">1</span>]<span class="op">;</span></span>
<span id="cb3-5"><a href="sdp.html#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="va">K2</span> <span class="op">=</span> [<span class="fl">1</span><span class="op">,</span> <span class="op">-</span><span class="fl">10</span><span class="op">,</span> <span class="fl">0</span><span class="op">;</span> <span class="fl">0</span><span class="op">,</span> <span class="fl">1</span><span class="op">,</span> <span class="fl">0</span><span class="op">;</span> <span class="op">-</span><span class="fl">1</span><span class="op">,</span> <span class="fl">0</span><span class="op">,</span> <span class="fl">1</span>]<span class="op">;</span></span>
<span id="cb3-6"><a href="sdp.html#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="va">K</span> <span class="op">=</span> (<span class="va">K1</span> <span class="op">+</span> <span class="va">K2</span>)<span class="op">/</span><span class="fl">2</span><span class="op">;</span></span>
<span id="cb3-7"><a href="sdp.html#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="sdp.html#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">%% get the groundtruth LQR controller</span></span>
<span id="cb3-9"><a href="sdp.html#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="va">Q</span> <span class="op">=</span> <span class="va">eye</span>(<span class="fl">3</span>)<span class="op">;</span> <span class="va">R</span> <span class="op">=</span> <span class="va">eye</span>(<span class="fl">3</span>)<span class="op">;</span></span>
<span id="cb3-10"><a href="sdp.html#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="va">K_lqr</span> <span class="op">=</span> <span class="va">lqr</span>(<span class="va">A</span><span class="op">,</span><span class="va">B</span><span class="op">,</span><span class="va">Q</span><span class="op">,</span><span class="va">R</span><span class="op">,</span><span class="va">zeros</span>(<span class="fl">3</span><span class="op">,</span><span class="fl">3</span>))<span class="op">;</span></span>
<span id="cb3-11"><a href="sdp.html#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="va">Omega</span> <span class="op">=</span> <span class="va">eye</span>(<span class="fl">3</span>)<span class="op">;</span></span>
<span id="cb3-12"><a href="sdp.html#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="sdp.html#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">%% solve SDP</span></span>
<span id="cb3-14"><a href="sdp.html#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="va">addpath</span>(<span class="va">genpath</span>(<span class="ss">&#39;../YALMIP&#39;</span>))</span>
<span id="cb3-15"><a href="sdp.html#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="va">addpath</span>(<span class="va">genpath</span>(<span class="ss">&#39;../../../mosek&#39;</span>))</span>
<span id="cb3-16"><a href="sdp.html#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="sdp.html#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="va">X</span> <span class="op">=</span> <span class="va">sdpvar</span>(<span class="fl">3</span><span class="op">,</span><span class="fl">3</span>)<span class="op">;</span></span>
<span id="cb3-18"><a href="sdp.html#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="va">Y</span> <span class="op">=</span> <span class="va">sdpvar</span>(<span class="fl">3</span><span class="op">,</span><span class="fl">3</span><span class="op">,</span><span class="ss">&#39;full&#39;</span>)<span class="op">;</span></span>
<span id="cb3-19"><a href="sdp.html#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="va">Z</span> <span class="op">=</span> <span class="va">sdpvar</span>(<span class="fl">3</span><span class="op">,</span><span class="fl">3</span>)<span class="op">;</span></span>
<span id="cb3-20"><a href="sdp.html#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="va">M</span> <span class="op">=</span> [<span class="va">Z</span><span class="op">,</span> <span class="va">R</span><span class="op">*</span><span class="va">Y</span><span class="op">;</span> <span class="va">Y</span><span class="op">&#39;*</span><span class="va">R</span><span class="op">,</span> <span class="va">X</span>]<span class="op">;</span></span>
<span id="cb3-21"><a href="sdp.html#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="va">F</span> <span class="op">=</span> [</span>
<span id="cb3-22"><a href="sdp.html#cb3-22" aria-hidden="true" tabindex="-1"></a>    <span class="va">A</span><span class="op">*</span><span class="va">X</span> <span class="op">-</span> <span class="va">B</span><span class="op">*</span><span class="va">Y</span> <span class="op">+</span> <span class="va">X</span><span class="op">*</span><span class="va">A</span><span class="op">&#39;</span> <span class="op">-</span> <span class="va">Y</span><span class="op">&#39;*</span><span class="va">B</span><span class="op">&#39;</span> <span class="op">+</span> <span class="va">Omega</span> <span class="op">==</span> <span class="fl">0</span><span class="op">;</span></span>
<span id="cb3-23"><a href="sdp.html#cb3-23" aria-hidden="true" tabindex="-1"></a>    <span class="va">M</span> <span class="op">&gt;=</span> <span class="fl">0</span></span>
<span id="cb3-24"><a href="sdp.html#cb3-24" aria-hidden="true" tabindex="-1"></a>]<span class="op">;</span></span>
<span id="cb3-25"><a href="sdp.html#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="va">obj</span> <span class="op">=</span> <span class="va">trace</span>(<span class="va">Q</span><span class="op">*</span><span class="va">X</span>) <span class="op">+</span> <span class="va">trace</span>(<span class="va">Z</span>)<span class="op">;</span></span>
<span id="cb3-26"><a href="sdp.html#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="va">optimize</span>(<span class="va">F</span><span class="op">,</span><span class="va">obj</span>)<span class="op">;</span></span>
<span id="cb3-27"><a href="sdp.html#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="va">K_sdp</span> <span class="op">=</span> <span class="va">value</span>(<span class="va">Y</span>)<span class="op">*</span><span class="va">inv</span>(<span class="va">value</span>(<span class="va">X</span>))<span class="op">;</span></span></code></pre></div>
</div>
</div>

</div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-blekherman12book-semidefinite" class="csl-entry">
Blekherman, Grigoriy, Pablo A Parrilo, and Rekha R Thomas. 2012. <em>Semidefinite Optimization and Convex Algebraic Geometry</em>. SIAM.
</div>
<div id="ref-boyd94book-lmi" class="csl-entry">
Boyd, Stephen, Laurent El Ghaoui, Eric Feron, and Venkataramanan Balakrishnan. 1994. <em>Linear Matrix Inequalities in System and Control Theory</em>. SIAM.
</div>
<div id="ref-fazel18icml-global" class="csl-entry">
Fazel, Maryam, Rong Ge, Sham Kakade, and Mehran Mesbahi. 2018. <span>“Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator.”</span> In <em>International Conference on Machine Learning</em>, 1467–76. PMLR.
</div>
<div id="ref-hu23review-toward" class="csl-entry">
Hu, Bin, Kaiqing Zhang, Na Li, Mehran Mesbahi, Maryam Fazel, and Tamer Başar. 2023. <span>“Toward a Theoretical Foundation of Policy Optimization for Learning Control Policies.”</span> <em>Annual Review of Control, Robotics, and Autonomous Systems</em> 6: 123–58.
</div>
<div id="ref-mohammadi21tac-convergence" class="csl-entry">
Mohammadi, Hesameddin, Armin Zare, Mahdi Soltanolkotabi, and Mihailo R Jovanović. 2021. <span>“Convergence and Sample Complexity of Gradient Methods for the Model-Free Linear–Quadratic Regulator Problem.”</span> <em>IEEE Transactions on Automatic Control</em> 67 (5): 2435–50.
</div>
<div id="ref-nie23book-moment" class="csl-entry">
Nie, Jiawang. 2023. <em>Moment and Polynomial Optimization</em>. SIAM.
</div>
<div id="ref-ramana97mp-exact" class="csl-entry">
Ramana, Motakuri V. 1997. <span>“An Exact Duality Theory for Semidefinite Programming and Its Complexity Implications.”</span> <em>Mathematical Programming</em> 77: 129–62.
</div>
<div id="ref-todd01an-semidefinite" class="csl-entry">
Todd, Michael J. 2001. <span>“Semidefinite Optimization.”</span> <em>Acta Numerica</em> 10: 515–60.
</div>
<div id="ref-wolkowicz12book-sdp" class="csl-entry">
Wolkowicz, Henry, Romesh Saigal, and Lieven Vandenberghe. 2000. <em>Handbook of Semidefinite Programming: Theory, Algorithms, and Applications</em>. Vol. 27. Springer.
</div>
<div id="ref-yang22mp-inexact" class="csl-entry">
Yang, Heng, Ling Liang, Luca Carlone, and Kim-Chuan Toh. 2022. <span>“An Inexact Projected Gradient Method with Rounding and Lifting by Nonlinear Programming for Solving Rank-One Semidefinite Relaxation of Polynomial Optimization.”</span> <em>Mathematical Programming</em>, 1–64.
</div>
</div>
<div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://semidefinite.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="background.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/hankyang94/Semidefinite/blob/main/02-semidefinite-optimization.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["semidefinite-optimization-relaxation.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
