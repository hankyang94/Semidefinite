<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Sums of Squares Relaxation | Semidefinite Optimization and Relaxation</title>
  <meta name="description" content="Lecture notes for Harvard ES 257 Semidefinite Optimization and Relaxation." />
  <meta name="generator" content="bookdown 0.38 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Sums of Squares Relaxation | Semidefinite Optimization and Relaxation" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture notes for Harvard ES 257 Semidefinite Optimization and Relaxation." />
  <meta name="github-repo" content="hankyang94/Semidefinite" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Sums of Squares Relaxation | Semidefinite Optimization and Relaxation" />
  
  <meta name="twitter:description" content="Lecture notes for Harvard ES 257 Semidefinite Optimization and Relaxation." />
  

<meta name="author" content="Heng Yang" />


<meta name="date" content="2024-03-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Shor.html"/>
<link rel="next" href="Moment.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Semidefinite Optimization and Relaxation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#feedback"><i class="fa fa-check"></i>Feedback</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#offerings"><i class="fa fa-check"></i>Offerings</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="notation.html"><a href="notation.html"><i class="fa fa-check"></i>Notation</a></li>
<li class="chapter" data-level="1" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>1</b> Mathematical Background</a>
<ul>
<li class="chapter" data-level="1.1" data-path="background.html"><a href="background.html#background:convexity"><i class="fa fa-check"></i><b>1.1</b> Convexity</a></li>
<li class="chapter" data-level="1.2" data-path="background.html"><a href="background.html#background:convex:geometry"><i class="fa fa-check"></i><b>1.2</b> Convex Geometry</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="background.html"><a href="background.html#basic-facts"><i class="fa fa-check"></i><b>1.2.1</b> Basic Facts</a></li>
<li class="chapter" data-level="1.2.2" data-path="background.html"><a href="background.html#cones-duality-polarity"><i class="fa fa-check"></i><b>1.2.2</b> Cones, Duality, Polarity</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="background.html"><a href="background.html#background:convex:optimization"><i class="fa fa-check"></i><b>1.3</b> Convex Optimization</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="background.html"><a href="background.html#minimax-theorem"><i class="fa fa-check"></i><b>1.3.1</b> Minimax Theorem</a></li>
<li class="chapter" data-level="1.3.2" data-path="background.html"><a href="background.html#background:convex:optimization:Lagrangian"><i class="fa fa-check"></i><b>1.3.2</b> Lagrangian Duality</a></li>
<li class="chapter" data-level="1.3.3" data-path="background.html"><a href="background.html#kkt-optimality-conditions"><i class="fa fa-check"></i><b>1.3.3</b> KKT Optimality Conditions</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="background.html"><a href="background.html#background:linear:optimization"><i class="fa fa-check"></i><b>1.4</b> Linear Optimization</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="background.html"><a href="background.html#polyhedra"><i class="fa fa-check"></i><b>1.4.1</b> Polyhedra</a></li>
<li class="chapter" data-level="1.4.2" data-path="background.html"><a href="background.html#linear-program"><i class="fa fa-check"></i><b>1.4.2</b> Linear Program</a></li>
<li class="chapter" data-level="1.4.3" data-path="background.html"><a href="background.html#farkas-lemma"><i class="fa fa-check"></i><b>1.4.3</b> Farkas Lemma</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="sdp.html"><a href="sdp.html"><i class="fa fa-check"></i><b>2</b> Semidefinite Optimization</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sdp.html"><a href="sdp.html#positive-semidefinite-matrices"><i class="fa fa-check"></i><b>2.1</b> Positive Semidefinite Matrices</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="sdp.html"><a href="sdp.html#geometric-properties"><i class="fa fa-check"></i><b>2.1.1</b> Geometric Properties</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="sdp.html"><a href="sdp.html#semidefinite-programming"><i class="fa fa-check"></i><b>2.2</b> Semidefinite Programming</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="sdp.html"><a href="sdp.html#spectrahedra"><i class="fa fa-check"></i><b>2.2.1</b> Spectrahedra</a></li>
<li class="chapter" data-level="2.2.2" data-path="sdp.html"><a href="sdp.html#formulation-and-duality"><i class="fa fa-check"></i><b>2.2.2</b> Formulation and Duality</a></li>
<li class="chapter" data-level="2.2.3" data-path="sdp.html"><a href="sdp.html#geometric-properties-1"><i class="fa fa-check"></i><b>2.2.3</b> Geometric Properties</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="sdp.html"><a href="sdp.html#software-for-conic-optimization"><i class="fa fa-check"></i><b>2.3</b> Software for Conic Optimization</a></li>
<li class="chapter" data-level="2.4" data-path="sdp.html"><a href="sdp.html#interior-point-algorithm"><i class="fa fa-check"></i><b>2.4</b> Interior Point Algorithm</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="sdp.html"><a href="sdp.html#the-central-path"><i class="fa fa-check"></i><b>2.4.1</b> The Central Path</a></li>
<li class="chapter" data-level="2.4.2" data-path="sdp.html"><a href="sdp.html#the-aho-newton-direction"><i class="fa fa-check"></i><b>2.4.2</b> The AHO Newton Direction</a></li>
<li class="chapter" data-level="2.4.3" data-path="sdp.html"><a href="sdp.html#basic-algorithm"><i class="fa fa-check"></i><b>2.4.3</b> Basic Algorithm</a></li>
<li class="chapter" data-level="2.4.4" data-path="sdp.html"><a href="sdp.html#nondegeneracy"><i class="fa fa-check"></i><b>2.4.4</b> Nondegeneracy</a></li>
<li class="chapter" data-level="2.4.5" data-path="sdp.html"><a href="sdp.html#generalization"><i class="fa fa-check"></i><b>2.4.5</b> Generalization</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="sdp.html"><a href="sdp.html#applications"><i class="fa fa-check"></i><b>2.5</b> Applications</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="sdp.html"><a href="sdp.html#LyapunovLinearSystem"><i class="fa fa-check"></i><b>2.5.1</b> Lyapunov Stability</a></li>
<li class="chapter" data-level="2.5.2" data-path="sdp.html"><a href="sdp.html#linear-quadratic-regulator"><i class="fa fa-check"></i><b>2.5.2</b> Linear Quadratic Regulator</a></li>
<li class="chapter" data-level="2.5.3" data-path="sdp.html"><a href="sdp.html#domain-adaptation"><i class="fa fa-check"></i><b>2.5.3</b> Domain Adaptation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Shor.html"><a href="Shor.html"><i class="fa fa-check"></i><b>3</b> Shor’s Semidefinite Relaxation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="Shor.html"><a href="Shor.html#semidefinite-relaxation-of-qcqps"><i class="fa fa-check"></i><b>3.1</b> Semidefinite Relaxation of QCQPs</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="Shor.html"><a href="Shor.html#lagrangian-dual-problem"><i class="fa fa-check"></i><b>3.1.1</b> Lagrangian Dual Problem</a></li>
<li class="chapter" data-level="3.1.2" data-path="Shor.html"><a href="Shor.html#dual-of-the-dual-bidual"><i class="fa fa-check"></i><b>3.1.2</b> Dual of the Dual (Bidual)</a></li>
<li class="chapter" data-level="3.1.3" data-path="Shor.html"><a href="Shor.html#maxcut"><i class="fa fa-check"></i><b>3.1.3</b> MAXCUT</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="Shor.html"><a href="Shor.html#certifiably-optimal-rotation-averaging"><i class="fa fa-check"></i><b>3.2</b> Certifiably Optimal Rotation Averaging</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="Shor.html"><a href="Shor.html#dual-optimality-certifier"><i class="fa fa-check"></i><b>3.2.1</b> Dual Optimality Certifier</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="Shor.html"><a href="Shor.html#stretch-to-high-degree-polynomial-optimization"><i class="fa fa-check"></i><b>3.3</b> Stretch to High-Degree Polynomial Optimization</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="SOS.html"><a href="SOS.html"><i class="fa fa-check"></i><b>4</b> Sums of Squares Relaxation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="SOS.html"><a href="SOS.html#basic-algebraic-geometry"><i class="fa fa-check"></i><b>4.1</b> Basic Algebraic Geometry</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="SOS.html"><a href="SOS.html#groups-rings-fields"><i class="fa fa-check"></i><b>4.1.1</b> Groups, Rings, Fields</a></li>
<li class="chapter" data-level="4.1.2" data-path="SOS.html"><a href="SOS.html#polynomials-ideals-and-varieties"><i class="fa fa-check"></i><b>4.1.2</b> Polynomials, Ideals, and Varieties</a></li>
<li class="chapter" data-level="4.1.3" data-path="SOS.html"><a href="SOS.html#gröbner-bases"><i class="fa fa-check"></i><b>4.1.3</b> Gröbner Bases</a></li>
<li class="chapter" data-level="4.1.4" data-path="SOS.html"><a href="SOS.html#quotient-ring"><i class="fa fa-check"></i><b>4.1.4</b> Quotient Ring</a></li>
<li class="chapter" data-level="4.1.5" data-path="SOS.html"><a href="SOS.html#zero-dimensional-ideal"><i class="fa fa-check"></i><b>4.1.5</b> Zero-dimensional Ideal</a></li>
<li class="chapter" data-level="4.1.6" data-path="SOS.html"><a href="SOS.html#algebraic-and-semialgebraic-sets"><i class="fa fa-check"></i><b>4.1.6</b> Algebraic and Semialgebraic Sets</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="SOS.html"><a href="SOS.html#sos-and-nonnegative-polynomials"><i class="fa fa-check"></i><b>4.2</b> SOS and Nonnegative Polynomials</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="SOS.html"><a href="SOS.html#nonnegative-polynomials"><i class="fa fa-check"></i><b>4.2.1</b> Nonnegative polynomials</a></li>
<li class="chapter" data-level="4.2.2" data-path="SOS.html"><a href="SOS.html#sums-of-squares-polynomials"><i class="fa fa-check"></i><b>4.2.2</b> Sums-of-Squares Polynomials</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="SOS.html"><a href="SOS.html#compute-sos-decompositions"><i class="fa fa-check"></i><b>4.3</b> Compute SOS Decompositions</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="SOS.html"><a href="SOS.html#univaraite-polynomials"><i class="fa fa-check"></i><b>4.3.1</b> Univaraite Polynomials</a></li>
<li class="chapter" data-level="4.3.2" data-path="SOS.html"><a href="SOS.html#multivariate-polynomials"><i class="fa fa-check"></i><b>4.3.2</b> Multivariate Polynomials</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="SOS.html"><a href="SOS.html#sos-programming"><i class="fa fa-check"></i><b>4.4</b> SOS Programming</a></li>
<li class="chapter" data-level="4.5" data-path="SOS.html"><a href="SOS.html#positivstellensatz"><i class="fa fa-check"></i><b>4.5</b> Positivstellensatz</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="SOS.html"><a href="SOS.html#univaraite-intervals"><i class="fa fa-check"></i><b>4.5.1</b> Univaraite Intervals</a></li>
<li class="chapter" data-level="4.5.2" data-path="SOS.html"><a href="SOS.html#affine-variety"><i class="fa fa-check"></i><b>4.5.2</b> Affine Variety</a></li>
<li class="chapter" data-level="4.5.3" data-path="SOS.html"><a href="SOS.html#basic-semialgebraic-sets"><i class="fa fa-check"></i><b>4.5.3</b> Basic Semialgebraic Sets</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="SOS.html"><a href="SOS.html#applications-1"><i class="fa fa-check"></i><b>4.6</b> Applications</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="SOS.html"><a href="SOS.html#SOS:POP"><i class="fa fa-check"></i><b>4.6.1</b> Polynomial Optimization</a></li>
<li class="chapter" data-level="4.6.2" data-path="SOS.html"><a href="SOS.html#lyapunov-certificates"><i class="fa fa-check"></i><b>4.6.2</b> Lyapunov Certificates</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="Moment.html"><a href="Moment.html"><i class="fa fa-check"></i><b>5</b> Moment Relaxation</a>
<ul>
<li class="chapter" data-level="5.1" data-path="Moment.html"><a href="Moment.html#dual-cones-of-polynomials"><i class="fa fa-check"></i><b>5.1</b> Dual Cones of Polynomials</a></li>
<li class="chapter" data-level="5.2" data-path="Moment.html"><a href="Moment.html#dual-of-quadratic-modules-and-ideals"><i class="fa fa-check"></i><b>5.2</b> Dual of Quadratic Modules and Ideals</a></li>
<li class="chapter" data-level="5.3" data-path="Moment.html"><a href="Moment.html#the-moment-sos-hierarchy"><i class="fa fa-check"></i><b>5.3</b> The Moment-SOS Hierarchy</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="Moment.html"><a href="Moment.html#conversion-to-standard-sdp"><i class="fa fa-check"></i><b>5.3.1</b> Conversion to Standard SDP</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Semidefinite Optimization and Relaxation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="SOS" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Sums of Squares Relaxation<a href="SOS.html#SOS" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="basic-algebraic-geometry" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Basic Algebraic Geometry<a href="SOS.html#basic-algebraic-geometry" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We first review several basic concepts in algebraic geometry. We refer to standard textbooks for a more comprehensive treatment <span class="citation">(<a href="#ref-bochnak13book-real">Bochnak, Coste, and Roy 2013</a>)</span>, <span class="citation">(<a href="#ref-cox13book-ideals">Cox, Little, and OShea 2013</a>)</span>, <span class="citation">(<a href="#ref-dummit04book-abstract">Dummit and Foote 2004</a>)</span>, <span class="citation">(<a href="#ref-lang12book-algebra">Lang 2012</a>)</span>.</p>
<div id="groups-rings-fields" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Groups, Rings, Fields<a href="SOS.html#groups-rings-fields" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="definitionbox">
<div class="definition">
<p><span id="def:Group" class="definition"><strong>Definition 4.1  (Group) </strong></span>A <strong>group</strong> consists of a set <span class="math inline">\(G\)</span> and a binary operation “<span class="math inline">\(\cdot\)</span>” defined on <span class="math inline">\(G\)</span> that satisfies the following conditions:</p>
<ol style="list-style-type: decimal">
<li><p>Associative: <span class="math inline">\((a \cdot b) \cdot c = a \cdot (b \cdot c)\)</span>, for all <span class="math inline">\(a,b,c \in G\)</span>.</p></li>
<li><p>Identity: there exists <span class="math inline">\(1 \in G\)</span> such that <span class="math inline">\(1 \cdot a = a \cdot 1 = a\)</span>, for all <span class="math inline">\(a \in G\)</span>.</p></li>
<li><p>Inverse: Given <span class="math inline">\(a \in G\)</span>, there exists <span class="math inline">\(b \in G\)</span> such that <span class="math inline">\(a \cdot b = b \cdot a = 1\)</span>.</p></li>
</ol>
</div>
</div>
<p>For example, the integers <span class="math inline">\(\mathbb{Z}\)</span> form a group under addition, but not under multiplication; the set <span class="math inline">\(GL(n,\mathbb{R}^{})\)</span> that contains nonsingular <span class="math inline">\(n \times n\)</span> matrices forms a group under the usual matrix multiplication. Another example is the set of rotation matrices <span class="math inline">\(\mathrm{SO}(d):= \{ R \in \mathbb{R}^{d \times d} \mid RR^\top= \mathrm{I}_d, \det(R) = +1 \}\)</span>.</p>
<p>In a group we only have one binary operation (“multiplication”). We will introduce another operation (“addition”).</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:Ring" class="definition"><strong>Definition 4.2  (Commutative Ring) </strong></span>A <strong>commutative ring</strong> (with identity) consists of a set <span class="math inline">\(S\)</span> and two binary operations “<span class="math inline">\(\cdot\)</span>” and “<span class="math inline">\(+\)</span>” defined on <span class="math inline">\(S\)</span> that satisfy the following conditions</p>
<ol style="list-style-type: decimal">
<li><p>Associative: <span class="math inline">\((a+b)+c = a + (b+c)\)</span>, and <span class="math inline">\((a \cdot b) \cdot c = a \cdot (b \cdot c)\)</span>, for all <span class="math inline">\(a,b,c \in S\)</span>.</p></li>
<li><p>Commutative: <span class="math inline">\(a+b=b+a\)</span> and <span class="math inline">\(a\cdot b = b \cdot a\)</span>, for all <span class="math inline">\(a,b \in S\)</span>.</p></li>
<li><p>Distributive: <span class="math inline">\(a \cdot (b+c) = a\cdot b + a \cdot c\)</span> for all <span class="math inline">\(a,b,c \in S\)</span>.</p></li>
<li><p>Identities: there exist <span class="math inline">\(0, 1 \in S\)</span> such that <span class="math inline">\(a + 0 = a \cdot 1 = a\)</span>, for all <span class="math inline">\(a \in S\)</span>.</p></li>
<li><p>Additive inverse: given <span class="math inline">\(a \in S\)</span>, there exists <span class="math inline">\(b \in S\)</span> such that <span class="math inline">\(a + b = 0\)</span>.</p></li>
</ol>
</div>
</div>
<p>A simple example of a ring is the set of integers <span class="math inline">\(\mathbb{Z}\)</span> under the usual addition and multiplication.</p>
<p>If we add a requirement for the existence of multiplicative inverse, we obtain a field.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:Field" class="definition"><strong>Definition 4.3  (Field) </strong></span>A <strong>field</strong> consists of a set <span class="math inline">\(S\)</span> and two binary operations “<span class="math inline">\(\cdot\)</span>” and “<span class="math inline">\(+\)</span>” defined on <span class="math inline">\(S\)</span> that satisfy the following conditions</p>
<ol style="list-style-type: decimal">
<li><p>Associative: <span class="math inline">\((a+b)+c = a + (b+c)\)</span>, and <span class="math inline">\((a \cdot b) \cdot c = a \cdot (b \cdot c)\)</span>, for all <span class="math inline">\(a,b,c \in S\)</span>.</p></li>
<li><p>Commutative: <span class="math inline">\(a+b=b+a\)</span> and <span class="math inline">\(a\cdot b = b \cdot a\)</span>, for all <span class="math inline">\(a,b \in S\)</span>.</p></li>
<li><p>Distributive: <span class="math inline">\(a \cdot (b+c) = a\cdot b + a \cdot c\)</span> for all <span class="math inline">\(a,b,c \in S\)</span>.</p></li>
<li><p>Identities: there exist <span class="math inline">\(0, 1 \in S\)</span>, where <span class="math inline">\(0 \neq 1\)</span>, such that <span class="math inline">\(a + 0 = a \cdot 1 = a\)</span>, for all <span class="math inline">\(a \in S\)</span>.</p></li>
<li><p>Additive inverse: given <span class="math inline">\(a \in S\)</span>, there exists <span class="math inline">\(b \in S\)</span> such that <span class="math inline">\(a + b = 0\)</span>.</p></li>
<li><p>Multiplicative inverse: given <span class="math inline">\(a \in S\)</span> and <span class="math inline">\(a \neq 0\)</span>, there exists <span class="math inline">\(c \in S\)</span> such that <span class="math inline">\(a \cdot c = 1\)</span>.</p></li>
</ol>
</div>
</div>
<p>Any field is obvious a commutative ring. Some commonly used fields are the rationals <span class="math inline">\(\mathbb{Q}\)</span>, the reals <span class="math inline">\(\mathbb{R}^{}\)</span>, and the complex numbers <span class="math inline">\(\mathbb{C}\)</span>. Another important field is given by <span class="math inline">\(k(x_1,\dots,x_n)\)</span>, the set of rational functions with coefficients in the field <span class="math inline">\(k\)</span>, with the natural operations.</p>
</div>
<div id="polynomials-ideals-and-varieties" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Polynomials, Ideals, and Varieties<a href="SOS.html#polynomials-ideals-and-varieties" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We will use <span class="math inline">\(\mathbb{F}= \mathbb{R}\)</span> or <span class="math inline">\(\mathbb{C}\)</span> to denote the field of real or complex numbers from now on. Let <span class="math inline">\(x_1,\dots,x_n\)</span> be indeterminates, we can define a polynomial.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:Polynomial" class="definition"><strong>Definition 4.4  (Polynomial) </strong></span>A polynomial <span class="math inline">\(f\)</span> in <span class="math inline">\(x_1,\dots,x_n\)</span> with coefficients in a field <span class="math inline">\(\mathbb{F}\)</span> is a finite linear combination of monomials:
<span class="math display">\[
f = \sum_{\alpha} c_\alpha x^\alpha = \sum_{\alpha} c_\alpha x_1^{\alpha_1}\cdots x_n^{\alpha_n}, \quad c_\alpha \in \mathbb{F},
\]</span>
where the sum is over a finite number of <span class="math inline">\(n\)</span>-tuples (exponents) <span class="math inline">\(\alpha = (\alpha_1,\dots,\alpha_n)\)</span>, <span class="math inline">\(\alpha_i \in \mathbb{N}\)</span>. The set of all polynomials in <span class="math inline">\(x\)</span> with coefficients in <span class="math inline">\(\mathbb{F}\)</span> is denoted <span class="math inline">\(\mathbb{F}[x]\)</span> or <span class="math inline">\(\mathbb{F}[x_1,\dots,x_n]\)</span>.</p>
</div>
</div>
<p>The <strong>degree</strong> of a monomial is the sum of its exponents:
<span class="math display">\[
\deg(x^\alpha) = \deg(x_1^{\alpha_1}\cdots x_n^{\alpha_n}) = \sum_{i=1}^n \alpha_i.
\]</span>
The degree of a polynomial is the maximum degree of its monomials:
<span class="math display">\[
\deg(f) = \max_{\alpha} \deg(x^\alpha).
\]</span></p>
<p>It is clear that <span class="math inline">\(\mathbb{F}[x]\)</span> is a commutative ring with the <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> identities.</p>
<p>A <strong>form</strong> is a polynomial where all the monomials have the same degree. It is also called a <strong>homogeneous polynomial</strong>. For example,
<span class="math display">\[
f = 2 x_1^2 + x_1 x_2 + x_2^2
\]</span>
is a form of degree <span class="math inline">\(2\)</span>. A homogeneous polynomial of degree <span class="math inline">\(d\)</span> satisfies
<span class="math display">\[
f(\lambda x_1,\dots,\lambda x_n) = \lambda^d f(x_1,\dots,x_n).
\]</span></p>
<p>A polynomial in <span class="math inline">\(n\)</span> variables of degree <span class="math inline">\(d\)</span> has
<span class="math display">\[
s(n,d) = \begin{pmatrix} n + d \\ d \end{pmatrix}
\]</span>
coefficients. Let <span class="math inline">\(\mathbb{F}[x]_{d}\)</span> be the set of polynomials in <span class="math inline">\(n\)</span> variables of degree <span class="math inline">\(d\)</span>, then any <span class="math inline">\(f \in \mathbb{F}[x]_d\)</span> can be written as
<span class="math display">\[
f = c^\top[x]_d, \quad c \in \mathbb{F}^{s(n,d)}
\]</span>
with <span class="math inline">\([x]_d\)</span> the <strong>standard monomial basis</strong> in <span class="math inline">\(x\)</span> of degree up to <span class="math inline">\(d\)</span>. For example, when <span class="math inline">\(x = (x_1,x_2)\)</span>, then
<span class="math display">\[
[x]_2 = \begin{bmatrix} 1 \\ x_1 \\ x_2 \\ x_1^2 \\ x_1 x_2 \\ x_2^2 \end{bmatrix}.
\]</span></p>
<p>Let <span class="math inline">\(G\)</span> be a set of polynomials, and <span class="math inline">\(\mathbb{F}[G]\)</span> denote the set of all polynomials that can be written as
<span class="math display">\[
\sum_{\alpha} c_\alpha g_1^{\alpha_1} \cdots g_k^{\alpha_k}, \quad c_\alpha \in \mathbb{F}, g_1,\dots,g_k \in G
\]</span>
with finitely many nonzero coefficients. The polynomials in <span class="math inline">\(G\)</span> are called <strong>generators</strong> and <span class="math inline">\(G\)</span> is called a <strong>generator set</strong> for <span class="math inline">\(\mathbb{F}[G]\)</span>. Clearly, the set
<span class="math display">\[
G = \{1, x_1, \dots, x_n\}
\]</span>
is a generator set for <span class="math inline">\(\mathbb{F}[x]\)</span>.</p>
<p>We consider next ideals, which are subrings with an “absorbent” property.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:Ideal" class="definition"><strong>Definition 4.5  (Ideal) </strong></span>Let <span class="math inline">\(R\)</span> be a commutative ring. A subset <span class="math inline">\(I \subset R\)</span> is an ideal if it satisfies</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(0 \in I\)</span>.</p></li>
<li><p>If <span class="math inline">\(a, b \in I\)</span>, then <span class="math inline">\(a + b \in I\)</span>.</p></li>
<li><p>If <span class="math inline">\(a \in I\)</span> and <span class="math inline">\(b \in R\)</span>, then <span class="math inline">\(a \cdot b \in I\)</span>.</p></li>
</ol>
</div>
</div>
<p>A simple example of an ideal is the set of even integers, considered as a subset of the integer ring <span class="math inline">\(\mathbb{Z}\)</span>. If the ideal <span class="math inline">\(I\)</span> contains the multiplicative identity “<span class="math inline">\(1\)</span>”, then <span class="math inline">\(I = R\)</span>. For a tuple <span class="math inline">\(h = (h_1,\dots,h_s)\)</span> of polynomials in <span class="math inline">\(\mathbb{F}[x]\)</span>, <span class="math inline">\(\mathrm{Ideal}[h]:= \mathrm{Ideal}[h_1,\dots,h_m]\)</span> denotes the smallest ideal containing <span class="math inline">\(h\)</span>, or equivalently
<span class="math display">\[
\mathrm{Ideal}[h] = h_1 \cdot \mathbb{F}[x] + \cdots + h_s \cdot \mathbb{F}[x].
\]</span>
The set <span class="math inline">\(\mathrm{Ideal}[h]\)</span> is called the ideal generated by <span class="math inline">\(h\)</span>. Every ideal of <span class="math inline">\(\mathbb{F}[x]\)</span> is generated by finitely many polynomials, i.e., every ideal is <strong>finitely generated</strong>.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:HilbertBasisTheorem" class="theorem"><strong>Theorem 4.1  (Hilbert Basis Theorem) </strong></span>For every ideal <span class="math inline">\(I \subseteq \mathbb{F}[x]\)</span>, there exist finitely many polynomials <span class="math inline">\(g_1,\dots,g_m \in I\)</span> such that <span class="math inline">\(I = \mathrm{Ideal}[g_1,\dots,g_m]\)</span>.</p>
</div>
</div>
<p>We define the concept of an <strong>algebraic variety</strong> as the zero set of a set of polynomial equations.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:AffineVariety" class="definition"><strong>Definition 4.6  (Affine Variety) </strong></span>Let <span class="math inline">\(f_1,\dots,f_s \in \mathbb{F}[x_1,\dots,x_n]\)</span> and <span class="math inline">\(x = (x_1,\dots,x_n)\)</span>, and the set <span class="math inline">\(V\)</span> be
<span class="math display">\[
V_{\mathbb{F}}(f_1,\dots,f_s) = \{ x \in \mathbb{F}^{n}\mid f_i(x) = 0, i=1,\dots,s \}.
\]</span>
We call <span class="math inline">\(V_{\mathbb{F}}(f_1,\dots,f_s)\)</span> the affine variety defined by <span class="math inline">\(f_1,\dots,f_s\)</span>.</p>
</div>
</div>
<p>Similarly, let <span class="math inline">\(I \subset \mathbb{F}[x]\)</span> be an ideal, we denote its zero set as
<span class="math display">\[
V_{\mathbb{F}}(I) = \{ x \in \mathbb{F}^n \mid f(x) = 0, \forall f \in I \}.
\]</span>
Since the ideal is finitely generated, we have
<span class="math display">\[
V_{\mathbb{F}}(I) = V_{\mathbb{F}}(g_1,\dots,g_m),
\]</span>
where <span class="math inline">\(g_1,\dots,g_m\)</span> are the generators of <span class="math inline">\(I\)</span>.</p>
<p>The set of polynomials that vanish in a given variety, i.e.,
<span class="math display">\[
I(V)= \{ f \in \mathbb{F}[x] \mid f(x) = 0, \forall x \in V \},
\]</span>
is an ideal, called the <strong>vanishing ideal</strong> of <span class="math inline">\(V\)</span>.</p>
<p>We define the <strong>radical</strong> of an ideal.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:Radical" class="definition"><strong>Definition 4.7  (Radical) </strong></span>Let <span class="math inline">\(I \subset \mathbb{F}[x]\)</span> be an ideal. The radical of <span class="math inline">\(I\)</span>, denoted <span class="math inline">\(\sqrt{I}\)</span>, is the set
<span class="math display">\[
\sqrt{I} := \{ f \mid f^k \in I \text{ for some integer }k \}.
\]</span></p>
</div>
</div>
<p>It is clear that <span class="math inline">\(I \subset \sqrt{I}\)</span>, and it can be shown that <span class="math inline">\(\sqrt{I}\)</span> is also a polynomial ideal.</p>
<p>Given an ideal <span class="math inline">\(I\)</span> and <span class="math inline">\(V_{\mathbb{C}}(I)\)</span>, it is clear that any <span class="math inline">\(f \in I\)</span> vanishes on <span class="math inline">\(V_{\mathbb{C}}(I)\)</span>, that is
<span class="math display">\[
I \subseteq I(V_{\mathbb{C}}(I)).
\]</span>
However, not all polynomials that vanish on <span class="math inline">\(V_{\mathbb{C}}(I)\)</span> belong to <span class="math inline">\(I\)</span>.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:HilbertNull" class="theorem"><strong>Theorem 4.2  (Hilbert's Nullstellensatz) </strong></span>Let <span class="math inline">\(I \subseteq \mathbb{C}[x]\)</span> be an ideal.</p>
<ul>
<li><p>(Weak Nullstellensatz) If <span class="math inline">\(V_{\mathbb{C}}(I) = \emptyset\)</span>, then <span class="math inline">\(1 \in I\)</span>.</p></li>
<li><p>(Strong Nullstellensatz) For <span class="math inline">\(f \in \mathbb{C}[x]\)</span>, if <span class="math inline">\(f(u) = 0\)</span> for all <span class="math inline">\(u \in V_{\mathbb{C}}(I)\)</span>, then <span class="math inline">\(f^k \in I\)</span> for some integer <span class="math inline">\(k \geq 1\)</span>, i.e., <span class="math inline">\(I(V_{\mathbb{C}}(I)) = \sqrt{I}\)</span>.</p></li>
</ul>
</div>
</div>
<p>Let us see an example of Hilbert’s Nullstellensatz.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:HilbertNullstellensatz" class="example"><strong>Example 4.1  (Hilbert's Nullstellensatz) </strong></span>Consider the ideal
<span class="math display">\[
I=\mathrm{Ideal}[x_1^2 x_2^3, x_1 x_2^4].
\]</span>
The affine variety defined by <span class="math inline">\(I\)</span> is
<span class="math display">\[
V = V_{\mathbb{C}}(I) = \{ (x_1,x_2) \in \mathbb{C}^2 \mid x_1^2 x_2^3 = 0, x_1 x_2^4=0 \}.
\]</span>
It is easy to see that the variety is the union of the two coordinate axes <span class="math inline">\(x_1=0\)</span> and <span class="math inline">\(x_2 = 0\)</span>.</p>
<p>Therefore, the polynomial <span class="math inline">\(x_1x_2\)</span> vanishes on the variety <span class="math inline">\(V\)</span>, but <span class="math inline">\(x_1 x_2\)</span> does not belong to the ideal <span class="math inline">\(I\)</span> (because the degree is lower).</p>
<p>We claim that
<span class="math display">\[
\sqrt{I} = \mathrm{Ideal}[x_1 x_2].
\]</span>
Indeed, <span class="math inline">\(x_1 x_2 \in \sqrt{I}\)</span> because
<span class="math display">\[
(x_1x_2)^3 = x_1^3 x_2^3 = x_1 \cdot x_1^2 x_3^3 \in I.
\]</span>
Conversely, if <span class="math inline">\(f \in \sqrt{I}\)</span>, then <span class="math inline">\(f^k \in I\)</span> for some integer <span class="math inline">\(k\)</span>, i.e.,
<span class="math display">\[
f^k = x_1^2 x_2^3 p(x) + x_1 x_2^4 q(x) = x_1 x_2 r(x)
\]</span>
which implies <span class="math inline">\(f^k \in \mathrm{Ideal}[x_1 x_2]\)</span>. Therefore, all the polynomials that vanish on the variety <span class="math inline">\(V\)</span> can be generated by <span class="math inline">\(x_1 x_2\)</span>.</p>
<p>As another example, consider the ideal generated by a single univariate polynomial
<span class="math display">\[
I = \mathrm{Ideal}[f], \quad f = \prod_{i=1}^{s} (x - a_i)^{n_i}
\]</span>
with <span class="math inline">\(a_i \neq a_j\)</span> for <span class="math inline">\(i \neq j\)</span> the unique roots of the polynomial <span class="math inline">\(f\)</span>. Clearly, the affine variety defined by <span class="math inline">\(I\)</span> is the set of unique roots:
<span class="math display">\[
V= V_{\mathbb{C}}(I) = \{a_1,\dots,a_s\}.
\]</span>
The vanishing ideal of <span class="math inline">\(V\)</span> is
<span class="math display">\[
\sqrt{I} = \mathrm{Ideal}[(x-a_1)\cdots (x-a_s)].
\]</span></p>
</div>
</div>
</div>
<div id="gröbner-bases" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Gröbner Bases<a href="SOS.html#gröbner-bases" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A polynomial ideal can have different “descriptions” in terms of its generators. We will now focus on a particular type of description that is better than the others.</p>
<p>Let’s first define a monomial ordering.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:MonomialOrdering" class="definition"><strong>Definition 4.8  (Monomial Ordering) </strong></span>A monomial ordering on <span class="math inline">\(\mathbb{C}[x]\)</span> is a binary relation <span class="math inline">\(\succ\)</span> on <span class="math inline">\(\mathbb{N}^n\)</span>, i.e., the exponents of the monomials, that satisfies</p>
<ol style="list-style-type: decimal">
<li><p>The relation <span class="math inline">\(\succ\)</span> is a total ordering, i.e., given any two monomials <span class="math inline">\(x^{\alpha}, x^{\beta}\)</span>, we must have either <span class="math inline">\(x^{\alpha} \succ x^{\beta}\)</span>, or <span class="math inline">\(x^\beta \succ x^\alpha\)</span>, or <span class="math inline">\(x^\alpha = x^\beta\)</span>.</p></li>
<li><p>If <span class="math inline">\(x^\alpha \succ x^\beta\)</span>, then <span class="math inline">\(x^\alpha \cdot x^\gamma \succ x^\beta \cdot x^\gamma\)</span> for any monomial <span class="math inline">\(x^\gamma\)</span>.</p></li>
<li><p>The relation <span class="math inline">\(\succ\)</span> is well ordered, i.e., every nonempty set has a smallest element under <span class="math inline">\(\succ\)</span>.</p></li>
</ol>
</div>
</div>
<p>There are several monomial orderings of interest in computational algebra.</p>
<ul>
<li><p><strong>Lexicographic</strong> (“dictionary”). Here <span class="math inline">\(\alpha \succ_{\mathrm{lex}}\beta\)</span> if the left-most nonzero entry of <span class="math inline">\(\alpha - \beta\)</span> is positive. Note that a particular ordering of the variables is assumed.</p></li>
<li><p><strong>Graded lexicographic</strong>. Sort first by total degree, then Lexicographic, i.e., <span class="math inline">\(\alpha \succ_{\mathrm{grlex}}\beta\)</span> if <span class="math inline">\(|\alpha| &gt; |\beta|\)</span>, or <span class="math inline">\(|\alpha| = |\beta|\)</span> and <span class="math inline">\(\alpha \succ_{\mathrm{lex}}\beta\)</span>.</p></li>
<li><p><strong>Graded reverse lexicographic</strong>. Here <span class="math inline">\(\alpha \succ_{\mathrm{grevlex}}\beta\)</span> if <span class="math inline">\(|\alpha| &gt; |\beta|\)</span> or <span class="math inline">\(|\alpha| = |\beta|\)</span> but the right-most nonzero entry of <span class="math inline">\(\alpha - \beta\)</span> is negative. This ordering, although somewhat nonintuitive, has some desirable computational properties.</p></li>
</ul>
<div class="examplebox">
<div class="example">
<p><span id="exm:MonomialOrdering" class="example"><strong>Example 4.2  (Monomial Ordering) </strong></span>Consider the polynomial ring <span class="math inline">\(\mathbb{C}[x,y]\)</span> in two variables. With the lexicographic ordering <span class="math inline">\(\prec_{\mathrm{lex}}\)</span>, we have
<span class="math display">\[
1 \prec_{\mathrm{lex}}y \prec_{\mathrm{lex}}y^2 \prec_{\mathrm{lex}}\cdots \prec_{\mathrm{lex}}x \prec_{\mathrm{lex}}xy \prec_{\mathrm{lex}}xy^2 \prec_{\mathrm{lex}}\cdots \prec_{\mathrm{lex}}x^2 \prec_{\mathrm{lex}}x^2 y \prec_{\mathrm{lex}}x^2 y^2 \prec_{\mathrm{lex}}\cdots.
\]</span>
For the other two orderings <span class="math inline">\(\prec_{\mathrm{grlex}}\)</span> and <span class="math inline">\(\prec_{\mathrm{grevlex}}\)</span>, which in the case of two variables are the same, we have
<span class="math display">\[
1 \prec y \prec x \prec y^2 \prec xy \prec x^2 \prec y^3 \prec xy^2 \prec x^2 y \prec x^3 \prec \cdots.
\]</span></p>
<p>As another example, consider the monomials <span class="math inline">\(\alpha = x^3 y^2 z^8\)</span> and <span class="math inline">\(\beta = x^2 y^9 z^2\)</span>. If the variables are ordered as <span class="math inline">\((x,y,z)\)</span>, then
<span class="math display">\[
\alpha \succ_{\mathrm{lex}}\beta, \quad \alpha \succ_{\mathrm{grlex}}\beta, \quad \alpha \prec_{\mathrm{grevlex}}\beta.
\]</span>
Note that <span class="math inline">\(x \succ y \succ z\)</span> for all three orderings.</p>
</div>
</div>
<p>We define a monomial ideal.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:MonomialIdeal" class="definition"><strong>Definition 4.9  (Monomial Ideal) </strong></span>A monomial ideal is a polynomial ideal that can be generated by monomials.</p>
</div>
</div>
<p>What are the possible monomials that belong to a given monomial ideal? Since <span class="math inline">\(x^\alpha \in I \Rightarrow x^{\alpha + \beta} \in I\)</span> for any <span class="math inline">\(\beta \geq 0\)</span>, we have that these sets are “closed upwards”.</p>
<p>A polynomial belongs to a monomial ideal <span class="math inline">\(I\)</span> if and only if its terms are in <span class="math inline">\(I\)</span>.</p>
<p>Similarly, we have that every monomial ideal is finitely generated.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:Dickson" class="theorem"><strong>Theorem 4.3  (Dickson's Lemma) </strong></span>Every monomial ideal is finitely generated.</p>
</div>
</div>
<p>We next consider a special monomial ideal, associated with every polynomial ideal. From now on, we assume a fixed monomial ordering (e.g., graded reverse lexicographic), and define the notion of an initial ideal.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:InitialIdeal" class="definition"><strong>Definition 4.10  (Initial Ideal) </strong></span>Denote by <span class="math inline">\(\mathrm{in}(f)\)</span> the “largest” (or leading) monomial appearing in the polynomial <span class="math inline">\(f\neq 0\)</span>. Consider an ideal <span class="math inline">\(I \subset \mathbb{C}[x]\)</span> with a fixed monomial ordering. The initial ideal of <span class="math inline">\(I\)</span>, denoted by <span class="math inline">\(\mathrm{in}(I)\)</span>, is the monomial ideal generated by the leading monomials of all the elements in <span class="math inline">\(I\)</span>, i.e.,
<span class="math display">\[
\mathrm{in}(I) = \mathrm{Ideal}[\{ \mathrm{in}(f) \mid f \in I \backslash \{0\} \}].
\]</span>
A monomial <span class="math inline">\(x^\alpha\)</span> is called <strong>standard</strong> if it does not belong to the initial ideal <span class="math inline">\(\mathrm{in}(I)\)</span>.</p>
</div>
</div>
<p>Given an ideal <span class="math inline">\(I = \mathrm{Ideal}[f_1,\dots,f_s]\)</span>, we can construct two monomial ideals associated with it:</p>
<ul>
<li><p>The initial ideal <span class="math inline">\(\mathrm{in}(I)\)</span> as defined in Definition <a href="SOS.html#def:InitialIdeal">4.10</a>.</p></li>
<li><p>The monomial ideal generated by the leading monomials of the generators, i.e.,
<span class="math display">\[
\mathrm{Ideal}[\mathrm{in}(f_1),\dots,\mathrm{in}(f_s)].
\]</span></p></li>
</ul>
<p>Clearly, we have
<span class="math display">\[
\mathrm{Ideal}[\mathrm{in}(f_1),\dots,\mathrm{in}(f_s)] \subseteq \mathrm{in}(I).
\]</span></p>
<div class="examplebox">
<div class="example">
<p><span id="exm:InitialIdeal" class="example"><strong>Example 4.3  (Initial Ideal and the Ideal of Initials) </strong></span>Consider the ideal
<span class="math display">\[
I = \mathrm{Ideal}[x^3 -1, x^2 + 1],
\]</span>
we have <span class="math inline">\(1 \in I\)</span> due to
<span class="math display">\[
1 = \frac{1}{2}(x-1)(x^3 - 1) - \frac{1}{2}(x^2 - x - 1)(x^2 +1).
\]</span>
Therefore, <span class="math inline">\(\mathrm{in}(I) = I = \mathbb{C}[x]\)</span>. On the other hand, the monomial ideal generated by the leading monomials is
<span class="math display">\[
\mathrm{Ideal}[x^3, x^2],
\]</span>
and clearly does not contain <span class="math inline">\(1\)</span>.</p>
</div>
</div>
<p>We have seen that in general these two monomial ideals are not the same. However, is it possible to find a set of generators for which the two monomial ideals are the same? This is exactly the notion of a Gröbner basis.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:GrobnerBasis" class="definition"><strong>Definition 4.11  (Gröbner Basis) </strong></span>Consider the polynomial ring <span class="math inline">\(\mathbb{C}[x]\)</span>, a fixed monomial ordering, and an ideal <span class="math inline">\(I\)</span>. A finite set of polynomials <span class="math inline">\(\{ g_1,\dots,g_s \} \subset I\)</span> is a Gröbner basis of <span class="math inline">\(I\)</span> if the initial ideal of <span class="math inline">\(I\)</span> is generated by the leading terms of the <span class="math inline">\(g_i\)</span>’s, i.e.,
<span class="math display">\[
\mathrm{in}(I) = \mathrm{Ideal}[\mathrm{in}(g_1),\dots,\mathrm{in}(g_s)].
\]</span></p>
</div>
</div>
<p>We have the result that every ideal has a Grobner basis.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:GrobnerBasis" class="theorem"><strong>Theorem 4.4  (Gröbner Basis) </strong></span>Every ideal <span class="math inline">\(I\)</span> has a Grobner basis. Further, <span class="math inline">\(I = \mathrm{Ideal}[g_1,\dots,g_s]\)</span>.</p>
</div>
</div>
<p>Theorem <a href="SOS.html#thm:GrobnerBasis">4.4</a> indeed proves the Hilbert Basis Theorem <a href="SOS.html#thm:HilbertBasisTheorem">4.1</a>.</p>
<p>Note that the Grobner basis as defined is not unique. It can be fixed to define a so-called <strong>reduced Gröbner Basis</strong>, which is unique when fixing a monomial ordering.</p>
<p>There exist numerical algorithms that can compute the Grobner basis. The most well-known algorithm is called Buchberger’s algorithm, developed by Bruno Buchberger around 1965. The algorithm, however, is in general slow because it is double exponential time. Several software packages provide implementations that can compute the Grobner basis, for example Mathematica, Maple, Macaulay2, and Matlab.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:GrobnerBasis" class="example"><strong>Example 4.4  (Grobner Basis) </strong></span>Consider the ideal <span class="math inline">\(I = \mathrm{Ideal}[x^2+y^2-2, x^2 - y^2]\)</span>. The affine variety of <span class="math inline">\(I\)</span> is finite and only contains four points <span class="math inline">\((\pm 1, \pm 1)\)</span>. It is easy to see that the given generators are not a Grobner basis.</p>
<p>Computing a Grobner basis (e.g., using the <a href="https://www.mathworks.com/help/symbolic/sym.gbasis.html">Matlab <code>gbasis</code> function</a>) gives us
<span class="math display">\[
\{ x^2 - 1, y^2 - 1 \}.
\]</span>
The standard monomials are <span class="math inline">\(\{ 1,x,y,xy \}\)</span>.</p>
</div>
</div>
<p>We will see that Grobner basis is a powerful tool with many applications in computational algebra. For a brief introduction to Grobner Basis, see <span class="citation">(<a href="#ref-sturmfels05notes-grobner">Sturmfels 2005</a>)</span>.</p>
</div>
<div id="quotient-ring" class="section level3 hasAnchor" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> Quotient Ring<a href="SOS.html#quotient-ring" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Given an ideal <span class="math inline">\(I\)</span>, we can immediately define a notion of <strong>equivalence classess</strong>, where we identify two elements in the ring if and only if their difference is in the ideal.</p>
<p>For example, in the ring of integers <span class="math inline">\(\mathbb{Z}\)</span>, the set of even integers is an ideal. We can identify two integers as the same if their difference is even. This effectively divides the ring <span class="math inline">\(\mathbb{Z}\)</span> into two equivalence classess, the set of odd and even integers.</p>
<p>We can do the same for the ring of polynomials <span class="math inline">\(\mathbb{C}[x]\)</span> given an ideal <span class="math inline">\(I\)</span>.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:CongruenceIdeal" class="definition"><strong>Definition 4.12  (Congruence) </strong></span>Let <span class="math inline">\(I \subset \mathbb{C}[x]\)</span> be an ideal. We are two polynomials <span class="math inline">\(f,g \in \mathbb{C}[x]\)</span> is <strong>congruent</strong> modulo <span class="math inline">\(I\)</span>, written as
<span class="math display">\[
f \equiv g \quad \text{mod } I,
\]</span>
if <span class="math inline">\(f - g \in I\)</span>.</p>
</div>
</div>
<p>It is easy to see that this is an <a href="https://en.wikipedia.org/wiki/Equivalence_relation">equivalence relation</a>, i.e., it is reflexive, symmetric, and transitive. Therefore, an ideal <span class="math inline">\(I\)</span> partitions <span class="math inline">\(\mathbb{C}[x]\)</span> into equivalence classes, where two polynomials are the same if their difference belongs to the ideal. This allows us to define the notion of a quotient ring.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:QuotientRing" class="definition"><strong>Definition 4.13  (Quotient Ring) </strong></span>The quotient <span class="math inline">\(\mathbb{C}[x]/I\)</span> is the set of equivalence classes for congruence modulo <span class="math inline">\(I\)</span>.</p>
</div>
</div>
<p>The quotient <span class="math inline">\(\mathbb{C}[x]/I\)</span> inherits the ring structure of <span class="math inline">\(\mathbb{C}[x]\)</span>. With the addition and multiplication operations defined between equivalence classes, <span class="math inline">\(\mathbb{C}[x]/I\)</span> becomes a ring, known as the quotient ring. Indeed, given a polynomial <span class="math inline">\(p\)</span>, the set of all polynomials equivalent to <span class="math inline">\(p\)</span> is denoted as
<span class="math display">\[
[p]:= \{ p + q \mid q \in I \}.
\]</span>
We have <span class="math inline">\([p] = [q]\)</span> if and only if <span class="math inline">\(p - q \in I\)</span>. Given two equivalent classes <span class="math inline">\([p]\)</span> and <span class="math inline">\([q]\)</span>, the addition and multiplication are defined as
<span class="math display">\[
[p] + [q] = [p+q], \quad [p] \cdot [q] = [p q].
\]</span>
One can verify that <span class="math inline">\((\mathbb{C}[x],+,\cdot)\)</span> with <span class="math inline">\(+\)</span> and <span class="math inline">\(\cdot\)</span> defined above forms a ring structure.</p>
<p>The quotient ring <span class="math inline">\(\mathbb{C}[x]/I\)</span> is in fact a vector space, and the Grobner basis gives us a way to find a set of basis in the quotient ring! Let <span class="math inline">\(G\)</span> be a Grobner basis of the ideal <span class="math inline">\(I\)</span>, and recall from Definition <a href="SOS.html#def:InitialIdeal">4.10</a> that a monomial is standard if it does not belong to the initial ideal <span class="math inline">\(\mathrm{in}(I)\)</span>. This implies that when the Grobner basis is available, the set of all <strong>standard monomials</strong> can be directly read off from the Grobner basis, as in Example <a href="SOS.html#exm:GrobnerBasis">4.4</a>. Let <span class="math inline">\(S\)</span> be this set of standard monomials, then the basis of the quotient ring is simply
<span class="math display">\[
\{ [s] \mid s\in S \}.
\]</span>
Note that the quotient ring needs not be finite-dimensional as the set of standard monomials can be infinite. Given such a basis of the quotient ring, we can associate every polynomial with a <strong>normal form</strong> that is a linear combination of the standard monomials.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:NormalForm" class="definition"><strong>Definition 4.14  (Normal Form) </strong></span>Let <span class="math inline">\(G\)</span> be a Grobner basis of the ideal <span class="math inline">\(I \subset \mathbb{C}[x]\)</span>. Given any <span class="math inline">\(p \in \mathbb{C}[x]\)</span>, there exists a unique polynomial <span class="math inline">\(\bar{p}\)</span>, called the <strong>normal form</strong> of <span class="math inline">\(p\)</span> such that</p>
<ul>
<li><p><span class="math inline">\(p\)</span> and <span class="math inline">\(\bar{p}\)</span> are congruent mod <span class="math inline">\(I\)</span>, i.e., <span class="math inline">\(p - \bar{p} \in I\)</span>.</p></li>
<li><p>Only standard monomials appear in <span class="math inline">\(\bar{p}\)</span>.</p></li>
</ul>
</div>
</div>
<p>Note that since <span class="math inline">\(p - \bar{p} \in I\)</span>, we have
<span class="math display">\[
p = \sum_{i}^s\lambda_i g_i + \bar{p}, \quad g_i \in G.
\]</span>
Therefore, the normal form <span class="math inline">\(\bar{p}\)</span> can be interpreted as the “reminder” of <span class="math inline">\(p\)</span> divided by the ideal <span class="math inline">\(I\)</span>. The unique property of the Grobner basis ensures that the normal form is unique and it is just a <span class="math inline">\(\mathbb{C}\)</span>-combination of the standard monomials.</p>
<p>As a consequence, we can check the ideal membership of a given polynomial. Indeed, a polynomial <span class="math inline">\(p\)</span> belongs to the ideal <span class="math inline">\(I\)</span> if and only if its normal form is the zero polynomial.</p>
<p>See an example of using Grobner basis to compute the normal form in the <a href="https://www.maplesoft.com/support/help/maple/view.aspx?path=Groebner%2FNormalForm">Maple software</a>.</p>
</div>
<div id="zero-dimensional-ideal" class="section level3 hasAnchor" number="4.1.5">
<h3><span class="header-section-number">4.1.5</span> Zero-dimensional Ideal<a href="SOS.html#zero-dimensional-ideal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In practice, we are often interested in polynomial systems that have only a finite number of solutions, in which case the associated ideal is called zero-dimensional.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:ZeroDimensional" class="definition"><strong>Definition 4.15  (Zero-Dimensional Ideal) </strong></span>An ideal <span class="math inline">\(I\)</span> is zero-dimensional if the associated affine variety <span class="math inline">\(V_{\mathbb{C}}(I)\)</span> is a finite set.</p>
</div>
</div>
<p>Note that the variety <span class="math inline">\(V_{\mathbb{C}}(I)\)</span> having a finite number of points is stronger than <span class="math inline">\(V_{\mathbb{R}}(I)\)</span> have a finite number of points.</p>
<p>The following result characterizes when an ideal is zero-dimensional.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:FiniteTheorem" class="theorem"><strong>Theorem 4.5  (Finiteness Theorem) </strong></span>Let <span class="math inline">\(I \subset \mathbb{C}[x]\)</span> be an ideal. Fix a monomial ordering and let <span class="math inline">\(G\)</span> be a Grobner basis of <span class="math inline">\(I\)</span>. Then the following statements are equivalent.</p>
<ol style="list-style-type: decimal">
<li><p>The ideal <span class="math inline">\(I\)</span> is finite-dimensional (i.e., <span class="math inline">\(V(I)\)</span> is a finite set of points).</p></li>
<li><p>The quotient ring <span class="math inline">\(\mathbb{C}[x]/I\)</span> is a finite-dimensional vector space (i.e., there are a finite number of standard monomials).</p></li>
<li><p>For each <span class="math inline">\(x_i, i=1,\dots,n\)</span>, there exists an integer <span class="math inline">\(m_i \in \mathbb{N}\)</span> such that <span class="math inline">\(x_i^{m_i}\)</span> is the leading monomial of some <span class="math inline">\(g \in G\)</span>.</p></li>
</ol>
</div>
</div>
<p>Let us work out an example.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:ZeroDIdeal" class="example"><strong>Example 4.5  (Zero-dimensional Ideal) </strong></span>Consider the ideal in <span class="math inline">\(\mathbb{C}[x,y]\)</span>:
<span class="math display">\[
I = \mathrm{Ideal}[xy^3-x^2, x^3y^2 - y].
\]</span>
Using the graded lexicographic monomial ordering, we obtain the reduced Grobner basis
<span class="math display">\[
G = \{ x^3 y^2 - y, x^4 - y^2,  xy^3 - x^2, y^4 - xy \}.
\]</span>
We can see that <span class="math inline">\(x^4\)</span> is the leading monomial of <span class="math inline">\(x^4 - y^2\)</span>, and <span class="math inline">\(y^4\)</span> is the leading monomial of <span class="math inline">\(y^4 - xy\)</span>. Therefore, we know <span class="math inline">\(I\)</span> is zero-dimensional. We can also see this by checking the number of standard monomials. The standard monomials are those that do not belong to the initial ideal <span class="math inline">\(\mathrm{in}(I)\)</span>, which in the case of a Grobner basis, is simply
<span class="math display">\[
\mathrm{in}(I) = \mathrm{Ideal}[x^3 y^2, x^4, xy^3, y^4].
\]</span>
This is a monomial ideal and hence is “closed upwards”. The shaded gray areas in Fig. <a href="SOS.html#fig:ZeroDimensional1">4.1</a> shows all the monomials in the initial ideal, whose boundary forms a “staircase”. The standard monomials, shown as blue squares in the figure, are those that are below the staircase:
<span class="math display">\[
1,x,x^2,x^3,y,xy,x^2 y, x^3 y, y^2, xy^2, x^2 y^2, y^3.
\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ZeroDimensional1"></span>
<img src="images/zero_dimensional_1.png" alt="Initial ideal and the standard monomials with graded lexicographic monomial ordering." width="60%" />
<p class="caption">
Figure 4.1: Initial ideal and the standard monomials with graded lexicographic monomial ordering.
</p>
</div>
<p>We can change the monomial ordering and see what happens. Let us use the lexicographic monomial ordering this time. We obtain the reduced Grobner basis
<span class="math display">\[
G = \{ x^2-y^6, xy - y^4, y^{11} - y \}.
\]</span>
The monomial <span class="math inline">\(x^2\)</span> is the leading monomial of <span class="math inline">\(x^2 - y^6\)</span>, and the monomial <span class="math inline">\(y^{11}\)</span> is the leading monomial of <span class="math inline">\(y^11 - y\)</span>. Hence, the ideal is verified to be zero-dimensional as well. A different monomial ordering does change the set of standard monomials. Fig. <a href="SOS.html#fig:ZeroDimensional2">4.2</a> shows the initial ideal and the standard monomials (blue squares) under the staircase:
<span class="math display">\[
1,x,y,y^2,y^3,y^4,y^5,y^6,y^7,y^8,y^9,y^{10}.
\]</span>
Though the set of standard monomials has changed, the number of standard monomials remains to be <span class="math inline">\(12\)</span>. This makes sense because the dimension of the quotient ring <span class="math inline">\(\mathbb{C}[x]/I\)</span> should not change.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ZeroDimensional2"></span>
<img src="images/zero_dimensional_2.png" alt="Initial ideal and the standard monomials with lexicographic monomial ordering." width="60%" />
<p class="caption">
Figure 4.2: Initial ideal and the standard monomials with lexicographic monomial ordering.
</p>
</div>
<p>The code for computing the Grobner basis can be found <a href="https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/zero_d_ideal.m">here</a>.</p>
</div>
</div>
<p>If an ideal <span class="math inline">\(I\)</span> is zero-dimensional, can we find all the points in the affine variety <span class="math inline">\(V(I)\)</span>? The next result shows that the number of points in <span class="math inline">\(V(I)\)</span> (counting multiplicity) is precisely the number of standard monomials.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:PolySysRoots" class="theorem"><strong>Theorem 4.6  (Number of Roots) </strong></span>If an ideal <span class="math inline">\(I \subset \mathbb{C}[x]\)</span> is zero-dimensional, then the number of standard monomials equals to the cardinality of <span class="math inline">\(V(I)\)</span>, counting multiplicities.</p>
</div>
</div>
<p>Once a set of standard monomials is found, we can also design a numerical procedure to compute the roots of the polynomial system of equations. For each <span class="math inline">\(x_i,\dots,x_n\)</span>, define the multiplication mapping
<span class="math display">\[
\mathcal{M}_{x_i}: \mathbb{C}[x]/I \rightarrow \mathbb{C}[x]/I, \quad [p] \rightarrow [x_i p].
\]</span>
It can be shown that <span class="math inline">\(\mathcal{M}_{x_i}\)</span> is a linear mapping. Let <span class="math inline">\(M_{x_i}\)</span> be the matrix representation of this linear map using <span class="math inline">\(S\)</span>, the set of standard monomials, as the basis of the quotient ring <span class="math inline">\(\mathbb{C}[x]/I\)</span>. <span class="math inline">\(M_{x_i}\)</span> is called the <strong>companion matrix</strong> or <strong>multiplication matrix</strong> of the ideal <span class="math inline">\(I\)</span> with respect to <span class="math inline">\(x_i\)</span>. The companion matrices <span class="math inline">\(M_{x_1},\dots,M_{x_n}\)</span> commute with each other and share common eigenvectors. The affine variety <span class="math inline">\(V_{\mathbb{C}}(I)\)</span> can be determined by eigenvalues of the companion matrices.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:StickelbergerTheorem" class="theorem"><strong>Theorem 4.7  (Stickelberger's Theorem) </strong></span>Let <span class="math inline">\(I \subset \mathbb{C}[x]\)</span> be a zero-dimensional ideal and let <span class="math inline">\(M_{x_1},\dots,M_{x_n}\)</span> be the companion matrices, then
<span class="math display">\[
V_{\mathbb{C}}(I) = \{ (\lambda_1,\dots,\lambda_n) \mid \exists v \in \mathbb{C}^D \backslash \{0 \}, M_{x_i} v = \lambda_i v, i=1,\dots,n  \},
\]</span>
where <span class="math inline">\(D\)</span> is the dimension of the quotient ring <span class="math inline">\(\mathbb{C}[x]/I\)</span>.</p>
</div>
</div>
<p>With Stickelberger’s Theorem, one can further show that a zero-dimensional ideal <span class="math inline">\(I\)</span> is radical if and only if the companion matrices <span class="math inline">\(M_{x_1},\dots,M_{x_n}\)</span> are simultaneously diagonalizable, which occurs if and only if the cardinality <span class="math inline">\(|V_{\mathbb{C}}(I)| = D\)</span>.</p>
<p>Let us make Stickelberger’s Theorem concrete through an example.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:SolvingPolynomialSystem" class="example"><strong>Example 4.6  (Solving Polynomial Equations) </strong></span>Consider the ideal <span class="math inline">\(I \subset \mathbb{C}[x,y,z]\)</span>
<span class="math display">\[
I = \mathrm{Ideal}[xy-z, yz -x, zx - y].
\]</span>
Choosing lexicographic monomial ordering, we get the Groebner basis
<span class="math display">\[
G = \{ z - yx, y^2 - x^2, yx^2 - y, x^3 - x \}.
\]</span>
We can see that this ideal is zero-dimensional (due to <span class="math inline">\(z\)</span>, <span class="math inline">\(y^2\)</span>, <span class="math inline">\(x^3\)</span> being the leading monomials in <span class="math inline">\(G\)</span>). The standard monomials are
<span class="math display">\[
S = \{ 1, x, x^2, y, yx \}.
\]</span>
We now need to form the matrices <span class="math inline">\(M_x, M_y, M_z\)</span>.
This can be done as follows.
<span class="math display">\[
\mathrm{NormalForm}\left(
x \cdot \begin{bmatrix}
1 \\
x \\
x^2 \\
y \\
yx
\end{bmatrix}
\right) =
\begin{bmatrix}
x \\
x^2 \\
x \\
xy \\
y \end{bmatrix} =
\underbrace{\begin{bmatrix}
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0
\end{bmatrix}}_{M_x}
\begin{bmatrix}
1 \\
x \\
x^2 \\
y \\
yx
\end{bmatrix}
\]</span>
<span class="math display">\[
\mathrm{NormalForm}\left(
y \cdot \begin{bmatrix}
1 \\
x \\
x^2 \\
y \\
yx
\end{bmatrix}
\right) =
\begin{bmatrix}
y \\
xy \\
y \\
x^2 \\
x \end{bmatrix} =
\underbrace{\begin{bmatrix}
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}}_{M_y}
\begin{bmatrix}
1 \\
x \\
x^2 \\
y \\
yx
\end{bmatrix}
\]</span>
<span class="math display">\[
\mathrm{NormalForm}\left(
z \cdot \begin{bmatrix}
1 \\
x \\
x^2 \\
y \\
yx
\end{bmatrix}
\right) =
\begin{bmatrix}
yx \\
y \\
xy \\
x \\
x^2 \end{bmatrix} =
\underbrace{\begin{bmatrix}
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0
\end{bmatrix}}_{M_z}
\begin{bmatrix}
1 \\
x \\
x^2 \\
y \\
yx
\end{bmatrix}
\]</span>
We can then simultaneously diagonalize <span class="math inline">\(M_x,M_y,M_z\)</span> using the following matrix
<span class="math display">\[
V = \frac{1}{4}\begin{bmatrix}
4 &amp; 0 &amp; -4 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 1 &amp; 1 &amp; 1\\
0 &amp; 1 &amp; 1 &amp; -1 &amp; -1 \\
0 &amp; -1 &amp; 1 &amp; 1 &amp; -1 \\
0 &amp; -1 &amp; 1 &amp; -1 &amp; 1
\end{bmatrix}, \quad
V^{-1}= \begin{bmatrix}
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\\
0 &amp; 1 &amp; 1 &amp; -1 &amp; -1\\
0 &amp; 1 &amp; 1 &amp; 1 &amp; 1\\
0 &amp; 1 &amp; -1 &amp; 1 &amp; -1 \\
0 &amp; 1 &amp; -1 &amp; -1 &amp; 1
\end{bmatrix}.
\]</span>
The result is
<span class="math display">\[\begin{equation}
\begin{split}
V M_x V^{-1}&amp;= \mathrm{diag}(0 , 1, 1, -1, -1)\\
V M_y V^{-1}&amp;= \mathrm{diag}(0 , 1, -1, 1, -1)\\
V M_z V^{-1}&amp;= \mathrm{diag}(0 , 1, -1, -1, 1)
\end{split}.
\end{equation}\]</span>
Therefore, the five roots of the polynomial system is
<span class="math display">\[
\begin{pmatrix}
x \\ y \\ z
\end{pmatrix} =
\left\{
    \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix},
    \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix},
    \begin{pmatrix} 1 \\ -1 \\ -1 \end{pmatrix},
    \begin{pmatrix} -1 \\ 1 \\ -1 \end{pmatrix},
    \begin{pmatrix} -1 \\ -1 \\ 1 \end{pmatrix}
\right\} .
\]</span></p>
</div>
</div>
<p>In practice, instead of simultaneously diagonalizing the companion matrices, a Schur decomposition type method is used to compute the roots <span class="citation">(<a href="#ref-corless97-reordered">Corless, Gianni, and Trager 1997</a>)</span>. We will see that in the homework.</p>
</div>
<div id="algebraic-and-semialgebraic-sets" class="section level3 hasAnchor" number="4.1.6">
<h3><span class="header-section-number">4.1.6</span> Algebraic and Semialgebraic Sets<a href="SOS.html#algebraic-and-semialgebraic-sets" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An <strong>algebraic set</strong> in <span class="math inline">\(\mathbb{R}^{n}\)</span> is the set of common <strong>real</strong> roots of a set of polynomials. For instance, the unit sphere is an algebraic set because it is real zero set of the polynomial <span class="math inline">\(x_1^2 + \dots + x_n^2 - 1\)</span>.</p>
<p>Intersections and unions of finitely many algebraic sets are again algebraic sets. A nonempty algebraic set is said to be <strong>irreducible</strong> if it cannot be written as a union of two distinct proper algebraic subsets; otherwise it is called reducible. Every algebraic set is the union of finitely many irreducible ones.</p>
<p>More general than algebraic sets are <strong>semialgebraic sets</strong>.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:BasisSemialgebraic" class="definition"><strong>Definition 4.16  (Basic Semialgebraic Set) </strong></span>A set <span class="math inline">\(S \subset \mathbb{R}^{n}\)</span> defined as
<span class="math display">\[
S = \{ x \in \mathbb{R}^{n} \mid f_i(x) \triangleright_i 0, i=1,\dots,\ell  \},
\]</span>
where for each <span class="math inline">\(i\)</span>, <span class="math inline">\(\triangleright_i\)</span> is one of <span class="math inline">\(\{ \geq, &gt;, =, \neq \}\)</span> and <span class="math inline">\(f_i(x) \in \mathbb{R}[x]\)</span>, is called a basic semialgebraic set.</p>
<p>A basic closed semialgebraic set is a set of the form
<span class="math display">\[
S = \{ x \in \mathbb{R}^{n} \mid f_1\geq 0, \dots f_\ell(x) \geq 0 \}.
\]</span></p>
</div>
</div>
<p>Every basic semialgebraic set can be expressed with polynomial inequalities of the form <span class="math inline">\(f(x) \geq 0\)</span> and a single inequality <span class="math inline">\(g \neq 0\)</span>.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:SemialgebraicSet" class="definition"><strong>Definition 4.17  (Semialgebraic Set) </strong></span>A finite union of basic semialgebraic sets in <span class="math inline">\(\mathbb{R}^{n}\)</span> is called a semialgebraic set, and a finite union of basic closed semialgebraic sets is a closed semialgebraic set.</p>
</div>
</div>
<p>Semialgebraic sets are closed under finite unions, finite intersections, and complementation. The following theorem states that they are also closed under projections.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:TarskiSeidenberg" class="theorem"><strong>Theorem 4.8  (Tarski-Seidenberg Theorem) </strong></span>Let <span class="math inline">\(S \subset \mathbb{R}^{k+n}\)</span> be a semialgebraic set and <span class="math inline">\(\pi : \mathbb{R}^{k+n} \rightarrow \mathbb{R}^{n}\)</span> be the projection map that sends <span class="math inline">\((y,x) \mapsto x\)</span>. Then <span class="math inline">\(\pi(S)\)</span> is a semialgebraic set in <span class="math inline">\(\mathbb{R}^{n}\)</span>.</p>
</div>
</div>
<p>Note that an algebraic set is not closed under projection. For example consider the algebraic set defined by <span class="math inline">\(xy = 1\)</span>. The projection of this algebraic set to <span class="math inline">\(x\)</span> is defined by <span class="math inline">\(x \neq 0\)</span>, which is not an algebraic set, but a semialgebraic set.</p>
<p>Semialgebraic functions are similarly defined. Let <span class="math inline">\(f: D \rightarrow \mathbb{R}^{}\)</span> be a real-valued function where the domain <span class="math inline">\(D\)</span> is a semialgebraic set. Then <span class="math inline">\(f\)</span> is called a <strong>semialgebraic function</strong> if the graph <span class="math inline">\(\{ (x,y) \mid x \in D, f(x)=y \}\)</span> is a semialgebraic set.</p>
</div>
</div>
<div id="sos-and-nonnegative-polynomials" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> SOS and Nonnegative Polynomials<a href="SOS.html#sos-and-nonnegative-polynomials" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="nonnegative-polynomials" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Nonnegative polynomials<a href="SOS.html#nonnegative-polynomials" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider polynomials in <span class="math inline">\(n\)</span> variables with real coefficients, i.e., the set <span class="math inline">\(\mathbb{R}[x]\)</span>. A polynomial <span class="math inline">\(p(x_1,\dots,x_n)\)</span> is nonnegative if
<span class="math display">\[
p(x_1,\dots,x_n) \geq 0, \quad \forall (x_1,\dots,x_n) \in \mathbb{R}^{n}.
\]</span></p>
<p>Of couse, a natural question is, given a polynomial <span class="math inline">\(p(x)\)</span>, is it possible to efficiently decide whether <span class="math inline">\(p(x)\)</span> is nonnegative?</p>
<p><strong>Univariate Polynomials</strong>. Let us start the discussion on univariate polynomials, i.e., polynomials in a single variable <span class="math inline">\(x\)</span>. A univariate polynomial of degree <span class="math inline">\(d\)</span> can be written as
<span class="math display" id="eq:univariate-poly">\[\begin{equation}
p(x) = p_d x^d + p_{d-1} x^{d-1} + \cdots + p_1 x + p_0.
\tag{4.1}
\end{equation}\]</span>
Without loss of generality, we can assume <span class="math inline">\(p_d = 1\)</span>, in which case the polynomial is said to be <strong>monic</strong>. The univariate polynomial can also be written as
<span class="math display" id="eq:univariate-poly-root">\[\begin{equation}
p(x) = p_d \prod_{i=1}^d (x - x_i),
\tag{4.2}
\end{equation}\]</span>
with <span class="math inline">\(x_i,i=1,\dots,d\)</span> its complex roots that may have multiplicities.</p>
<p>How do we decide if <span class="math inline">\(p(x)\)</span> is nonnegative? A simple necessary condition is that <span class="math inline">\(d\)</span> must be even. Otherwise if <span class="math inline">\(d\)</span> is odd, then either pushing <span class="math inline">\(x \rightarrow \infty\)</span> or <span class="math inline">\(x \rightarrow -infinity\)</span> will lead to <span class="math inline">\(p(x)\)</span> negative.</p>
<p>In certain cases it is easy to derive an explict characterization of nonnegativity.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:NonnegativeQuadratic" class="example"><strong>Example 4.7  (Univaraite Quadratic Polynomial) </strong></span>Let <span class="math inline">\(p(x) = x^2 + p_1 x + p_0\)</span> be a monic quadratic polynomial. Clearly, <span class="math inline">\(p(x) \geq 0\)</span> if and only if
<span class="math display">\[
\min_{x} p(x) \geq 0.
\]</span>
Since <span class="math inline">\(p(x)\)</span> is convex, its global minimum can be easily computed by setting its gradient to zero, which gives
<span class="math display">\[
x_\star = - \frac{p_1}{2}, \quad p(x_\star) = p_0 - \frac{p_1^2}{4}.
\]</span>
Therefore, <span class="math inline">\(p(x)\)</span> is nonnegative if and only if
<span class="math display">\[
4 p_0 - p_1^2 \geq 0.
\]</span></p>
</div>
</div>
<p>For general univariate polynomials, we describe a technique known as the Hermite method for deciding nonnegativity. Consider a monic polynomial as in <a href="SOS.html#eq:univariate-poly">(4.1)</a> and <a href="SOS.html#eq:univariate-poly-root">(4.2)</a> and define its associated <strong>Hermite matrix</strong> as the following <span class="math inline">\(d \times d\)</span> symmetric Hankel matrix
<span class="math display">\[
H_1(p) = \begin{bmatrix}
s_0 &amp; s_1 &amp; \cdots &amp; s_{d-1} \\
s_1 &amp; s_2 &amp; \cdots &amp; s_d \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
s_{d-1} &amp; s_d &amp; \cdots &amp; s_{2d-2}
\end{bmatrix}, \quad s_k = \sum_{j=1}^d x_j^k,
\]</span>
where recall <span class="math inline">\(x_j,j=1,\dots,d\)</span> are the roots of <span class="math inline">\(p\)</span>. The quantities <span class="math inline">\(s_k\)</span> are known as the power sums. The follow lemma states that the power sums can be computed without computing the roots.</p>
<div class="theorembox">
<div class="lemma">
<p><span id="lem:NewtonIdentity" class="lemma"><strong>Lemma 4.1  (Newton Identities) </strong></span>The power sums <span class="math inline">\(s_k\)</span> satisfy the following recursive equations known as the Newton identities:
<span class="math display">\[
s_0 = d, \quad s_k = -1\left(k p_{d-k} + \sum_{i=1}^{k-1} p_{d-i} s_{k-i} \right), k=1,2,\dots.
\]</span></p>
</div>
</div>
<p>After forming the Hermite matrix, its rank and signature tells us the number of complex and real roots.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:HermiteMatrix" class="theorem"><strong>Theorem 4.9  (Hermite Matrix) </strong></span>The rank of the Hermite matrix <span class="math inline">\(H_1(p)\)</span> is equal to the number of distinct complex roots. The signature of <span class="math inline">\(H_1(p)\)</span> is equal to the number of distinct real roots.</p>
</div>
</div>
<p>Recall that given a symmetric matrix <span class="math inline">\(A\)</span>, its <strong>inertia</strong>, denoted <span class="math inline">\(\mathcal{I}(A)\)</span>, is the triplet <span class="math inline">\((n_+, n_0, n_{-})\)</span>, where <span class="math inline">\(n_+,n_0, n_-\)</span> are the number of positive, zero, and negative eigenvalues, respectively. The <strong>signature</strong> of <span class="math inline">\(A\)</span> is equal to <span class="math inline">\(n_+ - n_-\)</span>.</p>
<p>With the Hermite matrix, we can decide nonnegativity.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:NonnegativityHermite" class="theorem"><strong>Theorem 4.10  (Nonnegativity from Hermite Matrix) </strong></span>Let <span class="math inline">\(p(x)\)</span> be a monic polynomial of degree <span class="math inline">\(2d\)</span>. Then the following statements are equivalent.</p>
<ol style="list-style-type: decimal">
<li><p>The polynomial <span class="math inline">\(p(x)\)</span> is strictly positive.</p></li>
<li><p>The polynomial <span class="math inline">\(p(x)\)</span> has no real roots.</p></li>
<li><p>The inertia of the Hermite matrix is <span class="math inline">\(\mathcal{I}(H_1(p)) = (k, 2d-k, k)\)</span> for some <span class="math inline">\(1 \leq k \leq d\)</span>.</p></li>
</ol>
</div>
</div>
<p>We can use this result on the quadratic example before.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:HermiteQuadratic" class="example"><strong>Example 4.8  (Hermite Matrix of A Quadratic Polynomial) </strong></span>Consider the quadratic polynomial <span class="math inline">\(p(x) = x^2 + p_1 x + p_0\)</span>. Using the Newton identifies, we have
<span class="math display">\[
s_0 = 2, \quad s_1 = -p_1, \quad s_2 = p_1^2 - 2p_0.
\]</span>
The Hermite matrix is then
<span class="math display">\[
H_1(p) = \begin{bmatrix} 2 &amp; - p_1 \\ -p_1 &amp; p_1^2 - 2 p_0 \end{bmatrix}.
\]</span>
Let <span class="math inline">\(\Delta = \det H_1(p) = p_1^2 - 4p_0\)</span>. The inertia of the Hermite matrix is
<span class="math display">\[
\mathcal{I}(H_1(p)) = \begin{cases}
(0,0,2) &amp; \text{if } \Delta &gt; 0 \\
(0,1,1) &amp; \text{if } \Delta = 0 \\
(1,0,1) &amp; \text{if } \Delta &lt; 0.
\end{cases}
\]</span>
Thus, <span class="math inline">\(p\)</span> is strictly positive if and only if <span class="math inline">\(\Delta &lt; 0\)</span>.</p>
</div>
</div>
<p><strong>Multivariate Polynomials</strong>. Let us denote by <span class="math inline">\(P_{n,2d}\)</span> the set of nonnegative polynomials in <span class="math inline">\(n\)</span> variables with degree up to <span class="math inline">\(2d\)</span>, i.e.,
<span class="math display">\[
P_{n,2d} = \{ f \in \mathbb{R}[x]_{2d} \mid f(x) \geq 0, \forall x \in \mathbb{R}^{n} \}.
\]</span>
There are
<span class="math display">\[
s(n,2d) = \begin{pmatrix} n + 2d \\ 2d \end{pmatrix}
\]</span>
coefficients for <span class="math inline">\(f \in P_{n,2d}\)</span>. Notice that the constraint <span class="math inline">\(f(x) \geq 0\)</span> when fixing <span class="math inline">\(x\)</span> is an affine constraint in the coefficients of <span class="math inline">\(p\)</span>. Therefore, <span class="math inline">\(P_{n,2d}\)</span> is in fact a convex set. Further, it is a proper cone.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:ConeNonnegative" class="theorem"><strong>Theorem 4.11  (Cone of Nonnegative Polynomials) </strong></span>The set of nonnegative polynomials <span class="math inline">\(P_{n,2d}\)</span> is a proper cone (i.e., closed, convex, pointed, and solid) in <span class="math inline">\(\mathbb{R}[x]_{2d} \sim \mathbb{R}^{s(n,2d)}\)</span>.</p>
</div>
</div>
<p>Let us see an example of quadratic polynomials.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:ConeNonnegativeQuadratic" class="example"><strong>Example 4.9  (Cone of Nonnegative Quadratic Polynomials) </strong></span>Consider the cone <span class="math inline">\(P_{n,2}\)</span>, nonnegative polynomials in <span class="math inline">\(n\)</span> variables of degree up to <span class="math inline">\(2\)</span>. Such polynomials can be written as
<span class="math display">\[
p(x) = x^\top A x + 2 b^\top x + c,
\]</span>
for some <span class="math inline">\(A \in \mathbb{S}^{n}\)</span>, <span class="math inline">\(b \in \mathbb{R}^{n}\)</span>, <span class="math inline">\(c \in \mathbb{R}^{}\)</span>. Observe that we can write
<span class="math display">\[
p(x) = \begin{bmatrix} x \\ 1 \end{bmatrix}^\top\begin{bmatrix} A &amp; b \\ b^\top&amp; c \end{bmatrix} \begin{bmatrix} x \\ 1 \end{bmatrix},
\]</span>
therefore <span class="math inline">\(p(x) \geq 0\)</span> if and only if
<span class="math display">\[
\begin{bmatrix} A &amp; b \\ b^\top&amp; c \end{bmatrix} \succeq 0.
\]</span>
Thus, in this case the set <span class="math inline">\(P_{n,2}\)</span> is isomorphic to the positive semidefinite cone <span class="math inline">\(\mathbb{S}^{n+1}_{+}\)</span>.</p>
</div>
</div>
<p>One may wonder is it the case that <span class="math inline">\(P_{n,2d}\)</span>, being a convex cone, will always have nice descriptions as in the previous example?</p>
<p>Unfortunately the answer is no. In general the geometry of <span class="math inline">\(P_{n,2d}\)</span> is extremely complicated. In Example <a href="SOS.html#exm:ConeNonnegativeQuadratic">4.9</a> we showed <span class="math inline">\(P_{n,2}\)</span> is isomorphic to <span class="math inline">\(\mathbb{S}^{n+1}_{+}\)</span> and hence it is <strong>basic semialgebraic</strong> (recall that the PSD cone can be described by a finite number of polynomial constraints). However, in general <span class="math inline">\(P_{n,2d}\)</span> is semialgebraic but not basic semialgebraic.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:DegreeFourNonnegative" class="example"><strong>Example 4.10  (Semialgebraic Set of Nonnegative Polynomials) </strong></span>Consider the quartic univariate polynomial
<span class="math display">\[
p(x) = x^4 + 2ax^2 + b, \quad a,b \in \mathbb{R}^{}.
\]</span>
We are interested in finding conditions on <span class="math inline">\(a,b\)</span> such that <span class="math inline">\(p(x) \geq 0\)</span> for any <span class="math inline">\(x \in \mathbb{R}^{}\)</span>.</p>
<p>A formal analysis can be done via the discriminant of <span class="math inline">\(p(x)\)</span>. But here we will leverage a powerful tool known as <strong>quantifier elimination</strong>, using cylindrical algebraic decomposition, to directly give us the answer. For example, we can use the quantifier elimination function in the Maple software.</p>
<p>Fig. <a href="SOS.html#fig:QuantifierEliminationQuartic">4.3</a> shows my query to Maple. The quantifier elimination algorithm produces me a set of conditions on <span class="math inline">\(a,b\)</span> such that <span class="math inline">\(p(x) \geq 0\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:QuantifierEliminationQuartic"></span>
<img src="images/quantifier_elimination_quartic.png" alt="Quantifier elimination in Maple." width="60%" />
<p class="caption">
Figure 4.3: Quantifier elimination in Maple.
</p>
</div>
<p>Plotting the conditions we get the blue region in Fig. <a href="SOS.html#fig:NonnegativeQuartic">4.4</a>. As we can see, the set of <span class="math inline">\((a,b)\)</span> such that <span class="math inline">\(p(x)\)</span> is nonnegative is indeed a convex set, but it is not a basic semialgebraic set in the sense that it cannot be written as the feasible set of a finite number of polynomial constraints. However, it is a semialgebraic set that can be described by the union of several basic semialgebraic sets.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:NonnegativeQuartic"></span>
<img src="images/nonnegative_quartic.png" alt="Set of coefficients such that the polynomial is nonnegative." width="60%" />
<p class="caption">
Figure 4.4: Set of coefficients such that the polynomial is nonnegative.
</p>
</div>
<p>Another issue with the convex set shown in Fig. <a href="SOS.html#fig:NonnegativeQuartic">4.4</a> is that there exists a zero-dimensional face (a vertex) that is not exposed, which is the point <span class="math inline">\((0,0)\)</span>. A non-exposed face is a known obstruction for a convex set to be the feasible set of a semidefinite program <span class="citation">(<a href="#ref-ramana95jgo-some">M. Ramana and Goldman 1995</a>)</span>.</p>
</div>
</div>
<p>This shows the difficulty of working with nonnegative polynomials.</p>
<p>From the computational complexity perspective, the difficulty of working with nonnegative polynomials is seen by the fact that deciding polynomial nonnegativity for <span class="math inline">\(2d \geq 4\)</span> is known to be NP-hard in the worst case.</p>
<p>However, we do know very well a special class of nonnegative polynomials, the nonnegative polynomials that can be written as a sum of squares.</p>
</div>
<div id="sums-of-squares-polynomials" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Sums-of-Squares Polynomials<a href="SOS.html#sums-of-squares-polynomials" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A multivariate polynomial <span class="math inline">\(p(x)\)</span> is a <strong>sum of squares</strong> (SOS) if it can be written as the sum of squares of some other polynomials.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:SumOfSquares" class="definition"><strong>Definition 4.18  (Sum of Squares Polynomial) </strong></span>A polynomial <span class="math inline">\(p(x) \in \mathbb{R}[x]_{2d}\)</span> is a sum of squares if there exist <span class="math inline">\(q_1,\dots,q_m \in \mathbb{R}[x]_d\)</span> such that
<span class="math display">\[
p(x) = \sum_{k=1}^m q_k^2(x).
\]</span></p>
</div>
</div>
<p>We will use <span class="math inline">\(\Sigma_{n,2d}\)</span> to denote the set of SOS polynomials in <span class="math inline">\(n\)</span> variables of degree up to <span class="math inline">\(2d\)</span>. Clearly, we have
<span class="math display">\[
\Sigma_{n,2d} \subseteq P_{n,2d},
\]</span>
because any SOS polynomial is necessarily nonnegative.</p>
<p>Similar to <span class="math inline">\(P_{n,2d}\)</span>, the set of SOS polynomials is also a convex proper cone.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:ConeSOSPolynomial" class="theorem"><strong>Theorem 4.12  (Cone of SOS Polynomials) </strong></span>The set of SOS polynomials <span class="math inline">\(\Sigma_{n,2d}\)</span> is a proper cone (i.e., closed, convex, pointed, and solid) in <span class="math inline">\(\mathbb{R}[x]_{2d}\)</span>.</p>
</div>
</div>
<p>One of the central questions in convex algebraic geometry is to understand the relationships between <span class="math inline">\(P_{n,2d}\)</span> and <span class="math inline">\(\Sigma_{n,2d}\)</span>.</p>
<p>The first question is when is nonnegativity equal to sum of squares? David Hilbert showed that equality between <span class="math inline">\(\Sigma_{n,2d}\)</span> and <span class="math inline">\(P_{n,2d}\)</span> happens only in the following three cases:</p>
<ul>
<li><p>Univariate polynomials, <span class="math inline">\(n=1\)</span></p></li>
<li><p>Quadratic polynomials, <span class="math inline">\(2d=2\)</span></p></li>
<li><p>Bivariate quartics, <span class="math inline">\(n=2, 2d=4\)</span>.</p></li>
</ul>
<p>For all other cases, there always exist nonnegative polynomials that are not SOS. One of the most famous examples is the <strong>Motzkin’s polynomial</strong> written as
<span class="math display">\[
M(x,y) = x^4 y^2 + x^2 y^4 + 1 - 3 x^2 y^2.
\]</span>
One can show that this polynomial is nonnegative but not SOS. Other examples of nonnegative but not SOS polynomials can be found in <span class="citation">(<a href="#ref-reznick00cm-some">Reznick 2000</a>)</span>.</p>
<p>Let us show that univariate nonnegative polynomials can always be written as a sum of squares.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:UnivaraiteNonSOS" class="theorem"><strong>Theorem 4.13  (Univaraite Nonnegative Polynomials are SOS) </strong></span>A univariate polynomial is nonnegative if and only if it is a sum of squares.</p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-15" class="proof"><em>Proof</em>. </span>Since <span class="math inline">\(p(x)\)</span> is univariate, we can factorize it as
<span class="math display" id="eq:proof-univariate-non-sos-factorization">\[\begin{equation}
p(x) = p_n \prod_j (x - r_j)^{n_j} \prod_{k} (x - a_k + i b_k)^{m_k} (x - a_k - i b_k)^{m_k},
\tag{4.3}
\end{equation}\]</span>
where <span class="math inline">\(r_j\)</span>’s are the real roots and <span class="math inline">\(a_k \pm i b_k\)</span>’s are the complex roots. Because <span class="math inline">\(p(x)\)</span> is nonnegative, then <span class="math inline">\(p_n &gt; 0\)</span> and the multiplicities of the real roots must be even, i.e., <span class="math inline">\(n_j = 2 s_j\)</span>.</p>
<p>Also note that
<span class="math display">\[
(x - a + ib)(x - a - ib) = (x-a)^2 + b^2.
\]</span>
Consequently we can write <a href="SOS.html#eq:proof-univariate-non-sos-factorization">(4.3)</a> as
<span class="math display">\[
p(x) = p_n \prod_j (x - r_j)^{2 s_j} \prod_k ((x-a_k)^2 + b_k^2)^{m_k}.
\]</span>
Since products of sums of squares are still sums of squares and all the factors in the above expression are SOS, it follows that <span class="math inline">\(p(x)\)</span> is SOS.</p>
<p>Furthermore, the two-squares identify
<span class="math display">\[
(\alpha^2 + \beta^2)(\gamma^2 + \delta^2) = (\alpha \gamma - \beta \delta)^2 + (\alpha \delta + \beta \delta)^2
\]</span>
allows us to combine very partial product as a sum of only two squares:
<span class="math display">\[
p(x) = q_1^2(x) + q_2^2(x).
\]</span>
Therefore, it suffices to write every nonnegative univariate polynomial as the sum of only two squares.</p>
</div>
</div>
<p>In the next section, we focus on how to numerically compute SOS decompositions.</p>
</div>
</div>
<div id="compute-sos-decompositions" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Compute SOS Decompositions<a href="SOS.html#compute-sos-decompositions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Given a polynomial <span class="math inline">\(p(x)\)</span>, how do we decide if <span class="math inline">\(p(x)\)</span> is SOS? We knew that deciding if <span class="math inline">\(p(x)\)</span> is nonnegative is generally NP-hard. The nice thing about SOS polynomials is that the decision problem is tractable and it is a convex semidefinite program.</p>
<div id="univaraite-polynomials" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Univaraite Polynomials<a href="SOS.html#univaraite-polynomials" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider a univariate polynomial <span class="math inline">\(p(x)\)</span> of degree <span class="math inline">\(2d\)</span>
<span class="math display">\[
p(x) = p_{2d} x^{2d} + p_{2d-1} x^{2d-1} + \cdots + p_1 x + p_0.
\]</span>
Assume <span class="math inline">\(p(x)\)</span> is SOS and can be written as
<span class="math display" id="eq:univariate-sos">\[\begin{equation}
p(x) = q_1^2(x) + \dots + q_m^2(x).
\tag{4.4}
\end{equation}\]</span>
Note that the degree of the polynomials <span class="math inline">\(q_k\)</span> must be at most <span class="math inline">\(d\)</span> since the leading term of <span class="math inline">\(q_k^2(x)\)</span> must have positive coefficients and there cannot be any cancellation in the highest power of <span class="math inline">\(x\)</span>. Then, we can write
<span class="math display" id="eq:univariate-q-V">\[\begin{equation}
\begin{bmatrix} q_1(x) \\ q_2(x) \\ \vdots \\ q_m(x) \end{bmatrix} = V \begin{bmatrix} 1 \\ x \\ \vdots \\ x^d \end{bmatrix} = V [x]_d,
\tag{4.5}
\end{equation}\]</span>
where recall <span class="math inline">\([x]_d\)</span> is the vector of monomials in <span class="math inline">\(x\)</span> of degree up to <span class="math inline">\(d\)</span>. Plugging <a href="SOS.html#eq:univariate-q-V">(4.5)</a> into <a href="SOS.html#eq:univariate-sos">(4.4)</a>, we get
<span class="math display" id="eq:univariate-sos-gram-Q">\[\begin{equation}
p(x) = \sum_{k=1}^m q_k^2 (x) = (V [x]_d)^\top(V [x]_d) = [x]_d^\top V^\top V [x]_d = [x]_d^\top Q [x]_d.
\tag{4.6}
\end{equation}\]</span></p>
<p>This suggests the following characterization of univariate SOS polynomials.</p>
<div class="theorembox">
<div class="lemma">
<p><span id="lem:UnivaraiteSOS" class="lemma"><strong>Lemma 4.2  (Characterization of Univaraite SOS Polynomials) </strong></span>A univariate polynomial <span class="math inline">\(p(x) \in \mathbb{R}[x]_{2d}\)</span> is SOS if and only if there exists a symmetric matrix <span class="math inline">\(Q \in \mathbb{S}^{d+1}\)</span> that satisfies
<span class="math display">\[
p(x) = [x]_d^\top Q [x]_d, \quad Q \succeq 0.
\]</span></p>
</div>
</div>
<p>The matrix <span class="math inline">\(Q\)</span> is typically called the <strong>Gram matrix</strong> of the SOS representation. Lemma <a href="SOS.html#lem:UnivaraiteSOS">4.2</a> can be easily verified: one direction is clear from <a href="SOS.html#eq:univariate-sos-gram-Q">(4.6)</a> and the other direction can be shown by factorizing a positive semidefinite matrix <span class="math inline">\(Q = V^\top V\)</span>.</p>
<p>Although it may not be immediately clear, but the nice property of Lemma <a href="SOS.html#lem:UnivaraiteSOS">4.2</a> is that it says deciding if a univariate polynomial is SOS (and finding its SOS decomposition) is in fact a convex semidefinite program!</p>
<p>To see this, note that the constraint <span class="math inline">\(Q \succeq 0\)</span> is a convex PSD constraint and the constraint <span class="math inline">\(p(x) = [x]_d^\top Q [x]_d\)</span> leads to a finite number of affine constraints on the entries of <span class="math inline">\(Q\)</span> by “matching coefficients”. In particular, let us index the rows and columns of <span class="math inline">\(Q\)</span> from <span class="math inline">\(0\)</span> to <span class="math inline">\(d\)</span>, and expand
<span class="math display">\[
[x]_d^\top Q [x]_d = \sum_{k=0}^{2d} \left( \sum_{i+j=k} Q_{ij} \right) x^k.
\]</span>
It now becomes clear that <span class="math inline">\(p(x) = [x]_d^\top Q [x]_d\)</span> simply askes
<span class="math display">\[
\sum_{i+j=k} Q_{ij} = p_k, \quad k = 0, \dots, 2d.
\]</span></p>
<p>It is easier to work this out via an example.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:SOSDecompositionUnivariate" class="example"><strong>Example 4.11  (SOS Decomposition of Univaraite Polynomials) </strong></span>Consider the univariate polynomial
<span class="math display">\[
p(x) = x^4 + 4 x^3 + 6 x^2 + 4 x + 5.
\]</span>
To decide if this polynomial is SOS, we write the polynomial equality constraint
<span class="math display">\[\begin{equation}
\begin{split}
p(x) &amp; = \begin{bmatrix} 1 \\ x \\ x^2 \end{bmatrix}^\top\begin{bmatrix} Q_{00} &amp; Q_{01} &amp; Q_{02} \\
Q_{01} &amp; Q_{11} &amp; Q_{12} \\
Q_{02} &amp; Q_{12} &amp; Q_{22}
\end{bmatrix}  \begin{bmatrix} 1 \\ x \\ x^2 \end{bmatrix} \\
&amp; = Q_{22} x^4 + 2 Q_{12} x^3 + (Q_{11} + 2 Q_{02}) x^2 + 2 Q_{01} x + Q_{00}.
\end{split}
\end{equation}\]</span>
Matching coefficients, we get the constraints
<span class="math display">\[\begin{equation}
\begin{split}
x^4: &amp; \quad Q_{22} = 1\\
x^3: &amp; \quad 2 Q_{12} = 4\\
x^2: &amp; \quad Q_{11} + 2 Q_{02} = 6\\
x: &amp; \quad 2Q_{01} = 4\\
1: &amp; \quad Q_{00} = 5
\end{split}
\end{equation}\]</span>
We need to find a <span class="math inline">\(Q \succeq 0\)</span> that satisfies the above constraints, which is clearly a convex SDP. In this case, the SDP is feasible and we can find a solution
<span class="math display">\[
Q = \begin{bmatrix} 5 &amp; 2 &amp; 0 \\ 2 &amp; 6 &amp; 2 \\ 0 &amp; 2 &amp; 1 \end{bmatrix}.
\]</span>
Factorizing <span class="math inline">\(Q=V^\top V\)</span> with
<span class="math display">\[
V = \begin{bmatrix} 0 &amp; 2 &amp; 1 \\ \sqrt{2} &amp; \sqrt{2} &amp; 0 \\ \sqrt{3} &amp; 0 &amp; 0 \end{bmatrix},
\]</span>
we obtain the SOS decomposition
<span class="math display">\[
p(x) = (x^2 + 2x)^2 + 2 (1+x)^2 + 3,
\]</span></p>
</div>
</div>
</div>
<div id="multivariate-polynomials" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Multivariate Polynomials<a href="SOS.html#multivariate-polynomials" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Deciding if a multivariate polynomial is SOS is almost identical to what we have shown for univariate polynomials. Consider a multivariate polynomial <span class="math inline">\(p(x)\)</span> in <span class="math inline">\(n\)</span> variables of degree <span class="math inline">\(2d\)</span>:
<span class="math display">\[
p(x) = \sum_{\alpha} p_{\alpha} x^{\alpha}, \quad \alpha \in \mathcal{F}_{n,2d} := \{ (\alpha_1,\dots,\alpha_n) \in \mathbb{N}^n \mid \alpha_1 + \cdots + \alpha_n \leq 2d \}.
\]</span>
Let
<span class="math display" id="eq:SOS-standard-basis">\[\begin{equation}
[x]_d := \begin{bmatrix} 1 \\ x_1 \\ \vdots \\ x_n \\ x_1^2 \\ x_1 x_2 \\ \vdots \\ x_n^d \end{bmatrix} = [x^\alpha]_{\alpha \in \mathcal{F}_{n,d}}
\tag{4.7}
\end{equation}\]</span>
be the standard basis of monomials with degree up to <span class="math inline">\(d\)</span>. Then in parallel to Lemma <a href="SOS.html#lem:UnivaraiteSOS">4.2</a>, we have that <span class="math inline">\(p(x)\)</span> is SOS if and only if there exists a positive semidefinite Gram matrix.</p>
<div class="theorembox">
<div class="lemma">
<p><span id="lem:MultivariateSOS" class="lemma"><strong>Lemma 4.3  (Characterization of Multivariate SOS Polynomials) </strong></span>A multivariate polynomial <span class="math inline">\(p(x) \in \mathbb{R}[x]_{2d}\)</span> is SOS if and only if there exists a symmetric matrix <span class="math inline">\(Q \in \mathbb{S}^{s(n,d)}\)</span> that satisfies
<span class="math display">\[
p(x) = [x]_d^\top Q [x]_d, \quad Q \succeq 0.
\]</span></p>
</div>
</div>
<p>Let us index the monomials in the basis <a href="SOS.html#eq:SOS-standard-basis">(4.7)</a>, as well as the rows and columns of <span class="math inline">\(Q\)</span>, using their exponents. Then by matching coefficients of the polynomial equation <span class="math inline">\(p(x) = [x]_d^\top Q [x]_d\)</span>, Lemma <a href="SOS.html#lem:MultivariateSOS">4.3</a> is equivalent to finding <span class="math inline">\(Q \in \mathbb{S}^{s(n,d)}\)</span> that satisfies
<span class="math display" id="eq:multivariate-SOS-SDP-formulation">\[\begin{equation}
p_\alpha = \sum_{\beta + \gamma = \alpha} Q_{\beta\gamma}, \forall \alpha \in \mathcal{F}_{n,2d}, \quad Q \succeq 0.
\tag{4.8}
\end{equation}\]</span>
That is, for every <span class="math inline">\(\alpha \in \mathcal{F}_{n,2d}\)</span>, we search for all possible pairs of <span class="math inline">\(\beta,\gamma \in \mathcal{F}_{n,d}\)</span> such that <span class="math inline">\(\beta + \gamma = \alpha\)</span>, the sum of <span class="math inline">\(Q_{\beta \gamma}\)</span> should be equal to <span class="math inline">\(p_{\alpha}\)</span> by the virtue of matching coefficients. <strong>Note that <a href="SOS.html#eq:multivariate-SOS-SDP-formulation">(4.8)</a> boils down to solving an SDP with matrix size <span class="math inline">\(s(n,d) \times s(n,d)\)</span> and <span class="math inline">\(s(n,2d)\)</span> affine constraints.</strong> Therefore, it grows quickly with <span class="math inline">\(n\)</span> and <span class="math inline">\(d\)</span>.</p>
<p>Let us work out a simple example.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:SOSDecompositionMultivariate" class="example"><strong>Example 4.12  (SOS Decomposition of a Multivariate Polynomial) </strong></span>We want to check if the following polynomial in two variables is SOS:
<span class="math display">\[
p(x) = 2 x_1^4 + 5 x_2^4 - x_1^2 x_2^2 + 2 x_1^3 x_2 + 2 x_1 + 2.
\]</span>
Since <span class="math inline">\(\deg(p) = 4\)</span>, we pick the standard monomial basis of degree up to <span class="math inline">\(2\)</span>
<span class="math display">\[
[x]_2 = \begin{bmatrix} 1 \\ x_1 \\ x_2 \\ x_1^2 \\ x_1 x_2 \\ x_2^2 \end{bmatrix},
\]</span>
and write down the polynomial equality constraint
<span class="math display">\[
p(x) = [x]_2^\top Q [x]_2 =
[x]_2^\top\begin{bmatrix}
Q_{00,00} &amp; Q_{00,10} &amp; Q_{00,01} &amp; Q_{00,20} &amp; Q_{00,11} &amp; Q_{00,02} \\
* &amp; Q_{10,10} &amp; Q_{10,01} &amp; Q_{10,20} &amp; Q_{10,11} &amp; Q_{10,02} \\
* &amp; * &amp; Q_{01,01} &amp; Q_{01,20} &amp; Q_{01,11} &amp; Q_{01,02} \\
* &amp; * &amp; * &amp; Q_{20,20} &amp; Q_{20,11} &amp; Q_{20,02} \\
* &amp; * &amp; * &amp; * &amp; Q_{11,11} &amp; Q_{11,02} \\
* &amp; * &amp; * &amp; * &amp; * &amp; Q_{02,02}
\end{bmatrix}
[x]_2
\]</span>
By matching coefficients, we obtain
<span class="math display">\[
s(n,2d) = s(2,4) = \begin{pmatrix} 2 + 4 \\ 4 \end{pmatrix} = 15
\]</span>
affine constraints on the entries of <span class="math inline">\(Q\)</span>, which has size <span class="math inline">\(6 \times 6\)</span>.</p>
<p>Solving the SDP, we obtain a solution
<span class="math display">\[
Q = \frac{1}{3} \begin{bmatrix} 6 &amp; 3 &amp; 0 &amp; -2 &amp; 0 &amp; -2 \\
3 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 \\
-2 &amp; 0 &amp; 0 &amp; 6 &amp; 3 &amp; -4 \\
0 &amp; 0 &amp; 0 &amp; 3 &amp; 5 &amp; 0 \\
-2 &amp; 0 &amp; 0 &amp; -4 &amp; 0 &amp; 15
\end{bmatrix}.
\]</span></p>
</div>
</div>
<p><strong>Choice of Basis</strong>. It is worth noting that so far, when computing SOS decompositions, we have been using the standard monomial basis <span class="math inline">\([x]_d\)</span>. This is the most popular choice in practice, but it is not necessarily the only choice. See Chapter 3.1.5 of <span class="citation">(<a href="#ref-blekherman12book-semidefinite">Blekherman, Parrilo, and Thomas 2012</a>)</span> for other basis choices.</p>
</div>
</div>
<div id="sos-programming" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> SOS Programming<a href="SOS.html#sos-programming" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have seen that finding SOS decompositions of given polynomials can be written as semidefinite programs. It is clear to see that we can do more than just finding SOS decompositions – we can also formulate optimization problems subject to SOS constraints, known as SOS programming.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:SOSProgram" class="definition"><strong>Definition 4.19  (SOS Program) </strong></span>An SOS optimization problem or SOS program is a convex optimization problem of the form
<span class="math display" id="eq:SOS-program">\[\begin{equation}
\begin{split}
\max_y &amp; \quad b_1 y_1 + \cdots + b_m y_m \\
\mathrm{s.t.}&amp; \quad p_i(x;y) \text{ is SOS in } \mathbb{R}[x], \quad i=1,\dots,k.
\end{split}
\tag{4.9}
\end{equation}\]</span>
where <span class="math inline">\(b = (b_1,\dots,b_m) \in \mathbb{R}^{m}\)</span> is a given constant vector, <span class="math inline">\(y= (y_1,\dots,y_m)\)</span> is the unknown variable to be optimized, and
<span class="math display">\[
p_i(x;y) = a_{i0}(x) + y_1 a_{i1}(x) + \cdots + y_m a_{im}(x), \quad i=1,\dots,k,
\]</span>
are polynomials in <span class="math inline">\(x\)</span> with coefficientss affine in <span class="math inline">\(y\)</span>, with <span class="math inline">\(a_{ij}(x),i=1,\dots,k, j=0,\dots,m\)</span> given polynomials.</p>
</div>
</div>
<p>For readers seeing SOS programs for the first time, it is critical to realize that <strong>the variable <span class="math inline">\(x\)</span> in an SOS program <a href="SOS.html#eq:SOS-program">(4.9)</a> is “dummy”</strong>, in the sense that it is only used to formulate the problem, but not really being optimized. The variable <span class="math inline">\(y \in \mathbb{R}^{m}\)</span> is the optimization variable.</p>
<p>To see this point more clearly, we will show that the SOS program <a href="SOS.html#eq:SOS-program">(4.9)</a> can be reformulated as a convex semidefinite program (or in general a conic optimization problem). Let
<span class="math display">\[
d_i = \lceil \deg(p_i)/2 \rceil, \quad i=1,\dots,k,
\]</span>
where importantly, the degree of <span class="math inline">\(p_i\)</span> is taken w. r. t. <span class="math inline">\(x\)</span> (but not <span class="math inline">\(y\)</span>). Then we can clearly see that the constraint “<span class="math inline">\(p_i(x;y)\)</span> is SOS in <span class="math inline">\(\mathbb{R}[x]\)</span>” is equivalent to
<span class="math display" id="eq:SOS-program-expand">\[\begin{equation}
p_i(x;y) = [x]_{d_i}^\top Q_i [x]_{d_i}, \quad Q_i \in \mathbb{S}^{s(n,d_i)}_{+}, \quad i=1,\dots,k,
\tag{4.10}
\end{equation}\]</span>
where recall <span class="math inline">\([x]_{d_i}\)</span> is the standard monomial basis in <span class="math inline">\(x\)</span> of degree up to <span class="math inline">\(d_i\)</span>. By matching coefficients in equation <a href="SOS.html#eq:SOS-program-expand">(4.10)</a>, we obtain a set of affine constraints in <span class="math inline">\(y\)</span> and <span class="math inline">\(Q_i\)</span>, while the variable <span class="math inline">\(x\)</span> is simply removed! Therefore, the SOS program <a href="SOS.html#eq:SOS-program">(4.9)</a> is equivalent to a conic optimization in the variable
<span class="math display">\[
(y,Q_1,\dots,Q_k) \in \mathbb{R}^{m} \times \mathbb{S}^{s(n,d_1)}_{+} \times \cdots \times \mathbb{S}^{s(n,d_k)}_{+}.
\]</span>
The number of affine constraints is
<span class="math display">\[
s(n,2d_1) + \cdots + s(n,2d_k).
\]</span></p>
<p>Let us make this observation concrete using a simple example.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:SOSProgram" class="example"><strong>Example 4.13  (SOS Programming) </strong></span>Consider the following SOS program
<span class="math display" id="eq:SOS-program-example">\[\begin{equation}
\begin{split}
\max_y &amp; \quad y_1 + y_2 \\
\mathrm{s.t.}&amp; \quad x^4 + y_1 x + (2+y_2) \text{ is SOS}\\
&amp; \quad (y_1 - y_2 + 1) x^2 + y_2 x + 1 \text{ is SOS}
\end{split}
\tag{4.11}
\end{equation}\]</span>
The first SOS constraint is equivalent to
<span class="math display">\[
x^4 + y_1 x + (2 + y_2) = [x]_2^\top Q_1 [x]_2 = \begin{bmatrix} 1 \\ x \\ x^2 \end{bmatrix}^\top
\underbrace{\begin{bmatrix}
Q_{1,00} &amp; Q_{1,01} &amp; Q_{1,02} \\
Q_{1,01} &amp; Q_{1,11} &amp; Q_{1,12} \\
Q_{1,02} &amp; Q_{1,12} &amp; Q_{1,22}
\end{bmatrix}}_{Q_1}
\begin{bmatrix} 1 \\ x \\ x^2 \end{bmatrix}.
\]</span>
Matching coefficients, we obtain
<span class="math display" id="eq:SOS-program-constraint-1">\[\begin{equation}
\begin{split}
x^4: &amp; \quad 1 = Q_{1,22} \\
x^3: &amp; \quad 0 = 2 Q_{1,12} \\
x^2: &amp; \quad 0 = Q_{1,11} + 2 Q_{1,02} \\
x: &amp; \quad y_1 = 2 Q_{1,01} \\
1: &amp; \quad 2 + y_2 = Q_{1,00}
\end{split}
\tag{4.12}
\end{equation}\]</span>
The second SOS constraint is equivalent to
<span class="math display">\[
(y_1 - y_2 + 1)x^2 + y_2 x + 1 = [x]_1^\top Q_2 [x]_1 = \begin{bmatrix} 1 \\ x \end{bmatrix}^\top
\underbrace{\begin{bmatrix} Q_{2,00} &amp; Q_{2,01} \\
Q_{2,01} &amp; Q_{2,11} \end{bmatrix}}_{Q_2}
\begin{bmatrix} 1 \\ x \end{bmatrix}.
\]</span>
Matching coefficients, we obtain
<span class="math display" id="eq:SOS-program-constraint-2">\[\begin{equation}
\begin{split}
x^2: &amp; \quad y_1 - y_2 + 1 = Q_{2,11} \\
x: &amp; \quad y_2 = 2 Q_{2,01} \\
1: &amp; \quad 1 = Q_{2,00}
\end{split}
\tag{4.13}
\end{equation}\]</span>
Therefore, we obtain a conic optimization in
<span class="math display">\[
(y_1,y_2,Q_1,Q_2)
\]</span>
subject to the affine constraints in <a href="SOS.html#eq:SOS-program-constraint-1">(4.12)</a> and <a href="SOS.html#eq:SOS-program-constraint-2">(4.13)</a>, plus <span class="math inline">\(Q_1 \succeq 0, Q_2 \succeq 0\)</span>.</p>
<p>For this simple example, it is tractable to collect the linear constraints by hand. When the SOS program grows larger, we can use existing software packages to perform the conversion for us.</p>
<p>In the next, we show how to use the software package SOSTOOLS <span class="citation">(<a href="#ref-prajna02cdc-sostools">Prajna, Papachristodoulou, and Parrilo 2002</a>)</span> to implement SOS programming in Matlab.</p>
<p>I first create the dummy polynomial variable <span class="math inline">\(x\)</span> and the decision variable <span class="math inline">\(y\)</span>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span id="cb6-1"><a href="SOS.html#cb6-1" tabindex="-1"></a><span class="va">dim_y</span> <span class="op">=</span> <span class="fl">2</span><span class="op">;</span></span>
<span id="cb6-2"><a href="SOS.html#cb6-2" tabindex="-1"></a><span class="va">dim_x</span> <span class="op">=</span> <span class="fl">1</span><span class="op">;</span></span>
<span id="cb6-3"><a href="SOS.html#cb6-3" tabindex="-1"></a><span class="va">x</span> <span class="op">=</span> <span class="va">mpvar</span>(<span class="ss">&#39;x&#39;</span><span class="op">,</span><span class="fl">1</span>)<span class="op">;</span> <span class="co">% dummy x </span></span>
<span id="cb6-4"><a href="SOS.html#cb6-4" tabindex="-1"></a><span class="va">prog</span> <span class="op">=</span> <span class="va">sosprogram</span>(<span class="va">x</span>)<span class="op">;</span></span>
<span id="cb6-5"><a href="SOS.html#cb6-5" tabindex="-1"></a><span class="va">y_name</span> <span class="op">=</span> {}<span class="op">;</span> <span class="co">% decision variable y</span></span>
<span id="cb6-6"><a href="SOS.html#cb6-6" tabindex="-1"></a><span class="kw">for</span> <span class="va">i</span> <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">dim_y</span></span>
<span id="cb6-7"><a href="SOS.html#cb6-7" tabindex="-1"></a>    <span class="va">y_name</span>{<span class="va">i</span>} <span class="op">=</span> <span class="va">sprintf</span>(<span class="ss">&#39;y_%d&#39;</span><span class="op">,</span><span class="va">i</span>)<span class="op">;</span></span>
<span id="cb6-8"><a href="SOS.html#cb6-8" tabindex="-1"></a><span class="kw">end</span></span>
<span id="cb6-9"><a href="SOS.html#cb6-9" tabindex="-1"></a><span class="va">y</span> <span class="op">=</span> <span class="va">dpvar</span>(<span class="va">y_name</span>)<span class="op">;</span></span>
<span id="cb6-10"><a href="SOS.html#cb6-10" tabindex="-1"></a><span class="va">y</span> <span class="op">=</span> <span class="va">y</span>(<span class="op">:</span>)<span class="op">;</span></span>
<span id="cb6-11"><a href="SOS.html#cb6-11" tabindex="-1"></a><span class="va">prog</span> <span class="op">=</span> <span class="va">sosdecvar</span>(<span class="va">prog</span><span class="op">,</span><span class="va">y</span>)<span class="op">;</span></span></code></pre></div>
<p>I then define the two polynomials in the SOS constraints, two SOS polynomials, and enforce them to the equal.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span id="cb7-1"><a href="SOS.html#cb7-1" tabindex="-1"></a><span class="co">% two polynomials</span></span>
<span id="cb7-2"><a href="SOS.html#cb7-2" tabindex="-1"></a><span class="va">p1</span> <span class="op">=</span> <span class="va">x</span><span class="op">^</span><span class="fl">4</span> <span class="op">+</span> <span class="va">y</span>(<span class="fl">1</span>)<span class="op">*</span><span class="va">x</span> <span class="op">+</span> (<span class="fl">2</span> <span class="op">+</span> <span class="va">y</span>(<span class="fl">2</span>))<span class="op">;</span></span>
<span id="cb7-3"><a href="SOS.html#cb7-3" tabindex="-1"></a><span class="va">p2</span> <span class="op">=</span> (<span class="va">y</span>(<span class="fl">1</span>)<span class="op">-</span><span class="va">y</span>(<span class="fl">2</span>)<span class="op">+</span><span class="fl">1</span>)<span class="op">*</span><span class="va">x</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="va">y</span>(<span class="fl">2</span>)<span class="op">*</span><span class="va">x</span> <span class="op">+</span> <span class="fl">1</span><span class="op">;</span></span>
<span id="cb7-4"><a href="SOS.html#cb7-4" tabindex="-1"></a><span class="co">% two SOS polynomials</span></span>
<span id="cb7-5"><a href="SOS.html#cb7-5" tabindex="-1"></a>[<span class="va">prog</span><span class="op">,</span> <span class="va">sig1</span>] <span class="op">=</span> <span class="va">sossosvar</span>(<span class="va">prog</span><span class="op">,</span><span class="va">monomials</span>(<span class="va">x</span><span class="op">,</span><span class="fl">0</span><span class="op">:</span><span class="fl">2</span>))<span class="op">;</span></span>
<span id="cb7-6"><a href="SOS.html#cb7-6" tabindex="-1"></a>[<span class="va">prog</span><span class="op">,</span> <span class="va">sig2</span>] <span class="op">=</span> <span class="va">sossosvar</span>(<span class="va">prog</span><span class="op">,</span><span class="va">monomials</span>(<span class="va">x</span><span class="op">,</span><span class="fl">0</span><span class="op">:</span><span class="fl">1</span>))<span class="op">;</span></span>
<span id="cb7-7"><a href="SOS.html#cb7-7" tabindex="-1"></a><span class="co">% matching coefficients</span></span>
<span id="cb7-8"><a href="SOS.html#cb7-8" tabindex="-1"></a><span class="va">prog</span> <span class="op">=</span> <span class="va">soseq</span>(<span class="va">prog</span><span class="op">,</span><span class="va">p1</span><span class="op">-</span><span class="va">sig1</span>)<span class="op">;</span></span>
<span id="cb7-9"><a href="SOS.html#cb7-9" tabindex="-1"></a><span class="va">prog</span> <span class="op">=</span> <span class="va">soseq</span>(<span class="va">prog</span><span class="op">,</span><span class="va">p2</span><span class="op">-</span><span class="va">sig2</span>)<span class="op">;</span></span></code></pre></div>
<p>Finally, I set the objective function, choose a solver, and solve the SOS program.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span id="cb8-1"><a href="SOS.html#cb8-1" tabindex="-1"></a><span class="co">% objective</span></span>
<span id="cb8-2"><a href="SOS.html#cb8-2" tabindex="-1"></a><span class="va">prog</span> <span class="op">=</span> <span class="va">sossetobj</span>(<span class="va">prog</span><span class="op">,-</span>(<span class="va">y</span>(<span class="fl">1</span>)<span class="op">+</span><span class="va">y</span>(<span class="fl">2</span>)))<span class="op">;</span></span>
<span id="cb8-3"><a href="SOS.html#cb8-3" tabindex="-1"></a><span class="co">% choose solver</span></span>
<span id="cb8-4"><a href="SOS.html#cb8-4" tabindex="-1"></a><span class="va">options</span>.<span class="va">solver</span> <span class="op">=</span> <span class="ss">&#39;mosek&#39;</span><span class="op">;</span></span>
<span id="cb8-5"><a href="SOS.html#cb8-5" tabindex="-1"></a><span class="va">prog</span> <span class="op">=</span> <span class="va">sossolve</span>(<span class="va">prog</span><span class="op">,</span><span class="va">options</span>)<span class="op">;</span></span></code></pre></div>
<p>After solving the SOS program, I extract the optimal solution</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span id="cb9-1"><a href="SOS.html#cb9-1" tabindex="-1"></a><span class="co">% get solution</span></span>
<span id="cb9-2"><a href="SOS.html#cb9-2" tabindex="-1"></a><span class="va">ystar</span> <span class="op">=</span> <span class="va">double</span>(<span class="va">sosgetsol</span>(<span class="va">prog</span><span class="op">,</span><span class="va">y</span>))<span class="op">;</span></span></code></pre></div>
<p>which produces
<span class="math display">\[
y_{\star} = (6.6189, 3.8716).
\]</span></p>
<p>How do I get the solutions to <span class="math inline">\(Q_1\)</span> and <span class="math inline">\(Q_2\)</span>? If I go to the field <code>prog.solinfo.x</code>, I see a vector of dimension <span class="math inline">\(15\)</span>, which is <span class="math inline">\(2 + 3^2 + 2^2\)</span>. Therefore, I can extract <span class="math inline">\(Q_{1\star}\)</span> and <span class="math inline">\(Q_{2\star}\)</span> with</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span id="cb10-1"><a href="SOS.html#cb10-1" tabindex="-1"></a><span class="va">Q1star</span> <span class="op">=</span> <span class="va">reshape</span>(<span class="va">prog</span>.<span class="va">solinfo</span>.<span class="va">x</span>(<span class="fl">2</span><span class="op">+</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">+</span><span class="fl">9</span>)<span class="op">,</span><span class="fl">3</span><span class="op">,</span><span class="fl">3</span>)<span class="op">;</span></span>
<span id="cb10-2"><a href="SOS.html#cb10-2" tabindex="-1"></a><span class="va">Q2star</span> <span class="op">=</span> <span class="va">reshape</span>(<span class="va">prog</span>.<span class="va">solinfo</span>.<span class="va">x</span>(<span class="fl">2</span><span class="op">+</span><span class="fl">9</span><span class="op">+</span><span class="fl">1</span><span class="op">:</span><span class="kw">end</span>)<span class="op">,</span><span class="fl">2</span><span class="op">,</span><span class="fl">2</span>)<span class="op">;</span></span></code></pre></div>
<p>which produces
<span class="math display">\[
Q_{1\star} = \begin{bmatrix} 5.8716 &amp; 3.3095 &amp; -1.3990 \\
3.3095 &amp; 2.7980 &amp; 0 \\-1.3990 &amp; 0 &amp; 1 \end{bmatrix}, \quad
Q_{2\star} = \begin{bmatrix} 1 &amp; 1.9358 \\ 1.9358 &amp; 3.7473 \end{bmatrix}.
\]</span></p>
<p>The implementation can be found <a href="https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/sos_program_example_sostools.m">here</a>.</p>
<p>The implementation in SOSTOOLS is a bit unsatisfying because (i) one needs to separately define <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, (ii) the extraction of <span class="math inline">\(Q_1\)</span> and <span class="math inline">\(Q_2\)</span> is not very intuitive. The following implementation shows how to solve the same SOS program using YALMIP <span class="citation">(<a href="#ref-lofberg04icra-yalmip">Lofberg 2004</a>)</span>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span id="cb11-1"><a href="SOS.html#cb11-1" tabindex="-1"></a><span class="co">% define all variables</span></span>
<span id="cb11-2"><a href="SOS.html#cb11-2" tabindex="-1"></a><span class="va">x</span> <span class="op">=</span> <span class="va">sdpvar</span>(<span class="fl">1</span>)<span class="op">;</span></span>
<span id="cb11-3"><a href="SOS.html#cb11-3" tabindex="-1"></a><span class="va">y</span> <span class="op">=</span> <span class="va">sdpvar</span>(<span class="fl">2</span><span class="op">,</span><span class="fl">1</span>)<span class="op">;</span></span>
<span id="cb11-4"><a href="SOS.html#cb11-4" tabindex="-1"></a><span class="va">Q1</span> <span class="op">=</span> <span class="va">sdpvar</span>(<span class="fl">3</span><span class="op">,</span><span class="fl">3</span>)<span class="op">;</span></span>
<span id="cb11-5"><a href="SOS.html#cb11-5" tabindex="-1"></a><span class="va">Q2</span> <span class="op">=</span> <span class="va">sdpvar</span>(<span class="fl">2</span><span class="op">,</span><span class="fl">2</span>)<span class="op">;</span></span>
<span id="cb11-6"><a href="SOS.html#cb11-6" tabindex="-1"></a><span class="co">% define polynomials</span></span>
<span id="cb11-7"><a href="SOS.html#cb11-7" tabindex="-1"></a><span class="va">p1</span> <span class="op">=</span> <span class="va">x</span><span class="op">^</span><span class="fl">4</span> <span class="op">+</span> <span class="va">y</span>(<span class="fl">1</span>)<span class="op">*</span><span class="va">x</span> <span class="op">+</span> (<span class="fl">2</span> <span class="op">+</span> <span class="va">y</span>(<span class="fl">2</span>))<span class="op">;</span></span>
<span id="cb11-8"><a href="SOS.html#cb11-8" tabindex="-1"></a><span class="va">p2</span> <span class="op">=</span> (<span class="va">y</span>(<span class="fl">1</span>)<span class="op">-</span><span class="va">y</span>(<span class="fl">2</span>)<span class="op">+</span><span class="fl">1</span>)<span class="op">*</span><span class="va">x</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="va">y</span>(<span class="fl">2</span>)<span class="op">*</span><span class="va">x</span> <span class="op">+</span> <span class="fl">1</span><span class="op">;</span></span>
<span id="cb11-9"><a href="SOS.html#cb11-9" tabindex="-1"></a><span class="co">% SOS polynomials</span></span>
<span id="cb11-10"><a href="SOS.html#cb11-10" tabindex="-1"></a><span class="va">sig1</span> <span class="op">=</span> <span class="va">monolist</span>(<span class="va">x</span><span class="op">,</span><span class="fl">2</span>)<span class="op">&#39;</span> <span class="op">*</span> <span class="va">Q1</span> <span class="op">*</span> <span class="va">monolist</span>(<span class="va">x</span><span class="op">,</span><span class="fl">2</span>)<span class="op">;</span></span>
<span id="cb11-11"><a href="SOS.html#cb11-11" tabindex="-1"></a><span class="va">sig2</span> <span class="op">=</span> <span class="va">monolist</span>(<span class="va">x</span><span class="op">,</span><span class="fl">1</span>)<span class="op">&#39;</span> <span class="op">*</span> <span class="va">Q2</span> <span class="op">*</span> <span class="va">monolist</span>(<span class="va">x</span><span class="op">,</span><span class="fl">1</span>)<span class="op">;</span></span>
<span id="cb11-12"><a href="SOS.html#cb11-12" tabindex="-1"></a><span class="co">% define all constraints</span></span>
<span id="cb11-13"><a href="SOS.html#cb11-13" tabindex="-1"></a><span class="va">F</span> <span class="op">=</span> [<span class="va">Q1</span><span class="op">&gt;=</span><span class="fl">0</span><span class="op">,</span> <span class="va">Q2</span><span class="op">&gt;=</span><span class="fl">0</span><span class="op">,...</span></span>
<span id="cb11-14"><a href="SOS.html#cb11-14" tabindex="-1"></a>    <span class="va">coefficients</span>(<span class="va">p1</span><span class="op">-</span><span class="va">sig1</span><span class="op">,</span><span class="va">x</span>)<span class="op">==</span><span class="fl">0</span><span class="op">,...</span></span>
<span id="cb11-15"><a href="SOS.html#cb11-15" tabindex="-1"></a>    <span class="va">coefficients</span>(<span class="va">p2</span><span class="op">-</span><span class="va">sig2</span><span class="op">,</span><span class="va">x</span>)<span class="op">==</span><span class="fl">0</span>]<span class="op">;</span></span>
<span id="cb11-16"><a href="SOS.html#cb11-16" tabindex="-1"></a><span class="co">% objective</span></span>
<span id="cb11-17"><a href="SOS.html#cb11-17" tabindex="-1"></a><span class="va">obj</span> <span class="op">=</span> <span class="op">-</span>(<span class="va">y</span>(<span class="fl">1</span>)<span class="op">+</span><span class="va">y</span>(<span class="fl">2</span>))<span class="op">;</span></span>
<span id="cb11-18"><a href="SOS.html#cb11-18" tabindex="-1"></a><span class="co">% solve</span></span>
<span id="cb11-19"><a href="SOS.html#cb11-19" tabindex="-1"></a><span class="va">options</span> <span class="op">=</span> <span class="va">sdpsettings</span>(<span class="ss">&#39;solver&#39;</span><span class="op">,</span><span class="ss">&#39;mosek&#39;</span>)<span class="op">;</span></span>
<span id="cb11-20"><a href="SOS.html#cb11-20" tabindex="-1"></a><span class="va">optimize</span>(<span class="va">F</span><span class="op">,</span><span class="va">obj</span><span class="op">,</span><span class="va">options</span>)<span class="op">;</span></span>
<span id="cb11-21"><a href="SOS.html#cb11-21" tabindex="-1"></a><span class="co">% extract solution</span></span>
<span id="cb11-22"><a href="SOS.html#cb11-22" tabindex="-1"></a><span class="va">ystar</span> <span class="op">=</span> <span class="va">value</span>(<span class="va">y</span>)<span class="op">;</span></span>
<span id="cb11-23"><a href="SOS.html#cb11-23" tabindex="-1"></a><span class="va">Q1star</span> <span class="op">=</span> <span class="va">value</span>(<span class="va">Q1</span>)<span class="op">;</span></span>
<span id="cb11-24"><a href="SOS.html#cb11-24" tabindex="-1"></a><span class="va">Q2star</span> <span class="op">=</span> <span class="va">value</span>(<span class="va">Q2</span>)<span class="op">;</span></span></code></pre></div>
<p>We get the same solution as using SOSTOOLS. The implementation in YALMIP can be found <a href="https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/sos_program_example_yalmip.m">here</a>.</p>
</div>
</div>
</div>
<div id="positivstellensatz" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Positivstellensatz<a href="SOS.html#positivstellensatz" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have seen that in the univariate case, a polynomial is nonnegative if and only if it is SOS; while in the multivariate case, being SOS is a sufficient but not necessary condition for nonnegativity in general (e.g., think of the Motzkin’s polynomial). Those characterizations are stated with respect to <span class="math inline">\(\mathbb{R}^{n}\)</span>. What if we are interested in nonnegativity over only a subset of <span class="math inline">\(\mathbb{R}^{n}\)</span>?</p>
<div id="univaraite-intervals" class="section level3 hasAnchor" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Univaraite Intervals<a href="SOS.html#univaraite-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The first result we present here is w.r.t. univariate intervals.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:SOSUnivariateInterval" class="theorem"><strong>Theorem 4.14  (Nonnegativity Over Univaraite Intervals) </strong></span>A univariate polynomial <span class="math inline">\(p(x)\)</span> is nonnegative on <span class="math inline">\([0,\infty]\)</span> if and only if it can be written as
<span class="math display" id="eq:SOS-univariate-interval-1">\[\begin{equation}
p(x) = s(x) + x \cdot t(x)
\tag{4.14}
\end{equation}\]</span>
where <span class="math inline">\(s(x)\)</span> and <span class="math inline">\(t(x)\)</span> are both SOS polynomials. If <span class="math inline">\(\deg(p) = 2d\)</span>, then we have <span class="math inline">\(\deg(s) \leq 2d\)</span> and <span class="math inline">\(\deg(t) \leq 2d -2\)</span>, while if <span class="math inline">\(\deg(p) = 2d+1\)</span>, then <span class="math inline">\(\deg(s) \leq 2d, \deg(t) \leq 2d\)</span>.</p>
<p>Similarly, a univariate polynomial <span class="math inline">\(p(x)\)</span> is nonnegative on the interval <span class="math inline">\([a,b]\)</span> with <span class="math inline">\(a &lt; b\)</span> if and only if it can be written as
<span class="math display" id="eq:SOS-univariate-interval-2">\[\begin{equation}
\begin{cases}
p(x) = s(x) + (x-a)(b-x) \cdot t(x) &amp; \text{if } \deg(p) = 2d, \\
p(x) = (x-a)\cdot s(x) + (b-x) \cdot t(x) &amp; \text{if } \deg(p) = 2d + 1
\end{cases}
\tag{4.15}
\end{equation}\]</span>
where both <span class="math inline">\(s(x),t(x)\)</span> are SOS polynomials. In the first case, <span class="math inline">\(\deg(s) \leq 2d\)</span>, <span class="math inline">\(\deg(t) \leq 2d -2\)</span>. In the second case, <span class="math inline">\(\deg(s) \leq 2d, \deg(t) \leq 2d\)</span>.</p>
</div>
</div>
<p>A simple example of the above theorem is that the polynomial <span class="math inline">\(p(x)=x^3\)</span> is nonnegative on the interval <span class="math inline">\([0,\infty]\)</span> (but not on <span class="math inline">\(\mathbb{R}^{}\)</span>) because we can write <span class="math inline">\(p(x) = x \cdot x^2\)</span> where <span class="math inline">\(x^2\)</span> is SOS.</p>
<p>It should be noted that the “if” direction is clear, i.e., when <span class="math inline">\(p(x)\)</span> can be written as in <a href="SOS.html#eq:SOS-univariate-interval-1">(4.14)</a> and <a href="SOS.html#eq:SOS-univariate-interval-2">(4.15)</a>, it certifies nonnegativity because the polynomials <span class="math inline">\(x, x-a, b-x, (x-a)(b-x)\)</span> are all nonnegative on the respective intervals. The “only if” direction is nontrivial and it states that it is sufficient to consider the decompositions in <a href="SOS.html#eq:SOS-univariate-interval-1">(4.14)</a> and <a href="SOS.html#eq:SOS-univariate-interval-2">(4.15)</a> with bounded degrees on <span class="math inline">\(s(x)\)</span> and <span class="math inline">\(t(x)\)</span>. It should also be noted that finding <span class="math inline">\(s(x)\)</span> and <span class="math inline">\(t(x)\)</span> can be done using SOS programming as introduced above.</p>
</div>
<div id="affine-variety" class="section level3 hasAnchor" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> Affine Variety<a href="SOS.html#affine-variety" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider now the case where we are interested in deciding if a polynomial <span class="math inline">\(p(x)\)</span> is nonnegative on the set defined by a finite number of polynomial equalities
<span class="math display">\[
I = \mathrm{Ideal}[h_1,\dots,h_\ell], \quad V(I) = V_{\mathbb{R}}(I) = \{ x \in \mathbb{R}^{n} \mid h_i(x) = 0, i=1,\dots,\ell \}.
\]</span>
This is an algebraic set. Clearly, if we can decompose <span class="math inline">\(p(x)\)</span> as
<span class="math display">\[
p(x) = \sigma_0(x) + \sum_{i=1}^{\ell} \lambda_i(x) h_i(x),
\]</span>
with <span class="math inline">\(\sigma_0(x)\)</span> SOS and <span class="math inline">\(\lambda_i(x)\)</span> arbitrary polynomials, then it verifies nonnegativity on <span class="math inline">\(V(I)\)</span>. To see this, for any <span class="math inline">\(x \in V(I)\)</span>, we have <span class="math inline">\(h_i(x) = 0,i=1,\dots,\ell\)</span> and hence
<span class="math display">\[
p(x) = \sigma_0(x) + \sum_{i=1}^{\ell} \lambda_i(x) \cdot h_i(x) = \sigma_0(x) \geq 0.
\]</span>
The following result states that it is also a necessary condition under additional assumptions.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:SOSonVaritty" class="theorem"><strong>Theorem 4.15  (SOS on Affine Variety) </strong></span>Let <span class="math inline">\(I\)</span> be a radical ideal. Then <span class="math inline">\(p(x)\)</span> is nonnegative on <span class="math inline">\(V(I)\)</span> if and only if
<span class="math display" id="eq:SOS-variety-decomposition">\[\begin{equation}
p(x) = \sigma_0(x) + \sum_{i=1}^{\ell} \lambda_i(x) h_i(x)
\tag{4.16}
\end{equation}\]</span>
for <span class="math inline">\(\sigma_0(x)\)</span> that is SOS and <span class="math inline">\(\lambda_1(x),\dots,\lambda_{\ell}(x)\)</span> that are arbitrary polynomials.</p>
</div>
</div>
<p>Note that the assumption that <span class="math inline">\(I\)</span> is radical is necessary when <span class="math inline">\(p(x)\)</span> is nonnegative but not strictly positive. For example, the polynomial <span class="math inline">\(p(x)=x\)</span> is nonnegative on the variety defined by the non-radical ideal <span class="math inline">\(\mathrm{Ideal}[x^2]\)</span>, but no decomposition of the form <span class="math inline">\(x = \sigma_0(x) + \lambda(x) x^2\)</span> can possibly exist.</p>
<p>It is also worth noting that, in stark contrast with the Positivstellensatz conditions we stated so far, the degrees of <span class="math inline">\(\sigma_0(x)\)</span> and <span class="math inline">\(\lambda_i(x)\)</span> are not bounded in the decomposition <a href="SOS.html#eq:SOS-variety-decomposition">(4.16)</a>! Therefore, one may need to search for nonnegativity certifcates with infinite degrees. To make the decomposition tractable, it is often done in practice to limit the degrees of <span class="math inline">\(\sigma_0(x)\)</span> and <span class="math inline">\(\lambda_i(x)\)</span> to bound the computational complexity.</p>
<p>It is clear that finding a decomposition of the form <a href="SOS.html#eq:SOS-variety-decomposition">(4.16)</a> with bounded degrees on <span class="math inline">\(\sigma_0(x)\)</span> and <span class="math inline">\(\lambda_i(x)\)</span> is an instance of SOS programming.</p>
<p>When a Grobner basis of the ideal <span class="math inline">\(I\)</span> is available, we can leverage the structure of the problem to formulate a more efficient type of SOS program.</p>
<p>Define the quotient ring <span class="math inline">\(\mathbb{R}[x]/I\)</span>, a different perspective to look at <a href="SOS.html#eq:SOS-variety-decomposition">(4.16)</a> is that
<span class="math display">\[
p(x) \text{ is SOS on } \mathbb{R}[x]/I.
\]</span>
With this perspective, we can formulate an SOS program not with the standard monomial basis, but instead with the <strong>standard monomials</strong>. Let us see an example.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:SOSonQuotientRing" class="example"><strong>Example 4.14  (SOS on Quotient Ring) </strong></span>Consider the problem of deciding if the polynomial
<span class="math display">\[
p(x,y) = 10 - x^2 - y
\]</span>
is nonnegative on the affine variety <span class="math inline">\(V(I)\)</span> with
<span class="math display">\[
I = \mathrm{Ideal}[x^2 + y^2 - 1].
\]</span>
Clearly, <span class="math inline">\(V(I)\)</span> is the unit circle. Since the ideal is generated by a single polynomial, we know that <span class="math inline">\(h(x,y):= x^2 + y^2 - 1\)</span> is already a Grobner basis. With the graded lexicographic monomial ordering and <span class="math inline">\(x \prec y\)</span>, the corresponding set of standard monomials is
<span class="math display">\[
S = \{ 1,x,y,x^2, xy, x^3, x^2 y, \dots \}.
\]</span>
We pick a partial basis of the quotient ring, <span class="math inline">\(\{ 1,x,y \}\)</span>. Then we write
<span class="math display">\[\begin{equation}
\begin{split}
10 - x^2 - y = &amp;  \begin{bmatrix} 1 \\ x \\ y \end{bmatrix}^\top\begin{bmatrix} Q_{11} &amp; Q_{12} &amp; Q_{13} \\ Q_{12} &amp; Q_{22} &amp; Q_{23} \\ Q_{13} &amp; Q_{23} &amp; Q_{33} \end{bmatrix} \begin{bmatrix} 1 \\ x \\ y \end{bmatrix} \\
= &amp; Q_{11} + 2 Q_{12}x + 2 Q_{13} y + Q_{22} x^2 + 2 Q_{23} xy + Q_{33} y^2 \\
\equiv &amp; (Q_{11} + Q_{33}) + (Q_{22} - Q_{33}) x^2 + 2 Q_{12} x + 2 Q_{13} y + 2 Q_{23} xy \quad \text{mod }I
\end{split}
\end{equation}\]</span>
where in the last equation we used the normal form of <span class="math inline">\(y^2\)</span> to write everything using the standard monomials. We can then do the same procedure of matching coefficients and solving the SDP, which gives us a solution
<span class="math display">\[
Q = \begin{bmatrix} 9 &amp; 0 &amp; -\frac{1}{2} \\
0 &amp; 0 &amp; 0 \\
- \frac{1}{2} &amp; 0 &amp; 1
\end{bmatrix}.
\]</span>
Finding a factorization of <span class="math inline">\(Q\)</span> gives us
<span class="math display">\[
10 - x^2 - y \equiv \left( 3 - \frac{y}{6} \right)^2 +
\frac{35}{36} y^2 \quad \text{mod }I,
\]</span>
and shows that it is SOS on the quotient ring.</p>
<p>What if we do not want to use the Grobner basis and standard monomials? We can directly search for the certificate of the form <a href="SOS.html#eq:SOS-variety-decomposition">(4.16)</a> using SOSTOOLS, as shown below</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode matlab"><code class="sourceCode matlab"><span id="cb12-1"><a href="SOS.html#cb12-1" tabindex="-1"></a><span class="va">x</span> <span class="op">=</span> <span class="va">mpvar</span>(<span class="ss">&#39;x&#39;</span><span class="op">,</span><span class="fl">2</span><span class="op">,</span><span class="fl">1</span>)<span class="op">;</span> <span class="co">% dummy x </span></span>
<span id="cb12-2"><a href="SOS.html#cb12-2" tabindex="-1"></a><span class="va">p</span> <span class="op">=</span> <span class="fl">10</span> <span class="op">-</span> <span class="va">x</span>(<span class="fl">1</span>)<span class="op">^</span><span class="fl">2</span> <span class="op">-</span> <span class="va">x</span>(<span class="fl">2</span>)<span class="op">;</span></span>
<span id="cb12-3"><a href="SOS.html#cb12-3" tabindex="-1"></a><span class="va">h</span> <span class="op">=</span> <span class="va">x</span>(<span class="fl">1</span>)<span class="op">^</span><span class="fl">2</span> <span class="op">+</span> <span class="va">x</span>(<span class="fl">2</span>)<span class="op">^</span><span class="fl">2</span> <span class="op">-</span> <span class="fl">1</span><span class="op">;</span></span>
<span id="cb12-4"><a href="SOS.html#cb12-4" tabindex="-1"></a><span class="va">prog</span> <span class="op">=</span> <span class="va">sosprogram</span>(<span class="va">x</span>)<span class="op">;</span></span>
<span id="cb12-5"><a href="SOS.html#cb12-5" tabindex="-1"></a><span class="va">kappa</span> <span class="op">=</span> <span class="fl">1</span><span class="op">;</span> <span class="co">% bound of degree</span></span>
<span id="cb12-6"><a href="SOS.html#cb12-6" tabindex="-1"></a>[<span class="va">prog</span><span class="op">,</span> <span class="va">sig0</span>] <span class="op">=</span> <span class="va">sossosvar</span>(<span class="va">prog</span><span class="op">,</span><span class="va">monomials</span>(<span class="va">x</span><span class="op">,</span><span class="fl">0</span><span class="op">:</span><span class="va">kappa</span>))<span class="op">;</span></span>
<span id="cb12-7"><a href="SOS.html#cb12-7" tabindex="-1"></a>[<span class="va">prog</span><span class="op">,</span> <span class="va">lam</span>] <span class="op">=</span> <span class="va">sospolyvar</span>(<span class="va">prog</span><span class="op">,</span><span class="va">monomials</span>(<span class="va">x</span><span class="op">,</span><span class="fl">0</span><span class="op">:</span>(<span class="fl">2</span><span class="op">*</span><span class="va">kappa</span><span class="op">-</span><span class="fl">2</span>)))<span class="op">;</span></span>
<span id="cb12-8"><a href="SOS.html#cb12-8" tabindex="-1"></a><span class="va">prog</span> <span class="op">=</span> <span class="va">soseq</span>(<span class="va">prog</span><span class="op">,</span><span class="va">p</span><span class="op">-</span><span class="va">sig0</span><span class="op">-</span><span class="va">lam</span><span class="op">*</span><span class="va">h</span>)<span class="op">;</span></span>
<span id="cb12-9"><a href="SOS.html#cb12-9" tabindex="-1"></a><span class="va">options</span>.<span class="va">solver</span> <span class="op">=</span> <span class="ss">&#39;mosek&#39;</span><span class="op">;</span></span>
<span id="cb12-10"><a href="SOS.html#cb12-10" tabindex="-1"></a><span class="va">prog</span> <span class="op">=</span> <span class="va">sossolve</span>(<span class="va">prog</span><span class="op">,</span><span class="va">options</span>)<span class="op">;</span></span></code></pre></div>
<p>Note that the variable <code>kappa</code> is used to bound the degree of SOS polynomials. Solving the above SOS program, I get a solution
<span class="math display">\[
\sigma_0 = 2.8808 x^2 + 3.8808 y ^2 - y + 6.1192, \quad \lambda = -3.8808.
\]</span>
It is easy to verify that <span class="math inline">\(p = \sigma_0 + \lambda h\)</span>.</p>
<p>Note that the decomposition in <a href="SOS.html#eq:SOS-variety-decomposition">(4.16)</a> needs not be unique. If we increase <span class="math inline">\(\kappa\)</span> to be <span class="math inline">\(2\)</span>, we get the solution
<span class="math display">\[\begin{equation}
\begin{split}
\sigma_0 = 2.3716 x^4 + 4.8085 x^2 y^2 + 2.4369 y^4 - 0.14344 x^2 y \\ - 0.14344 y^3 + 1.3059 x^2 + 2.2406 y^2 - 0.85656 y + 5.3225,
\end{split}
\end{equation}\]</span>
<span class="math display">\[
\lambda = -2.3716 x^2 - 2.4369 y^2 + 0.14344 y - 4.6775.
\]</span>
You can play with the code <a href="https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/sos_quotient_ring.m">here</a>.</p>
</div>
</div>
</div>
<div id="basic-semialgebraic-sets" class="section level3 hasAnchor" number="4.5.3">
<h3><span class="header-section-number">4.5.3</span> Basic Semialgebraic Sets<a href="SOS.html#basic-semialgebraic-sets" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We are ready to bring SOS nonnegativity certifcates to full generality. In optimization, usually we are faced with a constraint set defined by finitely many polynomial equalities and inequalities:
<span class="math display" id="eq:basic-semialgebraic-set">\[\begin{equation}
S = \{ x \in \mathbb{R}^{n} \mid h_i(x)=0, i=1,\dots,\ell_h, g_i(x) \geq 0, i = 1,\dots,\ell_g \},
\tag{4.17}
\end{equation}\]</span>
where <span class="math inline">\(h_i\)</span> and <span class="math inline">\(g_i\)</span> are polynomials in <span class="math inline">\(x\)</span>. <span class="math inline">\(S\)</span> is a basic closed semialgebraic set. Often times we are interested in minimizing another polynomial <span class="math inline">\(p(x)\)</span> over <span class="math inline">\(S\)</span>. Before talking about this optimization problem, let us discuss how we can certify nonnegativity of <span class="math inline">\(p(x)\)</span> over <span class="math inline">\(S\)</span>, because minimizing <span class="math inline">\(p(x)\)</span> can be equivalently written as certifying nonnegativity.</p>
<div id="quadratic-module-and-preorder" class="section level4 hasAnchor" number="4.5.3.1">
<h4><span class="header-section-number">4.5.3.1</span> Quadratic Module and Preorder<a href="SOS.html#quadratic-module-and-preorder" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Given a set of polynomials <span class="math inline">\(h_1,\dots,h_{\ell_h}\)</span>, we have seen that the ideal generated by them is
<span class="math display">\[
I=\mathrm{Ideal}[h_1,\dots,h_{\ell_h}] =  \left\{ \sum_{i=1}^{\ell_h} \lambda_i(x) h_i(x) \ \middle\vert\ \lambda_i(x) \in \mathbb{R}[x],i=1,\dots,\ell_h  \right\} .
\]</span>
Every polynomial in the ideal vanishes on <span class="math inline">\(V_{\mathbb{R}}(I)\)</span>, i.e., the algebraic set defined by <span class="math inline">\(I\)</span>.</p>
<p>What is the corresponding notion of an ideal when we have inequalities <span class="math inline">\(g_1,\dots,g_{\ell_g}\)</span>? That is to say, we can try to generate many other polynomials that are also nonnegative on the basic semialgebraic set defined by the inequalities.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:QuadraticModule" class="definition"><strong>Definition 4.20  (Quadratic Module) </strong></span>Given a set of multivariate polynomials <span class="math inline">\(\{ g_1(x),\dots,g_{\ell_g}(x) \}\)</span>, the quadratic module generated by them is the set
<span class="math display">\[
\mathrm{Qmodule}[g_1,\dots,g_{\ell_g}] =  \left\{  \sigma_0(x) + \sigma_1(x)g_1(x) + \cdots + \sigma_{\ell_g}(x) g_{\ell_g}(x) \mid \sigma_0,\dots,\sigma_{\ell_g} \text{ are SOS}  \right\} .
\]</span></p>
<p>The <span class="math inline">\(2d\)</span>-th order truncated quadratic module is
<span class="math display">\[\begin{equation}
\begin{split}
\mathrm{Qmodule}[g_1,\dots,g_{\ell_g}]_{2d} = \\
\left\{  \sigma_0(x) + \sum_{i=1}^{\ell_g} \sigma_i(x)g_i(x) \mid \sigma_0,\dots,\sigma_{\ell_g} \text{ are SOS}, \deg(\sigma_0) \leq 2d, \deg(\sigma_i g_i) \leq 2d,i=1,\dots,\ell_g \right\} .
\end{split}
\end{equation}\]</span></p>
</div>
</div>
<p>For any polynomial <span class="math inline">\(g\)</span> in the quadratic module, and any <span class="math inline">\(x\)</span> such that <span class="math inline">\(g_i(x) \geq 0,i=1,\dots,\ell_g\)</span>, we have <span class="math inline">\(g(x) \geq 0\)</span> due to the fact that <span class="math inline">\(\sigma_i(x)\)</span> are SOS polynomials.</p>
<p>This is not the only way to generate valid inequality constraints given the existing inequalities <span class="math inline">\(\{ g_1(x),\dots,g_{\ell_g}(x) \}\)</span>. More general than the quadratic module is the notion of a preorder.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:Preorder" class="definition"><strong>Definition 4.21  (Preorder) </strong></span>Given a set of multivariate polynomials <span class="math inline">\(\{ g_1(x),\dots,g_{\ell_g}(x) \}\)</span>, the preorder generated by them is the set
<span class="math display">\[\begin{equation}
\begin{split}
\mathrm{Preorder}[g_1,\dots,g_{\ell_g}] = \{ \sigma_0(x) + \sum_{i} \sigma_i(x) g_i(x) +  \sum_{i,j} \sigma_{ij}(x) g_i(x) g_j(x) \\
+ \sum_{i,j,k} \sigma_{ijk}(x) g_i(x) g_j(x) g_k(x) + \cdots \mid \sigma_0(x),\sigma_i(x),\sigma_{ij}(x),\sigma_{ijk}(x)\dots \text{ are SOS} \}
\end{split}
\end{equation}\]</span></p>
</div>
</div>
<p>Comparing the preorder with the quadratic module, we see that when forming the preorder, it is allowed to take arbitrary products of the given polynomials. For this reason, it is clear to observe that
<span class="math display">\[
\mathrm{Qmodule}[g_1,\dots,g_{\ell_g}] \subset \mathrm{Preorder}[g_1,\dots,g_{\ell_g}].
\]</span>
Moreover, for any <span class="math inline">\(g \in \mathrm{Preorder}[g_1,\dots,g_{\ell_g}]\)</span>, and any <span class="math inline">\(x\)</span> such that <span class="math inline">\(g_i \geq 0, i=1,\dots,\ell_g\)</span>, we have that <span class="math inline">\(g(x) \geq 0\)</span> must also hold.</p>
<p>Now the question is, consider the set
<span class="math display">\[
S_{\geq 0} := \{ x \in \mathbb{R}^{n} \mid g_i(x) \geq 0, i=1,\dots,\ell_g \},
\]</span>
do the quadratic module and the preorder generate <strong>all possible</strong> polynomials that are nonnegative on the set <span class="math inline">\(S_{\geq 0}\)</span>? The answer is no, as shown by the following exercise.</p>
<div class="exercisebox">
<div class="exercise">
<p><span id="exr:unlabeled-div-16" class="exercise"><strong>Exercise 4.1  </strong></span></p>
<ul>
<li><p>Let <span class="math inline">\(S = \{ x \in \mathbb{R}^{} \mid x^3 \geq 0 \}\)</span>. Show that the polynomial <span class="math inline">\(x\)</span> is nonnegative on <span class="math inline">\(S\)</span> but it is not in <span class="math inline">\(\mathrm{Preorder}[x^3]\)</span> (and thus is also not in <span class="math inline">\(\mathrm{Qmodule}[x^3]\)</span>).</p></li>
<li><p>Let <span class="math inline">\(S = \{ x \in \mathbb{R}^{}\mid x\geq 0, y\geq 0 \}\)</span>. Show that the polynomial <span class="math inline">\(xy\)</span> is nonnegative on the feasible set but is not in <span class="math inline">\(\mathrm{Qmodule}[x,y]\)</span> (but it is in <span class="math inline">\(\mathrm{Preorder}[x,y]\)</span>).</p></li>
</ul>
</div>
</div>
</div>
<div id="the-positivstellensatz" class="section level4 hasAnchor" number="4.5.3.2">
<h4><span class="header-section-number">4.5.3.2</span> The Positivstellensatz<a href="SOS.html#the-positivstellensatz" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>With the introduction of the quadratic module and the preorder, we can state one of the cornerstone results in real algebraic geometry, the Positivstellensatz, due to <span class="citation">(<a href="#ref-stengle74ma-nullstellensatz">Stengle 1974</a>)</span> and presented in the following form due to <span class="citation">(<a href="#ref-bochnak13book-real">Bochnak, Coste, and Roy 2013</a>)</span>.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:Positivstellensatz" class="theorem"><strong>Theorem 4.16  (Positivstellensatz) </strong></span>Consider the set <span class="math inline">\(S\)</span> in <a href="SOS.html#eq:basic-semialgebraic-set">(4.17)</a> that is defined by polynomial equalities and inequalities. The set <span class="math inline">\(S\)</span> is empty (i.e., the polynomial equalities and inequalities have no solutions in <span class="math inline">\(\mathbb{R}^{n}\)</span>) if and only if
<span class="math display">\[
\exists H(x), G(x) \in \mathbb{R}[x] \quad \mathrm{s.t.}\quad \begin{cases}
H(x) + G(x) = -1 \\
H(x) \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}] \\
G(x) \in \mathrm{Preorder}[g_1,\dots,g_{\ell_g}]
\end{cases}.
\]</span></p>
</div>
</div>
<p>Let us parse the Positivstellensatz result a bit.</p>
<ul>
<li><p>The if direction should be clear. If <span class="math inline">\(S\)</span> is nonempty, then pick <span class="math inline">\(x \in S\)</span>, we have
<span class="math display">\[
H(x) = 0, \quad G(x) \geq 0
\]</span>
for any <span class="math inline">\(H(x)\)</span> in the ideal and <span class="math inline">\(G(x)\)</span> in the preorder. However, <span class="math inline">\(H(x) + G(x) = -1\)</span> exists for some <span class="math inline">\(H\)</span> and <span class="math inline">\(G\)</span>, creating a contradiction. The only if direction is not easy to prove but it states that as long as <span class="math inline">\(S\)</span> is empty, there exists <span class="math inline">\(H(x)\)</span> and <span class="math inline">\(G(x)\)</span> that will serve as <strong>certificates of infeasibility</strong>.</p></li>
<li><p>The Positivstellensatz holds <strong>without any assumptions</strong> on the defining polynomials <span class="math inline">\(h_1,\dots,h_{\ell_h}\)</span> and <span class="math inline">\(g_1,\dots,g_{\ell_g}\)</span>. They need not be convex.</p></li>
<li><p>There is no guarantee that the degrees of the polynomials <span class="math inline">\(H(x)\)</span> and <span class="math inline">\(G(x)\)</span> are bounded. However, once we bound the degrees of <span class="math inline">\(H(x)\)</span> and <span class="math inline">\(G(x)\)</span> (more precisely bound the degrees of the polynomial and SOS multipliers in the ideal and the preorder), then seaching for such certificates is a <strong>convex optimization</strong> problem! In particular, they are SOS programs that we have seen before.</p></li>
</ul>
<p>Let us see an example.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:Positivstellensatz" class="example"><strong>Example 4.15  (Positivstellensatz) </strong></span>Consider the following polynomial system:
<span class="math display">\[\begin{equation}
\begin{split}
h_1 &amp; := x_1^2 + x_2^2 -1 = 0 \\
g_1 &amp; := 3x_2 - x_1^3 -2 \geq 0 \\
g_2 &amp; := x_1 - 8 x_2^3 \geq 0
\end{split}
\end{equation}\]</span></p>
<p>We will use the Positivstellensatz to prove that this system has no real solutions. To do so, according to the Positivstellensatz, the system is infeasible if and only if
<span class="math display">\[
\underbrace{\lambda_1(x) h_1(x)}_{\mathrm{Ideal}[h_1]} + \underbrace{\sigma_0(x) + \sigma_1(x) g_1(x) + \sigma_2(x) g_2(x) + \sigma_{12}(x) g_1(x) g_2(x)}_{\mathrm{Preorder}[g_1,g_2]} = -1.
\]</span>
where <span class="math inline">\(\lambda_1\)</span> is an arbitrary polynomial and <span class="math inline">\(\sigma_0,\sigma_1,\sigma_2,\sigma_{12}\)</span> are SOS polynomials.</p>
<p>We will use SOS programming to find such certificates. In particular, we will search for certifcates with bounded degree <span class="math inline">\(2\kappa\)</span>, where <span class="math inline">\(\kappa \in \mathbb{N}\)</span> is the degree of choice. Solving the SOS program with <span class="math inline">\(\kappa=4\)</span>, we found an infeasibility certifcate. The code can be found <a href="https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/example_infeasibility.m">here</a>.</p>
</div>
</div>
<p>We can use the Positivstellensatz to induce a positivity certificate. Given the set <span class="math inline">\(S\)</span> defined in <a href="SOS.html#eq:basic-semialgebraic-set">(4.17)</a>, and another polynomial <span class="math inline">\(p(x)\)</span>, how can we certify that <span class="math inline">\(p(x)\)</span> is <strong>strictly positive</strong> on <span class="math inline">\(S\)</span>? This is equivalent to showing that the following polynomial system has no real solutions:
<span class="math display" id="eq:Positivstellensatz-positivity">\[\begin{equation}
\begin{cases}
h_i(x) = 0, i=1,\dots,\ell_h \\
g_i(x) \geq 0, i=1,\dots, \ell_g \\
p(x) \leq 0 \Leftrightarrow -p(x) \geq 0
\end{cases}.
\tag{4.18}
\end{equation}\]</span>
By the Positivstellensatz, the polynomial system in <a href="SOS.html#eq:Positivstellensatz-positivity">(4.18)</a> has no real solutions if and only if
<span class="math display">\[
\underbrace{\sum_{i}^{\ell_h} \lambda_i h_i}_{\mathrm{Ideal}[h_1,\dots,h_{\ell_h}]} + \underbrace{\sigma_0 + \sigma_{p} (-p) + \sum_{i=1}^{\ell_g} \sigma_i g_i + \sum_{i,j} \sigma_{ij} g_i g_j + \sum_{i,p} \sigma_{ip} g_i (-p) + \cdots}_{\mathrm{Preorder}[-p,g_1,\dots,g_{\ell_g}]} = -1
\]</span>
Rearranging terms we get
<span class="math display">\[
p\underbrace{\left( \sigma_p + \sum_{i,p} \sigma_{ip} g_i  + \cdots \right)}_{\mathrm{Preorder}[g_1,\dots,g_{\ell_g}]} = 1 + \underbrace{\sum_{i=1}^{\ell_h}}_{\mathrm{Ideal}[h_1,\dots,h_{\ell_h}]} + \underbrace{\sigma_0 + \sum_{i=1}^{\ell_g} \sigma_i g_i + \sum_{i,j} \sigma_{ij} g_i g_j + \cdots}_{\mathrm{Preorder}[g_1,\dots,g_{\ell_g}]}.
\]</span>
Consequently, we have the following corollary.</p>
<div class="theorembox">
<div class="corollary">
<p><span id="cor:Positivstellensatz" class="corollary"><strong>Corollary 4.1  (Positivstellensatz) </strong></span>Consider the set <span class="math inline">\(S\)</span> defined in <a href="SOS.html#eq:basic-semialgebraic-set">(4.17)</a>. A polynomial <span class="math inline">\(p(x)\)</span> is strictly positive on <span class="math inline">\(S\)</span> if and only if there exist <span class="math inline">\(G_1(x),G_2(x),H(x) \in \mathbb{R}[x]\)</span> such that
<span class="math display">\[
p(x) = \frac{1 + H(x) + G_1(x)}{G_2(x)}, \quad H(x) \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}], G_1(x),G_2(x) \in \mathrm{Preorder}[g_1,\dots,g_{\ell_g}].
\]</span></p>
</div>
</div>
</div>
<div id="schmudgens-and-putinars-positivity-certificates" class="section level4 hasAnchor" number="4.5.3.3">
<h4><span class="header-section-number">4.5.3.3</span> Schmudgen’s and Putinar’s Positivity Certificates<a href="SOS.html#schmudgens-and-putinars-positivity-certificates" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The positivity certifcate in Corollay <a href="SOS.html#cor:Positivstellensatz">4.1</a> holds without any assumptions on the set <span class="math inline">\(S\)</span>. However, when the set <span class="math inline">\(S\)</span> is compact, the positivity certifcate can be simplified.</p>
<p>The first simplification is due to Schmudgen <span class="citation">(<a href="#ref-Schmudgen91ma-moment">Schmudgen 1991</a>)</span>.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:Schmudgen" class="theorem"><strong>Theorem 4.17  (Schmudgen's Positivstellensatz) </strong></span>Let <span class="math inline">\(S\)</span> defined in <a href="SOS.html#eq:basic-semialgebraic-set">(4.17)</a> be compact. A polynomial <span class="math inline">\(p(x)\)</span> is strictly positive on <span class="math inline">\(S\)</span> if and only if
<span class="math display">\[
p(x) \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}] + \mathrm{Preorder}[g_1,\dots,g_{\ell_g}].
\]</span></p>
</div>
</div>
<p>The second simplification, due to Putinar <span class="citation">(<a href="#ref-putinar93-positive">Putinar 1993</a>)</span> adds a further assumption that the set <span class="math inline">\(S\)</span> is compact with a certifcate.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:Archimedean" class="definition"><strong>Definition 4.22  (Archimedean) </strong></span>The set <span class="math inline">\(S\)</span> is said to be Archimedean if there exists <span class="math inline">\(N \in \mathbb{N}\)</span> such that
<span class="math display">\[
N - \sum_{i=1}^n x_i^2 \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}] + \mathrm{Qmodule}[g_1,\dots,g_{\ell_g}].
\]</span></p>
</div>
</div>
<p>In practice, if we know the set <span class="math inline">\(S\)</span> is compact, then we might as well just add a constraint <span class="math inline">\(g:=N - \sum_{i=1}^{n} x_i^2\)</span> to the set <span class="math inline">\(S\)</span> to make the Archimedean condition trivially satisfied. Under the Archimedean condition, we have the simpler Positivstellensatz.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:Putinar" class="theorem"><strong>Theorem 4.18  (Putinar's Positivstellensatz) </strong></span>Let <span class="math inline">\(S\)</span> defined in <a href="SOS.html#eq:basic-semialgebraic-set">(4.17)</a> be Archimedean. A polynomial <span class="math inline">\(p(x)\)</span> is strictly positive on <span class="math inline">\(S\)</span> if and only if
<span class="math display">\[
p(x) \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}] + \mathrm{Qmodule}[g_1,\dots,g_{\ell_g}].
\]</span></p>
</div>
</div>
<p>It is important to recognize that searching for positivity certifcates in the form of Schmudgen or Putinar with <strong>bounded degrees</strong> is a convex optimization problem.</p>
</div>
</div>
</div>
<div id="applications-1" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Applications<a href="SOS.html#applications-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The Positivstellensatz results stated above are extremely powerful tools and they have a broad set of applications due to their connections with semidefinite programming.</p>
<div id="SOS:POP" class="section level3 hasAnchor" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> Polynomial Optimization<a href="SOS.html#SOS:POP" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider the polynomial optimization problem (POP)
<span class="math display" id="eq:pop">\[\begin{equation}
\begin{split}
p^\star = \min_{x \in \mathbb{R}^{n}} &amp; \quad p(x) \\
\mathrm{s.t.}&amp; \quad h_i(x) = 0, i=1,\dots,\ell_h \\
&amp; \quad g_i(x) \geq 0, i=1,\dots,\ell_g
\end{split}
\tag{4.19}
\end{equation}\]</span>
We denote the feasible set of <a href="SOS.html#eq:pop">(4.19)</a> as <span class="math inline">\(S\)</span> and we assume <span class="math inline">\(S\)</span> is nonempty. The POP is a very general modelling language and in general it is NP-hard to solve it to global optimality. To connect it with the QCQP formulation we introduced before, we clearly see that POP subsumes QCQP.</p>
<p>We will show that the Positivstellensatz provides a way to use convex optimization to approximately solve POP to global optimality. To see this, note that the original POP formulation <a href="SOS.html#eq:pop">(4.19)</a> is equivalent to
<span class="math display" id="eq:pop-gamma-nonnegative">\[\begin{equation}
\max \quad \gamma \quad \mathrm{s.t.}\quad p(x) - \gamma \text{ is nonnegative on } S.
\tag{4.20}
\end{equation}\]</span>
Since it is challenging to handle the nonnegativity constraint, we can relax it using the Positivstellensatz results before. For example, assuming the set <span class="math inline">\(S\)</span> is Archimedean, we can invoke Putinar’s Positivstellensatz and equivalently write <a href="SOS.html#eq:pop-gamma-nonnegative">(4.20)</a> as
<span class="math display" id="eq:pop-gamma-nonnegative-Putinar">\[\begin{equation}
\max \quad \gamma \quad \mathrm{s.t.}\quad p(x) - \gamma \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}] + \mathrm{Qmodule}[g_1,\dots,g_{\ell_g}].
\tag{4.21}
\end{equation}\]</span>
To make <a href="SOS.html#eq:pop-gamma-nonnegative-Putinar">(4.21)</a> computationally tractable, we can bound the degree of the terms and formulate the following optimization problem
<span class="math display" id="eq:pop-gamma-nonnegative-Putinar-truncated">\[\begin{equation}
\max \quad \gamma \quad \mathrm{s.t.}\quad p(x) - \gamma \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}]_{2\kappa} + \mathrm{Qmodule}[g_1,\dots,g_{\ell_g}]_{2\kappa},
\tag{4.22}
\end{equation}\]</span>
where the subscript <span class="math inline">\(2\kappa\)</span> indicates the ideal and the quadratic module are truncated at degree <span class="math inline">\(2\kappa\)</span>. Problem <a href="SOS.html#eq:pop-gamma-nonnegative-Putinar-truncated">(4.22)</a> can be explicitly written as
<span class="math display" id="eq:pop-gamma-nonnegative-Putinar-bound">\[\begin{equation}
\begin{split}
\gamma^\star_{\kappa}=\max &amp; \quad \gamma\\
\mathrm{s.t.}&amp; \quad p(x) - \gamma = \sum_{i}^{\ell_h} \lambda_i(x) h_i(x) + \sum_{i=0}^{\ell_g} \sigma_i(x) g_i(x) \\
&amp; \quad \deg(\lambda_i(x) h_i(x)) \leq 2\kappa, i=1,\dots,\ell_h \\
&amp; \quad \deg(\sigma_i(x) g_i(x)) \leq 2\kappa, i=1,\dots,\ell_g \\
&amp; \quad \lambda_i(x) \in \mathbb{R}[x], i=1,\dots,\ell_h, \quad \sigma_i(x) \in \Sigma[x], i=1,\dots,\ell_g.
\end{split}
\tag{4.23}
\end{equation}\]</span>
where I have added <span class="math inline">\(g_0:=1\)</span> as a dummy constraint, <span class="math inline">\(\Sigma[x]\)</span> denotes the set of SOS polynomials, and <span class="math inline">\(\kappa\)</span> is called the <strong>relaxation order</strong>. We have
<span class="math display">\[
\gamma^\star_{\kappa} \leq p^\star.
\]</span></p>
<p><strong>Problem <a href="SOS.html#eq:pop-gamma-nonnegative-Putinar-bound">(4.23)</a> is convex!</strong> In fact, it is an instance of an SOS program. Note, again, <strong>the decision variable of <a href="SOS.html#eq:pop-gamma-nonnegative-Putinar-bound">(4.23)</a> is not <span class="math inline">\(x\)</span>!</strong> The decision variable is <span class="math inline">\(\gamma\)</span>, the coefficients of <span class="math inline">\(\lambda_i\)</span>, and the coefficients (Gram matrix) of <span class="math inline">\(\sigma_i\)</span>.</p>
<p>Let us use a simple example to illustrate this.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:SOSRelaxation" class="example"><strong>Example 4.16  (SOS Relaxation of Polynomial Optimization) </strong></span>Consider the optimization problem
<span class="math display">\[
\min_{x_1,x_2} \quad 4 x_1^3 + 6 x_2  \quad \mathrm{s.t.}\quad x_1^2 = x_2^2 = 1, x_1 \geq 0.
\]</span>
This is a POP we can solve by hand. The optimal solution is
<span class="math display">\[
x_\star = (1,-1),
\]</span>
with the optimal value <span class="math inline">\(p^\star = -2\)</span>.
The feasible set is Archimedean. Therefore, we can solve <a href="SOS.html#eq:pop-gamma-nonnegative-Putinar-bound">(4.23)</a> to obtain a lower bound to <span class="math inline">\(p^\star\)</span>.</p>
<p>Solving <a href="SOS.html#eq:pop-gamma-nonnegative-Putinar-bound">(4.23)</a> at <span class="math inline">\(\kappa=2\)</span>, we obtain <span class="math inline">\(\gamma_{2}^\star = -2\)</span>, which is actually the true global optimum!</p>
<p>Make sure you check out the <a href="https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/example_pop.m">code</a>.</p>
</div>
</div>
</div>
<div id="lyapunov-certificates" class="section level3 hasAnchor" number="4.6.2">
<h3><span class="header-section-number">4.6.2</span> Lyapunov Certificates<a href="SOS.html#lyapunov-certificates" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In Chapter <a href="sdp.html#LyapunovLinearSystem">2.5.1</a> we have seen the application of SDP in certifying stability of linear systems via the notion of a Lyapunov function. With sums of squares, we can generalize Lyapunov certifcates to nonlinear systems, in particular systems whose dynamics can be written as polynomials. You can find more information in this webpage.</p>

</div>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-blekherman12book-semidefinite" class="csl-entry">
Blekherman, Grigoriy, Pablo A Parrilo, and Rekha R Thomas. 2012. <em>Semidefinite Optimization and Convex Algebraic Geometry</em>. SIAM.
</div>
<div id="ref-bochnak13book-real" class="csl-entry">
Bochnak, Jacek, Michel Coste, and Marie-Françoise Roy. 2013. <em>Real Algebraic Geometry</em>. Vol. 36. Springer Science &amp; Business Media.
</div>
<div id="ref-corless97-reordered" class="csl-entry">
Corless, Robert M, Patrizia M Gianni, and Barry M Trager. 1997. <span>“A Reordered Schur Factorization Method for Zero-Dimensional Polynomial Systems with Multiple Roots.”</span> In <em>Proceedings of the 1997 International Symposium on Symbolic and Algebraic Computation</em>, 133–40.
</div>
<div id="ref-cox13book-ideals" class="csl-entry">
Cox, David, John Little, and Donal OShea. 2013. <em>Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra</em>. Springer Science &amp; Business Media.
</div>
<div id="ref-dummit04book-abstract" class="csl-entry">
Dummit, David Steven, and Richard M Foote. 2004. <em>Abstract Algebra</em>. Vol. 3. Wiley Hoboken.
</div>
<div id="ref-lang12book-algebra" class="csl-entry">
Lang, Serge. 2012. <em>Algebra</em>. Vol. 211. Springer Science &amp; Business Media.
</div>
<div id="ref-lofberg04icra-yalmip" class="csl-entry">
Lofberg, Johan. 2004. <span>“YALMIP: A Toolbox for Modeling and Optimization in MATLAB.”</span> In <em>2004 IEEE International Conference on Robotics and Automation (IEEE Cat. No. 04CH37508)</em>, 284–89. IEEE.
</div>
<div id="ref-prajna02cdc-sostools" class="csl-entry">
Prajna, Stephen, Antonis Papachristodoulou, and Pablo A Parrilo. 2002. <span>“Introducing SOSTOOLS: A General Purpose Sum of Squares Programming Solver.”</span> In <em>Proceedings of the 41st IEEE Conference on Decision and Control, 2002.</em>, 1:741–46. IEEE.
</div>
<div id="ref-putinar93-positive" class="csl-entry">
Putinar, Mihai. 1993. <span>“Positive Polynomials on Compact Semi-Algebraic Sets.”</span> <em>Indiana University Mathematics Journal</em> 42 (3): 969–84.
</div>
<div id="ref-ramana95jgo-some" class="csl-entry">
Ramana, Motakuri, and Alan J Goldman. 1995. <span>“Some Geometric Results in Semidefinite Programming.”</span> <em>Journal of Global Optimization</em> 7 (1): 33–50.
</div>
<div id="ref-reznick00cm-some" class="csl-entry">
Reznick, Bruce. 2000. <span>“Some Concrete Aspects of Hilbert’s 17th Problem.”</span> <em>Contemporary Mathematics</em> 253: 251–72.
</div>
<div id="ref-Schmudgen91ma-moment" class="csl-entry">
Schmudgen, Konrad. 1991. <span>“THE k-MOMENT PROBLEM FOR COMPACT SEMI-ALGEBRAIC SETS.”</span> <em>Mathematische Annalen</em>.
</div>
<div id="ref-stengle74ma-nullstellensatz" class="csl-entry">
Stengle, Gilbert. 1974. <span>“A Nullstellensatz and a Positivstellensatz in Semialgebraic Geometry.”</span> <em>Mathematische Annalen</em> 207: 87–97.
</div>
<div id="ref-sturmfels05notes-grobner" class="csl-entry">
Sturmfels, Bernd. 2005. <span>“What Is... A Grobner Basis?”</span> <em>Notices-American Mathematical Society</em> 52 (10): 1199.
</div>
</div>
<div id="disqus_thread"></div>
<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://semidefinite.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="Shor.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Moment.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/hankyang94/Semidefinite/blob/main/04-SOSRelaxation.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["semidefinite-optimization-relaxation.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
