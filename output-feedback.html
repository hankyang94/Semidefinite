<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Output Feedback | Optimal Control and Estimation</title>
  <meta name="description" content="Lecture notes for Harvard ES/AM 158 Introduction to Optimal Control and Estimation." />
  <meta name="generator" content="bookdown 0.33 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Output Feedback | Optimal Control and Estimation" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture notes for Harvard ES/AM 158 Introduction to Optimal Control and Estimation." />
  <meta name="github-repo" content="hankyang94/OptimalControlEstimation" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Output Feedback | Optimal Control and Estimation" />
  
  <meta name="twitter:description" content="Lecture notes for Harvard ES/AM 158 Introduction to Optimal Control and Estimation." />
  

<meta name="author" content="Heng Yang" />


<meta name="date" content="2023-08-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="stability.html"/>
<link rel="next" href="adaptivecontrol.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Optimal Control and Estimation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="formulation.html"><a href="formulation.html"><i class="fa fa-check"></i><b>1</b> The Optimal Control Formulation</a>
<ul>
<li class="chapter" data-level="1.1" data-path="formulation.html"><a href="formulation.html#the-basic-problem"><i class="fa fa-check"></i><b>1.1</b> The Basic Problem</a></li>
<li class="chapter" data-level="1.2" data-path="formulation.html"><a href="formulation.html#dynamic-programming-and-principle-of-optimality"><i class="fa fa-check"></i><b>1.2</b> Dynamic Programming and Principle of Optimality</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="exactdp.html"><a href="exactdp.html"><i class="fa fa-check"></i><b>2</b> Exact Dynamic Programming</a>
<ul>
<li class="chapter" data-level="2.1" data-path="exactdp.html"><a href="exactdp.html#lqr"><i class="fa fa-check"></i><b>2.1</b> Linear Quadratic Regulator</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="exactdp.html"><a href="exactdp.html#infinite-horizon-lqr"><i class="fa fa-check"></i><b>2.1.1</b> Infinite-Horizon LQR</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="approximatedp.html"><a href="approximatedp.html"><i class="fa fa-check"></i><b>3</b> Approximate Dynamic Programming</a>
<ul>
<li class="chapter" data-level="3.1" data-path="approximatedp.html"><a href="approximatedp.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="approximatedp.html"><a href="approximatedp.html#approximation-in-value-space"><i class="fa fa-check"></i><b>3.2</b> Approximation in value space</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="approximatedp.html"><a href="approximatedp.html#problem-approximation"><i class="fa fa-check"></i><b>3.2.1</b> Problem Approximation</a></li>
<li class="chapter" data-level="3.2.2" data-path="approximatedp.html"><a href="approximatedp.html#parametric-cost-approximation"><i class="fa fa-check"></i><b>3.2.2</b> Parametric cost approximation</a></li>
<li class="chapter" data-level="3.2.3" data-path="approximatedp.html"><a href="approximatedp.html#online-approximate-optimization"><i class="fa fa-check"></i><b>3.2.3</b> Online approximate optimization</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="approximatedp.html"><a href="approximatedp.html#approximation-in-policy-space"><i class="fa fa-check"></i><b>3.3</b> Approximation in policy space</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="approximatedp.html"><a href="approximatedp.html#training-by-using-an-expert"><i class="fa fa-check"></i><b>3.3.1</b> Training by using an expert</a></li>
<li class="chapter" data-level="3.3.2" data-path="approximatedp.html"><a href="approximatedp.html#training-by-cost-optimization"><i class="fa fa-check"></i><b>3.3.2</b> Training by cost optimization</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="approximatedp.html"><a href="approximatedp.html#extension"><i class="fa fa-check"></i><b>3.4</b> Extension</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="stability.html"><a href="stability.html"><i class="fa fa-check"></i><b>4</b> Stability Analysis</a>
<ul>
<li class="chapter" data-level="4.1" data-path="stability.html"><a href="stability.html#autonomous-systems"><i class="fa fa-check"></i><b>4.1</b> Autonomous Systems</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="stability.html"><a href="stability.html#concepts-of-stability"><i class="fa fa-check"></i><b>4.1.1</b> Concepts of Stability</a></li>
<li class="chapter" data-level="4.1.2" data-path="stability.html"><a href="stability.html#stability-by-linearization"><i class="fa fa-check"></i><b>4.1.2</b> Stability by Linearization</a></li>
<li class="chapter" data-level="4.1.3" data-path="stability.html"><a href="stability.html#lyapunov-analysis"><i class="fa fa-check"></i><b>4.1.3</b> Lyapunov Analysis</a></li>
<li class="chapter" data-level="4.1.4" data-path="stability.html"><a href="stability.html#invariant-set-theorem"><i class="fa fa-check"></i><b>4.1.4</b> Invariant Set Theorem</a></li>
<li class="chapter" data-level="4.1.5" data-path="stability.html"><a href="stability.html#computing-lyapunov-certificates"><i class="fa fa-check"></i><b>4.1.5</b> Computing Lyapunov Certificates</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="stability.html"><a href="stability.html#controlled-systems"><i class="fa fa-check"></i><b>4.2</b> Controlled Systems</a></li>
<li class="chapter" data-level="4.3" data-path="stability.html"><a href="stability.html#non-autonomous-systems"><i class="fa fa-check"></i><b>4.3</b> Non-autonomous Systems</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="output-feedback.html"><a href="output-feedback.html"><i class="fa fa-check"></i><b>5</b> Output Feedback</a>
<ul>
<li class="chapter" data-level="5.1" data-path="output-feedback.html"><a href="output-feedback.html#state-observer"><i class="fa fa-check"></i><b>5.1</b> State Observer</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="output-feedback.html"><a href="output-feedback.html#general-design-strategy"><i class="fa fa-check"></i><b>5.1.1</b> General Design Strategy</a></li>
<li class="chapter" data-level="5.1.2" data-path="output-feedback.html"><a href="output-feedback.html#luenberger-template"><i class="fa fa-check"></i><b>5.1.2</b> Luenberger Template</a></li>
<li class="chapter" data-level="5.1.3" data-path="output-feedback.html"><a href="output-feedback.html#state-affine-template"><i class="fa fa-check"></i><b>5.1.3</b> State-affine Template</a></li>
<li class="chapter" data-level="5.1.4" data-path="output-feedback.html"><a href="output-feedback.html#kazantzis-kravaris-luenberger-kkl-template"><i class="fa fa-check"></i><b>5.1.4</b> Kazantzis-Kravaris-Luenberger (KKL) Template</a></li>
<li class="chapter" data-level="5.1.5" data-path="output-feedback.html"><a href="output-feedback.html#triangular-template"><i class="fa fa-check"></i><b>5.1.5</b> Triangular Template</a></li>
<li class="chapter" data-level="5.1.6" data-path="output-feedback.html"><a href="output-feedback.html#design-with-convex-optimization"><i class="fa fa-check"></i><b>5.1.6</b> Design with Convex Optimization</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="output-feedback.html"><a href="output-feedback.html#observer-feedback"><i class="fa fa-check"></i><b>5.2</b> Observer Feedback</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html"><i class="fa fa-check"></i><b>6</b> Adaptive Control</a>
<ul>
<li class="chapter" data-level="6.1" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#model-reference-adaptive-control"><i class="fa fa-check"></i><b>6.1</b> Model-Reference Adaptive Control</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#first-order-systems"><i class="fa fa-check"></i><b>6.1.1</b> First-Order Systems</a></li>
<li class="chapter" data-level="6.1.2" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#high-order-systems"><i class="fa fa-check"></i><b>6.1.2</b> High-Order Systems</a></li>
<li class="chapter" data-level="6.1.3" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#robotic-manipulator"><i class="fa fa-check"></i><b>6.1.3</b> Robotic Manipulator</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#certainty-equivalent-adaptive-control"><i class="fa fa-check"></i><b>6.2</b> Certainty-Equivalent Adaptive Control</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html"><i class="fa fa-check"></i><b>A</b> Linear System Theory</a>
<ul>
<li class="chapter" data-level="A.1" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#app-lti-stability"><i class="fa fa-check"></i><b>A.1</b> Stability</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#app-lti-stability-ct"><i class="fa fa-check"></i><b>A.1.1</b> Continuous-Time Stability</a></li>
<li class="chapter" data-level="A.1.2" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#app-lti-stability-dt"><i class="fa fa-check"></i><b>A.1.2</b> Discrete-Time Stability</a></li>
<li class="chapter" data-level="A.1.3" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#lyapunov-analysis-1"><i class="fa fa-check"></i><b>A.1.3</b> Lyapunov Analysis</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#app-lti-controllable-observable"><i class="fa fa-check"></i><b>A.2</b> Controllability and Observability</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#cayley-hamilton-theorem"><i class="fa fa-check"></i><b>A.2.1</b> Cayley-Hamilton Theorem</a></li>
<li class="chapter" data-level="A.2.2" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#equivalent-statements-for-controllability"><i class="fa fa-check"></i><b>A.2.2</b> Equivalent Statements for Controllability</a></li>
<li class="chapter" data-level="A.2.3" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#duality"><i class="fa fa-check"></i><b>A.2.3</b> Duality</a></li>
<li class="chapter" data-level="A.2.4" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#equivalent-statements-for-observability"><i class="fa fa-check"></i><b>A.2.4</b> Equivalent Statements for Observability</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#stabilizability-and-detectability"><i class="fa fa-check"></i><b>A.3</b> Stabilizability And Detectability</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#equivalent-statements-for-stabilizability"><i class="fa fa-check"></i><b>A.3.1</b> Equivalent Statements for Stabilizability</a></li>
<li class="chapter" data-level="A.3.2" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#equivalent-statements-for-detectability"><i class="fa fa-check"></i><b>A.3.2</b> Equivalent Statements for Detectability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appconvex.html"><a href="appconvex.html"><i class="fa fa-check"></i><b>B</b> Convex Analysis and Optimization</a></li>
<li class="chapter" data-level="C" data-path="the-kalman-yakubovich-lemma.html"><a href="the-kalman-yakubovich-lemma.html"><i class="fa fa-check"></i><b>C</b> The Kalman-Yakubovich Lemma</a></li>
<li class="chapter" data-level="D" data-path="feedbacklinearization.html"><a href="feedbacklinearization.html"><i class="fa fa-check"></i><b>D</b> Feedback Linearization</a></li>
<li class="chapter" data-level="E" data-path="slidingcontrol.html"><a href="slidingcontrol.html"><i class="fa fa-check"></i><b>E</b> Sliding Control</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Optimal Control and Estimation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="output-feedback" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Output Feedback<a href="output-feedback.html#output-feedback" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Consider a continuous-time dynamical system
<span class="math display" id="eq:output-feedback-system">\[\begin{equation}
\begin{split}
\dot{x} &amp;= f(x,u)  \\
y &amp;= h(x,u)
\end{split}
\tag{5.1}
\end{equation}\]</span>
where <span class="math inline">\(x(t) \in \mathbb{X} \subseteq \mathbb{R}^n\)</span> the state of the system, <span class="math inline">\(u(t) \in \mathbb{U} \subseteq \mathbb{R}^m\)</span> the control (or input), <span class="math inline">\(y(t) \in \mathbb{Y} \subseteq \mathbb{R}^{d}\)</span> the output (i.e., measurement) of the state and control, and <span class="math inline">\(f,g\)</span> the evolution and measurement functions (which are sufficiently smooth).</p>
<div id="state-observer" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> State Observer<a href="output-feedback.html#state-observer" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For the system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a>, let us denote</p>
<ul>
<li><p><span class="math inline">\(X(x_0,t_0;t;u)\)</span> the solution at time <span class="math inline">\(t\)</span> with input <span class="math inline">\(u\)</span> and initial condition <span class="math inline">\(x_0\)</span> at time <span class="math inline">\(t_0\)</span>; when <span class="math inline">\(t_0 = 0\)</span>, we write <span class="math inline">\(X(x_0;t;u)\)</span></p></li>
<li><p><span class="math inline">\(Y(x_0,t_0;t;u)\)</span> the output at time <span class="math inline">\(t\)</span> with input <span class="math inline">\(u\)</span> and initial condition <span class="math inline">\(x_0\)</span> at time <span class="math inline">\(t_0\)</span>, i.e., <span class="math inline">\(Y(x_0,t_0;t;u) = h(X(x_0,t_0;t;u), u(t))\)</span>; when <span class="math inline">\(t_0 = 0\)</span>, we write <span class="math inline">\(y_{x_0,u}(t)\)</span>;</p></li>
<li><p><span class="math inline">\(\mathcal{X}_0\)</span> a subset of <span class="math inline">\(\mathbb{X}\)</span> containing the initial conditions we consider; for any <span class="math inline">\(x_0 \in \mathcal{X}_0\)</span>, we write <span class="math inline">\(\sigma^+_{\mathcal{X}}(x_0;u)\)</span> the maximal time of existence of <span class="math inline">\(X(x_0,\cdot;t;u)\)</span> in a set <span class="math inline">\(\mathcal{X}\)</span></p></li>
<li><p><span class="math inline">\(\mathcal{U}\)</span> the set of all sufficiently many times differentiable inputs <span class="math inline">\(u: [0,+\infty) \rightarrow \mathbb{U}\)</span>.</p></li>
</ul>
<p>The problem of state observation is to produce an estimated state <span class="math inline">\(\hat{x}(t)\)</span> of the true state <span class="math inline">\(X(x_0,t_0;t;u)\)</span> based on knowledge about the system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a> and information about the history of inputs <span class="math inline">\(u_{[0,t]}\)</span> and outputs <span class="math inline">\(y_{[0,t]}\)</span>, so that <span class="math inline">\(\hat{x}(t)\)</span> asymptotically converges to <span class="math inline">\(X(x_0,t_0;t;u)\)</span>, for any initial condition <span class="math inline">\(x_0 \in \mathcal{X}_0\)</span> and any input <span class="math inline">\(u \in \mathcal{U}\)</span>.</p>
<p>There are multiple ways for solving the problem of state observation (see e.g., <span class="citation">(<a href="#ref-bernard19book-observer">Bernard 2019</a>)</span>, <span class="citation">(<a href="#ref-bernard22arc-observer">Bernard, Andrieu, and Astolfi 2022</a>)</span>). Here we are particularly interested in the approach using a <em>state observer</em>, i.e., a dynamical system whose <em>internal state</em> evolves according to the history of inputs and outputs, from which a state estimation can be reconstructed that guarantees asymptotic convergence to the true state. We formalize this concept below.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:stateobserver" class="definition"><strong>Definition 5.1  (State Observer) </strong></span>A state observer for system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a> is a couple <span class="math inline">\((\mathcal{F},\mathcal{T})\)</span> such that</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\mathcal{F}: \mathbb{R}^{l} \times \mathbb{R}^{m} \times \mathbb{R}^d \rightarrow \mathbb{R}^l\)</span> is continuous</p></li>
<li><p><span class="math inline">\(\mathcal{T}\)</span> is a family of continuous functions indexed by <span class="math inline">\(u \in \mathcal{U}\)</span> where each <span class="math inline">\(\mathcal{T}_u: \mathbb{R}^l \times [0,+\infty) \rightarrow \mathbb{R}^n\)</span> respects the causality condition
<span class="math display">\[
\forall \tilde{u}: [0,+\infty) \rightarrow \mathbb{R}^m,\forall t \in [0,+\infty), u_{[0,t]} = \tilde{u}_{[0,t]} \Rightarrow  \mathcal{F}_u (\cdot,t) = \mathcal{F}_{\tilde{u}}(\cdot,t).
\]</span></p></li>
<li><p>For any <span class="math inline">\(u \in \mathcal{U}\)</span>, any <span class="math inline">\(z_0 \in \mathbb{R}^l\)</span>, and any <span class="math inline">\(x_0 \in \mathcal{X}_0\)</span> such that <span class="math inline">\(\sigma^+_{\mathbb{X}}(x_0;u) = +\infty\)</span>, any solution <span class="math inline">\(Z(z_0;t;u,y_{x_0,u})\)</span><a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> to
<span class="math display" id="eq:observer-definition-1">\[\begin{equation}
\dot{z} = \mathcal{F}(z,u,y_{x_0,u})
\tag{5.2}
\end{equation}\]</span>
initialized at <span class="math inline">\(z_0\)</span> at time <span class="math inline">\(0\)</span> with input <span class="math inline">\(u\)</span> and <span class="math inline">\(y_{x_0,u}\)</span> exists on <span class="math inline">\([0,+\infty)\)</span> and satisfies
<span class="math display" id="eq:observer-definition-2">\[\begin{equation}
\lim_{t \rightarrow \infty} \Vert \hat{X}(x_0,z_0;t;u) - X(x_0;t;u) \Vert = 0,
\tag{5.3}
\end{equation}\]</span>
with
<span class="math display" id="eq:observer-definition-3">\[\begin{equation}
\hat{X}(x_0,z_0;t;u) = \mathcal{T}_u(Z(z_0;t;u,y_{x_0,u}),t).
\tag{5.4}
\end{equation}\]</span>
In words, (i) the state observer maintains an internal state (or latent state) <span class="math inline">\(z \in \mathbb{R}^l\)</span> that evolves according to the latent dynamics <span class="math inline">\(\mathcal{F}\)</span> in <a href="output-feedback.html#eq:observer-definition-1">(5.2)</a>, where <span class="math inline">\(u\)</span> and <span class="math inline">\(y_{x_0,u}\)</span> are inputs; (ii) an estimated state can be reconstructed from the internal state using <span class="math inline">\(\mathcal{T}_u\)</span> as in <a href="output-feedback.html#eq:observer-definition-3">(5.4)</a>; and (iii) the error between the estimated state and the true state (defined by a proper distance function <span class="math inline">\(\Vert \cdot \Vert\)</span> on <span class="math inline">\(\mathbb{X}\)</span>) converges to zero.</p></li>
</ol>
<p>If <span class="math inline">\(\mathcal{T}_u\)</span> is the same for any <span class="math inline">\(u \in \mathcal{U}\)</span> and is also time independent, then we say <span class="math inline">\(\mathcal{T}\)</span> is <em>stationary</em>.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> In this case, we can simply write the observer <a href="output-feedback.html#eq:observer-definition-1">(5.2)</a> and <a href="output-feedback.html#eq:observer-definition-3">(5.4)</a> as
<span class="math display" id="eq:observer-definition-simple">\[\begin{equation}
\begin{split}
\dot{z} &amp;= \mathcal{F}(z,u,y) \\
\hat{x} &amp;= \mathcal{T}(z).
\end{split}
\tag{5.5}
\end{equation}\]</span></p>
<p>If <span class="math inline">\(\hat{x}\)</span> can be read off directly from <span class="math inline">\(z\)</span>, then we say the observer <a href="output-feedback.html#eq:observer-definition-simple">(5.5)</a> is <em>in the given coordinates</em>. A special case of this is when <span class="math inline">\(\hat{x} = z\)</span>, i.e., the internal state of the observer is the same as the system state.</p>
</div>
</div>
<div id="general-design-strategy" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> General Design Strategy<a href="output-feedback.html#general-design-strategy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:observerdesignmeta" class="theorem"><strong>Theorem 5.1  (Meta Observer) </strong></span>Let <span class="math inline">\(F: \mathbb{R}^p \times \mathbb{R}^m \times \mathbb{R}^d \rightarrow \mathbb{R}^p\)</span>, <span class="math inline">\(H: \mathbb{R}^p \times \mathbb{R}^m \rightarrow \mathbb{R}^d\)</span> and <span class="math inline">\(\mathcal{F}: \mathbb{R}^p \times \mathbb{R}^m \times \mathbb{R}^d \rightarrow \mathbb{R}^p\)</span> be continuous functions such that
<span class="math display" id="eq:meta-observer-zeta-hat">\[\begin{equation}
\dot{\hat{\xi}} = \mathcal{F}(\hat{\xi}, u, \tilde{y})
\tag{5.6}
\end{equation}\]</span>
is an observer for
<span class="math display" id="eq:meta-observer-zeta">\[\begin{equation}
\dot{\xi} = F(\xi,u,H(\xi,u)), \quad \tilde{y} = H(\xi,u),
\tag{5.7}
\end{equation}\]</span>
i.e., for any <span class="math inline">\(\xi_0,\hat{\xi}_0 \in \mathbb{R}^p\)</span> and any <span class="math inline">\(u \in \mathcal{U}\)</span>, the solution of the observer <a href="output-feedback.html#eq:meta-observer-zeta-hat">(5.6)</a>,
denoted by <span class="math inline">\(\hat{\Xi}(\hat{\xi}_0;t;u;\tilde{y}_{\xi_0,u})\)</span>, and the solution of the true system <a href="output-feedback.html#eq:meta-observer-zeta">(5.7)</a>, denoted by <span class="math inline">\(\Xi(\xi_0;t;u)\)</span>, satisfy
<span class="math display" id="eq:meta-observer-zeta-converge">\[\begin{equation}
\lim_{t \rightarrow \infty} \Vert \hat{\Xi}(\hat{\xi}_0;t;u;\tilde{y}_{\xi_0,u}) - \Xi(\xi_0;t;u) \Vert = 0.
\tag{5.8}
\end{equation}\]</span>
Note that the observer <a href="output-feedback.html#eq:meta-observer-zeta-hat">(5.6)</a> is stationary and in the given coordinates for system <a href="output-feedback.html#eq:meta-observer-zeta">(5.7)</a>. Indeed the internal state of the observer is the same as the system state.</p>
<p>Now suppose for any <span class="math inline">\(u \in \mathcal{U}\)</span>, there exists a continuous function (i.e., coordinate transformation) <span class="math inline">\(T_u: \mathbb{R}^n \times \mathbb{R} \rightarrow \mathbb{R}^p\)</span> and a subset <span class="math inline">\(\mathcal{X}\)</span> of <span class="math inline">\(\mathbb{X}\)</span> such that</p>
<ol style="list-style-type: decimal">
<li><p>For any <span class="math inline">\(x_0 \in \mathcal{X}_0\)</span> such that <span class="math inline">\(\sigma^+_{\mathbb{X}}(x_0;u) = + \infty\)</span>, <span class="math inline">\(X(x_0;\cdot;u)\)</span> remains in <span class="math inline">\(\mathcal{X}\)</span></p></li>
<li><p>There exists a concave <span class="math inline">\(\mathcal{K}\)</span><a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> function <span class="math inline">\(\rho\)</span> and a positive number <span class="math inline">\(\bar{t}\)</span> such that
<span class="math display">\[
\Vert x_a - x_b \Vert \leq \rho (| T_u(x_a,t) - T_u(x_b,t) |), \quad \forall x_a,x_b \in \mathcal{X}, t \geq \bar{t},
\]</span>
i.e., <span class="math inline">\(x \mapsto T_u(x,t)\)</span> becomes injective on <span class="math inline">\(\mathcal{X}\)</span>,<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> uniformly in time and space, after a certain time <span class="math inline">\(\bar{t}\)</span>.</p></li>
<li><p><span class="math inline">\(T_u\)</span> transforms the system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a> into the system <a href="output-feedback.html#eq:meta-observer-zeta">(5.7)</a>, i.e., for all <span class="math inline">\(x \in \mathcal{X}\)</span> and all <span class="math inline">\(t \geq 0\)</span>, we have
<span class="math display" id="eq:meta-observer-transform">\[\begin{equation}
L_{(f,1)} T_u(x,t) = F(T_u(x,t),u,h(x,u)), \quad h(x,u) = H(T_u(x,t),u),
\tag{5.9}
\end{equation}\]</span>
where <span class="math inline">\(L_{(f,1)} T_u(x,t)\)</span> is the Lie derivative of <span class="math inline">\(T_u\)</span> along the vector field <span class="math inline">\((f,1)\)</span>
<span class="math display">\[
L_{(f,1)} T_u(x,t) = \lim_{\tau \rightarrow 0} \frac{ T_u (X(x,t;t+\tau;u),t+\tau) - T_u(x,t) }{\tau}.
\]</span></p></li>
<li><p><span class="math inline">\(T_u\)</span> respects the causality condition
<span class="math display">\[
\forall \tilde{u}: [0,+\infty) \rightarrow \mathbb{R}^m, \forall t \in [0,+\infty), u_{[0,t]} = \tilde{u}_{[0,t]} \Rightarrow T_u(\cdot,t) = T_{\tilde{u}}(\cdot,t).
\]</span></p></li>
</ol>
<p>Then, for any <span class="math inline">\(u \in \mathcal{U}\)</span>, there exists a function <span class="math inline">\(\mathcal{T}_u: \mathbb{R}^p \times [0,+\infty) \rightarrow \mathcal{X}\)</span> (satisfying the causality condition) such that for any <span class="math inline">\(t \geq \bar{t}\)</span>, <span class="math inline">\(\xi \mapsto \mathcal{T}_u (\xi, t)\)</span> is uniformly continuous on <span class="math inline">\(\mathbb{R}^p\)</span> and satisfies
<span class="math display">\[
\mathcal{T}_u \left( T_u(x,t),t \right) = x, \forall x \in \mathcal{X}.
\]</span>
Moreover, denoting <span class="math inline">\(\mathcal{T}\)</span> the family of functions <span class="math inline">\(\mathcal{T}_u\)</span> for <span class="math inline">\(u \in \mathcal{U}\)</span>, the couple <span class="math inline">\((\mathcal{F}, \mathcal{T})\)</span> is an observer for the system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a> initialized in <span class="math inline">\(\mathcal{X}_0\)</span>.</p>
</div>
</div>
<div class="proof">
<p><span id="unlabeled-div-6" class="proof"><em>Proof</em>. </span>See Theorem 1.1 in <span class="citation">(<a href="#ref-bernard19book-observer">Bernard 2019</a>)</span>.</p>
</div>
<p>A simpler version of Theorem <a href="output-feedback.html#thm:observerdesignmeta">5.1</a> where the coordinate transformation <span class="math inline">\(T_u\)</span> is stationary and fixed for all <span class="math inline">\(u\)</span> is stated below as a corollary.</p>
<div class="theorembox">
<div class="corollary">
<p><span id="cor:observerdesignmetafixedT" class="corollary"><strong>Corollary 5.1  (Meta Observer with Fixed Transformation) </strong></span>Let <span class="math inline">\(F: \mathbb{R}^p \times \mathbb{R}^m \times \mathbb{R}^d \rightarrow \mathbb{R}^p\)</span>, <span class="math inline">\(H: \mathbb{R}^p \times \mathbb{R}^m \rightarrow \mathbb{R}^d\)</span> and <span class="math inline">\(\mathcal{F}: \mathbb{R}^p \times \mathbb{R}^m \times \mathbb{R}^d \rightarrow \mathbb{R}^p\)</span> be continuous functions such that <a href="output-feedback.html#eq:meta-observer-zeta-hat">(5.6)</a> is an observer for <a href="output-feedback.html#eq:meta-observer-zeta">(5.7)</a>.</p>
<p>Suppose there exists a continuous coordinate transformation <span class="math inline">\(T: \mathbb{R}^p \rightarrow \mathbb{R}^n\)</span> and a compact subset <span class="math inline">\(\Omega\)</span> of <span class="math inline">\(\mathbb{R}^n\)</span> such that</p>
<ol style="list-style-type: decimal">
<li><p>For any <span class="math inline">\(x_0 \in \mathcal{X}_0\)</span> such that <span class="math inline">\(\sigma^+_{\mathbb{X}}(x_0;u) = + \infty\)</span>, <span class="math inline">\(X(x_0;\cdot;u)\)</span> remains in <span class="math inline">\(\Omega\)</span></p></li>
<li><p><span class="math inline">\(x \mapsto T(x)\)</span> is injective on <span class="math inline">\(\Omega\)</span></p></li>
<li><p><span class="math inline">\(T\)</span> transforms the system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a> into system <a href="output-feedback.html#eq:meta-observer-zeta">(5.7)</a>
<span class="math display">\[
L_f T(x) = F(T(x),u,h(x,u)), \quad h(x,u) = H(T(x),u),
\]</span>
where <span class="math inline">\(L_f T(x)\)</span> is the Lie derivative of <span class="math inline">\(T(x)\)</span> along <span class="math inline">\(f\)</span>
<span class="math display">\[
L_f T(x) = \lim_{\tau \rightarrow 0} \frac{ T(X(x,t;t+\tau;u))  - T(x)}{\tau}.
\]</span></p></li>
</ol>
<p>Then, there exists a uniformly continuous function <span class="math inline">\(\mathcal{T}:\mathbb{R}^p \rightarrow \mathbb{R}^{n}\)</span> such that
<span class="math display">\[
\mathcal{T}(T(x)) = x, \quad \forall x \in \Omega,
\]</span>
and <span class="math inline">\((\mathcal{F},\mathcal{T})\)</span> is an observer for system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a> initialized in <span class="math inline">\(\mathcal{X}_0\)</span>.</p>
</div>
</div>
<p>Theorem <a href="output-feedback.html#thm:observerdesignmeta">5.1</a> and Corollary <a href="output-feedback.html#cor:observerdesignmetafixedT">5.1</a> suggest the following general observer design strategy:</p>
<ol style="list-style-type: decimal">
<li><p>Find an injective coordinate transformation <span class="math inline">\(T_u\)</span> (that may be time-varying and also dependent on <span class="math inline">\(u\)</span>) that transforms the original system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a> with coordinate <span class="math inline">\(x\)</span> into a new system <a href="output-feedback.html#eq:meta-observer-zeta">(5.7)</a> with coordinate <span class="math inline">\(\xi\)</span></p></li>
<li><p>Design an observer <a href="output-feedback.html#eq:meta-observer-zeta-hat">(5.6)</a>, <span class="math inline">\(\hat{\xi}\)</span>, for the new system</p></li>
<li><p>Compute a left inverse, <span class="math inline">\(\mathcal{T}_u\)</span>, of the transformation <span class="math inline">\(T_u\)</span> to recover a state estimation <span class="math inline">\(\hat{x}\)</span> of the original system.</p></li>
</ol>
<p>The transformed systems <a href="output-feedback.html#eq:meta-observer-zeta">(5.7)</a> are typically referred to as <em>normal forms</em>, or in my opinion, <em>templates</em>.</p>
<p>Of course, the general design strategy is rather conceptual, and in order for it to be practical, we have to answer three questions.</p>
<ul>
<li><p>What templates do we have, what are their associated observers, and what are the conditions for the observers to be asymptotically converging?</p></li>
<li><p>What kinds of (nonlinear) systems can be transformed into the templates, and how to perform the transformation?</p></li>
<li><p>How to invert the coordinate transformation? Is it analytical or does it require numerical approximation?</p></li>
</ul>
<p>In the following sections, we will study several representative normal forms and answer the above questions. Before presenting the results, let us first introduce several notions of observability.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:observability" class="definition"><strong>Definition 5.2  (Observability) </strong></span>Consider an open subset <span class="math inline">\(\mathcal{L}\)</span> of the state space <span class="math inline">\(\mathbb{X} \subseteq \mathbb{R}^n\)</span> of system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a>. The system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a> is said to be</p>
<ul>
<li><p><strong>Distinguishable</strong> on <span class="math inline">\(\mathcal{L}\)</span> for some input <span class="math inline">\(u(t)\)</span>, if for all <span class="math inline">\((x_a,x_b) \in \mathcal{L} \times \mathcal{L}\)</span>,
<span class="math display">\[
y_{x_a,u}(t) = y_{x_b,u}(t), \forall t \in [0,\min\left\{\sigma^+_{\mathbb{X}}(x_a;u), \sigma^+_{\mathbb{X}}(x_b;u) \right\}] \Longrightarrow x_a = x_b
\]</span></p></li>
<li><p><strong>Instantaneously distinguishable</strong> on <span class="math inline">\(\mathcal{L}\)</span> for some input <span class="math inline">\(u(t)\)</span>, if for all <span class="math inline">\((x_a,x_b) \in \mathcal{L} \times \mathcal{L}\)</span>, and for all <span class="math inline">\(\bar{t} \in (0, \min\left\{\sigma^+_{\mathbb{X}}(x_a;u), \sigma^+_{\mathbb{X}}(x_b;u) \right\})\)</span>,
<span class="math display">\[
y_{x_a,u}(t) = y_{x_b,u}(t), \forall t \in [0,\bar{t}) \Longrightarrow x_a = x_b
\]</span></p></li>
<li><p><strong>Uniformly observable</strong> on <span class="math inline">\(\mathcal{L}\)</span> if it is distinguishable on <span class="math inline">\(\mathcal{L}\)</span> for any input <span class="math inline">\(u(t)\)</span> (not only for <span class="math inline">\(u \in \mathcal{U}\)</span>)</p></li>
<li><p><strong>Uniformly instantaneously observable</strong> on <span class="math inline">\(\mathcal{L}\)</span> if it is instantaneously observable on <span class="math inline">\(\mathcal{L}\)</span> for any input <span class="math inline">\(u(t)\)</span> (not only for <span class="math inline">\(u \in \mathcal{U}\)</span>).</p></li>
</ul>
<p>Moreover, let <span class="math inline">\(\mathcal{X}\)</span> be a subset of <span class="math inline">\(\mathbb{X}\)</span> such that <span class="math inline">\(\mathrm{cl}(\mathcal{X})\)</span>, i.e., the closure of <span class="math inline">\(\mathcal{X}\)</span>, is contained in <span class="math inline">\(\mathcal{L}\)</span>. Then the system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a> is said to be</p>
<ul>
<li><strong>Backward <span class="math inline">\(\mathcal{L}\)</span>-distinguishable on <span class="math inline">\(\mathcal{X}\)</span></strong> for some input <span class="math inline">\(u(t)\)</span>, if for any <span class="math inline">\((x_a,x_b) \in \mathcal{X} \times \mathcal{X}\)</span> such that <span class="math inline">\(x_a \neq x_b\)</span>, there exists <span class="math inline">\(t \in (\max\left\{ \sigma^{-}_{\mathcal{L}}(x_a;u), \sigma^{-}_{\mathcal{L}}(x_b;u) \right\},0]\)</span> such that <span class="math inline">\(y_{x_a,u}(t) \neq y_{x_b,u}(t)\)</span>, or in words similar to the definition of distinguishable on <span class="math inline">\(\mathcal{L}\)</span>, for all <span class="math inline">\((x_a,x_b) \in \mathcal{X} \times \mathcal{X}\)</span>
<span class="math display">\[
y_{x_a,u}(t) = y_{x_b,u}(t), \forall t \in (\max\left\{\sigma^{-}_{\mathcal{L}}(x_a;u), \sigma^{-}_{\mathcal{L}}(x_b;u) \right\},0] \Longrightarrow x_a = x_b.
\]</span></li>
</ul>
</div>
</div>
</div>
<div id="luenberger-template" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Luenberger Template<a href="output-feedback.html#luenberger-template" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider an instance of the normal form <a href="output-feedback.html#eq:meta-observer-zeta">(5.7)</a> as follows:
<span class="math display" id="eq:Luenberger-linear-template">\[\begin{equation}
\dot{\xi} = A \xi + B(u,y), \quad y = C \xi,
\tag{5.10}
\end{equation}\]</span>
where <span class="math inline">\(A,C\)</span> are constant matrices, and <span class="math inline">\(B(u,y)\)</span> can depend nonlinearly on <span class="math inline">\(u\)</span> and <span class="math inline">\(y\)</span>.</p>
<p>For this template, we have the well-known Luenberger observer.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:LuenbergerLinear" class="theorem"><strong>Theorem 5.2  (Luenberger Observer) </strong></span>If the pair <span class="math inline">\((A,C)\)</span> is detectable (see Theorem <a href="app-lti-system-theory.html#thm:ltidetectable">A.9</a>), then there exists a matrix <span class="math inline">\(K\)</span> such that <span class="math inline">\(A-KC\)</span> is Hurwitz and the system
<span class="math display" id="eq:Luenberger-Linear">\[\begin{equation}
\dot{\hat{\xi}} = A \hat{\xi} + B(u,y) + K(y - C \hat{\xi})
\tag{5.11}
\end{equation}\]</span>
is an observer for <a href="output-feedback.html#eq:Luenberger-linear-template">(5.10)</a>.</p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-7" class="proof"><em>Proof</em>. </span>Define <span class="math inline">\(e(t) = \xi(t) - \hat{\xi}(t)\)</span>. In that case,
<span class="math display" id="eq:Luenberger-error">\[\begin{equation}
    \dot{e}(t) = [A - KC] e(t)
    \tag{5.12}
\end{equation}\]</span></p>
<p>Solving <a href="output-feedback.html#eq:Luenberger-error">(5.12)</a>, we obtain</p>
<p><span class="math display">\[\begin{equation}
    e(t) = \mathrm{exp}[(A - KC)t] e(0)
\end{equation}\]</span></p>
<p>Then, if the real components of the eigenvalues of <span class="math inline">\(A - KC\)</span> are strictly negative (i.e., <span class="math inline">\(A - KC\)</span> is Hurwitz), then <span class="math inline">\(e(t) \rightarrow 0\)</span> as <span class="math inline">\(t \rightarrow \infty\)</span>, independent of the initial error <span class="math inline">\(e(0) = \xi(0) - \hat{\xi}(0)\)</span>. From Theorem <a href="app-lti-system-theory.html#thm:ltidetectable">A.9</a>, we know that <span class="math inline">\((A,C)\)</span> being detectable implies the existence of <span class="math inline">\(K\)</span> such that <span class="math inline">\(A - KC\)</span> is Hurwitz.</p>
<p>If one is further interested in estimating the convergence rate of the Luenberger observer, then one can use the result from Corollary <a href="app-lti-system-theory.html#cor:bestconvergencerate">A.1</a>. Particularly, one can solve the Lyapunov equation
<span class="math display">\[
(A - KC)^T P + P (A - KC) = - I
\]</span>
to obtain <span class="math inline">\(P\)</span>. Then the convergence rate of <span class="math inline">\(\Vert e \Vert\)</span> towards zero is <span class="math inline">\(\frac{0.5}{\lambda_{\max}(P)}\)</span>.</p>
</div>
</div>
<p>The Luenberger observer is an elegant result in observer design (and even in control theory) that has far-reaching impact. In my opinion, the essence of observer design is twofold: (i) to simulate the dynamics when the state estimation is correct, and (ii) to correct the state estimation from observation when it is off. These two pieces of ideas are evident in <a href="output-feedback.html#eq:Luenberger-Linear">(5.11)</a>: the observer is a copy of the original dynamics (<span class="math inline">\(A \hat{\xi} + B(u,y)\)</span>) plus a feedback correction from the difference between the “imagined” observation <span class="math inline">\(C\hat{\xi}\)</span> and the true observation <span class="math inline">\(y\)</span>.</p>
<p>You may think the Luenberger template is restricting because it requires the system to be linear (up to the only nonlinearly in <span class="math inline">\(B(u,y)\)</span>). However, it turns out the Luenberger template is already quite useful, as I will show in the following pendulum example.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:pendulumLuenberger" class="example"><strong>Example 5.1  (Luenberger Observer for A Simple Pendulum) </strong></span>Consider a simple pendulum dynamics model
<span class="math display" id="eq:kbobserver-pendulum">\[\begin{equation}
x = \begin{bmatrix}
\theta \\ \dot{\theta}
\end{bmatrix}, \quad
\dot{x} = \begin{bmatrix}
\dot{\theta} \\
- \frac{1}{ml^2} (b \dot{\theta} + mgl \sin \theta)
\end{bmatrix} +
\begin{bmatrix}
0 \\
\frac{1}{ml^2}
\end{bmatrix} u, \quad y = \theta,
\tag{5.13}
\end{equation}\]</span>
where <span class="math inline">\(\theta\)</span> the angular position of the pendulum from the vertical line, <span class="math inline">\(m &gt; 0\)</span> the mass of the pendulum, <span class="math inline">\(l &gt; 0\)</span> the length, <span class="math inline">\(g\)</span> the gravitational constant, <span class="math inline">\(b &gt; 0\)</span> the dampling coefficient, and <span class="math inline">\(u\)</span> the control input (torque).</p>
<p>We assume we can only observe the angular position of the pendulum in <a href="output-feedback.html#eq:kbobserver-pendulum">(5.13)</a>, e.g., using a camera, but not the angular velocity. Our goal is to construct an observer that can provide a full state estimation.</p>
<p>We first note that the pendulum dynamics <a href="output-feedback.html#eq:kbobserver-pendulum">(5.13)</a> can actually be written in the (linear) Luenberger template <a href="output-feedback.html#eq:Luenberger-linear-template">(5.10)</a> as<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>
<span class="math display" id="eq:pendulum-Luenberger-Linear">\[\begin{equation}
\begin{split}
\dot{x} &amp; = \underbrace{\begin{bmatrix}
0 &amp; 1 \\
0 &amp; - \frac{b}{ml^2}
\end{bmatrix}}_{=:A} x +
\underbrace{\begin{bmatrix}
0 \\
\frac{u - mgl \sin \theta }{ml^2}
\end{bmatrix}}_{=:B(u,y)} \\
y &amp; = \underbrace{\begin{bmatrix}
1 &amp; 0
\end{bmatrix}}_{=:C} x
\end{split}.
\tag{5.14}
\end{equation}\]</span></p>
<p>In order for us to use the Luenberger observer, we need to check if the pair <span class="math inline">\((A,C)\)</span> is detectable. We can easily find the eigenvalues and eigenvectors of <span class="math inline">\(A\)</span>:
<span class="math display">\[
A \begin{bmatrix}
1 \\ 0
\end{bmatrix} = 0,\quad
A \begin{bmatrix}
- \frac{ml^2}{b} \\ 1
\end{bmatrix} = \begin{bmatrix}
1 \\ - \frac{b}{ml^2}
\end{bmatrix}
= - \frac{b}{ml^2} \begin{bmatrix}
- \frac{ml^2}{b} \\ 1 \end{bmatrix}.
\]</span>
The first eigenvalue has real part equal to <span class="math inline">\(0\)</span>. However,
<span class="math display">\[
C \begin{bmatrix}
1 \\ 0
\end{bmatrix} = 1 \neq 0.
\]</span>
According to Theorem <a href="app-lti-system-theory.html#thm:ltidetectable">A.9</a>, we conclude <span class="math inline">\((A,C)\)</span> is detectable. In fact, the pair <span class="math inline">\((A,C)\)</span> is more than just detectable, it is indeed observable (according to Theorem <a href="app-lti-system-theory.html#thm:ltiobservable">A.7</a>). Therefore, the poles of <span class="math inline">\(A - KC\)</span> can be arbitrarily placed.</p>
<p><strong>Finding <span class="math inline">\(K\)</span></strong>. Now we need to find <span class="math inline">\(K\)</span>. An easy choice of <span class="math inline">\(K\)</span> is
<span class="math display">\[
K = \begin{bmatrix} k \\ 0 \end{bmatrix}, \quad A - KC =
\begin{bmatrix}
- k &amp; 1 \\ 0 &amp; - \frac{b}{ml^2}
\end{bmatrix}.
\]</span>
With <span class="math inline">\(k &gt; 0\)</span>, we know <span class="math inline">\(A- KC\)</span> is guaranteed to be Hurwitz (the two eigenvalues of <span class="math inline">\(A-KC\)</span> are <span class="math inline">\(-k\)</span> and <span class="math inline">\(-b/ml^2\)</span>), and we have obtained an observer!</p>
<p>We can also estimate the convergence rate of this observer. Let us use <span class="math inline">\(m=1,g=9.8,l=1,b=0.1\)</span> as parameters of the pendulm dynamics. According to Theorem <a href="output-feedback.html#thm:LuenbergerLinear">5.2</a>, we solve the Lyapunov equation
<span class="math display">\[
(A - KC)^T P + P(A - KC) = -I
\]</span>
and <span class="math inline">\(\gamma = \frac{0.5}{\lambda_{\max}(P)}\)</span> will be our best estimate of the convergence rate (of <span class="math inline">\(\Vert e \Vert = \Vert \hat{x} - x \Vert\)</span> towards zero).</p>
<p>Table <a href="output-feedback.html#tab:pendulumLuenbergerRate">5.1</a> below shows the convergence rates computed for different values of <span class="math inline">\(k\)</span>. We can see that as <span class="math inline">\(k\)</span> is increased, the convergence rate estimation is also increased. However, it appears that <span class="math inline">\(0.1\)</span> is the best convergence rate we can achieve, regardless of how large <span class="math inline">\(k\)</span> is.</p>
<table>
<caption><span id="tab:pendulumLuenbergerRate">Table 5.1: </span> Convergence rate estimation of the Luenberger observer for a simple pendulm.</caption>
<colgroup>
<col width="15%" />
<col width="13%" />
<col width="15%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(k\)</span></th>
<th align="center"><span class="math inline">\(0.1\)</span></th>
<th align="center"><span class="math inline">\(1\)</span></th>
<th align="center"><span class="math inline">\(10\)</span></th>
<th align="center"><span class="math inline">\(100\)</span></th>
<th align="center"><span class="math inline">\(1000\)</span></th>
<th align="center"><span class="math inline">\(10000\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\gamma\)</span></td>
<td align="center"><span class="math inline">\(0.0019\)</span></td>
<td align="center"><span class="math inline">\(0.0523\)</span></td>
<td align="center"><span class="math inline">\(0.0990\)</span></td>
<td align="center"><span class="math inline">\(0.1000\)</span></td>
<td align="center"><span class="math inline">\(0.1000\)</span></td>
<td align="center"><span class="math inline">\(0.1000\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Optimal <span class="math inline">\(K\)</span></strong>. Is it true that <span class="math inline">\(0.1\)</span> is the best convergence rate, or in other words, what is the best <span class="math inline">\(K\)</span> that maximizes the convergence rate <span class="math inline">\(\gamma\)</span>?</p>
<p>A natural way (and my favorite way) to answer this question is to formulate an optimization problem.
<span class="math display" id="eq:pendulumLuenbergerMaxgammaNonCVX">\[\begin{equation}
\begin{split}
\min_{P,K} &amp; \quad \lambda_{\max}(P) \\
\text{subject to} &amp; \quad (A - KC)^T P + P (A - KC) = -I \\
&amp; \quad P \succeq 0
\end{split}
\tag{5.15}
\end{equation}\]</span>
The above formulation seeks the best possible <span class="math inline">\(K\)</span> that minimizes <span class="math inline">\(\lambda_{\max}(P)\)</span> which, according to <span class="math inline">\(\gamma = 0.5 / \lambda_{\max}(P)\)</span>, also maximizes <span class="math inline">\(\gamma\)</span>.</p>
<p>However, problem <a href="output-feedback.html#eq:pendulumLuenbergerMaxgammaNonCVX">(5.15)</a> is not a convex formulation due to the bilinear term <span class="math inline">\(PK\)</span>. Nevertheless, via a simple change of variable <span class="math inline">\(H = PK\)</span>, we arrive at the following convex formulation
<span class="math display" id="eq:pendulumLuenbergerMaxgammaCVX">\[\begin{equation}
\begin{split}
\min_{P,H} &amp; \quad \lambda_{\max}(P) \\
\text{subject to} &amp; \quad A^T P - C^T H^T + PA - H C = - I \\
&amp; \quad P \succeq 0
\end{split}
\tag{5.16}
\end{equation}\]</span>
Problem <a href="output-feedback.html#eq:pendulumLuenbergerMaxgammaCVX">(5.16)</a> is a semidefinite programming problem (SDP), that can be modeled and solved by off-the-shelf tools. We can recover <span class="math inline">\(K = P^{-1} H\)</span> from <a href="output-feedback.html#eq:pendulumLuenbergerMaxgammaCVX">(5.16)</a> after it is solved.</p>
<p>Interestingly, solving problem <a href="output-feedback.html#eq:pendulumLuenbergerMaxgammaCVX">(5.16)</a> verifies that the minimum <span class="math inline">\(\lambda_{\max}(P)\)</span> is <span class="math inline">\(5\)</span> and the maximum converge rate is <span class="math inline">\(0.1\)</span>. An optimal solution of <a href="output-feedback.html#eq:pendulumLuenbergerMaxgammaCVX">(5.16)</a> is
<span class="math display">\[
P^\star = \begin{bmatrix}
2.4923 &amp; 0 \\ 0 &amp; 5 \end{bmatrix}, \quad
K^\star = \begin{bmatrix}
0.2006 \\ 0.4985 \end{bmatrix}.
\]</span>
You should check out the Matlab code of this example <a href="https://github.com/ComputationalRobotics/OptimalControlEstimation-Examples/blob/main/pendulum_luenberger.m">here</a>.</p>
</div>
</div>
</div>
<div id="state-affine-template" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> State-affine Template<a href="output-feedback.html#state-affine-template" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider an instance of the normal form <a href="output-feedback.html#eq:meta-observer-zeta">(5.7)</a> where the dynamics is linear in <span class="math inline">\(\xi\)</span>, but the coefficients are time-varying and dependent on the input and output
<span class="math display" id="eq:state-affine-template">\[\begin{equation}
\dot{\xi} = A(u,y) \xi + B(u,y), \quad y = C(u) \xi.
\tag{5.17}
\end{equation}\]</span>
The difference between the state-affine template <a href="output-feedback.html#eq:state-affine-template">(5.17)</a> and the Luenberger template <a href="output-feedback.html#eq:Luenberger-linear-template">(5.10)</a> is that the linear matrices <span class="math inline">\(A,C\)</span> are allowed to depend nonlinearly on the input <span class="math inline">\((u,y)\)</span>.</p>
<p>Kalman and Bucy originally proposed an observer for linear time-varying systems <span class="citation">(<a href="#ref-kalman61-new">Kalman and Bucy 1961</a>)</span>. The result is later extened by <span class="citation">(<a href="#ref-besanccon96ejc-observer">Besançon, Bornard, and Hammouri 1996</a>)</span> and <span class="citation">(<a href="#ref-hammouri90cdc-observer">Hammouri and Leon Morales 1990</a>)</span> to deal with coefficient matrices dependent on the control. The following theorem is a direct extension of the result from <span class="citation">(<a href="#ref-besanccon96ejc-observer">Besançon, Bornard, and Hammouri 1996</a>)</span> and <span class="citation">(<a href="#ref-hammouri90cdc-observer">Hammouri and Leon Morales 1990</a>)</span> by considering <span class="math inline">\((u,y)\)</span> as an augmented control input.</p>
<p>Before presenting the theorem, we need to introduce the following terminology.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:lineartimevarying" class="definition"><strong>Definition 5.3  (Linear Time-Varying System) </strong></span>For a linear time-varying system of the form
<span class="math display" id="eq:linear-time-varying">\[\begin{equation}
\dot{\chi} = A(\nu) \chi, \quad y = C(\nu) \chi,
\tag{5.18}
\end{equation}\]</span>
with input <span class="math inline">\(\nu\)</span> and output <span class="math inline">\(y\)</span>, we define</p>
<ul>
<li><p>the <em>transition matrix</em> <span class="math inline">\(\Psi_\nu\)</span> as the unique solution to
<span class="math display">\[
\Psi_\nu (t,t) = I, \quad \frac{\partial \Psi_\nu}{\partial \tau}(\tau,t) = A(\nu(\tau)) \Psi_\nu (\tau, t).
\]</span>
Note that the transition matrix is used to express the solution to <a href="output-feedback.html#eq:linear-time-varying">(5.18)</a> because it satisfies
<span class="math display">\[
\chi(\chi_0,t_0;t;\nu) = \Psi_\nu (t,t_0) \chi_0.
\]</span></p></li>
<li><p>the <em>observability grammian</em> as
<span class="math display">\[
\Gamma_\nu (t_0,t_1) = \int_{t_0}^{t_1} \Psi_\nu (\tau,t_0)^T C(\nu(\tau))^T C(\nu(\tau)) \Psi_\nu (\tau,t_0) d\tau.
\]</span></p></li>
<li><p>the <em>backward observability grammian</em> as
<span class="math display">\[
\Gamma_\nu^b (t_0,t_1) = \int_{t_0}^{t_1} \Psi_\nu (\tau,t_1)^T C(\nu(\tau))^T C(\nu(\tau)) \Psi_\nu (\tau,t_1) d\tau.
\]</span></p></li>
</ul>
</div>
</div>
<p>We now introduce the Kalman-Bucy Observer for the state-affine template <a href="output-feedback.html#eq:state-affine-template">(5.17)</a>.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:kalmanbucystateaffine" class="theorem"><strong>Theorem 5.3  (Kalman-Bucy Observer) </strong></span>Let <span class="math inline">\(y_{\xi_0,u}(t) = C(u(t)) \Xi (\xi_0;t;u)\)</span> be the output of system <a href="output-feedback.html#eq:state-affine-template">(5.17)</a> at time <span class="math inline">\(t\)</span> with initialization <span class="math inline">\(\xi_0\)</span> and control <span class="math inline">\(u\)</span>. Suppose the control <span class="math inline">\(u\)</span> satisfies</p>
<ul>
<li><p>For any <span class="math inline">\(\xi_0\)</span>, <span class="math inline">\(t \mapsto A(u(t),y_{\xi_0,u}(t))\)</span> is bounded by <span class="math inline">\(A_{\max}\)</span></p></li>
<li><p>For any <span class="math inline">\(\xi_0\)</span>, the augmented input <span class="math inline">\(\nu = (u,y_{\xi_0,u})\)</span> is <em>regularly persistent</em> for the dynamics
<span class="math display" id="eq:kbobserver-auxilarydynamics">\[\begin{equation}
\dot{\chi} = A(\nu) \chi , \quad y = C(\nu) \chi
\tag{5.19}
\end{equation}\]</span>
uniformly with respect to <span class="math inline">\(\xi_0\)</span>. That is, there exist strictly positive numbers <span class="math inline">\(t_0,\bar{t}\)</span>, and <span class="math inline">\(\alpha\)</span> such that for any <span class="math inline">\(\xi_0\)</span> and any time <span class="math inline">\(t \geq t_0 \geq \bar{t}\)</span>,
<span class="math display">\[
\Gamma_v^b (t-\bar{t}, t) \succeq \alpha I,
\]</span>
where <span class="math inline">\(\Gamma_v^b\)</span> is the <em>backward observability grammian</em> associated with system <a href="output-feedback.html#eq:kbobserver-auxilarydynamics">(5.19)</a>.</p></li>
</ul>
<p>Then, given any positive definite matrix <span class="math inline">\(P_0\)</span>, there exist <span class="math inline">\(\alpha_1,\alpha_2 &gt; 0\)</span> such that for any <span class="math inline">\(\lambda \geq 2 A_{\max}\)</span> and any <span class="math inline">\(\xi_0 \in \mathbb{R}^p\)</span>, the matrix differential equation
<span class="math display" id="eq:kbobserver-matrixdifferential">\[\begin{equation}
\dot{P} = -\lambda P - A(u,y)^T P - P A(u,y) + C(u)^T C(u)
\tag{5.20}
\end{equation}\]</span>
initialized at <span class="math inline">\(P(0) = P_0\)</span> admits a unique solution satisfying <span class="math inline">\(P(t)=P(t)^T\)</span> and
<span class="math display">\[
\alpha_2 I \succeq P(t) \succeq \alpha_1 I.
\]</span>
Moreover, the system
<span class="math display" id="eq:kbobserver-observer">\[\begin{equation}
\dot{\hat{\xi}} = A(u,y) \hat{\xi} + B(u,y) + K (y - C(u)\hat{\xi})
\tag{5.21}
\end{equation}\]</span>
with a time-varying gain matrix
<span class="math display" id="eq:kbobserver-gain">\[\begin{equation}
K = P^{-1} C(u)^T
\tag{5.22}
\end{equation}\]</span>
is an observer for the state-affine system <a href="output-feedback.html#eq:state-affine-template">(5.17)</a>.</p>
</div>
</div>
<p>Let us work out an example of the Kalman-Bucy Observer for nonlinear systems.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:pendulumkbobserver" class="example"><strong>Example 5.2  (Kalman-Bucy Observer for A Simple Pendulum) </strong></span>Let us reconsider the pendulum dynamics <a href="output-feedback.html#eq:kbobserver-pendulum">(5.13)</a> but this time try to design a Kalman-Bucy observer.</p>
<p>We first write the pendulum dynamics in a new coordinate system so that it is in the state-affine normal form <a href="output-feedback.html#eq:state-affine-template">(5.17)</a>. We choose <span class="math inline">\(\xi = [\mathfrak{s},\mathfrak{c},\dot{\theta}]^T\)</span> with <span class="math inline">\(\mathfrak{s} = \sin \theta\)</span> and <span class="math inline">\(\mathfrak{c} = \cos \theta\)</span>. Clearly, we will be able to observe <span class="math inline">\(y = [\mathfrak{s},\mathfrak{c}]^T\)</span> in this new coordinate. The state-affine normal form of the pendulum dynamics reads
<span class="math display" id="eq:pendulum-state-affine">\[\begin{equation}
\begin{split}
\dot{\xi} = \begin{bmatrix}
\mathfrak{c} \dot{\theta} \\
- \mathfrak{s} \dot{\theta} \\
- \frac{1}{ml^2} (b \dot{\theta} + mgl \mathfrak{s} ) +  \frac{1}{ml^2} u
\end{bmatrix} &amp; =
\underbrace{\begin{bmatrix}
0 &amp; 0 &amp; \mathfrak{c} \\
0 &amp; 0 &amp; -\mathfrak{s} \\
0 &amp; 0 &amp; -\frac{b}{ml^2}
\end{bmatrix}}_{=:A(u,y)} \xi +
\underbrace{\begin{bmatrix}
0 \\ 0 \\ \frac{u - mgl \mathfrak{s}}{ml^2}
\end{bmatrix}}_{=:B(u,y)} \\
y &amp; = \underbrace{\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0
\end{bmatrix}}_{=:C(u)} \xi
\end{split}.
\tag{5.23}
\end{equation}\]</span>
Note that <span class="math inline">\(C(u)\)</span> is in fact time-invariant, and <span class="math inline">\(B(u,y)\)</span> only depends on <span class="math inline">\(u\)</span>; but we adopt the same notation as the general state-affine template <a href="output-feedback.html#eq:state-affine-template">(5.17)</a>.</p>
<p>In order to use the Kalman-Bucy observer in Theorem <a href="output-feedback.html#thm:kalmanbucystateaffine">5.3</a>, we need to verify the boundedness of <span class="math inline">\(A(u,y)\)</span>, and the regular persistence of <a href="output-feedback.html#eq:kbobserver-auxilarydynamics">(5.19)</a>.</p>
<p><strong>Boundedness of <span class="math inline">\(A(u,y)\)</span></strong>. We can easily show the boundedness of <span class="math inline">\(A(u,y)\)</span> by writing
<span class="math display">\[
\Vert A(u,y) \xi \Vert = \Vert \xi_3 (\mathfrak{c} - \mathfrak{s} - b/ml^2) \Vert  \leq |\xi_3| \sqrt{3} \sqrt{\mathfrak{c}^2 + \mathfrak{s}^2 + b^2 / m^2 l^4} \leq \Vert \xi \Vert \sqrt{3 + 3b^2 / m^2 l^4}.
\]</span>
Therefore, we can take <span class="math inline">\(A_{\max} = \sqrt{3 + 3b^2 / m^2 l^4}\)</span>.
<!-- <span style="color:red">Does the $A_{\max}$ in Theorem \@ref(thm:kalmanbucystateaffine) refer to the bound in operator norm?</span> --></p>
<p><strong>Regular persistence</strong>. We write the backward observability grammian of system <a href="output-feedback.html#eq:kbobserver-auxilarydynamics">(5.19)</a>
<span class="math display">\[
\Gamma_\nu^b(t - \bar{t},t) = \int_{t - \bar{t}}^t \Psi_\nu(\tau,t)^T C^T C \Psi_\nu (\tau, t) d \tau = \int_{t - \bar{t}}^t \Psi_\nu(\tau,t)^T \underbrace{\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{bmatrix}}_{=:\tilde{C}}
\Psi_\nu (\tau, t) d \tau.
\]</span>
<span class="math inline">\(\Gamma_\nu^b(t - \bar{t},t) \succeq \alpha I\)</span> if and only if
<span class="math display">\[
w^T \Gamma_\nu^b(t - \bar{t},t) w \geq \alpha, \quad \forall w \in \mathbb{R}^3, \Vert w \Vert = 1.
\]</span>
With this, we develop <span class="math inline">\(w^T \Gamma_\nu^b(t - \bar{t},t) w\)</span>
<span class="math display" id="eq:pendulm-regular-persistence-1">\[\begin{equation}
\begin{split}
w^T \Gamma_\nu^b(t - \bar{t},t) w &amp;= \int_{t - \bar{t}}^t s^T \tilde{C} s d\tau, \\
&amp; = \int_{t - \bar{t}}^t \left( s_1^2 + s_2^2 \right) d\tau, \quad s = \Psi_\nu (\tau, t) w
\end{split}
\tag{5.24}
\end{equation}\]</span>
and observe that <span class="math inline">\(s = \Psi_\nu (\tau,t) w\)</span> is equivalent to
<span class="math display">\[
w = (\Psi_\nu (\tau,t))^{-1} s = \Psi_\nu (t,\tau) s,
\]</span>
that is, <span class="math inline">\(w\)</span> is the solution of <span class="math inline">\(\dot{\xi} = A(\nu) \xi\)</span> at time <span class="math inline">\(t\)</span> with initial condition <span class="math inline">\(s\)</span> at time <span class="math inline">\(\tau \leq t\)</span>. Equivalently, this is saying <span class="math inline">\(s\)</span> is the initial condition of <span class="math inline">\(\dot{\xi} = A(\nu) \xi\)</span> at time <span class="math inline">\(\tau \leq t\)</span> such that its solution at time <span class="math inline">\(t\)</span> is <span class="math inline">\(w\)</span>. Note that from <a href="output-feedback.html#eq:pendulm-regular-persistence-1">(5.24)</a> it is clearly that <span class="math inline">\(\int_{t - \bar{t}}^t \left( s_1^2 + s_2^2 \right) d\tau \geq 0\)</span>, and <span class="math inline">\(\int_{t - \bar{t}}^t \left( s_1^2 + s_2^2 \right) d\tau = 0\)</span> if and only if <span class="math inline">\(s_1^2 + s_2^2 = 0\)</span>, or equivalently <span class="math inline">\(s_1 = s_2 = 0\)</span> for any <span class="math inline">\(\tau \in [t - \bar{t}, t]\)</span>.</p>
<p>We then take a closer look at the system <span class="math inline">\(\dot{\xi} = A(\nu) \xi\)</span>:
<span class="math display" id="eq:pendulm-state-affine-auxiliarysystem">\[\begin{equation}
\begin{split}
\dot{\xi}_1 &amp;= \mathfrak{c} \xi_3 \\
\dot{\xi}_2 &amp;= -\mathfrak{s} \xi_3 \\
\dot{\xi}_3 &amp;= - \frac{b}{ml^2} \xi_3.
\end{split}
\tag{5.25}
\end{equation}\]</span></p>
<p>If the solution of <span class="math inline">\(\xi_3\)</span> at time <span class="math inline">\(t\)</span> is <span class="math inline">\(w_3\)</span>, then
<span class="math display">\[
\xi_3(\tau) = w_3 e^{\frac{b}{ml^2}(t - \tau)}, \quad \tau \leq t.
\]</span>
We can now claim it is impossible that <span class="math inline">\(s_1 = s_2 = 0\)</span> at any time <span class="math inline">\(\tau \in [t - \bar{t}, t]\)</span>.</p>
<p>We can show this by contradiction. First of all, <span class="math inline">\(s_1 = s_2 = 0\)</span> at <span class="math inline">\(\tau = t\)</span> implies <span class="math inline">\(w_1 = w_2 = 0\)</span> and hence <span class="math inline">\(w_3 = \pm 1\)</span>. This implies <span class="math inline">\(\xi_3 \neq 0\)</span> for any <span class="math inline">\(\tau \in [t - \bar{t}, t]\)</span>. Then, <span class="math inline">\(s_1 = 0, \forall \tau \in [t - \bar{t}, t]\)</span> implies <span class="math inline">\(\dot{\xi}_1 = 0\)</span> which, due to <span class="math inline">\(\xi_3 \neq 0\)</span>, implies <span class="math inline">\(\mathfrak{c} = 0\)</span> for all <span class="math inline">\(\tau\)</span>. Similarly, <span class="math inline">\(s_2 = 0, \forall \tau \in [t - \bar{t}, t]\)</span> implies <span class="math inline">\(\dot{\xi}_2 = 0\)</span> and <span class="math inline">\(\mathfrak{s} = 0\)</span>. This creates a contradiction because <span class="math inline">\(\mathfrak{c}^2 + \mathfrak{s}^2 = 1\)</span> and <span class="math inline">\(\mathfrak{c}, \mathfrak{s}\)</span> cannot be simultaneously zero.</p>
<p>The above reasoning proves that the backward observability Grammian is positive definite, which is, however, still insufficient for the Kalman-Bucy observer. We need a stronger uniformly positive definite condition on <span class="math inline">\(\Gamma_\nu^b\)</span>, i.e., to find <span class="math inline">\(t_0, \bar{t}\)</span> and <span class="math inline">\(\alpha&gt;0\)</span> so that <span class="math inline">\(\Gamma_\nu^b(t-\bar{t},t) \succeq \alpha I\)</span> for all <span class="math inline">\(t \geq t_0\)</span>.</p>
<p>If the control <span class="math inline">\(u\)</span> is unbounded, then sadly, one can show that the uniform positive definite condition fails to hold, as left by you to show in the following exercise.</p>
<div class="exercise">
<p><span id="exr:kbobserverpendulumcounterexample" class="exercise"><strong>Exercise 5.1  (Counterexample for Kalman-Bucy Observer) </strong></span>Show that, if the control <span class="math inline">\(u\)</span> is unbounded, then for any <span class="math inline">\(\alpha &gt; 0\)</span>, <span class="math inline">\(t_0 \geq \bar{t} &gt; 0\)</span>, there exists <span class="math inline">\(t \geq t_0\)</span> such that <span class="math inline">\(\Gamma_\nu^b(t - \bar{t},t) \prec \alpha I\)</span>. (Hint: consider a controller that spins the pendulum faster and faster such that in time <span class="math inline">\(\bar{t}\)</span> it has rotated <span class="math inline">\(2k\pi\)</span>, in this case the angular velocity becomes unobservable because we are not sure how many rounds the pendulum has rotated.)</p>
</div>
<p>Fortunately, if the control <span class="math inline">\(u\)</span> is bounded, then we can prove the uniform positive define condition holds for <span class="math inline">\(\Gamma_\nu^b(t - \bar{t},t)\)</span>. The following proof is given by <a href="https://scholar.harvard.edu/weiyuli/home">Weiyu Li</a>.</p>
<p>Without loss of generality, let <span class="math inline">\(\frac{b}{ml^2} = 1\)</span>. Assume <span class="math inline">\(u\)</span> is bounded such that the third entry of <span class="math inline">\(B(u,y)\)</span> in <a href="output-feedback.html#eq:pendulum-state-affine">(5.23)</a> is bounded by <span class="math inline">\(\beta &gt; 0\)</span>
<span class="math display">\[
\left| \frac{u - mgl \mathfrak{s}}{ml^2} \right| \leq \beta.
\]</span>
Assuming the initial velocity of the pendulum is <span class="math inline">\(\dot{\theta}(0) = \dot{\theta}_0\)</span>, we know <span class="math inline">\(\dot{\theta}(t)\)</span> is bounded by
<span class="math display">\[
\dot{\theta}(t) \in \left[ c_1(1-\beta)e^{-t} - \beta  , c_2(1-\beta)e^{-t} + \beta \right],
\]</span>
where <span class="math inline">\(c_1,c_2\)</span> are constants chosen to satisfy the initial condition. Clearly, for all <span class="math inline">\(t &gt; 0\)</span>, we see <span class="math inline">\(\dot{\theta}(t)\)</span> is bounded, and hence we know <span class="math inline">\(\dot{\mathfrak{c}}\)</span> and <span class="math inline">\(\dot{\mathfrak{s}}\)</span> are bounded (due to <span class="math inline">\(\mathfrak{c}\)</span> and <span class="math inline">\(\mathfrak{s}\)</span> are bounded). Intuitively, what we have just shown says that when the control is bounded, the measurements <span class="math inline">\(\mathfrak{c}\)</span> and <span class="math inline">\(\mathfrak{s}\)</span> will have bounded time derivatives. (This will help us analyze the auxiliary system <a href="output-feedback.html#eq:pendulm-state-affine-auxiliarysystem">(5.25)</a>.)</p>
<p>Now back to checking regular persistence of the auxilary system <a href="output-feedback.html#eq:pendulm-state-affine-auxiliarysystem">(5.25)</a>. We will discuss two cases: (1) <span class="math inline">\(w_3^2 &gt; 1 - \delta\)</span>, and (2) <span class="math inline">\(w_3^2 \leq 1 - \delta\)</span>, for some constant <span class="math inline">\(\delta &lt; 0.5\)</span> determined later.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(w_3^2 &gt; 1 - \delta &gt; 0.5\)</span>. In this case we have <span class="math inline">\(w_1^2 + w_2^2 = 1 - w_3^2 &lt; \delta\)</span>, and hence <span class="math inline">\(w_1^2 &lt; \delta\)</span>, <span class="math inline">\(w_2^2 &lt; \delta\)</span>. On the other hand, from <a href="output-feedback.html#eq:pendulm-state-affine-auxiliarysystem">(5.25)</a> we have
<span class="math display">\[
\dot{\xi}_1^2(\tau) + \dot{\xi}_2^2(\tau) = \xi_3^2 = w_3^2 e^{2 (t - \tau)} &gt; w_3^2 &gt; 1 - \delta, \quad \forall \tau &lt; t.
\]</span>
Without loss of generality assume <span class="math inline">\(\dot{\xi}_1(t)^2 &gt; (1-\delta)/2\)</span>. As <span class="math inline">\(\dot{\xi}_1 = \mathfrak{c} \xi_3\)</span> and both <span class="math inline">\(\mathfrak{c}\)</span> and <span class="math inline">\(\xi_3\)</span> have bounded derivatives, we know <span class="math inline">\(\dot{\xi}_1\)</span> will not change sign for some duration <span class="math inline">\(T\)</span> that is independent from the choice of <span class="math inline">\(\delta\)</span> (because the time derivatives of <span class="math inline">\(\mathfrak{c}\)</span> and <span class="math inline">\(\xi_3\)</span> do not depend on <span class="math inline">\(\delta\)</span>). That is <span class="math inline">\(|\dot{\xi}_1| &gt; \sqrt{(1-\delta)/2} &gt; 1/2\)</span> for <span class="math inline">\(\tau \in [t - T,t]\)</span>. Consequently,
<span class="math display">\[
|\xi_1(t - \tau)| &gt; \frac{1}{2} \tau - |w_1| &gt; \frac{1}{2} \tau - \sqrt{\delta}, \quad \tau \in [0,T].
\]</span>
Choosing <span class="math inline">\(\delta\)</span> small enough, we have <span class="math inline">\(|\xi_1(t - \tau)| &gt; 0.25 \tau\)</span> for <span class="math inline">\(\tau \in [0.5T,T]\)</span>. Then we have
<span class="math display">\[
\Gamma_\nu^b(t - T, t) \succ [(0.25 \times 0.5 T)^2 \times 0.5T]I.
\]</span></p></li>
<li><p><span class="math inline">\(w_3^2 \leq 1-\delta\)</span>. In this case <span class="math inline">\(w_1^2 + w_2^2 = 1 - w_3^2 \geq \delta\)</span>, and at least one of <span class="math inline">\(w_1\)</span> and <span class="math inline">\(w_2\)</span> has absolute value larger than <span class="math inline">\(\sqrt{\delta/2}\)</span>. Because the derivatives of <span class="math inline">\(\xi_1\)</span> and <span class="math inline">\(\xi_2\)</span> are both bounded, we know <span class="math inline">\(\xi_1\)</span> and <span class="math inline">\(\xi_2\)</span> will remain large for some constant time. Thus there is a uniform lower bound.</p></li>
</ol>
<p>The intuition of the above proof is simple: when <span class="math inline">\(\xi_1\)</span> and/or <span class="math inline">\(\xi_2\)</span> already have large absolute value (case 2), we can find a time window such that <span class="math inline">\(\xi_1\)</span> and/or <span class="math inline">\(\xi_2\)</span> remain large in that time window; when <span class="math inline">\(\xi_1\)</span> and/or <span class="math inline">\(\xi_2\)</span> are small (case 1), using the observation that their time derivatives are large (because <span class="math inline">\(w_3\)</span> is large), together with the fact that these derivatives remain large (because the derivative of these derivatives are bounded), we can also find a time window that <span class="math inline">\(\xi_1\)</span> and/or <span class="math inline">\(\xi_2\)</span> are large (back in time). Therefore, the backward observability Grammian is uniformly positive definite.</p>
<!-- Therefore, there must exist $\alpha > 0$ such that $\Gamma_\nu^b (t - \bar{t},t) \succeq \alpha I$. -->
<!-- On the other hand,
$$
\frac{d}{d\tau}\left( \xi_1^2 + \xi_2^2 \right) = 2 \xi_1 \dot{\xi}_1 + 2 \xi_2 \dot{\xi}_2 = 2 \xi_3 \left(\mathfrak{c} \xi_1 - 2 \mathfrak{s}\xi_2 \right).
$$

This implies
$$
\xi_3^2 \leq w_3^2 e^{\frac{2b}{ml^2} \bar{t}}, \quad \forall t - \bar{t} \leq z \leq t. 
$$

On the other hand,
\begin{align}
(\dot{\xi}_1)^2 + (\dot{\xi}_2)^2 = (\mathfrak{c}^2 + \mathfrak{s}^2) \xi_3^2 \leq w_3^2 e^{\frac{2b}{ml^2} \bar{t}}, \quad \forall t - \bar{t} \leq z \leq t.
\end{align} -->
</div>
</div>
</div>
<div id="kazantzis-kravaris-luenberger-kkl-template" class="section level3 hasAnchor" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Kazantzis-Kravaris-Luenberger (KKL) Template<a href="output-feedback.html#kazantzis-kravaris-luenberger-kkl-template" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In Luenberger’s original paper about observer design for linear systems <span class="citation">(<a href="#ref-luenberger64-observer">Luenberger 1964</a>)</span>, the goal was to transform a linear system
<span class="math display">\[
\dot{x} = F x, \quad y = C x
\]</span>
into a Hurwitz form
<span class="math display" id="eq:kkl-history-dynamics">\[\begin{equation}
\dot{\xi} = A \xi + B y
\tag{5.26}
\end{equation}\]</span>
with <span class="math inline">\(A\)</span> a Hurwitz (stable) matrix. If such a transformation is available, then the following system
<span class="math display">\[
\dot{\hat{\xi}} = A \hat{\xi} + B y,
\]</span>
which is nothing but a copy of the dynamics <a href="output-feedback.html#eq:kkl-history-dynamics">(5.26)</a>, is in fact an observer. This is because the error <span class="math inline">\(e = \hat{\xi} - \xi\)</span> evolves as
<span class="math display">\[
\dot{e} = A e,
\]</span>
which implies that <span class="math inline">\(e\)</span> tends to zero regardless of the initial error <span class="math inline">\(e(0)\)</span>. Luenberger proved that when <span class="math inline">\((F,C)\)</span> is observable, a stationary transformation <span class="math inline">\(\xi = T x\)</span> with <span class="math inline">\(p = n\)</span>, i.e., <span class="math inline">\(T \in \mathbb{R}^{n\times n}\)</span>, always exists and is unique, for any matrix <span class="math inline">\(A\)</span> that is Hurwitz and <span class="math inline">\((A,B)\)</span> that is controllable. This is based on the fact that
<span class="math display">\[\begin{align}
(A T + B C) x =A \xi + B y =\dot{\xi} = T \dot{x} = TF x, \forall x \\
\Longleftrightarrow AT + BC = TF,
\end{align}\]</span>
known as the Sylvester equation, admits a unique and invertible solution <span class="math inline">\(T\)</span>.</p>
<p>A natural extension of Luenberger’s original idea is to find a transformation that converts the nonlinear system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a> into the following form
<span class="math display" id="eq:kkl-template">\[\begin{equation}
\dot{\xi} = A \xi + B(u,y), \quad y = H(\xi,u),
\tag{5.27}
\end{equation}\]</span>
with <span class="math inline">\(A\)</span> a Hurwitz matrix (but <span class="math inline">\(H\)</span> can be nonlinear, as opposed to the Luenberger template in Theorem <a href="output-feedback.html#thm:LuenbergerLinear">5.2</a>). If such a transformation can be found, then we can design a similar observer that copies the dynamics <a href="output-feedback.html#eq:kkl-template">(5.27)</a>
<span class="math display" id="eq:kkl-observer">\[\begin{equation}
\dot{\hat{\xi}} = A \hat{\xi} + B(u,y).
\tag{5.28}
\end{equation}\]</span>
We refer to such a nonlinear Luenberger template the Kazantzis-Kravaris-Luenberger (KKL) template, due to the seminal work <span class="citation">(<a href="#ref-kazantzis98scl-kkl">Kazantzis and Kravaris 1998</a>)</span>.</p>
<p>The KKL template, once found, is nice in the sense that (i) the observer <a href="output-feedback.html#eq:kkl-observer">(5.28)</a> is a simple copy of the dynamics and also very easy to implement (as opposed to the Kalman-Bucy observer); and (ii) checking if the matrix <span class="math inline">\(A\)</span> is Hurwitz is easy, at least when <span class="math inline">\(A\)</span> has reasonable size, (e.g., compared to checking the regular persistence condition in the state-affine template in Theorem <a href="output-feedback.html#thm:kalmanbucystateaffine">5.3</a>).</p>
<p>However, the KKL template is difficult to realize in the sense that (i) what kind of nonlinear systems can be converted to <a href="output-feedback.html#eq:kkl-template">(5.27)</a>, and (ii) for those systems, how do we find the coordinate transformation?</p>
<p>Recent works have leveraged deep learning to learn the coordinate transformation, for example in <span class="citation">(<a href="#ref-janny21cdc-deepkkl">Janny et al. 2021</a>)</span>, <span class="citation">(<a href="#ref-niazi23lacc-earning">Niazi et al. 2023</a>)</span>, <span class="citation">(<a href="#ref-miao23ll4dc-earning">Miao and Gatsis 2023</a>)</span>. Before hammering the problem with deep learning, let us look at the fundamentals of the KKL observer.</p>
<div id="autonomous-systems-1" class="section level4 hasAnchor" number="5.1.4.1">
<h4><span class="header-section-number">5.1.4.1</span> Autonomous Systems<a href="output-feedback.html#autonomous-systems-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Consider the autonomous version of system <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a> without control
<span class="math display" id="eq:kkl-autonomous-system">\[\begin{equation}
\dot{x} = f(x), \quad y = h(x),
\tag{5.29}
\end{equation}\]</span>
where <span class="math inline">\(x \in \mathbb{X} \subseteq \mathbb{R}^n, y \in \mathbb{Y} \subseteq \mathbb{R}^d\)</span>.</p>
<p>The following result, established by <span class="citation">(<a href="#ref-andrieu06sicopt-kkl">Andrieu and Praly 2006</a>)</span>, states that the KKL observer exists under mild conditions.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:kklautonomous" class="theorem"><strong>Theorem 5.4  (KKL Observer for Autonomous Systems) </strong></span>Assum <span class="math inline">\(\mathcal{X}\)</span> and <span class="math inline">\(\mathcal{L}\)</span> are open bounded sets in <span class="math inline">\(\mathbb{X}\)</span> (the state space) such that <span class="math inline">\(\mathrm{cl}(\mathcal{X})\)</span> is contained in <span class="math inline">\(\mathcal{L}\)</span> and the system <a href="output-feedback.html#eq:kkl-autonomous-system">(5.29)</a> is backward <span class="math inline">\(\mathcal{L}\)</span>-distinguishable on <span class="math inline">\(\mathcal{X}\)</span> (cf. Definition <a href="output-feedback.html#def:observability">5.2</a>). Then there exists a strictly positive number <span class="math inline">\(\gamma\)</span> and a set <span class="math inline">\(\mathcal{S}\)</span> of zero Lebesgue measure in <span class="math inline">\(\mathbb{C}^{n+1}\)</span> such that denoting <span class="math inline">\(\Omega = \{ \lambda \in \mathbb{C} \mid \mathrm{Re}(\lambda) &lt; - \gamma \}\)</span>, for any <span class="math inline">\((\lambda_1,\dots,\lambda_{n+1}) \in \Omega^{n+1} \backslash \mathcal{S}\)</span>, there exists a function <span class="math inline">\(T: \mathbb{R}^n \rightarrow \mathbb{R}^{(n+1)d}\)</span> uniformly injective on <span class="math inline">\(\mathcal{X}\)</span> satisfying
<span class="math display">\[
L_f T(x) = A T(x) + B(h(x))
\]</span>
with
<span class="math display">\[\begin{align}
A = \tilde{A} \otimes I_d, \quad B(y) = (\tilde{B} \otimes I_d ) y \\
\tilde{A} = \begin{bmatrix}
\lambda_1 &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; \lambda_{n+1} \end{bmatrix}
\quad \tilde{B} = \begin{bmatrix}
1 \\ \vdots \\ 1 \end{bmatrix}.
\end{align}\]</span>
Moreover, if <span class="math inline">\(\mathcal{X}\)</span> is backward invariant, then <span class="math inline">\(T\)</span> is unique and defined by
<span class="math display" id="eq:kkl-autonomous-T">\[\begin{equation}
T(x) = \int_{-\infty}^0 e^{-A\tau} B(h(X(x,\tau))) d\tau.
\tag{5.30}
\end{equation}\]</span></p>
</div>
</div>
<div class="remark">
<p><span id="unlabeled-div-8" class="remark"><em>Remark</em>. </span>The function <span class="math inline">\(T\)</span> in Theorem <a href="output-feedback.html#thm:kklautonomous">5.4</a> takes complex numbers. To simulate the observer
<span class="math display">\[
\dot{\hat{\xi}} = A \hat{\xi} + B(y),
\]</span>
one needs to implement in real numbers, for each <span class="math inline">\(\lambda_i\)</span> and <span class="math inline">\(j \in [d]\)</span>
<span class="math display">\[
\dot{\hat{\xi}}_{\lambda_i,j} =
\begin{bmatrix}
- \mathrm{Re}(\lambda_i) &amp; - \mathrm{Im}(\lambda_i) \\
\mathrm{Im}(\lambda_i) &amp; - \mathrm{Re}(\lambda_i)
\end{bmatrix} \hat{\xi}_{\lambda_i,j} + \begin{bmatrix} y_j \\ 0 \end{bmatrix}.   
\]</span>
Therefore, the dimension of the observer is <span class="math inline">\(2 \times d (n+1)\)</span>.</p>
</div>
<p>Theorem <a href="output-feedback.html#thm:kklautonomous">5.4</a> states that as long as the system <a href="output-feedback.html#eq:kkl-autonomous-system">(5.29)</a> is backward distinguishable, then there exists a stationary transformation <span class="math inline">\(T\)</span> that can transform the system to a new coordinate system <span class="math inline">\(\xi\)</span> such that the dynamics in <span class="math inline">\(\xi\)</span> is Hurwitz. A closer look at the structure of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> reveals that the coordinate transformation needs to satisfy <span class="math inline">\(n+1\)</span> differential equations of the form
<span class="math display">\[
\frac{\partial T_{\lambda}}{\partial x}(x) \dot{x} = \lambda T_{\lambda} (x) + y
\]</span>
where each <span class="math inline">\(T_{\lambda}\)</span> transforms the state <span class="math inline">\(x\)</span> into a new coordinate having the same dimension of <span class="math inline">\(y\)</span>. Clearly, if <span class="math inline">\(T = (T_\lambda)\)</span>, i.e., there is a single <span class="math inline">\(\lambda\)</span>, then <span class="math inline">\(T\)</span> is not uniformly injective (as the dimension of <span class="math inline">\(\xi\)</span> is <span class="math inline">\(d &lt; n\)</span>). Consequently, by choosing
<span class="math display">\[
T = (T_{\lambda_1},\dots,T_{\lambda_{n+1}}),
\]</span>
the uniform injectivity of <span class="math inline">\(T\)</span> is ensured.</p>
<p>However, the difficulty lies in the computation of <span class="math inline">\(T\)</span> (and <span class="math inline">\(T_\lambda\)</span>), let alone its inverse (that recovers <span class="math inline">\(x\)</span> from <span class="math inline">\(\xi\)</span>). Even though <span class="math inline">\(\mathcal{X}\)</span> is backward invariant, the formulation <a href="output-feedback.html#eq:kkl-autonomous-T">(5.30)</a> is difficult to compute. I tried very hard to find a coordinate transformation <span class="math inline">\(T\)</span> that can convert the non-controlled pendulum dynamics into the KKL form but did not succeed. <strong>You should let me know if you were able to find one!</strong> Nevertheless, the following example shows you the flavor of how such a transformation may look like for a different system.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:kklOscillator" class="example"><strong>Example 5.3  (KKL Observer for an Oscillator with Unknown Frequency) </strong></span>Consider a harmonic oscillator with unknown frequency
<span class="math display">\[
\begin{cases}
\dot{x}_1 = x_2 \\
\dot{x}_2 = - x_1 x_3 \\
\dot{x}_3 = 0
\end{cases}, \quad y = x_1
\]</span>
Consider the coordinate transformation
<span class="math display">\[
T_{\lambda_i} (x) = \frac{\lambda_i x_1 - x_2}{\lambda_i^2 + x_3}, \quad \lambda_i &gt; 0, i=1,\dots,p.
\]</span>
We have
<span class="math display">\[\begin{align}
\frac{\partial T_{\lambda_i}(x)}{\partial x} \dot{x} &amp;= \left\langle \begin{bmatrix}
\frac{\lambda_i}{\lambda_i^2 + x_3} \\
\frac{-1 }{\lambda_i^2 + x_3} \\
\frac{x_2 - \lambda_i x_1}{(\lambda_i^2 + x_3)^2}
\end{bmatrix}, \begin{bmatrix}
x_2 \\ -x_1 x_3 \\ 0 \end{bmatrix}
\right \rangle = \frac{\lambda_i x_2 + x_1 x_3}{\lambda_i^2 + x_3} \\
-\lambda_i T_{\lambda_i}(x) + y &amp;= \frac{-\lambda_i^2 x_1 + \lambda_i x_2 + x_1 \lambda_i^2 + x_1 x_3}{\lambda_i^2 + x_3} = \frac{\lambda_i x_2 + x_1 x_3}{\lambda_i^2 + x_3}
\end{align}\]</span>
Therefore, with
<span class="math display">\[
\xi = T(x) = [T_{\lambda_1}(x), T_{\lambda_2}(x),\dots,T_{\lambda_p}(x)]^T,
\]</span>
we have
<span class="math display">\[
\dot{\xi} = \underbrace{\begin{bmatrix}
- \lambda_1 &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; -\lambda_p \end{bmatrix}}_{A} \xi + \begin{bmatrix}1 \\ \vdots \\ 1 \end{bmatrix} y
\]</span>
with <span class="math inline">\(A\)</span> clearly Hurwitz.</p>
<p>With some extra arguments (cf. Section 8.1.1 in <span class="citation">(<a href="#ref-bernard19book-observer">Bernard 2019</a>)</span>), one can see that the transformation <span class="math inline">\(T\)</span> is injective with <span class="math inline">\(p \geq 4\)</span> distinct <span class="math inline">\(\lambda_i\)</span>’s. Therefore, this is a valid KKL observer.</p>
<p>The final issue that one needs to think about is, since the observer is estimating <span class="math inline">\(\hat{\xi}\)</span>, how to recover <span class="math inline">\(\hat{x}\)</span>? In this example, there is actually no analytical formula for recovering <span class="math inline">\(\hat{x}\)</span> from <span class="math inline">\(\hat{\xi}\)</span>. In this case, one approach is to solve the following optimization problem
<span class="math display">\[
\hat{x} = \arg\min_{x} \Vert \hat{\xi} - T(x) \Vert^2,
\]</span>
which may be quite expensive.</p>
<p>A more general treatment is given in Section 8.2.2 in <span class="citation">(<a href="#ref-bernard19book-observer">Bernard 2019</a>)</span>.</p>
</div>
</div>
</div>
<div id="controlled-systems-1" class="section level4 hasAnchor" number="5.1.4.2">
<h4><span class="header-section-number">5.1.4.2</span> Controlled Systems<a href="output-feedback.html#controlled-systems-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
</div>
<div id="triangular-template" class="section level3 hasAnchor" number="5.1.5">
<h3><span class="header-section-number">5.1.5</span> Triangular Template<a href="output-feedback.html#triangular-template" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="design-with-convex-optimization" class="section level3 hasAnchor" number="5.1.6">
<h3><span class="header-section-number">5.1.6</span> Design with Convex Optimization<a href="output-feedback.html#design-with-convex-optimization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider a nonlinear system
<span class="math display" id="eq:observerdesignconvex">\[\begin{equation}
\dot{x} = f(x) + \psi(u,y), \quad y = Cx
\tag{5.31}
\end{equation}\]</span>
where <span class="math inline">\(x \in \mathbb{X} \subseteq \mathbb{R}^n\)</span>, <span class="math inline">\(y \in \mathbb{R}^d\)</span>, <span class="math inline">\(C\)</span> a constant matrix, and <span class="math inline">\(\psi(u,y)\)</span> a nonlinear function. We assume that <span class="math inline">\(f(x)\)</span> is a polynomial vector map (i.e., each entry of <span class="math inline">\(f\)</span> is a polynomial function in <span class="math inline">\(x\)</span>). Certainly the formulation in <a href="output-feedback.html#eq:observerdesignconvex">(5.31)</a> is not as general as <a href="output-feedback.html#eq:output-feedback-system">(5.1)</a>, but it is general enough to include many examples in robotics.</p>
<p>Recall that I said the essence of observer design is to (i) simulate the dynamics when the state estimation is correct, and (ii) to correct the state estimation from observation when it is off. Therefore, we wish to design an observer for <a href="output-feedback.html#eq:observerdesignconvex">(5.31)</a> in the following form
<span class="math display" id="eq:sos-observer">\[\begin{equation}
\dot{\hat{x}} = \underbrace{f(\hat{x}) + \psi(u,y)}_{\text{dynamics simulation}} + \underbrace{K(y - \hat{y},y)(C \hat{x} - y)}_{\text{feedback correction}},
\tag{5.32}
\end{equation}\]</span>
where, compared to the Luenberger observer <a href="output-feedback.html#eq:Luenberger-Linear">(5.11)</a>, we allow the gain matrix <span class="math inline">\(K\)</span> to be nonlinear functions of the true observation <span class="math inline">\(y\)</span> and the estimated observation <span class="math inline">\(\hat{y}\)</span>.</p>
<p>With the observer <a href="output-feedback.html#eq:sos-observer">(5.32)</a>, the dynamics on the estimation error <span class="math inline">\(e = \hat{x} - x\)</span> becomes
<span class="math display">\[
\dot{e} = f(x + e) - f(x) + K(Ce,Cx)C e.
\]</span></p>
<p>If we can find a Lyapunov-like function <span class="math inline">\(V(e)\)</span> so that <span class="math inline">\(V(e)\)</span> is positive definite and <span class="math inline">\(\dot{V}(e)\)</span> is negative definite, then Lyapunov stability theorem <a href="stability.html#thm:lyapunovglobalstability">4.3</a> tells us that <span class="math inline">\(e=0\)</span> is asymptotically stable. Because we do not know the gain matrix <span class="math inline">\(K\)</span> either, we need to jointly search for <span class="math inline">\(V\)</span> and <span class="math inline">\(K\)</span> (that are polynomials). Mathematically, this is
<span class="math display" id="eq:sos-observer-nonconvex">\[\begin{equation}
\begin{split}
\text{find} &amp; \quad V, K \\
\text{subject to} &amp; \quad V(0) = 0, \quad V(e) &gt; 0, \forall e \neq 0 \\
&amp; \quad \dot{V}(e) = \frac{\partial V}{\partial e} \left( f(x + e) - f(x) + K(Ce,Cx)C e \right) &lt; 0, \forall e \neq 0, \forall x \in \mathbb{X} \\
&amp; \quad V(e) \geq \epsilon \Vert e \Vert^2, \forall e
\end{split}
\tag{5.33}
\end{equation}\]</span>
where the last constraint is added to make sure <span class="math inline">\(V(e)\)</span> is radially unbounded. Furthermore, if we replace the second constraint by <span class="math inline">\(\dot{V}(e) \leq - \lambda V(e)\)</span>, then we can guarantee <span class="math inline">\(V(e)\)</span> converges to zero exponentially.</p>
<p>Problem <a href="output-feedback.html#eq:sos-observer-nonconvex">(5.33)</a>, however, is not a convex optimization problem, due to the term <span class="math inline">\(\frac{\partial V}{\partial e} K\)</span> being bilinear in the coefficients of <span class="math inline">\(V\)</span> and <span class="math inline">\(K\)</span>. Nevertheless, as shown in <span class="citation">(<a href="#ref-ebenbauer05cdc-polynomial">Ebenbauer, Renz, and Allgower 2005</a>)</span>, we can use a reparameterization trick to formulate a stronger version of <a href="output-feedback.html#eq:sos-observer-nonconvex">(5.33)</a> as follows.
<span class="math display" id="eq:sos-observer-convex-formulation">\[\begin{equation}
\begin{split}
\text{find} &amp; \quad V, Q(Ce), M(Ce,Cx) \\
\text{subject to} &amp; \quad V(0) = 0, \quad V(e) &gt; 0, \forall e \neq 0 \\
&amp; \quad \frac{\partial V}{\partial e} = e^T Q(Ce), \quad Q(Ce) \succ 0 \\
&amp; \quad e^T Q(Ce) \left( f(x + e) - f(x) \right) + e^T M(Ce,Cx) C e &lt; 0, \forall e \neq 0, \forall x \in \mathbb{X} \\
&amp; \quad V(e) \geq \epsilon \Vert e \Vert^2, \forall e
\end{split}
\tag{5.34}
\end{equation}\]</span>
Clearly, if we can solve problem <a href="output-feedback.html#eq:sos-observer-convex-formulation">(5.34)</a>, then
<span class="math display">\[
K = Q(Ce)^{-1} M(Ce,Cx)
\]</span>
is the right gain matrix for the formulation <a href="output-feedback.html#eq:sos-observer-nonconvex">(5.33)</a>.</p>
<p>Let us bring this idea to action in our pendulum example.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:pendulumobserverconvex" class="example"><strong>Example 5.4  (Pendulum Observer with Convex Optimization) </strong></span>With <span class="math inline">\(x = [\mathfrak{s}, \mathfrak{c}, \dot{\theta}]^T\)</span> (<span class="math inline">\(\mathfrak{s} = \sin \theta, \mathfrak{c} = \cos \theta\)</span>), we can write the pendulum dynamics as
<span class="math display">\[
\dot{x} = \underbrace{\begin{bmatrix}
\mathfrak{c} \dot{\theta} \\
- \mathfrak{s} \dot{\theta} \\
- \frac{b}{ml^2} \dot{\theta}
\end{bmatrix}}_{=:f(x)} + \underbrace{\begin{bmatrix}
0 \\ 0 \\ \frac{u - mgl \mathfrak{s}}{ml^2} \end{bmatrix}}_{=: \psi(u,y)}, \quad y =
\underbrace{\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \end{bmatrix}}_{=:C} x
\]</span>
Clearly <span class="math inline">\(f(x)\)</span> is a polynomial. Solving the convex optimization problem <a href="output-feedback.html#eq:sos-observer-convex-formulation">(5.34)</a>, we obtain a solution
<span class="math display">\[
V(e) = 0.5954 e_1^2 + 0.5954 e_2^2 + 0.9431 e_3^2
\]</span>
<span class="math display">\[
Q(Ce) = \begin{bmatrix}
0.4603 e_2^2 + 1.1909 &amp; -0.4603 e_1 e_2 &amp; 0 \\
-0.4603 e_1 e_2 &amp; 0.4603 e_1^2 + 1.1909 &amp; 0 \\
0 &amp; 0 &amp; 1.8863 \end{bmatrix}
\]</span>
<span class="math display">\[
M(Ce,Cx) = \begin{bmatrix}
\substack{-2.0878 e_1^2 - 0.8667 e_2^2 - \\ 0.4588 (y_1^2 + y_2^2) - 0.4885} &amp; - 0.8667 e_1 e_2 \\
- 0.8667 e_1 e_2 &amp; \substack{-0.8667 e_1^2 - 2.0878 e_2^2 - \\ 0.4588 (y_1^2 + y_2^2) - 0.4885} \\
-1.1909 y_2 &amp; 1.1909 y_1
\end{bmatrix}
\]</span></p>
<p>Simulating this observer, we verify that the observer is in fact exponentially converging, as shown in Fig. <a href="output-feedback.html#fig:sos-observer-pendulum-simulation">5.1</a>.</p>
<p>The Matlab code for formulating and solving the convex optimization <a href="output-feedback.html#eq:sos-observer-convex-formulation">(5.34)</a> can be found <a href="https://github.com/ComputationalRobotics/OptimalControlEstimation-Examples/blob/main/pendulum_sos_observer.m">here</a>. The code for simulating the observer can be found <a href="https://github.com/ComputationalRobotics/OptimalControlEstimation-Examples/blob/main/pendulum_sos_observer_simulation.m">here</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sos-observer-pendulum-simulation"></span>
<img src="images/pendulum-simulation-sos-observer.png" alt="Simulation of the pendulum observer design from convex optimization" width="80%" />
<p class="caption">
Figure 5.1: Simulation of the pendulum observer design from convex optimization
</p>
</div>
</div>
</div>
</div>
</div>
<div id="observer-feedback" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Observer Feedback<a href="output-feedback.html#observer-feedback" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we have good ways to design a state observer, we will see how we can use the observer for feedback control.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:pendulumLuenbergerFeedback" class="example"><strong>Example 5.5  (Pendulum Stabilization with A Luenberger Observer) </strong></span>In Example <a href="output-feedback.html#exm:pendulumLuenberger">5.1</a>, we have written the dynamics of a pendulum, and the dynamics of a Luenberger observer as
<span class="math display">\[\begin{align}
\dot{x} &amp;= A x + B(u,y) \\
\dot{\hat{x}} &amp;= A \hat{x} + B(u,y) + KC (x - \hat{x})
\end{align}\]</span>
We wish to understand (so we can optimize) the behavior of this system under certain control input <span class="math inline">\(u\)</span>. To do so, let us denote <span class="math inline">\(e = \hat{x} - x\)</span>, and write the above dynamics as
<span class="math display">\[\begin{align}
\dot{x} &amp;= A x + B(u,Cx) \\
\dot{e} &amp; = (A - KC) e
\end{align}\]</span>
Denoting <span class="math inline">\(z = [x,e]^T\)</span>, we have the augmented dynamics
<span class="math display">\[
\dot{z} = \underbrace{\begin{bmatrix} A &amp; 0 \\ 0 &amp; A - KC \end{bmatrix}}_{=:F} z + \underbrace{\begin{bmatrix} B(u,Dz) \\ 0 \end{bmatrix}}_{=:G(z,u)}
\]</span>
We want to stabilize the system at <span class="math inline">\(z_0 = [\pi,0,0,0]^T\)</span> (the upright position) subject to control bounds <span class="math inline">\(u \in \mathbb{U} = [-u_{\max},u_{\max}]\)</span>.</p>
<p>We need to find a control Lyapunov function (CLF), <span class="math inline">\(V(z)\)</span>, that satisfies the following constraints:
<span class="math display">\[
    V(z_0) = 0
\]</span>
<span class="math display">\[
    V(z) &gt; 0 \quad \forall z \in \{z: V(z) &lt; \rho, z \neq z_0 \}
\]</span>
<span class="math display">\[
    \inf_{u \in \mathbb{U}} [L_F V(z) + L_G V(z)] \leq 0 \quad \forall z \in \mathcal{Z}
\]</span></p>
<p>where <span class="math inline">\(L_F V\)</span> and <span class="math inline">\(L_G V\)</span> are the Lie derivatives of <span class="math inline">\(V\)</span> along <span class="math inline">\(F\)</span> and <span class="math inline">\(G(z,u)\)</span>, respectively. <span class="math inline">\(\mathcal{Z}\)</span> is the set of all possible augmented states. The CLF will define the set of admissible control inputs <span class="math inline">\(U\)</span>.
<span class="math display">\[
    U = \{ u: L_f V(z) + L_g V(z)u \leq 0 \}
\]</span>
To find the smallest-magnitude control input such that <span class="math inline">\(u \in K\)</span>, we may use a quadratic program:</p>
<p><span class="math display">\[
    \min_{u \in \mathcal{U}} ||u||^2
\]</span>
<span class="math display">\[
\mathrm{s.t.} \quad L_f V(z) + L_g V(z)u \leq -c V(z)
\]</span></p>
<p>where <span class="math inline">\(c\)</span> is some positive constant. The challenge now is in choosing a suitable <span class="math inline">\(V(z)\)</span>.</p>
<!-- \inf_{u \in \mathcalU}
-->
<!-- Our controller has access to the observation $y$ (recall this is $\theta$) and the estimated state $\hat{x}$. Let us try a controller of the following form
$$
u = mgl \sin \theta - G \hat{x} = mgl \sin \theta - G (x + e).
$$
This leads to the dynamics 
\begin{align}
\dot{x} & = A x - \frac{1}{ml^2} G (x + e) = \left( A - \frac{1}{ml^2}G \right)x - \frac{1}{ml^2} G e \\
\dot{e} & = (A - KC)e
\end{align} -->
</div>
</div>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-andrieu06sicopt-kkl" class="csl-entry">
Andrieu, Vincent, and Laurent Praly. 2006. <span>“On the Existence of a Kazantzis–Kravaris/Luenberger Observer.”</span> <em>SIAM Journal on Control and Optimization</em> 45 (2): 432–56.
</div>
<div id="ref-astolfi03tac-immersion" class="csl-entry">
Astolfi, Alessandro, and Romeo Ortega. 2003. <span>“Immersion and Invariance: A New Tool for Stabilization and Adaptive Control of Nonlinear Systems.”</span> <em>IEEE Transactions on Automatic Control</em> 48 (4): 590–606.
</div>
<div id="ref-bernard19book-observer" class="csl-entry">
Bernard, Pauline. 2019. <em>Observer Design for Nonlinear Systems</em>. Vol. 479. Springer.
</div>
<div id="ref-bernard22arc-observer" class="csl-entry">
Bernard, Pauline, Vincent Andrieu, and Daniele Astolfi. 2022. <span>“Observer Design for Continuous-Time Dynamical Systems.”</span> <em>Annual Reviews in Control</em>.
</div>
<div id="ref-besanccon96ejc-observer" class="csl-entry">
Besançon, Gildas, Guy Bornard, and Hassan Hammouri. 1996. <span>“Observer Synthesis for a Class of Nonlinear Control Systems.”</span> <em>European Journal of Control</em> 2 (3): 176–92.
</div>
<div id="ref-ebenbauer05cdc-polynomial" class="csl-entry">
Ebenbauer, Christian, Jonathan Renz, and F Allgower. 2005. <span>“Polynomial Feedback and Observer Design Using Nonquadratic Lyapunov Functions.”</span> In <em>Proceedings of the 44th IEEE Conference on Decision and Control</em>, 7587–92. IEEE.
</div>
<div id="ref-hammouri90cdc-observer" class="csl-entry">
Hammouri, Hassan, and Jesus de Leon Morales. 1990. <span>“Observer Synthesis for State-Affine Systems.”</span> In <em>29th IEEE Conference on Decision and Control</em>, 784–85. IEEE.
</div>
<div id="ref-janny21cdc-deepkkl" class="csl-entry">
Janny, Steeven, Vincent Andrieu, Madiha Nadri, and Christian Wolf. 2021. <span>“Deep Kkl: Data-Driven Output Prediction for Non-Linear Systems.”</span> In <em>2021 60th IEEE Conference on Decision and Control (CDC)</em>, 4376–81. IEEE.
</div>
<div id="ref-kalman61-new" class="csl-entry">
Kalman, Rudolph E, and Richard S Bucy. 1961. <span>“New Results in Linear Filtering and Prediction Theory.”</span>
</div>
<div id="ref-karagiannis05cdc-nonlinear" class="csl-entry">
Karagiannis, Dimitrios, and Alessandro Astolfi. 2005. <span>“Nonlinear Observer Design Using Invariant Manifolds and Applications.”</span> In <em>Proceedings of the 44th IEEE Conference on Decision and Control</em>, 7775–80. IEEE.
</div>
<div id="ref-kazantzis98scl-kkl" class="csl-entry">
Kazantzis, Nikolaos, and Costas Kravaris. 1998. <span>“Nonlinear Observer Design Using Lyapunov’s Auxiliary Theorem.”</span> <em>Systems &amp; Control Letters</em> 34 (5): 241–47.
</div>
<div id="ref-luenberger64-observer" class="csl-entry">
Luenberger, David G. 1964. <span>“Observing the State of a Linear System.”</span> <em>IEEE Transactions on Military Electronics</em> 8 (2): 74–80.
</div>
<div id="ref-miao23ll4dc-earning" class="csl-entry">
Miao, Keyan, and Konstantinos Gatsis. 2023. <span>“Learning Robust State Observers Using Neural ODEs.”</span> In <em>Learning for Dynamics and Control Conference</em>, 208–19. PMLR.
</div>
<div id="ref-niazi23lacc-earning" class="csl-entry">
Niazi, Muhammad Umar B, John Cao, Xudong Sun, Amritam Das, and Karl Henrik Johansson. 2023. <span>“Learning-Based Design of Luenberger Observers for Autonomous Nonlinear Systems.”</span> In <em>2023 American Control Conference (ACC)</em>, 3048–55. IEEE.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>We say “any solution” because there may be several solutions to the observer <a href="output-feedback.html#eq:observer-definition-1">(5.2)</a> due to <span class="math inline">\(\mathcal{F}\)</span> only being continuous. This is not a problem as long as any such solution satisfies the required convergence property.<a href="output-feedback.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>The time dependence of <span class="math inline">\(\mathcal{T}_u\)</span> enables us to cover the case where the knowledge of the <span class="math inline">\(u\)</span> and <span class="math inline">\(y_{x_0,u}\)</span> is used to construct the estimate from the observer state. In particular, using the output sometimes can reduce the dimension of the observer state (and thus alleviate the computations), thus obtaining a reduced-order observer. For example, see <span class="citation">(<a href="#ref-karagiannis05cdc-nonlinear">Karagiannis and Astolfi 2005</a>)</span> and <span class="citation">(<a href="#ref-astolfi03tac-immersion">Astolfi and Ortega 2003</a>)</span>.<a href="output-feedback.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>A function <span class="math inline">\(\rho: \mathbb{R}_+ \rightarrow \mathbb{R}_+\)</span> is a <span class="math inline">\(\mathcal{K}\)</span> function if <span class="math inline">\(\rho(0) = 0\)</span>, <span class="math inline">\(\rho\)</span> is continuous, and <span class="math inline">\(\rho\)</span> is increasing.<a href="output-feedback.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>An injective function is a function <span class="math inline">\(f\)</span> that maps distinct elements of its domain to distinct elements. That is, <span class="math inline">\(f(x_a) = f(x_b)\)</span> implies <span class="math inline">\(x_a = x_b\)</span>, or equivalently, <span class="math inline">\(x_a \neq x_b\)</span> implies <span class="math inline">\(f(x_a) \neq f(x_b)\)</span>.<a href="output-feedback.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>I have to say I was a bit surprised when I arrived at this formulation.<a href="output-feedback.html#fnref10" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="stability.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="adaptivecontrol.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/hankyang94/OptimalControlEstimation/blob/main/06-output-feedback.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["optimal-control-estimation.pdf", "optimal-control-estimation.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
