[["index.html", "Semidefinite Optimization and Relaxation Preface Feedback Offerings", " Semidefinite Optimization and Relaxation Heng Yang 2024-01-20 Preface This is the textbook for Harvard ENG-SCI 257: Semidefinite Optimization and Relaxation. Feedback I would like to invite you to provide comments to the textbook via the following two ways: Inline comments with Hypothesis: Go to Hypothesis and create an account Install the Chrome extension of Hypothesis Provide public comments to textbook contents and I will try to address them Blog-style comments with Disqus: Offerings Information about the offerings of the class is listed below. 2024 Spring Time: Mon/Wed 2:15 - 3:30pm Location: Science and Engineering Complex, 1.413 Instructor: Heng Yang Teaching Fellow: Safwan Hossain Syllabus "],["notation.html", "Notation", " Notation We will use the following standard notation throughout this book. Basics \\(\\mathbb{R}^{}\\) real numbers \\(\\mathbb{R}^{}_{+}\\) nonnegative real \\(\\mathbb{R}^{}_{++}\\) positive real \\(\\mathbb{Z}\\) integers \\(\\mathbb{N}\\) nonnegative integers \\(\\mathbb{N}_{+}\\) positive integers \\(\\mathbb{R}^{n}\\) \\(n\\)-D column vector \\(\\mathbb{R}^{n}_{+}\\) nonnegative orthant \\(\\mathbb{R}^{n}_{++}\\) positive orthant \\(e_i\\) standard basic vector \\(\\Delta_n := \\{x \\in \\mathbb{R}^n_{+} \\mid \\sum x_i = 1 \\}\\) standard simplex Matrices \\(\\mathbb{R}^{m \\times n}\\) \\(m \\times n\\) real matrices \\(\\mathbb{S}^{n}\\) \\(n\\times n\\) symmetric matrices \\(\\mathbb{S}^{n}_{+}\\) \\(n\\times n\\) positive semidefinite matrices \\(\\mathbb{S}^{n}_{++}\\) \\(n\\times n\\) positive definite matrices \\(\\langle A, B \\rangle\\) or \\(\\bullet\\) inner product in \\(\\mathbb{R}^{m \\times n}\\) \\(\\mathrm{tr}(A)\\) trace of \\(A \\in \\mathbb{R}^{n \\times n}\\) \\(A^\\top\\) matrix transpose \\(\\det(A)\\) matrix determinant \\(\\mathrm{rank}(A)\\) rank of a matrix \\(\\mathrm{diag}(A)\\) diagonal of a matrix \\(A\\) as a vector \\(\\mathrm{Diag}(a)\\) turning a vector into a diagonal matrix \\(\\mathrm{BlkDiag}(A,B,\\dots)\\) block diagonal matrix with blocks \\(A,B,\\dots\\) \\(\\succeq 0\\) and \\(\\preceq 0\\) positive / negative semidefinite \\(\\succ 0\\) and \\(\\prec 0\\) positive / negative definite \\(\\lambda_{\\max}\\) and \\(\\lambda_{\\min}\\) maximum / minimum eigenvalue \\(\\sigma_{\\max}\\) and \\(\\sigma_{\\min}\\) maximum / minimum singular value \\(\\mathrm{vec}(A)\\) vectorization of \\(A \\in \\mathbb{R}^{m \\times n}\\) \\(\\mathrm{svec}(A)\\) symmetric vectorization of \\(A \\in \\mathbb{S}^{n}\\) \\(\\Vert A \\Vert_\\mathrm{F}\\) Frobenius norm Geometry \\(\\Vert a \\Vert_{p}\\) \\(p\\)-norm \\(\\Vert a \\Vert\\) \\(2\\)-norm \\(B(o,r)\\) ball with center \\(o\\) and radius \\(r\\) \\(\\mathrm{aff}(S)\\) affine hull of set \\(S\\) \\(\\mathrm{conv}(S)\\) convex hull of set \\(S\\) \\(\\mathrm{cone}(S)\\) conical hull of set \\(S\\) \\(\\mathrm{int}(S)\\) interior of set \\(S\\) \\(\\mathrm{ri}(S)\\) relative interior of set \\(S\\) \\(\\partial S\\) boundary of set \\(S\\) \\(P^\\circ\\) polar of convex body \\(P^{*}\\) dual of set \\(P\\) \\(\\mathrm{SO}(d)\\) special orthogonal group of dimension \\(d\\) \\(\\mathcal{S}^{d-1}\\) unit sphere in \\(\\mathbb{R}^{d}\\) Optimization KKT Karush–Kuhn–Tucker LP linear program QP quadratic program SOCP second-order cone program SDP semidefinite program Algebra \\(\\mathbb{R}[x]\\) polynomial ring in \\(x\\) with real coefficients \\(\\deg\\) degree of a monomial / polynomial \\(\\mathbb{R}[x]_d\\) polynomials in \\(x\\) of degree up to \\(d\\) \\([x]_d\\) vector of monomials of degree up to \\(d\\) \\([\\![x ]\\!]_d\\) vector of monomials of degree \\(d\\) "],["background.html", "Chapter 1 Mathematical Background 1.1 Convexity 1.2 Convex Geometry 1.3 Convex Optimization 1.4 Linear Optimization", " Chapter 1 Mathematical Background 1.1 Convexity A very important notion in modern optimization is that of convexity. To a large extent, an optimization problem is “easy” if it is convex, and “difficult” when convexity is lost, i.e., nonconvex. We give a basic review of convexity here and refer the reader to (Rockafellar 1970), (Boyd and Vandenberghe 2004), and (Bertsekas, Nedic, and Ozdaglar 2003) for comprehensive treatments. We will work on a finite-dimensional real vector space, which we will identify with \\(\\mathbb{R}^{n}\\). Definition 1.1 (Convex Set) A set \\(S\\) is convex if \\(x_1,x_2 \\in S\\) implies \\(\\lambda x_1 + (1-\\lambda) x_2 \\in S\\) for any \\(\\lambda \\in [0,1]\\). In other words, if \\(x_1,x_2 \\in S\\), then the line segment connecting \\(x_1\\) and \\(x_2\\) lies inside \\(S\\). Conversely, a set \\(S\\) is nonconvex if Definition 1.1 does not hold. Given \\(x_1, x_2 \\in S\\), \\(\\lambda x_1 + (1-\\lambda) x_2\\) is called a convex combination when \\(\\lambda \\in [0,1]\\). For convenience, we will use the following notation \\[\\begin{equation} \\begin{split} (x_1,x_2) = \\{ \\lambda x_1 + (1-\\lambda) x_2 \\mid \\lambda \\in (0,1) \\}, \\\\ [x_1,x_2] = \\{ \\lambda x_1 + (1-\\lambda) x_2 \\mid \\lambda \\in [0,1] \\}. \\end{split} \\end{equation}\\] A hyperplane is a common convex set defined as \\[\\begin{equation} H = \\{ x \\in \\mathbb{R}^{n} \\mid \\langle c, x \\rangle = d \\} \\tag{1.1} \\end{equation}\\] for some \\(c \\in \\mathbb{R}^{n}\\) and scalar \\(d\\). A halfspace is a convex set defined as \\[\\begin{equation} H^{+} = \\{ x \\in \\mathbb{R}^{n} \\mid \\langle c, x \\rangle \\geq d \\}. \\tag{1.2} \\end{equation}\\] Given two nonempty convex sets \\(C_1\\) and \\(C_2\\), the distance between \\(C_1\\) and \\(C_2\\) is defined as \\[\\begin{equation} \\mathrm{dist}(C_1,C_2) = \\inf \\{ \\Vert c_1 - c_2 \\Vert \\mid c_1 \\in C_1, c_2 \\in C_2 \\}. \\end{equation}\\] For a convex set \\(C\\), the hyperplane \\(H\\) in (1.1) is called a supporting hyperplane for \\(C\\) if \\(C\\) is contained in the half space \\(H^{+}\\) and the distance between \\(H\\) and \\(C\\) is zero. For example, the hyperplane \\(x_1 = 0\\) is supporting for the hyperboloid \\(\\{ (x_1,x_2) \\mid x_1 x_2 \\geq 1, x_1 \\geq 0, x_2 \\geq 0 \\}\\) in \\(\\mathbb{R}^{2}\\). An important property of a convex set is that we can certify when a point is not in the set. This is usually done via a separation theorem. Theorem 1.1 (Separation Theorem) Let \\(S_1,S_2\\) be two convex sets in \\(\\mathbb{R}^{n}\\) and \\(S_1 \\cap S_2 = \\emptyset\\), then there exists a hyperplane that separates \\(S_1\\) and \\(S_2\\), i.e., there exists \\(c\\) and \\(d\\) such that \\[\\begin{equation} \\begin{split} \\langle c, x \\rangle \\geq d, &amp; \\forall x \\in S_1,\\\\ \\langle c, x \\rangle \\leq d, &amp; \\forall x \\in S_2. \\end{split} \\tag{1.3} \\end{equation}\\] Further, if \\(S_1\\) is compact (i.e., closed and bounded) and \\(S_2\\) is closed, then the separation is strict, i.e., the inequalities in (1.3) are strict. The strict separation theorem is used typically when \\(S_1\\) is a single point (hence compact). We will see a generation of the separation theorem for nonconvex sets later after we introduce the idea of sums of squares. Exercise 1.1 Provide examples of two disjoint convex sets such that the separation in (1.3) is not strict in one way and both ways. Exercise 1.2 Provide a constructive proof that the separation hyperplane exists in Theorem 1.1 when (1) both \\(S_1\\) and \\(S_2\\) are closed, and (2) at least one of them is bounded. The intersection of convex sets is always convex (try to prove this). 1.2 Convex Geometry 1.2.1 Basic Facts Given a set \\(S\\), its affine hull is the set \\[ \\mathrm{aff}(S) = \\left\\{ \\sum_{i=1}^k \\lambda_i u_i \\mid \\lambda_1 + \\dots + \\lambda_k = 1, u_i \\in S, k \\in \\mathbb{N}_{+} \\right\\} , \\] where \\(\\sum_{i=1}^{k} \\lambda_i u_i\\) is called an affine combination of \\(u_1,\\dots,u_k\\) when \\(\\sum_i \\lambda_i = 1\\). The affine hull of the emptyset is the emptyset, of a singleton is the singleton itself. The affine hull of a set of two different points is the line going through them. The affine hull of a set of three points not on one line is the plane going through them. The affine hull of a set of four points not in a plane in \\(\\mathbb{R}^{3}\\) is the entire space \\(\\mathbb{R}^{3}\\). For a convex set \\(C \\subseteq \\mathbb{R}^{n}\\), the interior of \\(C\\) is defined as \\[ \\mathrm{int}(C) := \\{ u \\in C \\mid \\exists \\epsilon &gt; 0, B(u,\\epsilon) \\succeq C \\}, \\] where \\(B(u,\\epsilon)\\) denotes a ball centered at \\(u\\) with radius \\(\\epsilon\\) (using the usual 2-norm). Each point in \\(\\mathrm{int}(C)\\) is called an interior point of \\(C\\). If \\(\\mathrm{int}(C) = C\\), then \\(C\\) is said to be an open set. A convex set with nonempty interior is called a convex domain, while a compact (i.e., closed and bounded) convex domain is called a convex body. The boundary of \\(C\\) is the subset of points that are not in the interior of \\(C\\) and we denote it as \\(\\partial C\\). It is possible that a convex set has empty interior. For example, a hyperplane has no interior, and neither does a singleton. In such cases, the relative interior can be defined as \\[ \\mathrm{ri}(C) := \\{ u \\in C \\mid \\exists \\epsilon &gt; 0, B(u,\\epsilon) \\cap \\mathrm{aff}(C) \\subseteq C \\}. \\] For a nonempty convex set, the relative interior always exists. If \\(\\mathrm{ri}(C) = C\\), then \\(C\\) is said to be relatively open. For example, the relative interior of a singleton is the singleton itself, and hence a singleton is relatively open. For a convex set \\(C\\), a point \\(u \\in C\\) is called an extreme point if \\[ u \\in (x,y), x \\in C, y \\in C \\quad \\Rightarrow u = x = y. \\] For example, consider \\(C = \\{ (x,y)\\mid x^2 + y^2 \\leq 1 \\}\\), then all the points on the boundary \\(\\partial C = \\{ (x,y) \\mid x^2 + y^2 = 1 \\}\\) are extreme points. A subset \\(F \\subseteq C\\) is called a face if \\(F\\) itself is convex and \\[ u \\in (x,y), u \\in F, x,y \\in C \\quad \\Rightarrow x,y \\in F. \\] Clearly, the empty set \\(\\emptyset\\) and the entire set \\(C\\) are faces of \\(C\\), which are called trivial faces. The face \\(F\\) is said to be proper if \\(F \\neq C\\). The set of any single extreme point is also a face. A face \\(F\\) of \\(C\\) is called exposed if there exists a supporting hyperplane \\(H\\) for \\(C\\) such that \\[ F = H \\cap C. \\] 1.2.2 Cones, Duality, Polarity Definition 1.2 (Polar) For a nonempty set \\(T \\subseteq \\mathbb{R}^{n}\\), its polar is the set \\[\\begin{equation} T^\\circ := \\{ y \\in \\mathbb{R}^{n} \\mid \\langle x, y \\rangle \\leq 1, \\forall x \\in T \\}. \\tag{1.4} \\end{equation}\\] The polar \\(T^\\circ\\) is a closed convex set and contains the origin. Note that \\(T\\) is always contained in the polar of \\(T^\\circ\\), i.e., \\(T \\subseteq (T^\\circ)^\\circ\\). Indeed, they are equal under some assumptions. Theorem 1.2 (Bipolar) If \\(T \\subseteq \\mathbb{R}^{n}\\) is a closed convex set containing the origin, then \\((T^\\circ)^\\circ = T\\). An important class of convex sets are those that are invariant under nonnegative scalings. A set \\(K \\subseteq \\mathbb{R}^{n}\\) is a cone if \\(t x \\in K\\) for all \\(x \\in K\\) and for all \\(t &gt; 0\\). For example, the positive real line \\(\\{ x \\in \\mathbb{R}^{} \\mid x &gt; 0 \\}\\) is a cone. The cone \\(K\\) is pointed if \\(K \\cap -K = \\{ 0 \\}\\). It is said to be solid if its interior \\(\\mathrm{int}(K) \\neq \\emptyset\\). Any nonzero point of a cone cannot be extreme. If a cone is pointed, the only extreme point is the origin. The analogue of extreme point for convex cones is the extreme ray. For a convex cone \\(K\\) and \\(0 \\neq u \\in K\\), the line segment \\[ u \\cdot [0,\\infty) := \\{ tu \\mid t\\geq 0 \\} \\] is called an extreme ray of \\(K\\) if \\[ u \\in (x,y), x,y \\in K \\quad \\Rightarrow \\quad u,x,y \\text{ are parallel to each other}. \\] If \\(u \\cdot [0,\\infty)\\) is an extreme ray, then we say \\(u\\) generates the extreme ray. Definition 1.3 (Proper Cone) A cone \\(K\\) is proper if it is closed, convex, pointed, and solid. A proper cone \\(K\\) induces a partial order on the vector space, via \\(x \\succeq y\\) if \\(x - y \\in K\\). We also use \\(x \\succ y\\) if \\(x - y\\) is in \\(\\mathrm{int}(K)\\). Important examples of proper cones are the nonnegative orthant, the second-order cone, the set of symmetric positive semidefinite matrices, and the set of nonnegative polynomials, which we will describe later in the book. Definition 1.4 (Dual) The dual of a nonempty set \\(S\\) is \\[ S^* := \\{ y \\in \\mathbb{R}^{n} \\mid \\langle y, x \\rangle \\geq 0, \\forall x \\in S \\}. \\] Given any set \\(S\\), its dual \\(S^*\\) is always a closed convex cone. Duality reverses inclusion, that is, \\[ S_1 \\subseteq S_2 \\quad \\Rightarrow \\quad S_1^* \\supseteq S_2^*. \\] If \\(S\\) is a closed convex cone, then \\(S^{* *}= S\\). Otherwise, \\(S^{* *}\\) is the closure of the smallest convex cone that contains \\(S\\). For a cone \\(K \\subseteq \\mathbb{R}^{n}\\), one can show that \\[ K^\\circ = \\{ y \\in \\mathbb{R}^{n} \\mid \\langle x, y \\rangle \\leq 0, \\forall x \\in K \\}. \\] The set \\(K^\\circ\\) is called the polar cone of \\(K\\). The negative of \\(K^\\circ\\) is just the dual cone \\[ K^{*} = \\{ y \\in \\mathbb{R}^{n} \\mid \\langle x, y \\rangle \\geq 0, \\forall x \\in K \\}. \\] Definition 1.5 (Self-dual) A cone \\(K\\) is self-dual if \\(K^{*} = K\\). As an easy example, the nonnegative orthant \\(\\mathbb{R}^{n}_{+}\\) is self-dual. Example 1.1 (Second-order Cone) The second-order cone, or the Lorentz cone, or the ice cream cone \\[ \\mathcal{Q}_n := \\{ (x_0,x_1,\\dots,x_n) \\in \\mathbb{R}^{n+1} \\mid \\sqrt{x_1^2 + \\dots + x_n^2} \\leq x_0 \\} \\] is a proper cone of \\(\\mathbb{R}^{n+1}\\). We will show that it is also self-dual. Proof. Consider \\((y_0,y_1,\\dots,y_n) \\in \\mathcal{Q}_n\\), we want to show that \\[\\begin{equation} x_0 y_0 + x_1 y_1 + \\dots + x_n y_n \\geq 0, \\forall (x_0,x_1,\\dots,x_n) \\in \\mathcal{Q}_n. \\tag{1.5} \\end{equation}\\] This is easy to verify because \\[ x_1 y_1 + \\dots + x_n y_n \\geq - \\sqrt{x_1^2 + \\dots + x_n^2} \\sqrt{y_1^2 + \\dots + y_n^2} \\geq - x_0 y_0. \\] Hence we have \\(\\mathcal{Q}_n \\subseteq \\mathcal{Q}_n^{*}\\). Conversely, if (1.5) holds, then take \\[ x_1 = -y_1, \\dots, x_n = - y_n, \\quad x_0 = \\sqrt{x_1^2 + \\dots + x_n^2}, \\] we have \\[ y_0 \\geq \\sqrt{y_1^2 + \\dots + y_n^2}, \\] hence \\(\\mathcal{Q}_n^{*} \\subseteq \\mathcal{Q}_n\\). \\(\\blacksquare\\) Not very proper cone is self-dual. Exercise 1.3 Consider the following proper cone in \\(\\mathbb{R}^{2}\\) \\[ K = \\{ (x_1,x_2) \\mid 2x_1 - x_2 \\geq 0, 2x_2 - x_1 \\geq 0 \\}. \\] Show that it is not self-dual. 1.3 Convex Optimization 1.4 Linear Optimization References "],["sdp.html", "Chapter 2 Semidefinite Optimization", " Chapter 2 Semidefinite Optimization Positive Semidefinite Matrices Spectrahedra "],["psets.html", "Chapter 3 Problem Sets", " Chapter 3 Problem Sets Exercise 3.1 (Test) Test   Exercise 3.1 (Test) Test "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
