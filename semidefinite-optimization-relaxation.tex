% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=true]{hyperref}
\usepackage{tcolorbox}
\usepackage{color}
\usepackage{framed}
\setlength{\fboxsep}{.8em}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

% \newcommand{\Real}[1]{\mathbb{R}^{#1}}
% \newcommand{\sym}[1]{\mathbb{S}^{#1}}
% \newcommand{\psd}[1]{\sym{#1}_{+}}
% \newcommand{\pd}[1]{\sym{#1}_{++}}
% \newcommand{\inprod}[2]{\langle #1, #2 \rangle}
% \newcommand{\linprod}[2]{\left\langle #1, #2 \right\rangle}
% \newcommand{\trace}{\mathrm{tr}}
% \newcommand{\tran}{^\top}
% % \newcommand{\det}{\mathrm{det}}
% \newcommand{\rank}{\mathrm{rank}}
% \newcommand{\diag}{\mathrm{diag}}

\newtcolorbox{examplebox}{
  colback=green,
  colframe=orange,
  coltext=black,
  boxsep=5pt,
  arc=4pt}

\newtcolorbox{theorembox}{
  colback=green,
  colframe=green,
  coltext=black,
  boxsep=5pt,
  arc=4pt}

\newtcolorbox{definitionbox}{
colback=white,
colframe=green,
coltext=black,
boxsep=5pt,
arc=4pt}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Semidefinite Optimization and Relaxation},
  pdfauthor={Heng Yang},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Semidefinite Optimization and Relaxation}
\author{Heng Yang}
\date{2024-03-25}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\newcommand{\calG}{\mathcal{G}}
\newcommand{\calV}{\mathcal{V}}
\newcommand{\calE}{\mathcal{E}}
\newcommand{\calF}{\mathcal{F}}
\newcommand{\calP}{\mathcal{P}}
\newcommand{\calQ}{\mathcal{Q}}
\newcommand{\calA}{\mathcal{A}}
\newcommand{\calK}{\mathcal{K}}
\newcommand{\calS}{\mathcal{S}}
\newcommand{\calM}{\mathcal{M}}
\newcommand{\calI}{\mathcal{I}}
\newcommand{\calR}{\mathcal{R}}
\newcommand{\calZ}{\mathcal{Z}}
\newcommand{\mathx}{\mathrm{x}}
\newcommand{\mathy}{\mathrm{y}}
\newcommand{\bbE}{\mathbb{E}}
\newcommand{\calN}{\mathcal{N}}
\newcommand{\tldR}{\tilde{R}}
\newcommand{\bbZ}{\mathbb{Z}}
\newcommand{\bbQ}{\mathbb{Q}}
\newcommand{\bbC}{\mathbb{C}}
\newcommand{\bbF}{\mathbb{F}}
\newcommand{\bbR}{\mathbb{R}}

\newcommand{\Real}[1]{\mathbb{R}^{#1}}
\newcommand{\Comp}[1]{\mathbb{C}^{#1}}
\newcommand{\sym}[1]{\mathbb{S}^{#1}}
\newcommand{\psd}[1]{\sym{#1}_{+}}
\newcommand{\pd}[1]{\sym{#1}_{++}}
\newcommand{\inprod}[2]{\langle #1, #2 \rangle}
\newcommand{\linprod}[2]{\left\langle #1, #2 \right\rangle}
\newcommand{\trace}{\mathrm{tr}}
\newcommand{\tran}{^\top}

\newcommand{\rank}{\mathrm{rank}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\Diag}{\mathrm{Diag}}
\newcommand{\BlkDiag}{\mathrm{BlkDiag}}
\newcommand{\vectorize}{\mathrm{vec}}
\newcommand{\svec}{\mathrm{svec}}
\newcommand{\mat}{\mathrm{mat}}
\newcommand{\smat}{\mathrm{smat}}
\newcommand{\norm}[1]{\Vert #1 \Vert}
\newcommand{\lnorm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\pnorm}[2]{\Vert #1 \Vert_{#2}}
\newcommand{\Fnorm}[1]{\Vert #1 \Vert_\mathrm{F}}
\newcommand{\conv}{\mathrm{conv}}
\newcommand{\cone}{\mathrm{cone}}
\newcommand{\interior}{\mathrm{int}}
\newcommand{\relint}{\mathrm{ri}}
\newcommand{\poly}[1]{\mathbb{R}[#1]}
\newcommand{\SOd}{\mathrm{SO}(d)}
\newcommand{\SOthree}{\mathrm{SO}(3)}
\newcommand{\Od}{\mathrm{O}(d)}
\newcommand{\Ogroup}{\mathrm{O}}
\newcommand{\usphere}{\mathcal{S}}
\newcommand{\bmath}[1]{\boldsymbol{#1}}
\newcommand{\lbrkt}{[\![}
\newcommand{\rbrkt}{]\!]}
\newcommand{\brkt}[1]{\lbrkt #1 \rbrkt}
\newcommand{\bracket}[1]{[ #1 ]}
\newcommand{\sign}{\mathrm{sgn}}

\newcommand{\cbrace}[1]{\{ #1 \}}
\newcommand{\lcbrace}[1]{ \left\{ #1 \right\} }
\newcommand{\aff}{\mathrm{aff}}
\newcommand{\bbN}{\mathbb{N}}
\newcommand{\dist}{\mathrm{dist}}
\newcommand{\subject}{\mathrm{s.t.}}
\newcommand{\cl}{\mathrm{cl}}
\newcommand{\eye}{\mathrm{I}}
\newcommand{\inv}{^{-1}}
\newcommand{\invtran}{^{-\top}}
\newcommand{\Range}{\mathrm{Range}}
\renewcommand{\ker}{\mathrm{ker}}
\newcommand{\face}{\mathrm{face}}
\newcommand{\lmid}{\ \middle\vert\ }
\renewcommand{\Re}{\mathrm{Re}}
\newcommand{\hatmap}[1]{[#1]_{\times}}
\newcommand{\kron}{\otimes}
\newcommand{\skron}{\kron_{\mathrm{s}}}
\newcommand{\Ideal}{\mathrm{Ideal}}
\newcommand{\lexsucc}{\succ_{\mathrm{lex}}}
\newcommand{\lexprec}{\prec_{\mathrm{lex}}}
\newcommand{\grlexsucc}{\succ_{\mathrm{grlex}}}
\newcommand{\grlexprec}{\prec_{\mathrm{grlex}}}
\newcommand{\grevlexsucc}{\succ_{\mathrm{grevlex}}}
\newcommand{\grevlexprec}{\prec_{\mathrm{grevlex}}}
\newcommand{\abs}[1]{|#1|}
\newcommand{\initial}[1]{\mathrm{in}(#1)}
\newcommand{\NormalForm}{\mathrm{NormalForm}}
\newcommand{\ceil}[1]{\lceil #1 \rceil}

\newcommand{\qmodule}{\mathrm{Qmodule}}
\newcommand{\mom}{\mathrm{mom}}
\newcommand{\preorder}{\mathrm{Preorder}}
\newcommand{\supp}{\mathrm{supp}}
\newcommand{\myspan}{\mathrm{span}}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

This is the textbook for Harvard ENG-SCI 257: Semidefinite Optimization and Relaxation.

\section*{Feedback}\label{feedback}
\addcontentsline{toc}{section}{Feedback}

I would like to invite you to provide comments to the textbook via the following two ways:

\begin{itemize}
\tightlist
\item
  Inline comments with Hypothesis:

  \begin{itemize}
  \tightlist
  \item
    Go to \href{https://hypothes.is}{Hypothesis} and create an account
  \item
    Install the \href{https://chrome.google.com/webstore/detail/hypothesis-web-pdf-annota/bjfhmglciegochdpefhhlphglcehbmek}{Chrome extension of Hypothesis}
  \item
    Provide public comments to textbook contents and I will try to address them
  \end{itemize}
\item
  Blog-style comments with Disqus:

  \begin{itemize}
  \tightlist
  \item
    At the end of each Chapter, there is a Disqus module where you can leave feedback
  \end{itemize}
\end{itemize}

I would recommend using Disqus for high-level and general feedback regarding the entire Chapter, but using Hypothesis for feedback and questions about the technical details.

\section*{Offerings}\label{offerings}
\addcontentsline{toc}{section}{Offerings}

Information about the offerings of the class is listed below.

\subsubsection*{2024 Spring}\label{spring}
\addcontentsline{toc}{subsubsection}{2024 Spring}

\textbf{Time}: Mon/Wed 2:15 - 3:30pm

\textbf{Location}: Science and Engineering Complex, 1.413

\textbf{Instructor}: \href{https://hankyang.seas.harvard.edu/}{Heng Yang}

\textbf{Teaching Fellow}: \href{https://safwanhossain.github.io/}{Safwan Hossain}

\href{https://docs.google.com/document/d/1H6Wqht_PVw_n8Jl0kXN3HjZfHkeZJYqYWT4ayxvqRlU/edit?usp=sharing}{\textbf{Syllabus}}

\chapter*{Notation}\label{notation}
\addcontentsline{toc}{chapter}{Notation}

We will use the following standard notation throughout this book.

\textbf{Basics}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.7083}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.2917}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mathbb{R}^{}\) & real numbers \\
\(\mathbb{R}^{}_{+}\) & nonnegative real \\
\(\mathbb{R}^{}_{++}\) & positive real \\
\(\mathbb{Z}\) & integers \\
\(\mathbb{N}\) & nonnegative integers \\
\(\mathbb{N}_{+}\) & positive integers \\
\(\mathbb{R}^{n}\) & \(n\)-D column vector \\
\(\mathbb{R}^{n}_{+}\) & nonnegative orthant \\
\(\mathbb{R}^{n}_{++}\) & positive orthant \\
\(e_i\) & standard basic vector \\
\(\Delta_n := \{x \in \mathbb{R}^n_{+} \mid \sum x_i = 1 \}\) & standard simplex \\
\end{longtable}

\textbf{Matrices}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.7083}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.2917}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mathbb{R}^{m \times n}\) & \(m \times n\) real matrices \\
\(\mathbb{S}^{n}\) & \(n\times n\) symmetric matrices \\
\(\mathbb{S}^{n}_{+}\) & \(n\times n\) positive semidefinite matrices \\
\(\mathbb{S}^{n}_{++}\) & \(n\times n\) positive definite matrices \\
\(\langle A, B \rangle\) or \(\bullet\) & inner product in \(\mathbb{R}^{m \times n}\) \\
\(\mathrm{tr}(A)\) & trace of \(A \in \mathbb{R}^{n \times n}\) \\
\(A^\top\) & matrix transpose \\
\(\det(A)\) & matrix determinant \\
\(\mathrm{rank}(A)\) & rank of a matrix \\
\(\mathrm{diag}(A)\) & diagonal of a matrix \(A\) as a vector \\
\(\mathrm{Diag}(a)\) & turning a vector into a diagonal matrix \\
\(\mathrm{BlkDiag}(A,B,\dots)\) & block diagonal matrix with blocks \(A,B,\dots\) \\
\(\succeq 0\) and \(\preceq 0\) & positive / negative semidefinite \\
\(\succ 0\) and \(\prec 0\) & positive / negative definite \\
\(\lambda_{\max}\) and \(\lambda_{\min}\) & maximum / minimum eigenvalue \\
\(\sigma_{\max}\) and \(\sigma_{\min}\) & maximum / minimum singular value \\
\(\mathrm{vec}(A)\) & vectorization of \(A \in \mathbb{R}^{m \times n}\) \\
\(\mathrm{svec}(A)\) & symmetric vectorization of \(A \in \mathbb{S}^{n}\) \\
\(\Vert A \Vert_\mathrm{F}\) & Frobenius norm \\
\(\mathrm{Range}(A)\) & span of the column vectors \\
\(\mathrm{ker}(A)\) & right null space \\
\end{longtable}

\textbf{Geometry}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\Vert a \Vert_{p}\) & \(p\)-norm \\
\(\Vert a \Vert\) & \(2\)-norm \\
\(B(o,r)\) & ball with center \(o\) and radius \(r\) \\
\(\mathrm{aff}(S)\) & affine hull of set \(S\) \\
\(\mathrm{conv}(S)\) & convex hull of set \(S\) \\
\(\mathrm{cone}(S)\) & conical hull of set \(S\) \\
\(\mathrm{int}(S)\) & interior of set \(S\) \\
\(\mathrm{ri}(S)\) & relative interior of set \(S\) \\
\(\partial S\) & boundary of set \(S\) \\
\(P^\circ\) & polar of convex body \\
\(P^{*}\) & dual of set \(P\) \\
\(\mathrm{O}(d)\) & orthogonal group of dimension \(d\) \\
\(\mathrm{SO}(d)\) & special orthogonal group of dimension \(d\) \\
\(\mathcal{S}^{d-1}\) & unit sphere in \(\mathbb{R}^{d}\) \\
\end{longtable}

\textbf{Optimization}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
KKT & Karush--Kuhn--Tucker \\
LP & linear program \\
QP & quadratic program \\
SOCP & second-order cone program \\
SDP & semidefinite program \\
\end{longtable}

\textbf{Algebra}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mathbb{R}[x]\) & polynomial ring in \(x\) with real coefficients \\
\(\deg\) & degree of a monomial / polynomial \\
\(\mathbb{R}[x]_d\) & polynomials in \(x\) of degree up to \(d\) \\
\([x]_d\) & vector of monomials of degree up to \(d\) \\
\([\![x ]\!]_d\) & vector of monomials of degree \(d\) \\
\end{longtable}

\chapter{Mathematical Background}\label{background}

\section{Convexity}\label{background:convexity}

A very important notion in modern optimization is that of \emph{convexity}. To a large extent, an optimization problem is ``easy'' if it is convex, and ``difficult'' when convexity is lost, i.e., \emph{nonconvex}. We give a basic review of convexity here and refer the reader to \citep{rockafellar70-convexanalysis}, \citep{boyd04book-convex}, and \citep{bertsekas03book-convex} for comprehensive treatments.

We will work on a finite-dimensional real vector space, which we will identify with \(\mathbb{R}^{n}\).

\begin{definition}[Convex Set]
\protect\hypertarget{def:ConvexSet}{}\label{def:ConvexSet}A set \(S\) is convex if \(x_1,x_2 \in S\) implies \(\lambda x_1 + (1-\lambda) x_2 \in S\) for any \(\lambda \in [0,1]\). In other words, if \(x_1,x_2 \in S\), then the line segment connecting \(x_1\) and \(x_2\) lies inside \(S\).
\end{definition}

Conversely, a set \(S\) is nonconvex if Definition \ref{def:ConvexSet} does not hold.

Given \(x_1, x_2 \in S\), \(\lambda x_1 + (1-\lambda) x_2\) is called a \emph{convex combination} when \(\lambda \in [0,1]\). For convenience, we will use the following notation
\begin{equation}
\begin{split}
(x_1,x_2) = \{ \lambda x_1 + (1-\lambda) x_2 \mid \lambda \in (0,1) \}, \\ [x_1,x_2] = \{ \lambda x_1 + (1-\lambda) x_2 \mid \lambda \in [0,1] \}.
\end{split}
\end{equation}

A \textbf{hyperplane} is a common convex set defined as
\begin{equation}
H = \{  x \in \mathbb{R}^{n} \mid \langle c, x \rangle = d  \}
\label{eq:hyperplane}
\end{equation}
for some \(c \in \mathbb{R}^{n}\) and scalar \(d\). A \textbf{halfspace} is a convex set defined as
\begin{equation}
H^{+} = \{  x \in \mathbb{R}^{n} \mid \langle c, x \rangle \geq d  \}.
\label{eq:halfspace}
\end{equation}

Given two nonempty convex sets \(C_1\) and \(C_2\), the \textbf{distance} between \(C_1\) and \(C_2\) is defined as
\begin{equation}
\mathrm{dist}(C_1,C_2) = \inf \{ \Vert c_1 - c_2 \Vert \mid c_1 \in C_1, c_2 \in C_2 \}.
\end{equation}

For a convex set \(C\), the hyperplane \(H\) in \eqref{eq:hyperplane} is called a \textbf{supporting hyperplane} for \(C\) if \(C\) is contained in the half space \(H^{+}\) and the distance between \(H\) and \(C\) is zero. For example, the hyperplane \(x_1 = 0\) is supporting for the hyperboloid \(\{ (x_1,x_2) \mid x_1 x_2 \geq 1, x_1 \geq 0, x_2 \geq 0 \}\) in \(\mathbb{R}^{2}\).

An important property of a convex set is that we can \emph{certify} when a point is not in the set. This is usually done via a separation theorem.

\begin{theorem}[Separation Theorem]
\protect\hypertarget{thm:SeparationTheorem}{}\label{thm:SeparationTheorem}Let \(S_1,S_2\) be two convex sets in \(\mathbb{R}^{n}\) and \(S_1 \cap S_2 = \emptyset\), then there exists a hyperplane that separates \(S_1\) and \(S_2\), i.e., there exists \(c\) and \(d\) such that
\begin{equation}
\begin{split}
\langle c, x \rangle \geq d, &  \forall x \in S_1,\\
\langle c, x \rangle \leq d, & \forall x \in S_2.
\end{split}
\label{eq:separation}
\end{equation}
Further, if \(S_1\) is compact (i.e., closed and bounded) and \(S_2\) is closed, then the separation is strict, i.e., the inequalities in \eqref{eq:separation} are strict.
\end{theorem}

The strict separation theorem is used typically when \(S_1\) is a single point (hence compact).

We will see a generalization of the separation theorem for nonconvex sets later after we introduce the idea of sums of squares.

\begin{exercise}
Provide examples of two disjoint convex sets such that the separation in \eqref{eq:separation} is not strict in one way and both ways.
\end{exercise}

\begin{exercise}
Provide a constructive proof that the separation hyperplane exists in Theorem \ref{thm:SeparationTheorem} when (1) both \(S_1\) and \(S_2\) are closed, and (2) at least one of them is bounded.
\end{exercise}

The intersection of convex sets is always convex (try to prove this).

\section{Convex Geometry}\label{background:convex:geometry}

\subsection{Basic Facts}\label{basic-facts}

Given a set \(S\), its \textbf{affine hull} is the set
\[
\mathrm{aff}(S) =  \left\{  \sum_{i=1}^k \lambda_i u_i \mid \lambda_1 + \dots + \lambda_k = 1, u_i \in S, k \in \mathbb{N}_{+}  \right\} ,
\]
where \(\sum_{i=1}^{k} \lambda_i u_i\) is called an \emph{affine combination} of \(u_1,\dots,u_k\) when \(\sum_i \lambda_i = 1\). The affine hull of a set is the smallest affine subspace that contains \(S\), and the \textbf{dimension} of \(S\) is the dimension of its affine hull. The affine hull of the emptyset is the emptyset, of a singleton is the singleton itself. The affine hull of a set of two different points is the line going through them. The affine hull of a set of three points not on one line is the plane going through them. The affine hull of a set of four points not in a plane in \(\mathbb{R}^{3}\) is the entire space \(\mathbb{R}^{3}\).

For a convex set \(C \subseteq \mathbb{R}^{n}\), the \textbf{interior} of \(C\) is defined as
\[
\mathrm{int}(C) := \{  u \in C \mid \exists \epsilon > 0, B(u,\epsilon) \subseteq C  \},
\]
where \(B(u,\epsilon)\) denotes a ball centered at \(u\) with radius \(\epsilon\) (using the usual 2-norm). Each point in \(\mathrm{int}(C)\) is called an \emph{interior point} of \(C\). If \(\mathrm{int}(C) = C\), then \(C\) is said to be an \textbf{open set}. A convex set with nonempty interior is called a \textbf{convex domain}, while a compact (i.e., closed and bounded) convex domain is called a \textbf{convex body}.

The \textbf{boundary of \(C\)} is the subset of points that are in the \textbf{closure}\footnote{The closure of a subset \(C\) of points, denoted \(\mathrm{cl}(C)\), consists of all points in \(C\) together with all limit points of \(C\). The closure of \(C\) may equivalently be defined as the intersection of all closed sets containing \(C\). Intuitively, the closure can be thought of as all the points that are either in \(C\) or ``very near'' \(C\). For example, the closure of the open line segment \(C= (0,1)\) is the closed line segment \(C=[0,1]\).} of \(C\) but are not in the interior of \(C\), and we denote it as \(\partial C\). For example, the closed line segment \(C = [0,1]\) has two points on the boundary: \(0\) and \(1\); the open line segment \(C = (0,1)\) has the same two points as its boundary.

It is possible that a convex set has empty interior. For example, a hyperplane has no interior, and neither does a singleton. In such cases, the \textbf{relative interior} can be defined as
\[
\mathrm{ri}(C) := \{  u \in C \mid \exists \epsilon > 0, B(u,\epsilon) \cap \mathrm{aff}(C) \subseteq C  \}.
\]
For a nonempty convex set, the relative interior always exists. If \(\mathrm{ri}(C) = C\), then \(C\) is said to be \textbf{relatively open}. For example, the relative interior of a singleton is the singleton itself, and hence a singleton is relatively open.

For a convex set \(C\), a point \(u \in C\) is called an \textbf{extreme point} if
\[
u \in (x,y), x \in C, y \in C \quad \Rightarrow u = x = y.
\]
For example, consider \(C = \{ (x,y)\mid x^2 + y^2 \leq 1 \}\), then all the points on the boundary \(\partial C = \{ (x,y) \mid x^2 + y^2 = 1 \}\) are extreme points.

A subset \(F \subseteq C\) is called a \textbf{face} if \(F\) itself is convex and
\[
u \in (x,y), u \in F, x,y \in C \quad \Rightarrow x,y \in F. 
\]
Clearly, the empty set \(\emptyset\) and the entire set \(C\) are faces of \(C\), which are called \emph{trivial faces}. The face \(F\) is said to be \emph{proper} if \(F \neq C\). The set of any single extreme point is also a face. A face \(F\) of \(C\) is called \textbf{exposed} if there exists a supporting hyperplane \(H\) for \(C\) such that
\[
F = H \cap C.
\]

\subsection{Cones, Duality, Polarity}\label{cones-duality-polarity}

\begin{definition}[Polar]
\protect\hypertarget{def:polar}{}\label{def:polar}For a nonempty set \(T \subseteq \mathbb{R}^{n}\), its polar is the set
\begin{equation}
T^\circ := \{  y \in \mathbb{R}^{n} \mid \langle x, y \rangle \leq 1, \forall x \in T  \}.
\label{eq:polar}
\end{equation}
\end{definition}

The polar \(T^\circ\) is a closed convex set and contains the origin. Note that \(T\) is always contained in the polar of \(T^\circ\), i.e., \(T \subseteq (T^\circ)^\circ\). Indeed, they are equal under some assumptions.

\begin{theorem}[Bipolar]
\protect\hypertarget{thm:bipolar}{}\label{thm:bipolar}If \(T \subseteq \mathbb{R}^{n}\) is a closed convex set containing the origin, then \((T^\circ)^\circ = T\).
\end{theorem}

An important class of convex sets are those that are invariant under positive scalings.\footnote{Some authors define a cone using nonnegative scalings.} A set \(K \subseteq \mathbb{R}^{n}\) is a \textbf{cone} if \(t x \in K\) for all \(x \in K\) and for all \(t > 0\). For example, the positive real line \(\{ x \in \mathbb{R}^{} \mid x > 0 \}\) is a cone. The cone \(K\) is \textbf{pointed} if \(K \cap -K = \{ 0 \}\). It is said to be \textbf{solid} if its interior \(\mathrm{int}(K) \neq \emptyset\). Any nonzero point of a cone cannot be extreme. If a cone is pointed, the only extreme point is the origin.

The analogue of extreme point for convex cones is the \textbf{extreme ray}. For a convex cone \(K\) and \(0 \neq u \in K\), the line segment
\[
u \cdot [0,\infty) := \{ tu \mid t\geq 0 \}
\]
is called an extreme ray of \(K\) if
\[
u \in (x,y), x,y \in K \quad \Rightarrow \quad u,x,y \text{ are parallel to each other}.
\]
If \(u \cdot [0,\infty)\) is an extreme ray, then we say \(u\) generates the extreme ray.

\begin{definition}[Proper Cone]
\protect\hypertarget{def:ProperCone}{}\label{def:ProperCone}A cone \(K\) is proper if it is closed, convex, pointed, and solid.
\end{definition}

A proper cone \(K\) induces a \textbf{partial order} on the vector space, via \(x \succeq y\) if \(x - y \in K\). We also use \(x \succ y\) if \(x - y\) is in \(\mathrm{int}(K)\). Important examples of proper cones are the nonnegative orthant, the second-order cone, the set of symmetric positive semidefinite matrices, and the set of nonnegative polynomials, which we will describe later in the book.

\begin{definition}[Dual]
\protect\hypertarget{def:Dual}{}\label{def:Dual}The dual of a nonempty set \(S\) is
\[
S^* := \{  y \in \mathbb{R}^{n} \mid \langle y, x \rangle \geq 0, \forall x \in S \}.
\]
\end{definition}

Given any set \(S\), its dual \(S^*\) is always a closed convex cone. Duality reverses inclusion, that is,
\[
S_1 \subseteq S_2 \quad \Rightarrow \quad S_1^* \supseteq S_2^*.
\]
If \(S\) is a closed convex cone, then \(S^{* *}= S\). Otherwise, \(S^{* *}\) is the closure of the smallest convex cone that contains \(S\).

For a cone \(K \subseteq \mathbb{R}^{n}\), one can show that
\[
K^\circ = \{ y \in \mathbb{R}^{n} \mid \langle x, y \rangle \leq 0, \forall x \in K \}.
\]
The set \(K^\circ\) is called the \textbf{polar cone} of \(K\). The negative of \(K^\circ\) is just the \textbf{dual cone}
\[
K^{*} = \{ y \in \mathbb{R}^{n} \mid \langle x, y \rangle \geq 0, \forall x \in K \}.
\]

\begin{definition}[Self-dual]
\protect\hypertarget{def:selfdual}{}\label{def:selfdual}A cone \(K\) is self-dual if \(K^{*} = K\).
\end{definition}

As an easy example, the nonnegative orthant \(\mathbb{R}^{n}_{+}\) is self-dual.

\begin{example}[Second-order Cone]
\protect\hypertarget{exm:SecondOrderCone}{}\label{exm:SecondOrderCone}The second-order cone, or the Lorentz cone, or the ice cream cone
\[
\mathcal{Q}_n := \{  (x_0,x_1,\dots,x_n) \in \mathbb{R}^{n+1} \mid \sqrt{x_1^2 + \dots + x_n^2} \leq x_0  \}
\]
is a proper cone of \(\mathbb{R}^{n+1}\). We will show that it is also self-dual.

\textbf{Proof}. Consider \((y_0,y_1,\dots,y_n) \in \mathcal{Q}_n\), we want to show that
\begin{equation}
x_0 y_0 + x_1 y_1 + \dots + x_n y_n \geq 0, \forall (x_0,x_1,\dots,x_n) \in \mathcal{Q}_n.
\label{eq:dual-cone-condition}
\end{equation}
This is easy to verify because
\[
x_1 y_1 + \dots + x_n y_n \geq - \sqrt{x_1^2 + \dots + x_n^2} \sqrt{y_1^2 + \dots + y_n^2} \geq - x_0 y_0.
\]
Hence we have \(\mathcal{Q}_n \subseteq \mathcal{Q}_n^{*}\).

Conversely, if \eqref{eq:dual-cone-condition} holds, then take
\[
x_1 = -y_1, \dots, x_n = - y_n, \quad x_0 = \sqrt{x_1^2 + \dots + x_n^2},
\]
we have
\[
y_0 \geq \sqrt{y_1^2 + \dots + y_n^2},
\]
hence \(\mathcal{Q}_n^{*} \subseteq \mathcal{Q}_n\). \(\blacksquare\)
\end{example}

Not every proper cone is self-dual.

\begin{exercise}
Consider the following proper cone in \(\mathbb{R}^{2}\)
\[
K = \{ (x_1,x_2) \mid 2x_1 - x_2 \geq 0, 2x_2 - x_1 \geq 0 \}.
\]
Show that it is not self-dual.
\end{exercise}

\section{Convex Optimization}\label{background:convex:optimization}

\begin{definition}[Convex Function]
\protect\hypertarget{def:ConvexFun}{}\label{def:ConvexFun}A function \(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{}\) is a convex function if
\[
f(\lambda x + (1-\lambda) y) \leq \lambda f(x) + (1-\lambda) f(y), \forall \lambda \in [0,1], \forall x,y \in \mathbb{R}^{n}.
\]
\end{definition}

A function \(f\) is convex if and only if its \textbf{epigraph} \(\{ (x,t) \in \mathbb{R}^{n+1} \mid f(x) \leq t \}\) is a convex set.

When a function \(f\) is differentiable, then there are several equivalent characterizations of convexity, in terms of the gradient \(\nabla f(x)\) or the Hessian \(\nabla^2 f(x)\).

\begin{theorem}[Equivalent Characterizations of Convexity]
\protect\hypertarget{thm:CharacterizeConvexity}{}\label{thm:CharacterizeConvexity}

Let \(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{}\) be a twice differentiable function. The following propositions are equivalent.

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\item
  \(f\) is convex, i.e.,
  \[
  f(\lambda x + (1-\lambda) y) \leq \lambda f(x) + (1-\lambda) f(y), \forall \lambda \in [0,1], x,y \in \mathbb{R}^{n}.
  \]
\item
  The first-order convexity condition holds:
  \[
  f(y) \geq f(x) + \langle \nabla f(x),  y - x \rangle, \forall x, y \in \mathbb{R}^{n},
  \]
  i.e., the hyperplane going through \((x,f(x))\) with slope \(\nabla f(x)\) supports the epigraph of \(f\).
\item
  The second-order convexity condition holds:
  \[
  \nabla^2 f(x) \succeq 0, \forall x \in \mathbb{R}^{n},
  \]
  i.e., the Hessian is positive semidefinite everywhere.
\end{enumerate}

\end{theorem}

Let's work on a little exercise.

\begin{exercise}

Which one of the following functions \(f: \mathbb{R}^{n} \rightarrow \mathbb{R}^{}\) is not convex?

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \(\exp(-c^\top x)\), with \(c\) constant
\item
  \(\exp(c^\top x)\), with \(c\) constant
\item
  \(\exp(x^\top x)\)
\item
  \(\exp(-x^\top x)\)
\end{enumerate}

\end{exercise}

\subsection{Minimax Theorem}\label{minimax-theorem}

Given a function \(f: X \times Y \rightarrow \mathbb{R}^{}\), the following inequality always holds
\begin{equation}
\max_{y \in Y} \min_{x \in X} f(x,y) \leq \min_{x \in X} \max_{y \in Y} f(x,y).
\label{eq:weak-minimax}
\end{equation}
If the maximum or minimum is not attained, then \eqref{eq:weak-minimax} holds with \(\max\) / \(\min\) replaced by \(\sup\) and \(\inf\), respectively.

\begin{exercise}
Provide examples of \(f\) such that the inequality in \eqref{eq:weak-minimax} is strict.
\end{exercise}

It is of interest to understand when equality holds in \eqref{eq:weak-minimax}.

\begin{theorem}[Minimax Theorem]
\protect\hypertarget{thm:minimax}{}\label{thm:minimax}Let \(X \subset \mathbb{R}^{n}\) and \(Y \subset \mathbb{R}^{n}\) be compact convex sets, and \(f: X \times Y \rightarrow \mathbb{R}^{}\) be a continuous function that is convex in its first argument and concave in the second. Then
\[
\max_{y \in Y} \min_{x \in X} f(x,y) = \min_{x \in X} \max_{y \in Y} f(x,y).
\]
\end{theorem}

A special case of this theorem, used in game theory to prove the existence of equilibria for zero-sum games, is when \(X\) and \(Y\) are standard unit simplicies and the function \(f(x,y)\) is bilinear. In a research from our group \citep{tang23arxiv-uncertainty}, we used the minimax theorem to convert a minimax problem into a single-level minimization problem.

\subsection{Lagrangian Duality}\label{background:convex:optimization:Lagrangian}

Consider a nonlinear optimization problem
\begin{equation}
\begin{split}
u^\star = \min_{x \in \mathbb{R}^{n}} & \quad f(x) \\
\mathrm{s.t.}& \quad g_i(x) \leq 0, i=1,\dots,m, \\
& \quad h_j(x) = 0, j = 1,\dots,p.
\end{split}
\label{eq:background-nlp}
\end{equation}
Define the \textbf{Lagrangian} associated with the optimization problem \eqref{eq:background-nlp} as
\begin{equation}
\begin{split}
L: \mathbb{R}^{n} \times \mathbb{R}^{m}_{+} \times \mathbb{R}^{p} \quad & \rightarrow \quad \mathbb{R}^{}, \\
(x,\lambda,\mu) \quad & \mapsto \quad f(x) + \sum_{i=1}^m \lambda_i g_i(x) + \sum_{j=1}^p \mu_j h_j(x).
\end{split}
\label{eq:background-Lagrangian}
\end{equation}
The \textbf{Lagrangian dual function} is defined as
\begin{equation}
\phi(\lambda,\mu) := \min_{x \in \mathbb{R}^{n}} L(x,\lambda,\mu).
\label{eq:background-Lagrangian-dual}
\end{equation}
Maximizing this function over the dual variables \((\lambda,\mu)\) yields
\begin{equation}
v^\star := \max_{\lambda \geq 0, \mu \in \mathbb{R}^{p}} \phi(\lambda,\mu)
\label{eq:background-Lagrangian-dual-problem}
\end{equation}
Applying the minimax Theorem \ref{thm:minimax}, we can see that
\[
v^\star = \max_{(\lambda,\mu)} \min_{x} L(x,\lambda,\mu) \leq \min_{x} \max_{(\lambda,\mu)} L(x,\lambda,\mu) = u^\star.
\]
That is to say solving the dual problem \eqref{eq:background-Lagrangian-dual-problem} always provides a lower bound to the primal problem \eqref{eq:background-nlp}.

If the functions \(f,g_i\) are convex and \(h_i\) are affine, the Lagrangian is convex in \(x\) and convex in \((\lambda,\mu)\). To ensure strong duality (i.e., \(u^\star = v^\star\)), compactness or other \textbf{constraint qualifications} are needed. An often used condition is the Slater constraint qualification.

\begin{definition}[Slater Constraint Qualification]
\protect\hypertarget{def:SlaterCQ}{}\label{def:SlaterCQ}There exists a strictly feasible point for \eqref{eq:background-nlp}, i.e., a point \(z \in \mathbb{R}^{n}\) such that \(h_j(z) = 0,j=1,\dots,p\) and \(g_i(z) < 0,i=1,\dots,m\).
\end{definition}

Under these conditions, we have strong duality.

\begin{theorem}[Strong Duality]
\protect\hypertarget{thm:StrongDuality}{}\label{thm:StrongDuality}Consider the optimization \eqref{eq:background-nlp} and assume \(f,g_i\) are convex and \(h_j\) are affine. If Slater's constraint qualification holds, then the optimal value of the primal problem \eqref{eq:background-nlp} is the same as the optimal value of the dual problem \eqref{eq:background-Lagrangian-dual-problem}.
\end{theorem}

\subsection{KKT Optimality Conditions}\label{kkt-optimality-conditions}

Consider the nonlinear optimization problem \eqref{eq:background-nlp}. A pair of primal and dual variables \((x^\star,\lambda^\star,\mu^\star)\) is said to satisfy the Karush-Kuhn-Tucker (KKT) optimality conditions if

\begin{equation}
\begin{split}
\text{primal feasibility}:\ \  & g_i(x^\star) \leq 0,\forall i=1,\dots,m; h_j(x^\star) = 0, \forall j=1,\dots,p \\
\text{dual feasibility}:\ \  & \lambda_i^\star \geq 0, \forall i=1,\dots,m \\
\text{stationarity}:\ \  & \nabla_x L(x^\star,\lambda^\star,\mu^\star) = 0 \\
\text{complementarity}:\ \  & \lambda_i^\star \cdot g_i(x^\star) = 0, \forall i=1,\dots,m.
\end{split}
\label{eq:KKT-conditions}
\end{equation}

Under certain constraint qualifications, the KKT conditions are necessary for local optimality.

\begin{theorem}[Necessary Optimality Conditions]
\protect\hypertarget{thm:KKTNecessary}{}\label{thm:KKTNecessary}Assume any of the following constraint qualifications hold:

\begin{itemize}
\item
  The gradients of the constraints \(\{ \nabla g_i(x^\star) \}_{i=1}^m\), \(\{ \nabla h_j(x^\star) \}_{j=1}^p\) are linearly independent.
\item
  Slater's constraint qualification (cf.~Definition \ref{def:SlaterCQ}).
\item
  All constraints \(g_i(x)\) and \(h_j(x)\) are affine functions.
\end{itemize}

Then, at every local minimum \(x^\star\) of \eqref{eq:background-nlp}, the KKT conditions \eqref{eq:KKT-conditions} hold.
\end{theorem}

On the other hand, for convex optimization problems, the KKT conditions are sufficient for global optimality.

\begin{theorem}[Sufficient Optimality Conditions]
\protect\hypertarget{thm:KKTSufficient}{}\label{thm:KKTSufficient}Assume optimization \eqref{eq:background-nlp} is convex, i.e., \(f,g_i\) are convex and \(h_j\) are affine. Every point \(x^\star\) that satisfies the KKT conditions \eqref{eq:KKT-conditions} is a global minimizer.
\end{theorem}

\section{Linear Optimization}\label{background:linear:optimization}

\subsection{Polyhedra}\label{polyhedra}

In \(\mathbb{R}^{n}\), a \textbf{polyhedron} is a set defined by finitely many linear inequalities, i.e.,
\begin{equation}
P = \{ x \in \mathbb{R}^{n} \mid A x \geq b \},
\label{eq:polyhedron}
\end{equation}
for some matrix \(A \in \mathbb{R}^{m \times n}\) and \(b \in \mathbb{R}^{m}\). In \eqref{eq:polyhedron}, the inequality should be interpreted as \(A x - b \in \mathbb{R}^{m}_{+}\), i.e., every entry of \(Ax\) is no smaller than the corresponding entry of \(b\).

The convex hull of finitely many points in \(\mathbb{R}^{n}\) is called a \textbf{polytope}, where the convex hull of a set \(S\) is defined as
\begin{equation}
\hspace{-10mm} \mathrm{conv}(S) =  \left\{ \sum_{i=1}^k \lambda_i u_i \mid k \in \mathbb{N}_{+}, \sum_{i=1}^k \lambda_i = 1, \lambda_i \geq 0,i=1,\dots,k, u_i \in S, \forall i =1,\dots,k \right\} ,
\label{eq:convex-hull}
\end{equation}
i.e., all possible convex combinations of points in \(S\). Clearly, a polytope is bounded.

The conic hull of finitely many points in \(\mathbb{R}^{n}\) is called a \textbf{polyhedral cone}, where the conic hull of a set \(S\) is defined as
\begin{equation}
\hspace{-10mm} \mathrm{cone}(S) =  \left\{  \sum_{i=1}^k \lambda_i u_i \mid k \in \mathbb{N}_{+}, \lambda_i \geq 0,i=1,\dots,k, u_i \in S, \forall i =1,\dots,k   \right\} .
\label{eq:conic-hull}
\end{equation}
The only difference between \eqref{eq:conic-hull} and \eqref{eq:convex-hull} is the removal of \(\sum_{i} \lambda_i = 1\). Clearly, the origin belongs to the conic hull of any nonempty set, and the conic hull of any nonempty set is unbounded.

The next theorem characterizes a polyhedron.

\begin{theorem}[Polyhedron Decomposition]
\protect\hypertarget{thm:DecomposePolyhedron}{}\label{thm:DecomposePolyhedron}Every polyhedron \(P\) is finitely generated, i.e., it can be written as the Minkowski sum of a polytope and a polyhedral cone:
\[
P = \mathrm{conv}(u_1,\dots,u_r) + \mathrm{cone}(v_1,\dots,v_s),
\]
where the Minkowski sum of two sets is defined as \(X + Y := \{ x+y \mid x \in X, y \in Y \}\).

Further, a bounded polyhedron is a polytope.
\end{theorem}

An extreme point of a polytope is called a \textbf{vertex}. A \(1\)-dimensional face of a polytope is called an \textbf{edge}. A \(d-1\)-dimensional face of a \(d\)-dimensional polytope is called a \textbf{facet}.

\subsection{Linear Program}\label{linear-program}

We will now give a brief review of important results in linear programming (LP). The standard reference for linear programming is \citep{bertsimas97book-lp}. In some sense, the theory of semidefinite programming (SDP) has been developed in order to generalize those of LP to the setup where the decision variable becomes a symmetric matrix and the inequality is interpreted as being positive semidefinite.

A standard form linear program (LP) reads
\begin{equation}
\begin{split}
\min_{x \in \mathbb{R}^{n}} & \quad \langle c, x \rangle  \\
\mathrm{s.t.}& \quad Ax = b \\
& \quad x \geq 0
\end{split}
\label{eq:primal-lp}
\end{equation}
for given \(A \in \mathbb{R}^{m\times n}\), \(b \in \mathbb{R}^{m}\), and \(c \in \mathbb{R}^{n}\). Often the tuple \((A,b,c)\) is called the \emph{problem data} because the LP \eqref{eq:primal-lp} is fully defined once the tuple is given (indeed many LP numerical solvers take the tuple \((A,b,c)\) as input). Clearly, the feasible set of the LP \eqref{eq:primal-lp} is a polyhedron. The LP \eqref{eq:primal-lp} is often referred to as the \textbf{primal} LP. Associated with \eqref{eq:primal-lp} is the following \textbf{dual} LP
\begin{equation}
\begin{split}
\max_{y \in \mathbb{R}^{m}} & \quad \langle b, y \rangle \\
\mathrm{s.t.}& \quad c - A^\top y \geq 0
\end{split}
\label{eq:dual-lp}
\end{equation}
It is worth noting that the dimension of the dual variable \(y\) is exactly the number of constraints in the primal LP.

\textbf{Lagrangian duality}. Let us use the idea of Lagrangian duality introduced in Section \ref{background:convex:optimization:Lagrangian} to verify that \eqref{eq:dual-lp} is indeed the Lagrangian dual problem of \eqref{eq:primal-lp}. The Lagrangian associated with \eqref{eq:primal-lp} is
\begin{equation}
\begin{split}
L(x,\lambda,\mu) & = \langle c, x \rangle + \langle \mu, Ax - b \rangle + \langle \lambda, -x \rangle, \quad \mu \in \mathbb{R}^{m}, \lambda \in \mathbb{R}^{n}_{+}\\
& = \langle c + A^\top\mu - \lambda, x \rangle - \langle \mu, b \rangle, \quad \mu \in \mathbb{R}^{m}, \lambda \in \mathbb{R}^{n}_{+}.
\end{split}
\end{equation}
The Lagrangian dual function is therefore
\[
\phi(\lambda,\mu) = \min_{x} L(x,\lambda,\mu) = \begin{cases}
- \langle \mu, b \rangle & \text{if } c + A^\top\mu - \lambda = 0 \\
- \infty & \text{Otherwise}
\end{cases}, \mu \in \mathbb{R}^{m}, \lambda \in \mathbb{R}^{n}_{+}.
\]
The Lagrangian dual problem seeks to maximize the dual function \(\phi(\lambda,\mu)\), and hence it must set \(c + A^\top\mu - \lambda = 0\) (otherwise it leads to \(-\infty\)). As a result, the dual problem is
\begin{equation}
\begin{split}
\max_{\mu \in \mathbb{R}^{m}} & \quad \langle b, -\mu \rangle \\
\mathrm{s.t.}& \quad c + A^\top\mu = \lambda \geq 0
\end{split}
\label{eq:lp-Lagrangian-dual}
\end{equation}
With a change of variable \(y := -\mu\), we observe that problem \eqref{eq:lp-Lagrangian-dual} is precisely problem \eqref{eq:dual-lp}.

\textbf{Weak duality}. For the pair of primal-dual LPs, it is easy to verify that, for any \(x\) that is feasible for the primal \eqref{eq:primal-lp} and \(y\) that is feasible for the dual \eqref{eq:dual-lp}, we have
\begin{equation}
\langle c, x \rangle - \langle b, y \rangle = \langle c, x \rangle - \langle Ax, y \rangle = \langle c, x \rangle - \langle A^\top y, x \rangle = \langle c - A^\top y, x \rangle \geq 0.
\label{eq:weak-duality-lp}
\end{equation}
Therefore, denoting \(p^\star\) as the optimum of \eqref{eq:primal-lp} and \(d^\star\) as the optimum of \eqref{eq:dual-lp}, we have the weak duality
\[
p^\star \geq d^\star.
\]
Note that such weak duality can also be directly obtained since \eqref{eq:lp-Lagrangian-dual} is the Lagrangian dual of \eqref{eq:primal-lp}.

If \(p^\star = d^\star\), then we say \textbf{strong duality} holds. The LP \eqref{eq:primal-lp} is said to be \textbf{feasible} if its feasible set is nonempty. It is said to be \textbf{unbounded below} if there exists a sequence \(\{ u_i \}_{i=1}^{\infty} \subseteq \mathbb{R}^{n}_{+}\) such that \(\langle c, u_i \rangle \rightarrow -\infty\) and \(A u_i = b\). If the primal \eqref{eq:primal-lp} is infeasible (resp. unbounded below), we set \(p^\star = + \infty\) (resp. \(p^\star = - \infty\)). Similar characteristics are defined for the dual LP \eqref{eq:dual-lp}. In particular, if the dual \eqref{eq:dual-lp} is unbounded, then we set \(d^\star = + \infty\). If the dual is infeasible, then we set \(d^\star = - \infty\).

Strong duality is well understood in linear programming.

\begin{theorem}[LP Strong Duality]
\protect\hypertarget{thm:LPStrongDuality}{}\label{thm:LPStrongDuality}

For the LP primal-dual pair \eqref{eq:primal-lp} and \eqref{eq:dual-lp}, we have

\begin{itemize}
\item
  If one of \eqref{eq:primal-lp} and \eqref{eq:dual-lp} is feasible, then \(p^\star = d^\star\) (i.e., finite, \(+\infty\), or \(-\infty\)).
\item
  If one of \(p^\star\) or \(d^\star\) is finite, then \(p^\star = d^\star\) is finite, and both \eqref{eq:primal-lp} and \eqref{eq:dual-lp} achieve the same optimal value (i.e., they botb have optimizers).
\item
  A primal feasible point \(x^\star\) of \eqref{eq:primal-lp} is a minimizer if and only if there exists a dual feasible point \(y^\star\) such that \(\langle c, x^\star \rangle = \langle b, y^\star \rangle\).
\end{itemize}

\end{theorem}

For example, consider the following primal-dual LP pair
\begin{equation}
\begin{cases}
\min_{x \in \mathbb{R}^{3}_{+}} & x_1 + x_2 + 2 x_3 \\
\mathrm{s.t.}& \begin{bmatrix} -1 & 1 & 1 \\ 1 & 1 & 2 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} = \begin{bmatrix} 0 \\ 1 \end{bmatrix}
\end{cases},
\begin{cases}
\max_{y \in \mathbb{R}^{2}} & y_2 \\
\mathrm{s.t.}& \begin{bmatrix} 1 \\ 1 \\ 2 \end{bmatrix} - \begin{bmatrix} -1 & 1 \\ 1 & 1 \\ 1 & 2 \end{bmatrix} \begin{bmatrix} y_1 \\ y_2 \end{bmatrix} \geq 0
\end{cases}.
\end{equation}
\(x^\star = [1/2,1/2,0]^\top\) is feasible for the primal and attains \(p^\star = 1\). \(y^\star = [0,1]^\top\) is feasible for the dual and attains \(d^\star = 1\). Therefore, both \(x^\star\) and \(y^\star\) are optimizers for the primal and dual, respectively.

\textbf{Complementary slackness}. Strong duality, when combined with \eqref{eq:weak-duality-lp}, implies that
\[
x_i^\star (c - A^\top y^\star)_i = 0, \forall i = 1,\dots,n,
\]
where \((\cdot)_i\) denotes the \(i\)-th entry of a vector. This is known as complementary slackness, which states that whenever a primal optimal solution has a nonzero entry, the corresponding dual inequality must be tight.

An important property of LP is that if the primal problem is feasible and bounded below, then it must have an optimizer that is a \textbf{basic feasible point}, i.e., a feasible point has at most \(m\) nonzero entries. The simplex method \citep{bertsimas97book-lp} for solving LPs searches for optimizers among the basic feasible points.

We also introduce how to detect infeasibility and unboundedness of LPs.

\begin{theorem}[LP Infeasibility and Unboundedness]
\protect\hypertarget{thm:LPInfeasUnbound}{}\label{thm:LPInfeasUnbound}

Infeasibility and Unboundedness of LP can be certified by existence of an improving/decreasing ray for the primal and dual:

\begin{itemize}
\item
  When the primal \eqref{eq:primal-lp} is feasible, it is unbounded below if and only if it has a decreasing ray, i.e., there exists \(u \in \mathbb{R}^{n}\) such that
  \[
  A u = 0, \quad u \geq 0, \quad \langle c, u \rangle < 0.
  \]
\item
  When the dual \eqref{eq:dual-lp} is feasible, it is unbounded above if and only if it has an improving ray, i.e., there exists \(u \in \mathbb{R}^{m}\) such that
  \[
  A^\top u \leq 0, \quad \langle b, u \rangle > 0. 
  \]
\item
  The primal problem \eqref{eq:primal-lp} is infeasible if and only if the dual problem \eqref{eq:dual-lp} has an improving ray, i.e., there exists \(u \in \mathbb{R}^{m}\) such that
  \[
  A^\top u \leq 0, \quad \langle b, u \rangle > 0.
  \]
\item
  The dual problem \eqref{eq:dual-lp} is infeasible if and only if the primal problem \eqref{eq:primal-lp} has a decreasing ray, i.e., there exists \(u \in \mathbb{R}^{n}\) such that
  \[
  A u = 0, \quad u \geq 0, \quad \langle c, u \rangle < 0.
  \]
\end{itemize}

\end{theorem}

It is important to note that both the primal and dual can be infeasible, as in the following example.
\begin{equation}
\begin{cases}
\min_{x \in \mathbb{R}^{2}_{+}} & - x_1 - x_2 \\
\mathrm{s.t.}& \begin{bmatrix} -1 & 1 \\ -1 & 1 \end{bmatrix} x = \begin{bmatrix} 2 \\ 3 \end{bmatrix}
\end{cases},
\begin{cases}
\max_{y \in \mathbb{R}^{2}} & 2 y_1 + 3 y_2 \\
\mathrm{s.t.}& \begin{bmatrix} -1 \\ -1 \end{bmatrix} - \begin{bmatrix} -1 & -1 \\ 1 & 1 \end{bmatrix} y \geq 0
\end{cases}.
\end{equation}

\subsection{Farkas Lemma}\label{farkas-lemma}

A foundational result in linear programming is the Farkas Lemma.

\begin{theorem}[Farkas Lemma]
\protect\hypertarget{thm:FarkasLemma}{}\label{thm:FarkasLemma}For a given \(A \in \mathbb{R}^{m \times n}\) and \(c \in \mathbb{R}^{n}\), if \(\langle c, x \rangle \geq 0\) for all \(x\) satisfying \(Ax \geq 0\), then there exists \(\lambda \in \mathbb{R}^{m}\) such that
\[
c = A^\top\lambda, \quad \lambda \geq 0.
\]
\end{theorem}

As a simple example, take \(A = \mathrm{I}_n\) as the identity matrix, then Farkas Lemma says if \(\langle c, x \rangle \geq 0\) for all \(x \geq 0\), then \(c\) must be that \(c \geq 0\) -- this is exactly the fact that the nonnegative orthant \(\mathbb{R}^{n}_{+}\) is self-dual.

In general, the Farkas Lemma states if the linear function \(\langle c, x \rangle\) is nonnegative on the space \(\{ Ax \geq 0 \}\), then there exists \(\lambda \in \mathbb{R}^{m}_{+}\) such that
\begin{equation}
\langle c, x \rangle = \langle \lambda,  Ax \rangle = \sum_{i=1}^m \lambda_i (a_i^\top x),
\label{eq:farkas-lemma-imply}
\end{equation}
where \(a_i^\top\) is the \(i\)-th row of \(A\). Note that \eqref{eq:farkas-lemma-imply} is a polynomial identity. As we will see later in the course, the idea of sums of squares (SOS), to some extent, is to generalize Farkas Lemma to the case where the function is a polynomial and the set is a basic semialgebraic set (i.e., defined by polynomial equalities and inequalities).

A generalization of Farkas Lemma to inhomogeneous affine functions is stated below.

\begin{theorem}[Inhomogeneous Farkas Lemma]
\protect\hypertarget{thm:InhomogeneousFarkasLemma}{}\label{thm:InhomogeneousFarkasLemma}Suppose the set \(P = \{ x \in \mathbb{R}^{n} \mid A x \geq b \}\) with \(A \in \mathbb{R}^{m \times n}, b \in \mathbb{R}^{m}\) is nonempty. If a linear function \(\langle c, x \rangle - d\) is nonnegative on \(P\), then there exists \(\lambda \in \mathbb{R}^{m}\) and \(\nu \in \mathbb{R}^{}\) such that
\[
\langle c, x \rangle - d = \nu + \langle \lambda, A x - b \rangle, \quad \lambda \geq 0, \nu \geq 0. 
\]
\end{theorem}

A more general result is called the Theorem of Alternatives, which states that a polyhedral set is empty if and only if another polyhedral set is nonempty.

\begin{theorem}[Theorem of Alternatives]
\protect\hypertarget{thm:Alternative}{}\label{thm:Alternative}Given \(A_1 \in \mathbb{R}^{m_1 \times n}, A_2 \in \mathbb{R}^{m_2 \times n}\), \(b_1 \in \mathbb{R}^{m_1}\), and \(b_2 \in \mathbb{R}^{m_2}\), the set
\[
\{ x \in \mathbb{R}^{n} \mid A_1 x > b_1, A_2 x \geq b_2 \}
\]
is empty if and only if the following set
\[
 \left\{ (\lambda_1,\lambda_2) \in \mathbb{R}^{m_1} \times \mathbb{R}^{m_2}\ \middle\vert\ \begin{array}{r} \lambda_1 \geq 0, \lambda_2 \geq 0, \\ b_1^\top\lambda_1 + b_2^\top\lambda_2 \geq 0, \\ A_1^\top\lambda_1 + A_2^\top\lambda_2 = 0, \\ (e + b_1)^\top\lambda_1 + b_2^\top\lambda_2 = 1 \end{array}  \right\} 
\]
is nonempty, with \(e\) being the vector of all ones.
\end{theorem}

\chapter{Semidefinite Optimization}\label{sdp}

\section{Positive Semidefinite Matrices}\label{positive-semidefinite-matrices}

A real matrix \(A = (A_{ij}) \in \mathbb{R}^{n \times n}\) is symmetric if \(A = A^\top\), i.e., \(A_{ij} = A_{ji}\) for all \(i,j\). Let \(\mathbb{S}^{n}\) be the space of all real symmetric matrices.

Any symmetric matrix \(A\) defines a \textbf{quadratic form} \(x^\top A x\). A matrix \(A\) is said to be \textbf{positive semidefinite} (PSD) if and only if its associated quadratic form is nonnegative, i.e.,
\[
x^\top A x \geq 0, \quad \forall x \in \mathbb{R}^{n}.
\]
We use \(\mathbb{S}^{n}_{+}\) to denote the set of \(n\times n\) PSD matrices. We also write \(A \succeq 0\) to denote positive semidefiniteness when the dimension is clear.

There are several equivalent characterizations of positive semidefiniteness.

\begin{lemma}[Positive Semidefinite Matrices]
\protect\hypertarget{lem:PositiveSemidefinite}{}\label{lem:PositiveSemidefinite}

Let \(A \in \mathbb{S}^{n}\) be a symmetric matrix, the following statements are equivalent:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A is positive semidefinite.
\item
  \(x^\top A x \geq 0, \forall x \in \mathbb{R}^{n}\).
\item
  All eigenvalues of \(A\) are nonnegative.
\item
  All \(2^n-1\) principal minors of \(A\) are nonnegative.
\item
  The coefficients of \(p_A(\lambda)\) weakly alternate in sign, i.e., \((-1)^{n-k} p_k \geq 0\) for \(k=0,\dots,n-1\), where \(p_A(\lambda) = \det (A - \lambda \mathrm{I}_n)\) is the characteristics polynomial of \(A\).
\item
  There exists a factorization \(A = BB^\top\), where \(B \in \mathbb{R}^{n \times r}\) with \(r\) the rank of \(A\).
\end{enumerate}

\end{lemma}

Among the equivalent characterizations of PSD matrices, (5) is less well-known, but it can be very useful when we want to convert a PSD constraint into multiple scalar constraints. For example, consider the following subset of \(\mathbb{R}^{3}\):
\[
 \left\{ z \in \mathbb{R}^{3} \ \middle\vert\ X(z) = \begin{bmatrix} 1 & z_1 & z_2 \\ z_1 & z_2 & z_3 \\ z_2 & z_3 & 5 z_2 - 4  \end{bmatrix} \succeq 0  \right\} .
\]
We can first form the characteristic polynomial of \(X(z)\) --whose coefficients will be functions of \(z\)-- and then invoking (5) to obtain a finite number scalar inequality constraints. We can then pass these scalar constraints to Mathematica and plot the set as in the following figure \citep{yang22mp-inexact}.

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{images/spectrahedron-stride} 

}

\caption{An example spectrahedron.}\label{fig:SpectrahedronStride}
\end{figure}

Similarly, we say a matrix \(A \in \mathbb{S}^{n}\) is \textbf{positive definite} (PD) is its associated quadratic form is always positive, i.e.,
\[
x^\top A x > 0, \quad \forall x \in \mathbb{R}^{n}.
\]
We use \(\mathbb{S}^{n}_{++}\) to denote the set of \(n \times n\) PD matrices, and also write \(A \succ 0\) when the dimension is clear.

Below is set of equivalent characterizations of positive definite matrices.

\begin{lemma}[Positive Definite Matrices]
\protect\hypertarget{lem:PositiveDefinite}{}\label{lem:PositiveDefinite}

Let \(A \in \mathbb{S}^{n}\) be a symmetric matrix, the following statements are equivalent:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A is positive definite.
\item
  \(x^\top A x > 0, \forall x \in \mathbb{R}^{n}\).
\item
  All eigenvalues of \(A\) are strictly positive.
\item
  All \(n\) leading principal minors of \(A\) are strictly positive.
\item
  The coefficients of \(p_A(\lambda)\) strictly alternate in sign, i.e., \((-1)^{n-k} p_k > 0\) for \(k=0,\dots,n-1\), where \(p_A(\lambda) = \det (A - \lambda \mathrm{I}_n)\) is the characteristics polynomial of \(A\).
\item
  There exists a factorization \(A = BB^\top\) with \(B\) square and nonsingular (full-rank).
\end{enumerate}

\end{lemma}

\textbf{Schur Complements}. A useful technique to check whether a matrix is positive (semi-)definite is to use the Schur Complements. Consider a block-partitioned matrix
\begin{equation}
M = \begin{bmatrix} A & B \\ B^\top& C \end{bmatrix},
\label{eq:block-mat-M}
\end{equation}
where \(A\) and \(C\) are symmetric matrices.
If \(A\) is invertible, then the Schur complement of \(A\) is
\[
M / A = C - B^\top A^{-1}B.
\]
Similarly, if \(C\) is invertible, then the Schur complement of \(C\) is
\[
M / C = A - B C^{-1}B^\top.
\]

We have the following result relating the Schur Complements to positive (semi-)definiteness.

\begin{proposition}[Schur Complements and PSD]
\protect\hypertarget{prp:SchurPSD}{}\label{prp:SchurPSD}

Consider the block-partitioned matrix \(M\) in \eqref{eq:block-mat-M},

\begin{itemize}
\item
  \(M\) is positive definite if and only if both \(A\) and \(M/A\) are positive definite:
  \[
  M \succ 0 \Leftrightarrow A \succ 0, M/A = C - B^\top A^{-1}B \succ 0.
  \]
\item
  \(M\) is positive definite if and only if both \(C\) and \(M/C\) are positive definite:
  \[
  M \succ 0 \Leftrightarrow C \succ 0, M/C = A - B C^{-1}B^\top\succ 0.
  \]
\item
  If \(A\) is positive definite, then \(M\) is positive semidefinite if and only if \(M/A\) is positive semidefinite:
  \[
  \text{If } A \succ 0, \text{ then } M \succeq 0 \Leftrightarrow M / A \succeq 0.
  \]
\item
  If \(C\) is positive definite, then \(M\) is positive semidefinite if and only if \(M/C\) is positive semidefinite:
  \[
  \text{If } C \succ 0, \text{ then } M \succeq 0 \Leftrightarrow M / C \succeq 0.
  \]
\end{itemize}

\end{proposition}

\subsection{Geometric Properties}\label{geometric-properties}

The set \(\mathbb{S}^{n}_{+}\) is a proper cone (cf.~Definition \ref{def:ProperCone}). Its interior is \(\mathbb{S}^{n}_{++}\). Under the inner product
\[
\langle A, B \rangle = \mathrm{tr}(AB^\top), \quad A,B \in \mathbb{R}^{n \times n},
\]
the PSD cone \(\mathbb{S}^{n}_{+}\) is self-dual.

Next we want to characterize the face of the PSD cone. We first present the following lemma which will turn out to be useful afterwards.

\begin{lemma}[Range of PSD Matrices]
\protect\hypertarget{lem:PSDRange}{}\label{lem:PSDRange}Let \(A,B \in \mathbb{S}^{n}_{+}\), then we have
\begin{equation}
\mathrm{Range}(A) \subseteq \mathrm{Range}(A + B),
\label{eq:Range-PSD}
\end{equation}
where \(\mathrm{Range}(A)\) denotes the span of the column vectors of \(A\).
\end{lemma}

\begin{proof}
For any symmetric matrix \(S\), we know
\[
\mathrm{Range}(S) = \mathrm{ker}(S)^{\perp}.
\]
Therefore, to prove \eqref{eq:Range-PSD}, it is equivalent to prove
\[
\mathrm{ker}(A) \supseteq \mathrm{ker}(A + B).
\]
Pick any \(u \in \mathrm{ker}(A + B)\), we have
\[
(A + B) u = 0 \Rightarrow u ^\top(A + B) u = 0 \Rightarrow u^\top A u + u^\top B u = 0 \Rightarrow u^\top A u = u^\top B u = 0,
\]
where the last derivation is due to \(A, B \succeq 0\). Now that we have \(u^\top A u = 0\), we claim that \(Au = 0\) must hold, i.e., \(u \in \mathrm{ker}(A)\). To see this, write
\[
u = \sum_{i=1}^n a_i v_i,
\]
where \(a_i = \langle u, v_i \rangle\) and \(v_i,i=1,\dots,n\) are the eigenvectors of \(A\) corresponding to eigenvalues \(\lambda_i,i=1,\dots,n\). Then we have
\[
Au = \sum_{i=1}^n a_i A v_i = \sum_{i=1}^n a_i \lambda_i v_i,
\]
and
\[
u^\top A u = \sum_{i=1}^n \lambda_i a_i^2 = 0.
\]
Since \(\lambda_i \geq 0, a_i^2 \geq 0\), we have
\[
\lambda_i a_i^2 = 0, \forall i = 1,\dots,n.
\]
This indicates that if \(\lambda_i > 0\), then \(a_i = 0\). Therefore, \(a_i\) can only be nonzero for \(\lambda_i = 0\), which leads to
\[
Au = \sum_{i=1}^n a_i \lambda_i v_i = 0.
\]
Therefore, \(u \in \mathrm{ker}(A)\), proving the result.
\end{proof}

Lemma \ref{lem:PSDRange} indicates that if \(A \succeq B\), then \(\mathrm{Range}(B) \subseteq \mathrm{Range}(A)\). What about the reverse?

\begin{lemma}[Extend Line Segment]
\protect\hypertarget{lem:Extension}{}\label{lem:Extension}Let \(A,B \in \mathbb{S}^{n}_{+}\), if \(\mathrm{Range}(B) \subseteq \mathrm{Range}(A)\), then there must exist \(C \in \mathbb{S}^{n}_{+}\) such that
\[
A \in (B,C),
\]
i.e., the line segment from \(B\) to \(A\) can be extended past \(A\) within \(\mathbb{S}^{n}_{+}\).
\end{lemma}

\begin{proof}
Since \(\mathrm{Range}(B) \subseteq \mathrm{Range}(A)\), we have
\[
\mathrm{ker}(A) \subseteq \mathrm{ker}(B).
\]
Now consider extending the line segment past \(A\) to
\[
C_{\alpha} = A + \alpha(A - B) = (1+\alpha) A - \alpha B,
\]
with some \(\alpha > 0\). We want to show that there exists \(\alpha > 0\) such that \(C_{\alpha} \succeq 0\).

Pick \(u \in \mathbb{R}^{n}\), then either \(u \in \mathrm{ker}(B)\) or \(u \not\in \mathrm{ker}(B)\). If \(u \in \mathrm{ker}(B)\), then
\[
u^\top C_{\alpha} u = (1+\alpha) u^\top A u - \alpha u^\top B u = (1+\alpha) u^\top A u \geq 0.
\]
If \(u \not\in \mathrm{ker}(B)\), then due to \(\mathrm{ker}(A) \subseteq \mathrm{ker}(B)\), we have \(u \not\in \mathrm{ker}(A)\) as well. As a result, we have
\begin{equation}
u^\top C_{\alpha} u = (1+\alpha) u^\top A u - \alpha u^\top B u = (1+\alpha) u^\top A u \lparen{ 1- \frac{\alpha}{1+\alpha} \frac{u^\top B u}{u^\top A u} }.
\label{eq:prove-extension-1}
\end{equation}
Since
\[
\max_{u: u \not\in \mathrm{ker}(A)} \frac{u^\top B u}{u^\top A u} \leq \frac{\lambda_{\max}(B)}{\lambda_{\min,>0}(A)},
\]
where \(\lambda_{\min,>0}(A)\) denotes the minimum positive eigenvalue of \(A\), we can always choose \(\alpha\) sufficiently small to make \eqref{eq:prove-extension-1} nonnegative. Therefore, there exists \(\alpha > 0\) such that \(C_{\alpha} \succeq 0\).
\end{proof}

In fact, from Lemma \ref{lem:PSDRange} we can induce a corollary.

\begin{corollary}[Range of PSD Matrices]
\protect\hypertarget{cor:PSDRange}{}\label{cor:PSDRange}Let \(A, B \in \mathbb{S}^{n}_{+}\), then we have
\[
\mathrm{Range}(A + B) = \mathrm{Range}(A) + \mathrm{Range}(B),
\]
with ``\(+\)'' the Minkowski sum.
\end{corollary}

\begin{exercise}
Let \(A,B \in \mathbb{S}^{n}_{+}\), show that \(\langle A, B \rangle = 0\) if and only if \(\mathrm{Range}(A) \perp \mathrm{Range}(B)\).
\end{exercise}

For a subset \(T \subseteq \mathbb{S}^{n}_{+}\), we use \(\mathrm{face}(T,\mathbb{S}^{n}_{+})\) to denote the smallest face of \(\mathbb{S}^{n}_{+}\) that contains \(T\). We first characterize the smallest face that contains a given PSD matrix, i.e., \(\mathrm{face}(A,\mathbb{S}^{n}_{+})\) for \(A\succeq 0\). Clearly, if \(A\) is PD, then \(\mathrm{face}(A, \mathbb{S}^{n}_{+}) = \mathbb{S}^{n}_{+}\) is the entire cone. If \(A\) is PSD but singular with rank \(r < n\), then \(A\) has the following spectral decomposition
\[
Q^\top A Q = \begin{bmatrix} \Lambda & 0 \\ 0 & 0 \end{bmatrix},
\]
where \(\Lambda \in \mathbb{S}^{r}_{++}\) is a diagonal matrix with the \(r\) nonzero eigenvalues of \(A\), and \(Q \in \mathrm{O}(n)\) is orthogonal. If
\[
A = \lambda B + (1-\lambda)C, \quad B,C \in \mathbb{S}^{n}_{+},\lambda \in (0,1),
\]
then multiplying both sides by \(Q^\top\) and \(Q\) we have
\[
\begin{bmatrix} \Lambda & 0 \\ 0 & 0 \end{bmatrix} = Q^\top A Q = \lambda Q^\top B Q + (1-\lambda) Q^\top C Q.
\]
Therefore, it must hold that
\[
Q^\top B Q = \begin{bmatrix} B_1 & 0 \\ 0 & 0 \end{bmatrix}, \quad Q^\top C Q = \begin{bmatrix} C_1 & 0 \\ 0 & 0 \end{bmatrix}, \quad B_1 \in \mathbb{S}^{r}_{+}, C_1 \in \mathbb{S}^{r}_{+},
\]
which is equivalent to
\[
B = Q \begin{bmatrix} B_1 & 0 \\ 0 & 0 \end{bmatrix} Q^\top, C = Q \begin{bmatrix} C_1 & 0 \\ 0 & 0 \end{bmatrix} Q^\top, \quad B_1 \in \mathbb{S}^{r}_{+}, C_1 \in \mathbb{S}^{r}_{+}.
\]
We conclude that \(\mathrm{face}(A,\mathbb{S}^{n}_{+})\) must contain the set
\begin{equation}
G:=  \left\{ Q \begin{bmatrix} X & 0 \\ 0 & 0 \end{bmatrix} Q^\top\ \middle\vert\ X \in \mathbb{S}^{r}_{+} \right\} .
\label{eq:face-of-A-psd}
\end{equation}

\begin{exercise}
Show that \(G\) in \eqref{eq:face-of-A-psd} is a face of \(\mathbb{S}^{n}_{+}\), i.e., (i) \(G\) is convex; (ii) \(u \in (x,y), u \in G, x,y \in \mathbb{S}^{n}_{+} \Rightarrow x,y \in G\).
\end{exercise}

As a result, we have \(\mathrm{face}(A,\mathbb{S}^{n}_{+}) = G\).

More general faces of the PSD cone \(\mathbb{S}^{n}_{+}\) can be characterized as follows (Theorem 3.7.1 in \citep{wolkowicz12book-sdp}).

\begin{theorem}[Faces of the PSD Cone]
\protect\hypertarget{thm:FacePSD}{}\label{thm:FacePSD}A set \(F \subseteq \mathbb{S}^{n}_{+}\) is a face if and only if there exists a subspace \(L \subseteq \mathbb{R}^{n}\) such that
\[
F = \{ X \in \mathbb{S}^{n}_{+} \mid \mathrm{Range}(X) \subseteq L \}.
\]
\end{theorem}

\begin{proof}
It is easy to prove the ``\textbf{If}'' direction using Lemma \ref{lem:PSDRange}.

First we show \(F\) is convex. Pick \(A,B \in F\). We have \(\mathrm{Range}(A) \subseteq L\) and \(\mathrm{Range}(B) \subseteq L\). Let \(v_1,\dots,v_m\) be a set of basis spanning \(L\). We have that, for any \(u \in \mathbb{R}^{n}\),
\begin{equation}
\begin{split}
A u \in L & \Rightarrow Au = \sum_{i=1}^m a_i v_i, \\
B u \in L & \Rightarrow Bu = \sum_{i=1}^m b_i v_i. 
\end{split}
\end{equation}
So for any \(\lambda \in [0,1]\), we have
\[
(\lambda A + (1-\lambda) B) u = \lambda Au + (1-\lambda) Bu = \sum_{i=1}^m (\lambda a_i + (1-\lambda) b_i ) v_i \in L,
\]
implying \(\lambda A + (1-\lambda) B \in F\) for any \(\lambda \in [0,1]\).

Now we show that:
\[
X \in (A,B), X \in F, A,B \in \mathbb{S}^{n}_{+} \Rightarrow A, B \in F.
\]
From \(X = \lambda A + (1-\lambda) B\) for some \(\lambda \in (0,1)\), and invoking Lemma \ref{lem:PSDRange}, we have
\begin{equation}
\begin{split}
\mathrm{Range}(X) & = \mathrm{Range}(\lambda A + (1-\lambda) B) \supseteq \mathrm{Range}(\lambda A) = \mathrm{Range}(A) \\
\mathrm{Range}(X) & = \mathrm{Range}(\lambda A + (1-\lambda) B) \supseteq \mathrm{Range}((1-\lambda) B) = \mathrm{Range}(B).
\end{split}
\end{equation}
Since \(\mathrm{Range}(X) \subseteq L\) due to \(X \in F\), we have
\[
\mathrm{Range}(A) \subseteq L, \quad \mathrm{Range}(B) \subseteq L,
\]
leading to \(A,B \in F\).

The proof for the ``\textbf{Only If}'' direction can be found in Theorem 3.7.1 of \citep{wolkowicz12book-sdp}.
\end{proof}

\section{Semidefinite Programming}\label{semidefinite-programming}

\subsection{Spectrahedra}\label{spectrahedra}

Recall the definition of a polyhedron in \eqref{eq:polyhedron}, i.e., a vector \(x\) constrained by finitely many linear inequalities. The feasible set of a Linear Program is a polyhedron.

Similarly, we define a \textbf{spectrahedron} as a set defined by finitely many \textbf{linear matrix inequalities} (LMIs). Spectrahedra are the feasible sets of Semidefinite Programs (SDPs).

A linear matrix inequality has the form
\[
A_0 + \sum_{i=1}^m A_i x_i \succeq 0,
\]
where \(A_i \in \mathbb{S}^{n},i=0,\dots,m\) are given symmetric matrices. Correspondingly, a spectrahedron is defined by finitely many LMIs.

\begin{definition}[Spectrahedron]
\protect\hypertarget{def:Spectrahedron}{}\label{def:Spectrahedron}A set \(S \subseteq \mathbb{R}^{m}\) is a spectrahedron if it has the form
\[
S =  \left\{ x \in \mathbb{R}^{m} \ \middle\vert\ A_0 + \sum_{i=1}^m x_i A_i \succeq 0 \right\} ,
\]
for given symmetric matrices \(A_0,A_1,\dots,A_m \in \mathbb{S}^{n}\).
\end{definition}

Note that there is no less of generality in defining a spectrahedron using a single LMI. For example, in the case of a set defined by two LMIs:
\[
S =  \left\{ x \in \mathbb{R}^{m} \ \middle\vert\ A_0 + \sum_{i=1}^m x_i A_i \succeq 0, B_0 + \sum_{i=1}^m x_i B_i \succeq 0  \right\} , A_i \in \mathbb{S}^{n}, B_i \in \mathbb{S}^{d},
\]
we can compress the two LMIs into a single LMI by putting \(A_i\) and \(B_i\) along the diagonal:
\[
S =  \left\{ x \in \mathbb{R}^{m} \ \middle\vert\ \begin{bmatrix} A_0 & \\ & B_0 \end{bmatrix} + \sum_{i=1}^m x_i \begin{bmatrix} A_i & \\ & B_i \end{bmatrix} \succeq 0  \right\} .
\]

Leveraging (5) of Lemma \ref{lem:PositiveSemidefinite}, we know that a PSD constraint is equivalent to weakly alternating signs of the characteristic polynomial of the given matrix. Therefore, a spectrahedron is defined by finitely many polynomial inequalities, i.e., a spectrahedron is a (convex) \textbf{basic semialgebraic set}, as seen in the following example \citep{blekherman12book-semidefinite}.

\begin{example}[Elliptic Curve]
\protect\hypertarget{exm:EllipticCurve}{}\label{exm:EllipticCurve}

Consider the spectrahedron in \(\mathbb{R}^{2}\) defined by
\[
 \left\{ (x,y) \in \mathbb{R}^{2} \ \middle\vert\ A(x,y) = \begin{bmatrix} x+1 & 0 & y \\ 0 & 2 & -x-1 \\ y & -x-1 & 2 \end{bmatrix} \succeq 0  \right\} .
\]
To obtain scalar inequalities defining the set, let
\[
p_A(\lambda) = \det (\lambda I - A(x,y)) = \lambda^3 + p_2 \lambda^2 + p_1 \lambda + p_0
\]
be the characteristic polynomial of \(A(x,y)\). \(A(x,y) \succeq 0\) is then equivalent to the coefficients weakly alternating in sign:
\begin{equation}
\begin{split}
p_2 & = -(x+5) \leq 0, \\
p_1 & = -x^2 + 2x - y^2 + 7 \geq 0, \\
p_0 & = -(3+ x -x^3 -3x^2 - 2y^2) \leq 0.
\end{split}
\end{equation}
We can use the following Matlab script to plot the set shown in Fig. \ref{fig:EllipticCurve}. (The code is also available at \href{https://github.com/ComputationalRobotics/Semidefinite-Examples}{here}.) As we can see, the spectrahedron is convex, but it is not a polyhedron.

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{x} \OperatorTok{=} \OperatorTok{{-}}\FloatTok{2}\OperatorTok{:}\FloatTok{0.01}\OperatorTok{:}\FloatTok{2}\OperatorTok{;} 
\VariableTok{y} \OperatorTok{=} \OperatorTok{{-}}\FloatTok{2}\OperatorTok{:}\FloatTok{0.01}\OperatorTok{:}\FloatTok{2}\OperatorTok{;} 
\NormalTok{[}\VariableTok{X}\OperatorTok{,}\VariableTok{Y}\NormalTok{] }\OperatorTok{=} \VariableTok{meshgrid}\NormalTok{(}\VariableTok{x}\OperatorTok{,}\VariableTok{y}\NormalTok{)}\OperatorTok{;}

\VariableTok{ineq} \OperatorTok{=}\NormalTok{ (}\OperatorTok{{-}}\VariableTok{X} \OperatorTok{{-}} \FloatTok{5} \OperatorTok{\textless{}=} \FloatTok{0}\NormalTok{) }\OperatorTok{\&} \OperatorTok{...}
\NormalTok{    (}\OperatorTok{{-}}\VariableTok{X}\OperatorTok{.\^{}}\FloatTok{2} \OperatorTok{+} \FloatTok{2}\OperatorTok{*}\VariableTok{X} \OperatorTok{{-}} \VariableTok{Y}\OperatorTok{.\^{}}\FloatTok{2} \OperatorTok{+} \FloatTok{7} \OperatorTok{\textgreater{}=}\FloatTok{0}\NormalTok{) }\OperatorTok{\&} \OperatorTok{...}
\NormalTok{    (}\FloatTok{3} \OperatorTok{+} \VariableTok{X} \OperatorTok{{-}} \VariableTok{X}\OperatorTok{.\^{}}\FloatTok{3} \OperatorTok{{-}} \FloatTok{3}\OperatorTok{*}\VariableTok{X}\OperatorTok{.\^{}}\FloatTok{2} \OperatorTok{{-}} \FloatTok{2}\OperatorTok{*}\VariableTok{Y}\OperatorTok{.\^{}}\FloatTok{2} \OperatorTok{\textgreater{}=} \FloatTok{0}\NormalTok{)}\OperatorTok{;}

\VariableTok{h} \OperatorTok{=} \VariableTok{pcolor}\NormalTok{(}\VariableTok{X}\OperatorTok{,}\VariableTok{Y}\OperatorTok{,}\VariableTok{double}\NormalTok{(}\VariableTok{ineq}\NormalTok{)) }\OperatorTok{;}
\VariableTok{h}\NormalTok{.}\VariableTok{EdgeColor} \OperatorTok{=} \SpecialStringTok{\textquotesingle{}none\textquotesingle{}} \OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/elliptic_curve} 

}

\caption{Elliptic Curve.}\label{fig:EllipticCurve}
\end{figure}

\end{example}

We can use the same technique to visualize the elliptope, a spectrahedron that we will see again later when we study the MAXCUT problem.

\begin{example}[Elliptope]
\protect\hypertarget{exm:Elliptope}{}\label{exm:Elliptope}

Consider the 3D elliptope defined by
\[
 \left\{ (x,y,z) \in \mathbb{R}^{3} \ \middle\vert\ A(x,y,z) = \begin{bmatrix} 1 & x & y \\ x & 1 & z \\ y & z & 1 \end{bmatrix} \succeq 0 \right\} .
\]
The characteristic polynomial of \(A(x,y,z)\) is
\[
p_A(\lambda) = \lambda^3 - 3 \lambda^2 + (-x^2 - y^2 - z^2 + 3) \lambda + x^2 - 2 xyz + y^2 + z^2 -1. 
\]
The coefficients need to weakly alternative in sign, we have the inequalities
\begin{equation}
\begin{split}
-x^2 - y^2 - z^2 + 3 & \geq 0 \\
x^2 - 2 xyz + y^2 + z^2 -1 & \leq 0
\end{split}
\end{equation}

Using the Matlab script \href{https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/elliptope.m}{here}, we generate the following plot.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{images/elliptope} 

}

\caption{Elliptope.}\label{fig:Elliptope}
\end{figure}

\end{example}

Another example is provided in Fig. \ref{fig:SpectrahedronStride}.

\subsection{Formulation and Duality}\label{formulation-and-duality}

Semidefinite programs (SDPs) are linear optimization problems over spectrahedra. A standard SDP in \textbf{primal} form is written as
\begin{equation}
\boxed{
\begin{split}
p^\star = \min_{X \in \mathbb{S}^{n}} & \quad \langle C, X \rangle \\
\mathrm{s.t.}& \quad \mathcal{A}(X) = b, \\
& \quad X \succeq 0
\end{split}
}
\label{eq:SDP-P}
\end{equation}
where \(C \in \mathbb{S}^{n}\), \(b \in \mathbb{R}^{m}\), and the linear map \(\mathcal{A}: \mathbb{S}^{n} \rightarrow \mathbb{R}^{m}\) is defined as
\[
\mathcal{A}(X) := \begin{bmatrix} \langle A_1, X \rangle \\
\vdots \\ \langle A_i, X \rangle \\ \langle A_m, X \rangle \end{bmatrix}.
\]
Recall that \(\langle C, X \rangle = \mathrm{tr}(CX)\). The feasible set of \eqref{eq:SDP-P} is the intersection of the PSD cone (\(\mathbb{S}^{n}_{+}\)) and the affine subspace defined by \(\mathcal{A}(X) = b\).

Closely related to the primal SDP \eqref{eq:SDP-P} is the \textbf{dual} problem
\begin{equation}
\boxed{
\begin{split}
d^\star = \max_{y \in \mathbb{R}^{m}} & \quad \langle b, y \rangle \\
\mathrm{s.t.}& \quad C - \mathcal{A}^* (y) \succeq 0
\end{split}
}
\label{eq:SDP-D}
\end{equation}
where \(\mathcal{A}^{*}: \mathbb{R}^{m} \rightarrow \mathbb{S}^{n}\) is the \textbf{adjoint} map defined as
\[
\mathcal{A}^*(y) := \sum_{i=1}^m y_i A_i.
\]
Observe how the primal-dual SDP pair \eqref{eq:SDP-P}-\eqref{eq:SDP-D} parallels the primal-dual LP pair \eqref{eq:primal-lp}-\eqref{eq:dual-lp}.

\textbf{Weak duality}. We have a similar weak duality between the primal and dual. Pick any \(X\) that is feasible for the primal \eqref{eq:SDP-P} and \(y\) that is feasible for the dual \eqref{eq:SDP-D}, we have
\[
\boxed{\langle C, X \rangle - \langle b, y \rangle = \langle C, X \rangle - \langle \mathcal{A}(X), y \rangle = \langle C - \mathcal{A}^* (y), X \rangle \geq 0,}
\]
where the last inequality holds because both \(C - \mathcal{A}^*(y)\) and \(X\) are positive semidefinite. As a result, we have the weak duality
\[
d^\star \leq p^\star.
\]

Similar to the LP case, we will denote \(p^\star = +\infty\) if the primal is infeasible, \(p^\star = - \infty\) if the primal is unbounded below. We will denote \(d^\star = +\infty\) if the dual is unbounded above, and \(d^\star = -\infty\) if the dual is infeasible. We say the primal (or the dual) is \textbf{solvable} if it admits optimizers. We denote \(p^\star - d^\star\) as the \textbf{duality gap}.

Recall Theorem \ref{thm:LPStrongDuality} states that in LP, if at least one of the primal and dual is feasible, then strong duality holds (i.e., \(p^\star = d^\star = \{\pm \infty, \text{finite} \}\)). Unfortunately, this does not carry over to SDPs. Let us provide several examples.

\begin{example}[Failure of SDP Strong Duality]
\protect\hypertarget{exm:FailureSDPDuality}{}\label{exm:FailureSDPDuality}The first example, from \citep{ramana97mp-exact}, shows that even if both primal and dual are feasible, there could exist a nonzero duality gap. Consider the following SDP pair for some \(\alpha \geq 0\)
\[
\begin{cases}
\min_{X \in \mathbb{S}^{3}} & \alpha X_{11} \\
\mathrm{s.t.}& X_{22} = 0 \\
& X_{11} + 2 X_{23} = 1 \\
& \begin{bmatrix} X_{11} & X_{12} & X_{13} \\
* & X_{22} & X_{23} \\
* & * & X_{33} \end{bmatrix} \succeq 0 
\end{cases}, 
\begin{cases}
\max_{y \in \mathbb{R}^{2}} & y_2 \\
\mathrm{s.t.}& \begin{bmatrix} \alpha & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix} \succeq \begin{bmatrix} y_2 & 0 & 0 \\ 0 & y_1 & y_2 \\ 0 & y_2 & 0 \end{bmatrix}
\end{cases}
\]
To examine the primal feasible set, let us pick the bottom-right \(2\times 2\) submatrix of \(X\). The determinant of this submatrix needs to be nonnegative (due to (4) of Lemma \ref{lem:PositiveSemidefinite}):
\[
X_{22} X_{33} - X_{23}^2 \geq 0.
\]
Because \(X_{22} = 0\), we have \(X_{23} = 0\) and hence \(X_{11} = 1\). Therefore, \(p^\star = \alpha\) is attained.

To examine the dual feasible set, pick the bottom-right \(2 \times 2\) submatrix of
\[
\begin{bmatrix} \alpha - y_2 & 0 & 0 \\ 0 & - y_1 & -y_2 \\ 0 & -y_2 & 0 \end{bmatrix} \succeq 0,
\]
we have \(y_2 = 0\). As a result, \(d^\star = 0\), and strong duality fails.

The second example, from \citep{todd01an-semidefinite}, shows that the duality gap can even be infinite. Consider the primal-dual SDP
\[
\begin{cases}
\min_{X \in \mathbb{S}^{2}} & 0 \\
\mathrm{s.t.}& X_{11} = 0 \\
& X_{12} = 1 \\
& \begin{bmatrix} X_{11} & X_{12} \\ * & X_{22} \end{bmatrix} \succeq 0
\end{cases},
\begin{cases}
\max_{y \in \mathbb{R}^{2}} & 2 y_2 \\
\mathrm{s.t.}& \begin{bmatrix} - y_1 & - y_2 \\ - y_2 & 0 \end{bmatrix} \succeq 0 
\end{cases}
\]
Clearly, the primal is infeasible because
\[
\begin{bmatrix} 0 & 1 \\ 1 & X_{22} \end{bmatrix}
\]
can never be PSD. So \(p^\star = + \infty\). The dual problem, however, is feasible. From the PSD constraint we have \(y_2 = 0\) and \(d^\star = 0\). Therefore, the duality gap is infinite.

The third example, from \citep{todd01an-semidefinite}, shows that even when the duality gap is zero, the primal or dual problem may not admit optimizers. Consider the primal-dual SDP
\[
\begin{cases}
\min_{X \in \mathbb{S}^{2}} & 2 X_{12} \\
\mathrm{s.t.}& - X_{11} = -1 \\
& - X_{22} = 0 \\
& \begin{bmatrix} X_{11} & X_{12} \\ * & X_{22} \end{bmatrix} \succeq 0 
\end{cases},
\begin{cases}
\max_{y \in \mathbb{R}^{2}} & - y_1 \\
\mathrm{s.t.}& \begin{bmatrix} y_1 & 1 \\ 1 & y_2 \end{bmatrix} \succeq 0
\end{cases}
\]
To examine the primal feasible set, we have
\[
\begin{bmatrix} 1 & X_{12} \\ X_{12} & 0 \end{bmatrix} \succeq 0
\]
implies \(X_{12} = 0\). Hence the primal feasible set only has one point and \(p^\star = 0\). The dual feasible set reads
\[
y_1 y_2 \geq 1,\quad  y_1 \geq 0, \quad y_2 \geq 0,
\]
and we want to minimize \(y_1\). Clearly, \(d^\star = 0\) but it is not attainable. Therefore, strong duality holds but the dual problem is not solvable.

A Matlab script that passes these three examples to SDP solvers can be found \href{https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/failure_strong_duality.m}{here}.
\end{example}

The examples above are somewhat ``pathological'' and they show that SDPs in general can be more complicated that LPs. It turns out, with the addition of \textbf{Slater's condition}, i.e., \textbf{strict feasibility} of the primal and dual, we can recover nice results parallel to those of LP.

\begin{theorem}[SDP Strong Duality]
\protect\hypertarget{thm:SDPStrongDuality}{}\label{thm:SDPStrongDuality}Assume both the primal SDP \eqref{eq:SDP-P} and the dual SDP \eqref{eq:SDP-D} are \emph{strictly feasible}, i.e., there exists \(X \succ 0\) such that \(\mathcal{A}(X)=b\) for the primal and there exists \(y \in \mathbb{R}^{m}\) such that \(C - \mathcal{A}^* (y) \succ 0\) for the dual, then strong duality holds, i.e., both problems are solvable and admit optimizers, and \(p^\star = d^\star\) equals to some finite number.

Further, a pair of primal-dual feasible points \((X,y)\) is optimal if and only if
\[
\langle C, X \rangle = \langle b, y \rangle \Leftrightarrow \langle C - \mathcal{A}^* (y), X \rangle = 0 \Leftrightarrow (C - \mathcal{A}^* (y)) X = 0.
\]
\end{theorem}

One can relax the requirement of both primal and dual being strictly feasible to only one of them being strictly feasible, and similar results would hold. Precisely, if the primal is bounded below and strictly feasible, then \(p^\star = d^\star\) and the dual is solvable. If the dual is bounded above and strictly feasible, then \(p^\star = d^\star\) and the primal is solvable \citep{nie23book-moment}.

\begin{example}[SDP Strong Duality]
\protect\hypertarget{exm:SuccessSDPDuality}{}\label{exm:SuccessSDPDuality}Consider the following primal-dual SDP pair
\[
\begin{cases}
\min_{X \in \mathbb{S}^{2}} & 2 X_{11} + 2 X_{12} \\
\mathrm{s.t.}& X_{11} + X_{22} = 1 \\
& \begin{bmatrix} X_{11} & X_{12} \\ * & X_{22} \end{bmatrix} \succeq 0 
\end{cases},
\begin{cases}
\max_{y \in \mathbb{R}^{}} & y \\
\mathrm{s.t.}& \begin{bmatrix} 2 - y & 1 \\ 1 & - y \end{bmatrix} \succeq 0
\end{cases}
\]
Choose
\[
X = \begin{bmatrix} 0.5 & 0 \\ 0 & 0.5 \end{bmatrix} \succ 0
\]
we see the primal is strictly feasible.
Choose \(y = -1\), we have
\[
\begin{bmatrix} 3 & 1 \\ 1 & 1 \end{bmatrix} \succ 0
\]
and the dual is strictly feasible. Therefore, strong duality holds.

In this case, pick the pair of primal-dual feasible points
\[
X^\star = \begin{bmatrix} \frac{2 - \sqrt{2}}{4} & - \frac{1}{2 \sqrt{2}} \\ - \frac{1}{2 \sqrt{2}} & \frac{2 + \sqrt{2}}{4} \end{bmatrix}, \quad y^\star = 1 - \sqrt{2},
\]
we have
\[
\langle C, X^\star \rangle = 1-\sqrt{2} = \langle b, y^\star \rangle,
\]
and both \(X^\star\) and \(y^\star\) are optimal.
\end{example}

\subsection{Geometric Properties}\label{geometric-properties-1}

\section{Software for Conic Optimization}\label{software-for-conic-optimization}

Linear optimization over the nonnegative orthant (\(\mathbb{R}^{n}_{+}\)), the second-order cone (\(\mathcal{Q}_{n}\)), and the positive semidefinite cone (\(\mathbb{S}^{n}_{+}\)) forms the foundation of modern convex optimization, commonly referred to as conic optimization. These three types of cones are self-dual, and there exist efficient algorithms to solve the convex optimization problems. Popular solvers include SDPT3, SeDuMi, MOSEK, and SDPNAL+.

In this section, we introduce how we should ``talk to'' the numerical solvers for conic optimization, i.e., how should we pass a mathematically written conic optimization to a numerical solver. Note that in many cases, this ``transcription'' can be done by programming packages such as CVX, CVXPY, YALMIP etc., but I think it is important to understand the standard interface of numerical solvers because (i) it reinforces our understanding of the mathematical basics, (ii) it gets us closer to designing custom numerical solvers for specific problems, (iii) if you are a heavy convex optimization user you will realize that many of the programming packages are not ``efficient'' in transcribing the original optimization problem (but they are indeed very general). I have had cases where solving the conic optimization takes a few minutes but transcribing the problem to the solver takes half an hour.

We will use the SeDuMi format as an example. Consider the following general linear convex optimization problem
\begin{equation}
\begin{split}
\max_{y \in \mathbb{R}^{m}} & \quad b^\top y \\
\mathrm{s.t.}& \quad Fy = g \\
& \quad f \geq Gy \\
& \quad h_i^\top y + \tau_i \geq \Vert H_i y + p_i \Vert_2, i=1,\dots,r \\
& \quad B_{j,0} + \sum_{k=1}^m y_k B_{j,k} \succeq 0, j=1,\dots,s,
\end{split}
\label{eq:general-convex-sedumi}
\end{equation}
for given matrices and vectors
\[
F \in \mathbb{R}^{\ell_1 \times m},G \in \mathbb{R}^{\ell_2 \times m},H_i \in \mathbb{R}^{l_i \times m}, B_{j,k} \in \mathbb{S}^{n_j}, h_i \in \mathbb{R}^{m}, p_i \in \mathbb{R}^{l_i}, \tau_i \in \mathbb{R}^{}, g \in \mathbb{R}^{\ell_1},f \in \mathbb{R}^{\ell_2}.
\]
Define the linear function
\[
\phi(y):= \left(Fy, Gy, \begin{bmatrix} - h_1^\top y \\ - H_1 y \end{bmatrix}, \dots, \begin{bmatrix} - h_r^\top y \\ - H_r y \end{bmatrix}, - \sum_{k=1}^m y_k B_{1,k}, \dots,- \sum_{k=1}^m y_k B_{s,k} \right),
\]
which is a linear map from \(\mathbb{R}^{m}\) to the vector space of Cartesian products
\[
V:= \mathbb{R}^{\ell_1} \times \mathbb{R}^{\ell_2} \times \mathbb{R}^{l_1+1} \times \dots \times \mathbb{R}^{l_r + 1} \times \mathbb{S}^{n_1}\times \dots \times \mathbb{S}^{n_s}.
\]
A vector \(X \in V\) can be written as a tuple
\[
X = (x_1,x_2,\mathrm{x}_1,\dots,\mathrm{x}_r,X_1,\dots,X_s).
\]
Given another vector \(Y \in V\)
\[
X = (y_1,y_2,\mathrm{y}_1,\dots,\mathrm{y}_r,Y_1,\dots,Y_s),
\]
the inner product between \(X\) and \(Y\) is defined as
\[
\langle X, Y \rangle = \langle x_1, y_2 \rangle + \langle x_2, y_2 \rangle + \sum_{i=1}^r \langle \mathrm{x}_i, \mathrm{y}_i \rangle + \sum_{j=1}^s \langle X_j, Y_j \rangle.
\]

Let \(\mathcal{K}\) be the Cartesian product of the free cone, the nonnegative orthant, the second-order cone, and the PSD cone
\[
\mathcal{K}:= \mathbb{R}^{\ell_1} \times \mathbb{R}^{\ell_2}_{+} \times \mathcal{Q}_{l_1} \times \dots \times \mathcal{Q}_{l_r} \times \mathbb{S}^{n_1}_{+} \times \dots \times \mathbb{S}^{n_s}_{+}.
\]
Its dual cone is
\[
\mathcal{K}^* = \{0\}^{\ell_1} \times \times \mathbb{R}^{\ell_2}_{+} \times \mathcal{Q}_{l_1} \times \dots \times \mathcal{Q}_{l_r} \times \mathbb{S}^{n_1}_{+} \times \dots \times \mathbb{S}^{n_s}_{+}.
\]
Note that all the cones there are self-dual except the free cone whose dual is the zero point. Then denote
\[
C := \left( g,f,\begin{bmatrix} \tau_1 \\ p_1 \end{bmatrix},\dots,\begin{bmatrix} \tau_r \\ p_r \end{bmatrix},B_{1,0},\dots,B_{s,0} \right) \in V,
\]
we have that the original optimization \eqref{eq:general-convex-sedumi} is simply the following dual conic problem
\begin{equation}
\max_{y \in \mathbb{R}^{m}} \{ b^\top y \mid C - \phi(y) \in \mathcal{K}^* \}.
\label{eq:dual-conic}
\end{equation}
The linear map \(\phi(y)\) can be written as
\[
\phi(y) = y_1 A_1 + \dots, y_m A_m
\]
for vectors \(A_1,\dots,A_m\) in the space \(V\). Therefore, the primal problem to \eqref{eq:dual-conic} is
\begin{equation}
\min_{X \in V} \{ \langle C, X \rangle \mid \langle A_i, X \rangle=b_i,i=1,\dots,m,X \in \mathcal{K} \}.
\label{eq:primal-conic}
\end{equation}

Let us practice an example from \citep{nie23book-moment}.

\begin{example}[SeDuMi Example]
\protect\hypertarget{exm:SeDuMiExample}{}\label{exm:SeDuMiExample}Consider the following optimization problem as an instance of \eqref{eq:general-convex-sedumi}:
\begin{equation}
\begin{split}
\max_{y \in \mathbb{R}^{3}} & \quad y_3 - y_1 \\
\mathrm{s.t.}& \quad y_1 + y_2 + y_3 = 3\\
& \quad -1 \geq -y_1 - y_2 \\
& \quad -1 \geq -y_2 - y_3 \\
& \quad y_1 + y_3 \geq \sqrt{(y_1-1)^2 + y_2^2 + (y_3 -1)^2} \\
& \quad \begin{bmatrix} 1 & y_1 & y_2 \\ y_1 & 2 & y_3 \\ y_2 & y_3 & 3 \end{bmatrix} \succeq 0
\end{split}
\label{eq:sedumi-example}
\end{equation}
Clearly we have \(b = (-1,0,1)\). The linear map \(\phi(y)\) is
\[
\phi(y) = \left( y_1+y_2+y_3,\begin{bmatrix} -y_1 - y_2 \\ - y_2 - y_3 \end{bmatrix}, \begin{bmatrix} - y_1 - y_3 \\ -y_1 \\ -y_2 \\ -y_3 \end{bmatrix}, \begin{bmatrix} 0 & -y_1 & -y_2 \\ -y_1 & 0 & -y_3 \\ -y_2 & -y_3 & 0 \end{bmatrix} \right).
\]
The vector space \(V=\mathbb{R}^{} \times \mathbb{R}^{2} \times \mathbb{R}^{4} \times \mathbb{S}^{3}\), and the cone \(\mathcal{K}\) is
\[
\mathcal{K}= \mathbb{R}^{} \times \mathbb{R}^{2}_{+} \times \mathcal{Q}_3 \times \mathbb{S}^{3}_{+}.
\]
The vectors \(A_1,A_2,A_3\) are
\begin{equation}
\begin{split}
A_1 &= \left( 1,\begin{bmatrix}-1\\0\end{bmatrix}, \begin{bmatrix}-1\\-1\\0\\0\end{bmatrix},\begin{bmatrix}0&-1&0\\-1&0&0\\0&0&0\end{bmatrix} \right)\\
A_2 &= \left( 1,\begin{bmatrix}-1\\-1\end{bmatrix}, \begin{bmatrix}0\\0\\-1\\0\end{bmatrix},\begin{bmatrix}0&0&-1\\0&0&0\\-1&0&0\end{bmatrix} \right)\\
A_3 &= \left( 1,\begin{bmatrix}0\\-1\end{bmatrix}, \begin{bmatrix}-1\\0\\0\\-1\end{bmatrix},\begin{bmatrix}0&0&0\\0&0&-1\\0&-1&0\end{bmatrix} \right).
\end{split}
\end{equation}
The vector \(C\) is
\[
C = \left( 3,\begin{bmatrix}-1\\-1\end{bmatrix}, \begin{bmatrix}0\\-1\\0\\-1\end{bmatrix},\begin{bmatrix}1&0&0\\0&2&0\\0&0&3\end{bmatrix} \right).
\]

To input this problem to SeDuMi, we only need to provide the data \((A,b,C)\) together with the description of the cones \(\mathcal{K}\).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\% describe dimensions of the cones}
\VariableTok{K}\NormalTok{.}\VariableTok{f} \OperatorTok{=} \FloatTok{1}\OperatorTok{;} \CommentTok{\% free cone}
\VariableTok{K}\NormalTok{.}\VariableTok{l} \OperatorTok{=} \FloatTok{2}\OperatorTok{;} \CommentTok{\% nonnegative orthant}
\VariableTok{K}\NormalTok{.}\VariableTok{q} \OperatorTok{=} \FloatTok{4}\OperatorTok{;} \CommentTok{\% second order cone}
\VariableTok{K}\NormalTok{.}\VariableTok{s} \OperatorTok{=} \FloatTok{3}\OperatorTok{;} \CommentTok{\% psd cone}

\CommentTok{\% provide A,b,c}
\VariableTok{c} \OperatorTok{=}\NormalTok{ [}\FloatTok{3}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{2}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{3}\NormalTok{]}\OperatorTok{;}
\VariableTok{b} \OperatorTok{=}\NormalTok{ [}\OperatorTok{{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{1}\NormalTok{]}\OperatorTok{;}
\VariableTok{A} \OperatorTok{=}\NormalTok{ [}
    \FloatTok{1}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{;}
    \FloatTok{1}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{;}
    \FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,}\FloatTok{0}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}\OperatorTok{,{-}}\FloatTok{1}\OperatorTok{,}\FloatTok{0}
\NormalTok{    ]}\OperatorTok{;}

\CommentTok{\% solve using sedumi}
\NormalTok{[}\VariableTok{xopt}\OperatorTok{,}\VariableTok{yopt}\OperatorTok{,}\VariableTok{info}\NormalTok{] }\OperatorTok{=} \VariableTok{sedumi}\NormalTok{(}\VariableTok{A}\OperatorTok{,}\VariableTok{b}\OperatorTok{,}\VariableTok{c}\OperatorTok{,}\VariableTok{K}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Note that in providing \(A\), we vectorize each \(A_i\) and place it along the \(i\)-th row of the matrix \(A\).
The above Matlab script gives us the optimal solution
\[
y^\star = (0,1,2).
\]
To run the \href{https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/sedumi_example.m}{code}, make sure you download \href{https://github.com/sqlp/sedumi}{SeDuMi} and add that to your Matlab path.
\end{example}

\section{Interior Point Algorithm}\label{interior-point-algorithm}

A nice property of semidefinite optimization is that it can be solved in polynomial time. The algorithm of choice for solving SDPs is called an \textbf{interior point method} (IPM), which is also what popular SDP solvers like SeDuMI, MOSEK, and SDPT3 implement under the hood.

Although it can be difficult to implement an SDP solver as efficient and robust as MOSEK (as it requires many engineering wisdom), it is surprisingly simple to sketch out the basic algorithmic framework, as it is based on \href{https://en.wikipedia.org/wiki/Newton\%27s_method\#:~:text=14\%20External\%20links-,Description,the\%20method\%20can\%20be\%20iterated.}{Newton's method for solving a system of nonlinear equations}. Before I introduce you the basic algorithm, let me review two useful preliminaries.

Newton's Method

Given a function \(f: \mathbb{R}^{} \rightarrow \mathbb{R}^{}\) that is continuously differentiable, Newton's method is designed to find a root of \(f(x) = 0\). Given an initial iterate \(x^{(0)}\), Newton's method works as follows
\[
x^{(k+1)} = x^{(k)} - \frac{f(x^{(k)})}{f'(x^{(k)})},
\]
where \(f'(x^{(k)})\) denotes the derivative of \(f\) at the current iterate \(x^{(k)}\). This simple algorithm is indeed (in my opinion) the most important foundation of modern numerical optimization \citep{nocedal99book-numerical}. Under mild conditions, Newton's method has at least quadratic convergence rate, that is to say, if \(|x^{(k)} - x^\star| = \epsilon\), then \(|x^{(k+1)} - x^\star| = O(\epsilon^2)\). Of course, there exist pathological cases where even linear convergence is not guaranteed (e.g., when \(f'(x^\star) = 0\)).

Newton's method can be generalized to find a point at which multiple functions vanish simultaneously. Given a function \(F: \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}\) that is continuously differentiable, and an initial iterate \(x^{(0)}\), Newton's method reads
\begin{equation}
x^{(k+1)} = x^{(k)} - J_F(x^{(k)})^{-1}F(x^{(k)}),
\label{eq:newton-method-vector}
\end{equation}
where \(J_F(\cdot)\) denotes the Jacobian of \(F\). Iteration \eqref{eq:newton-method-vector} is equivalent to
\begin{equation}
\begin{split}
J_F(x^{(k)}) \Delta x^{(k)} & = - F(x^{(k)}) \\
x^{(k+1)} & = x^{(k)} + \Delta x^{(k)}
\end{split}
\label{eq:newton-method-vector-1}
\end{equation}
i.e., one first solves a linear system of equations to find an update direction \(\Delta x^{(k)}\), and then take a step along the direction.

As we will see, IPMs for solving SDPs can be interpreted as applying Newton's method to the perturbed KKT optimality conditions.

We introduce another useful preliminary about the symmetric Kronecker product.

Symmetric Vectorization and Kronecker Product

Consider a linear operator on \(\mathbb{R}^{n \times n}\):
\begin{equation}
\begin{split}
\mathbb{R}^{n \times n} & \rightarrow \mathbb{R}^{n \times n} \\
K & \mapsto N K M^\top
\end{split}
\label{eq:linear-opt-Rn}
\end{equation}
where \(N,M \in \mathbb{R}^{n \times n}\) are given square matrices. This linear map is equivalent to
\begin{equation}
\begin{split}
\mathbb{R}^{n^2} & \rightarrow \mathbb{R}^{n^2} \\
\mathrm{vec}(K) & \mapsto (M \otimes N) \mathrm{vec}(K)
\end{split}
\label{eq:linear-opt-Rn-kron}
\end{equation}
where \(\otimes\) denotes the usual kronecker product.

Symmetric vectorization and kronecker product is to generalize the above linear map on \(\mathbb{R}^{n \times n}\) to \(\mathbb{S}^{n}\).

Consider a linear operator on \(\mathbb{S}^{n}\):
\begin{equation}
\begin{split}
\mathbb{S}^{n} & \rightarrow \mathbb{S}^{n} \\
K & \mapsto \frac{1}{2} \left( N K M^\top+ M K N^\top\right)
\end{split}
\label{eq:linear-opt-Sn}
\end{equation}
where \(N,M\in\mathbb{R}^{n\times n}\) are given square matrices. This linear map is equivalent to
\begin{equation}
\begin{split}
\mathbb{R}^{n^{\Delta}} & \rightarrow \mathbb{R}^{n^{\Delta}} \\
\mathrm{svec}(K) & \mapsto (M \otimes_{\mathrm{s}}N) \mathrm{svec}(K)
\end{split}
\label{eq:linear-opt-Sn-skron}
\end{equation}
where
\[
n^{\Delta} = \frac{n(n+1)}{2}
\]
is the \(n\)-th triangle number, \(\mathrm{svec}(K)\) denotes the symmetric vectorization of \(K\) defined as
\[
\mathrm{svec}(K) = \begin{bmatrix}
K_{11} \\
\sqrt{2} K_{12} \\
\vdots \\
\sqrt{2} K_{1n} \\
K_{22} \\
\vdots \\
\sqrt{2} K_{2n} \\
\vdots \\
K_{nn}
\end{bmatrix},
\]
and \(M \otimes_{\mathrm{s}}N\) denotes the symmetric kronecker product. Note that we have
\[
\langle A, B \rangle = \langle \mathrm{svec}(A), \mathrm{svec}(B) \rangle, \quad \forall A,B \in \mathbb{S}^{n},
\]
and
\[
M \otimes_{\mathrm{s}}N = N \otimes_{\mathrm{s}}M.
\]
To compute the symmetric kronecker product, see \citep{schacke04mthesis-kronecker}. The \(\otimes_{\mathrm{s}}\) function is readily implemented in software packages such as SDPT3.

The following property of the symmetric kronecker product is useful for us later.

\begin{lemma}[Spectrum of Symmetric Kronecker Product]
\protect\hypertarget{lem:SkronEigLemma}{}\label{lem:SkronEigLemma}Let \(M,N \in \mathbb{S}^{n}\) be two symmetric matrices that commute, i.e., \(MN = NM\), and \(\alpha_1,\dots,\alpha_n\) and \(\beta_1,\dots,\beta_n\) be their eigenvalues with \(v_1,\dots,v_n\) a common basis of orthonormal eigenvectors. The \(n^\Delta\) eigenvalues of \(M \otimes_{\mathrm{s}}N\) are given by
\[
\frac{1}{2}(\alpha_i \beta_j + \beta_i \alpha_j), \quad 1 \leq i \leq j \leq n,
\]
with the corresponding set of orthonormal eigenvectors
\[
\begin{cases}
\mathrm{svec}(v_i v_i^\top) & \text{if } i = j \\
\frac{1}{\sqrt{2}} \mathrm{svec}(v_i v_j^\top+ v_j v_i^\top) & \text{if } i < j
\end{cases}.
\]
\end{lemma}

It is easy to see that, if \(M,N\) are two PSD matrices that commute, then \(M \otimes_{\mathrm{s}}N\) is also PSD.

For more properties of symmetric vectorization and Kronecker product, see \citep{schacke04mthesis-kronecker}.

Now we are ready to sketch the interior-point algorithm.

\subsection{The Central Path}\label{the-central-path}

Assuming strict feasibility, strong duality holds between the SDP primal \eqref{eq:SDP-P} and dual \eqref{eq:SDP-D}, then \((X,y,Z)\) is primal-dual optimal if and only if they satisfy the following KKT optimality conditions
\begin{equation}
\begin{split}
\mathcal{A}(X) = b, \quad X \succeq 0 \\
C - \mathcal{A}^*(y) - Z = 0, \quad Z \succeq 0 \\
\langle X, Z \rangle = 0 \Leftrightarrow XZ = 0
\end{split}
\label{eq:SDP-KKT}
\end{equation}
The first idea in IPM is to relax the last condition in \eqref{eq:SDP-KKT}, i.e., zero duality gap, to a small positive gap, which leads to the notion of a central path.

\begin{definition}[Central Path]
\protect\hypertarget{def:CentralPath}{}\label{def:CentralPath}A point \((X^\mu,y^\mu,Z^\mu)\) is said to lie on the central path if there exists \(\mu > 0\) such that
\begin{equation}
\begin{split}
\mathcal{A}(X^\mu) = b, \quad X^\mu \succeq 0 \\
C - \mathcal{A}^*(y^\mu) - Z^\mu = 0, \quad Z^\mu \succeq 0 \\
X^\mu Z^\mu = \mu \mathrm{I}
\end{split},
\label{eq:SDP-central-path}
\end{equation}
that is, \((X^\mu,y^\mu,Z^\mu)\) is primal and dual feasible, but attain a nonzero duality gap:
\[
\langle C, X^\mu \rangle - \langle b, y^\mu \rangle = \langle C, X^\mu \rangle - \langle \mathcal{A}(X^\mu), y^\mu \rangle = \langle C - \mathcal{A}^*(y^\mu), X^\mu \rangle = \langle X^\mu, Z^\mu \rangle = n\mu.
\]
\end{definition}

The central path exists and is unique.

\begin{theorem}[Central Path]
\protect\hypertarget{thm:UniqueCentralPath}{}\label{thm:UniqueCentralPath}Assume the SDP pair \eqref{eq:SDP-P} and \eqref{eq:SDP-D} are strictly feasible. For any \(\mu > 0\), \((X^\mu,y^\mu,Z^\mu)\) satisfying \eqref{eq:SDP-central-path} exists and is unique. Moreover,
\[
(X,y,Z) = \lim_{\mu \rightarrow 0} (X^\mu, y^\mu, Z^\mu)
\]
exists and solves \eqref{eq:SDP-P} and \eqref{eq:SDP-D}.
\end{theorem}

Theorem \ref{thm:UniqueCentralPath} states that the limit of the central path leads to a solution of the SDP. Therefore, the basic concept of IPM is to follow the central path and converge to the optimal solution.

\subsection{The AHO Newton Direction}\label{the-aho-newton-direction}

We will focus on the central path equation \eqref{eq:SDP-central-path} and for simplicity of notation, we will rename \((X^\mu,y^\mu,Z^\mu)\) as \((X,y,Z)\). Discarding the positive semidefiniteness condition for now, we can view \eqref{eq:SDP-central-path} as finding a root to the following function
\begin{equation}
F(X,y,Z) = \begin{pmatrix}
\mathcal{A}^*(y) + Z - C \\
\mathcal{A}(X) - b \\
X Z - \mu \mathrm{I}
\end{pmatrix} = 0.
\label{eq:central-path-F-1}
\end{equation}
However, there is an issue with \(F\) defined as above. The input of the function \((X,y,Z)\) lives in \(\mathbb{S}^{n} \times \mathbb{R}^{m} \times \mathbb{S}^{n}\), but the output lives in \(\mathbb{S}^{n} \times \mathbb{R}^{m} \times \mathbb{R}^{n \times n}\) because \(XZ\) is not guaranteed to be symmetric (two symmetric matrices may not commute). Therefore, Newton's method cannot be directly applied.

An easy way to fix this issue is to treat the input and output of \(F\) as both \(\mathbb{R}^{n \times n} \times \mathbb{R}^{m} \times \mathbb{R}^{n \times n}\). This could work, however, leads to nonsymmetric Newton iterates.

\citep{alizadeh98siopt-primal} proposed a better idea -- to equivalently rewrite \eqref{eq:central-path-F-1} as
\begin{equation}
F(X,y,Z) = \begin{pmatrix}
\mathcal{A}^*(y) + Z - C \\
\mathcal{A}(X) - b \\
\frac{1}{2}(X Z + Z X) - \mu \mathrm{I}
\end{pmatrix} = 0.
\label{eq:central-path-F-2}
\end{equation}

The next proposition states that \eqref{eq:central-path-F-2} and \eqref{eq:central-path-F-1} are indeed equivalent.

\begin{proposition}[Symmetrized Central Path]
\protect\hypertarget{prp:SymmetricCentralPath}{}\label{prp:SymmetricCentralPath}If \(X,Z \succeq 0\), then
\[
XZ = \mu \mathrm{I}\Leftrightarrow XZ + ZX = 2 \mu \mathrm{I}.
\]
\end{proposition}

\begin{proof}
The \(\Rightarrow\) direction is obvious. To show the ``\Leftarrow'' direction, write \(X = Q \Lambda Q^\top\) with \(QQ^\top= \mathrm{I}\).
\end{proof}

Now that the input and output domains of \(F\) in \eqref{eq:central-path-F-2} are both \(\mathbb{S}^{n} \times \mathbb{R}^{m} \times \mathbb{S}^{n}\), we can apply Newton's method to solving the system of equations. For ease of implementation, let us denote
\[
x = \mathrm{svec}(X), \quad z = \mathrm{svec}(Z), \quad c = \mathrm{svec}(C), 
\]
\[
A^\top= \begin{bmatrix}
\mathrm{svec}(A_1) & \mathrm{svec}(A_2) & \cdots & \mathrm{svec}(A_m)
\end{bmatrix}
\]
and rewrite \eqref{eq:central-path-F-2} as
\begin{equation}
F(x,y,z) = \begin{pmatrix}
A^\top y + z - c \\
A x - b \\
\frac{1}{2}\mathrm{svec}(XZ + ZX) - \mathrm{svec}(\mu \mathrm{I})
\end{pmatrix} = 0.
\label{eq:central-path-F-3}
\end{equation}
The Jacobian of \(F\) reads
\begin{equation}
J_F = \begin{bmatrix}
0 & A^\top& \mathrm{I}\\
A & 0 & 0 \\
P & 0 & Q
\end{bmatrix}
\label{eq:aho-Jacobian}
\end{equation}
where
\[
P = Z \otimes_{\mathrm{s}}\mathrm{I}, \quad Q = X \otimes_{\mathrm{s}}\mathrm{I},
\]
due to the symmetric kronecker product introduced before
\[
\frac{1}{2}\mathrm{svec}(XZ + ZX) = (Z \otimes_{\mathrm{s}}\mathrm{I}) x = (X \otimes_{\mathrm{s}}\mathrm{I}) z.
\]
Let
\[
r_d = c - A^\top y - z, \quad r_p = b - Ax, \quad r_c = \mathrm{svec}(\mu \mathrm{I}) - \frac{1}{2}\mathrm{svec}(XZ + ZX),
\]
be the dual, primal, and complementarity residuals, applying Newton's method to \eqref{eq:central-path-F-3} gives us the Newton direction as the solution to the following linear system
\begin{equation}
\begin{bmatrix}
0 & A^\top& \mathrm{I}\\
A & 0 & 0 \\
P & 0 & Q 
\end{bmatrix} 
\begin{bmatrix} \Delta x \\ \Delta y \\ \Delta z \end{bmatrix} = \begin{bmatrix} r_d \\ r_p \\ r_c \end{bmatrix}.
\label{eq:aho-newton-direction}
\end{equation}
One can directly form the block matrix in \eqref{eq:aho-newton-direction} and solve the linear system. However, leveraging the sparsity of the linear system, we can do better.

We can first use the third equation to eliminate \(\Delta z\):
\begin{equation}
\Delta z = Q^{-1}(r_c - P \Delta x).
\label{eq:aho-eliminate-z}
\end{equation}
Then we can use the first equation to eliminate \(\Delta x\):
\begin{equation}
\Delta x = - P^{-1}Q r_d + P^{-1}r_c + P^{-1}Q A^\top\Delta y.
\label{eq:aho-eliminate-x}
\end{equation}
Then we are left with a single equation of \(\Delta y\):
\begin{equation}
\underbrace{ A P^{-1}Q A^\top}_{M} \Delta y = r_p + A P^{-1}(Q r_d - r_c),
\label{eq:aho-schur-system}
\end{equation}
which is called the \textbf{Schur system}.

\subsection{Basic Algorithm}\label{basic-algorithm}

With the AHO Newton direction worked out above, we can formulate the basic primal-dual path following interior point algorithm.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Choose \(X,Z\) strictly feasible for \eqref{eq:SDP-P} and \eqref{eq:SDP-D}, \(0 \leq \sigma < 1\), define
  \[
  \mu = \sigma \frac{\langle X, Z \rangle}{n}
  \]
\item
  Solve the Newton direction from \eqref{eq:aho-schur-system}, \eqref{eq:aho-eliminate-x}, and \eqref{eq:aho-eliminate-z}
\item
  Step along the Newton direction
  \[
  x \leftarrow x + \alpha \Delta x, \quad y \leftarrow y + \beta \Delta y, \quad z \leftarrow z + \beta \Delta z,
  \]
  where the step sizes \(\alpha, \beta\) are chosen as
  \[
  \alpha = \min (1, \tau \hat{\alpha}), \quad \beta = \min (1, \tau \hat{\beta})
  \]
  with \(\tau \in (0,1)\) and \(\hat{\alpha}, \hat{\beta}\) computed by
  \begin{equation}
  \hat{\alpha} = \sup \{ \bar{\alpha} \mid x + \bar{\alpha} \Delta x \succeq 0  \}, \quad \hat{\beta} = \sup \{ \bar{\beta} \mid z + \bar{\beta} \Delta z \succeq 0  \}.
  \label{eq:ipm-step-size}
  \end{equation}
\end{enumerate}

To compute the maximum step sizes \(\hat{\alpha}\) and \(\hat{\beta}\) in \eqref{eq:ipm-step-size}, let
\[
X = \mathrm{smat}(x), \quad \Delta X = \mathrm{smat}(\Delta x)
\]
be the reconstructed matrices from the corresponding symmetric vectorizations. We can first perform a Cholesky factorization of \(X\)
\[
X = LL^\top.
\]
Then we perform a \href{https://en.wikipedia.org/wiki/Matrix_similarity}{matrix similarity transformation}
\[
X + \bar{\alpha} \Delta X \mapsto L^{-1}(X + \bar{\alpha} \Delta X) L^{-\top} = \mathrm{I}+ \bar{\alpha} L^{-1}\Delta X L^{-\top},
\]
which does not change the eigenvalues of \(X + \bar{\alpha} \Delta X\). Therefore, the maximum step size \(\hat{\alpha}\) is
\[
\hat{\alpha}^{-1}= \lambda_{\max}(- L^{-1}\Delta X L^{-\top}),
\]
assuming \(\Delta X\) is not PSD.

\subsection{Nondegeneracy}\label{nondegeneracy}

Since the algorithm above is an application of Newton's method to the system of equations \eqref{eq:central-path-F-3}, the key to understand its asymptotic behavior is to analyze the Jacobian \eqref{eq:aho-Jacobian} at the optimal solution. If the Jacobian at the optimal solution is nonsingular, then one can show that the algorithm above has asymptotic quadratic convergence rate.

\citep{alizadeh98siopt-primal} provided a sufficient condition for the Jacobian to be nonsingular, which is called nondegeneracy.

\begin{definition}[Nondegeneracy]
\protect\hypertarget{def:Nondegeneracy}{}\label{def:Nondegeneracy}

Let \((X,y,Z)\) be a solution to the SDP pair \eqref{eq:SDP-P} and \eqref{eq:SDP-D} and satisfies the KKT optimality conditions \eqref{eq:SDP-KKT}. In this case, \(X\) and \(Z\) can be simultaneously diagonalized
\[
X = Q \mathrm{Diag}(\lambda_1,\dots,\lambda_n) Q^\top, \quad Z = Q \mathrm{Diag}(\omega_1,\dots,\omega_n)Q^\top
\]
by some orthogonal matrix \(Q\). We assume
\[
\lambda_1, \geq \dots \geq \lambda_n, \quad \omega_1 \leq \dots \omega_n.
\]
Due to \(XZ = 0\), we have
\[
\lambda_i \omega_i = 0,\quad i=1,\dots,n.
\]

Let \(X\) have rank \(r\) with positive eigenvalues \(\lambda_1,\dots,\lambda_r\), and partition \(Q = [Q_1, Q_2]\) where the colums of \(Q_1\) are eigenvectors corresponding to \(\lambda_1,\dots,\lambda_r\). We say \((X,y,Z)\) satisfies the strict complementarity and primal and dual nondegeneracy conditions if the following hold:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{(Strict Complementarity)} \(\mathrm{rank}(Z) = n - r\).
\item
  \textbf{(Primal Nondegeneracy)} The matrices
  \begin{equation}
  \begin{bmatrix} Q_1^\top A_k Q_1 & Q_1^\top A_k Q_2 \\
  Q_2^\top A_k Q_1 & 0 \end{bmatrix}, \quad k=1,\dots,m
  \label{eq:primal-nondegeneracy}
  \end{equation}
  are linearly independent in \(\mathbb{S}^{n}\).
\item
  \textbf{(Dual Nondegeneracy)} The matrices
  \begin{equation}
  Q_1^\top A_k Q_1, \quad k=1,\dots,m
  \label{eq:dual-nondegeneracy}
  \end{equation}
  span the space \(\mathbb{S}^{r}\).
\end{enumerate}

\end{definition}

When strict complementarity holds, \textbf{primal nondegeneracy implies the dual optimal solution is unique}, and \textbf{dual nondegeneracy implies the primal optimal solution is unique}.

Strict complementarity and primal-dual nondegeneracy also immediately imply, recalling \(r^{\Delta} = r(r+1)/2\),
\begin{equation}
r^{\Delta} \leq m \leq r^{\Delta} + r (n - r),
\label{eq:sc-pn-dn-m}
\end{equation}
where \(r^\Delta \leq m\) is due to \eqref{eq:dual-nondegeneracy} and \(m \leq r^{\Delta} + r (n - r)\) is due to \eqref{eq:primal-nondegeneracy}.

From \eqref{eq:sc-pn-dn-m}, we can understand that when \(m\) is very large, then primal nondegeneracy must fail and the dual solution must not be unique. This is a property we will see later when we study the moment-SOS hierarchy.

\subsection{Generalization}\label{generalization}

The AHO Newton direction is obtained by symmetrizing the centrality condition \(XZ = \mu \mathrm{I}\) as
\[
\frac{1}{2}(XZ + ZX) = \mu \mathrm{I}.
\]

It turns out that is not the only way (and also not the most robust way) to symmetrize the centrality condition. A more popular symmetrization is due to \citep{monteiro97siopt-primal} and \citep{zhang98siopt-extending}, and is typically referred to as the Monteiro-Zhang family \citep{monteiro98siopt-polynomial}. The basic idea is to symmetrize the centrality condition as
\begin{equation}
\frac{1}{2}(P XZ P^{-1}+ P^{-\top}XZ P^\top) = \mu \mathrm{I}.
\label{eq:Monteiro-Zhang}
\end{equation}
Clearly, the AHO direction is a special case of \eqref{eq:Monteiro-Zhang} with the choice \(P = \mathrm{I}\).

Two other most popular Newton directions are:

\begin{itemize}
\item
  Nesterov-Todd \citep{todd98siopt-nesterov}, where \(P\) is obtained by first solving
  \[
  WZW = X, 
  \]
  and then setting
  \[
  P = W^{-1/2}.
  \]
  This is the Newton method implemented by SeDuMi.
\item
  HKM, which was proposed and analyzed by multiple authors \citep{helmberg96siopt-interior}, \citep{kojima97siopt-interior}, computes
  \[
  P = Z^{1/2}.
  \]
  This is the Newton method implemented by SDPT3 and MOSEK.
\end{itemize}

\section{Applications}\label{applications}

\subsection{Lyapunov Stability}\label{LyapunovLinearSystem}

One of the earliest and most important applications of semidefinite optimization is in the context of dynamical systems and control theory. The main reason is that it is possible to characterize the dynamical properties of a system (e.g., stability, contraction) in terms of algebraic statements such as the feasibility of specific forms of inequalities. We provide a simple example in the case of Lyapunov stability for linear dynamical systems. For a comprehensive overview, see \citep{boyd94book-lmi}.

Consider a discrete-time linear dynamical system
\begin{equation}
x_{k+1} = A x_k,\quad k=0,\dots
\label{eq:dt-linear-system}
\end{equation}
where \(x \in \mathbb{R}^{n}\) is called the state of the system, and \(k\) indexes the time. An important property that one wants to understand about the system \eqref{eq:dt-linear-system} is whether it is \textbf{stable}, i.e., given an initial state \(x_0\), does \(x_k\) tend to zero as \(k\) tends to infinity.

It is well-known that \(x_k\) tends to zero for all initial conditions \(x_0\) if and only if \(|\lambda_i(A)| < 1, \forall i=1,\dots,n\), i.e., all the eigenvalues of the transition matrix \(A\) lies inside the unit circle.

Equivalently, one can also \textbf{certify} the stability of the system if a \textbf{Lyapunov function}
\begin{equation}
V(x_k) = x_k^\top P x_k
\label{eq:Lyapunov-function}
\end{equation}
is given that satisfies the following matrix inequalities.

\begin{lemma}[Lyapunov Stability]
\protect\hypertarget{lem:LyapunovStability}{}\label{lem:LyapunovStability}

Given \(A \in \mathbb{R}^{n \times n}\), the following statements are equivalent:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  All eigenvalues of \(A\) lie strictly inside the unit circle, i.e., \(|\lambda_i(A)| < 1, i=1,\dots,n\)
\item
  There exists a matrix \(P \in \mathbb{S}^{n}\) such that
  \[
  P \succ 0, \quad A^\top P A - P \prec 0.
  \]
\end{enumerate}

\end{lemma}

\begin{proof}
2 \(\Rightarrow\) 1: Let \(\lambda \in \mathbb{C}^{}\) and \(v  \neq 0 \in \mathbb{C}^{n}\) be a pair of eigenvalue and eigenvector of \(A\) such that \(A v = \lambda v\). Since \(A^\top P A - P \prec 0\), we have
\[
v^* (A^\top P A - P) v < 0 \Rightarrow (\lambda v)^* P (\lambda v) - v^* P v < 0 \Rightarrow (|\lambda|^2 - 1) (v^* P v) < 0.
\]
Since \(P \succ 0\), we have \(v^* P v > 0\). Hence, \(|\lambda|^2 - 1 < 0\) and \(|\lambda| < 1\).

1 \(\Rightarrow\) 2: Construct
\[
P := \sum_{k=0}^{\infty} (A^k)^\top A^k.
\]
The sum converges by the condition that \(|\lambda_i(A)| < 1,\forall i\) and \(P \succ 0\). Then we have
\[
A^\top P A - P = \sum_{k=1}^{\infty} (A^k)^\top A^k - \sum_{k=0}^{\infty} (A^k)^\top A^k = - \mathrm{I}\prec 0,
\]
proving the result.
\end{proof}

Intuitively, the Lyapunov function \eqref{eq:Lyapunov-function} defines a positive definite energy function. The fact that \(P \succ 0\) implies \(V(0) = 0\) and \(V(x) > 0\) for any \(x\) that is nonzero. The condition \(A^\top P A - P \prec 0\) guarantees that the system's energy strictly decreases along any possible system trajectory. To see this, write
\[
V(x_{k+1}) - V(x_k) = V(Ax_k) - V(x_k) = x_k^\top(A^\top P A - P) x_k < 0, \forall x_k \neq 0.
\]
Therefore, the existence of a Lyapunov function guarantees any system trajectory will converge to the origin.

The nice property of constructing such a Lyapunov function is that it goes beyond linear systems and can be similarly generalized to nonlinear systems, where one can compute a stability certificate from semidefinite optimization. See for example \href{https://hankyang.seas.harvard.edu/OptimalControlEstimation/stability.html\#lyapunov-analysis}{this lecture notes}.

\textbf{Control Design}. Consider now the case where \(A\) is not stable, but we can use a linear \textbf{feedback controller} to stabilize the system, i.e.,
\[
u_k = K x_k, \quad x_{k+1} = A x_k + B u_k = (A+ BK) x_k,
\]
where the matrix \(K \in \mathbb{R}^{m \times n}\) is the feedback law we wish to design. We wish to design \(K\) using convex optimization, in particular semidefinite optimization.

Involving Lemma\textasciitilde\ref{lem:LyapunovStability}, we see that designing \(K\) to stabilize \(A + BK\) is equivalent to finding
\begin{equation}
P \succ 0, \quad (A + BK)^\top P (A + BK) - P \prec 0.
\label{eq:control-stability}
\end{equation}
Using the Schur complement technique in Proposition \ref{prp:SchurPSD}, we know \eqref{eq:control-stability} is equivalent to
\[
\begin{bmatrix}
P & (A + BK)^\top P \\
P(A+BK) & P \end{bmatrix} \succ 0.
\]
This matrix inequality is, however, not jointly convex in the unknowns \((P,A)\). To address this issue, we can pre-multiply and post-multiply the equation by \(\mathrm{BlkDiag}(P^{-1}, P^{-1})\), which leads to
\begin{equation}
\begin{split}
\begin{bmatrix} P^{-1}& \\
& P^{-1}\end{bmatrix}
\begin{bmatrix}
P & (A + BK)^\top P \\
P(A+BK) & P \end{bmatrix}
\begin{bmatrix} P^{-1}& \\
& P^{-1}\end{bmatrix} \succ 0  \Leftrightarrow \\
\begin{bmatrix} P^{-1}& P^{-1}(A + BK)^\top\\ (A+BK)P^{-1}& P^{-1}\end{bmatrix} \succ 0.
\end{split}
\end{equation}
Now with a change of variable \(Q:= P^{-1}\), \(Y = K P^{-1}\), we have
\[
\begin{bmatrix} Q & Q A^\top+ Y^\top B^\top\\
A Q + BY & Q \end{bmatrix} \succ 0,
\]
which is indeed a linear matrix inequality in the unknowns \((Q,Y)\). Solving the LMI, we can recover
\[
P = Q^{-1}, K = Y Q^{-1}.
\]

\subsection{Linear Quadratic Regulator}\label{linear-quadratic-regulator}

Another (somewhat surprising) application of semidefinite optimization is that it can be used to convexify the direct optimization of the linear quadratic regulator problem (one of the cornerstones in modern optimal control). In fact, such a convex formulation is the key to prove why \textbf{policy optimization} works in reinforcement learning, as least in the linear quadratic case \citep{hu23review-toward} \citep{mohammadi21tac-convergence}.

Consider a continuous-time linear dynamical system
\begin{equation}
\dot{x} = A x + B u, \quad x \in \mathbb{R}^{n}, u \in \mathbb{R}^{m}, A \in \mathbb{R}^{n \times n}, B \in \mathbb{R}^{n \times m},
\label{eq:ct-linear-dynamical}
\end{equation}
where \(x\) denotes the state and \(u\) denotes the control. Consider the following optimal control problem
\begin{equation}
\begin{split}
\min_{u(t)}  & \quad \mathbb{E} \left\{  \int_{t=0}^{\infty} x(t)^\top Q x(t) + u(t)^\top R u(t) dt  \right\}  \\
\mathrm{s.t.}& \quad \dot{x} = A x + Bu, \quad x(0) \sim \mathcal{N}(0,\Omega)
\end{split}
\label{eq:linear-quadratic-regulator}
\end{equation}
where \(Q,R\succ 0\) are known cost matrices, and \(x(0)\) is supposed to satisfy the zero-mean Gaussian distribution with covariance \(\Omega \succ 0\). In the case where \(A,B,Q,R\) are perfectly known to the control designer, and \((A,B)\) is controllable (to be defined soon), problem \eqref{eq:linear-quadratic-regulator} can be solved exactly and optimally, with the optimal controller being a linear feedback controller of the form
\[
u(t) = -Kx(t),
\]
where
\[
K = R^{-1}B^\top S,
\]
with \(S\) the unique positive definite solution to the continuous-time \textbf{algebraic Riccati equation} (ARE)
\[
SA + A^\top S - SBR^{-1}B^\top S + Q = 0.
\]

\textbf{Policy Optimization}. The control and reinforcement learning community are interested in whether it is possible to directly find the optimal feedback policy \(K\), i.e., directly solving
\begin{equation}
\begin{split}
\min_{K \in \mathcal{S}}  & \quad \mathbb{E} \left\{  \int_{t=0}^{\infty} x(t)^\top Q x(t) + u(t)^\top R u(t) dt  \right\}  \\
\mathrm{s.t.}& \quad \dot{x} = A x + Bu, \quad u = -Kx, \quad x(0) \sim \mathcal{N}(0,\Omega).
\end{split}
\label{eq:linear-quadratic-regulator-directK}
\end{equation}
Note that problem \eqref{eq:linear-quadratic-regulator-directK} is different from the original problem \eqref{eq:linear-quadratic-regulator} in the sense that we assume the knowledge that the optimal controller is linear and directly optimize \(K\). The feasible set \(\mathcal{S}\) contains the set of \textbf{stabilizing controllers}, i.e.,
\begin{equation}
\mathcal{S}= \{ K \in \mathbb{R}^{m \times n} \mid A - BK \text{ is Hurwitz} \},
\label{eq:stabilizing-K}
\end{equation}
where a matrix \(A\) is Hurwitz means \(\mathrm{Re}(\lambda_i(A)) < 0\) for all \(i=1,\dots,n\), i.e., all the eigenvalues of \(A\) have strictly negative real parts. When \(A - BK\) is Hurwitz, the closed-loop system is stable and the integral in \eqref{eq:linear-quadratic-regulator-directK} will not blow up (so it is sufficient to consider the class of stabilizing controllers).

We will first observe that the direct optimization \eqref{eq:linear-quadratic-regulator-directK} is nonconvex, because the feasible set \(\mathcal{S}\) is nonconvex. The following example is adapted from \citep{fazel18icml-global}.

\begin{example}[Nonconvex Set of Stabilizing Controllers]
\protect\hypertarget{exm:NonconvexStabilizingController}{}\label{exm:NonconvexStabilizingController}Consider the dynamical system \eqref{eq:ct-linear-dynamical} with
\[
A = 0_{3 \times 3}, \quad B = \mathrm{I}_3.
\]
It is easy to show that both
\[
K_1 = \begin{bmatrix} 1 & 0 & -10 \\ -1 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}, \quad K_2 = \begin{bmatrix} 1 & -10 & 0 \\ 0 & 1 & 0 \\ -1 & 0 & 1 \end{bmatrix}
\]
are stabilizing controllers, as
\[
\lambda(A - BK_1) = (-1,-1,-1), \quad \lambda(A - BK_2) = (-1,-1,-1).
\]
However, pick
\[
K = \frac{K_1 + K_2}{2} = \begin{bmatrix} 1 & -5 & -5 \\ -0.5 & 1 & 0 \\ -0.5 & 0 & 1 \end{bmatrix},
\]
we have
\[
\lambda(A - BK) = (-3.2361, 1.2361, -1)
\]
and \(K\) does not stabilize the closed-loop system.
\end{example}

\textbf{Convex Parameterization with Semidefinite Optimization}. We will now show that it is possible to reparameterize problem \eqref{eq:linear-quadratic-regulator-directK} as a semidefinite optimization so it becomes convex. To do so, we note
\[
x^\top Q x + u^\top R u = x^\top Q x + x^\top K^\top R K x = x^\top(Q + K^\top R K)x^\top= \mathrm{tr}((Q + K^\top R K)xx^\top),
\]
and therefore the objective of \eqref{eq:linear-quadratic-regulator-directK} can be written as
\begin{equation}
\mathbb{E} \left\{ \int_{0}^{\infty} \mathrm{tr}((Q + K^\top R K) xx^\top) dt  \right\}  = \mathrm{tr}\left( (Q + K^\top R K) \mathbb{E} \left\{  \int_{0}^{\infty} xx^\top dt  \right\}    \right).
\end{equation}
For any given initial condition, the solution of the closed-loop dynamics is given by the matrix exponential
\[
x(t) = e^{(A-BK)t} x(0).
\]
For the distribution of initial conditions, we have
\[
\mathbb{E} \left\{ x(t)x(t)^\top \right\}  = e^{(A-BK)t} \mathbb{E}\{ x(0)x(0)^\top \}  e^{(A-BK)^\top t} = e^{(A-BK)t} \Omega  e^{(A-BK)^\top t}.
\]
The integral of this function, call it \(X\), represents the expected energy of the closed-loop response
\[
X = \mathbb{E} \left\{ \int_{0}^{\infty} xx^\top dt \right\} .
\]
For every \(K \in \mathcal{S}\) that is stabilizing, \(X\) can be computed as the solution to the Lyapunov equation
\begin{equation}
(A - BK) X + X(A - BK)^\top+ \Omega = 0.
\label{eq:Lyapunov-equation}
\end{equation}
As a result, the objective of \eqref{eq:linear-quadratic-regulator-directK} is simplied as
\[
\mathrm{tr}((Q + K^\top R K) X),
\]
with \(X\) solves \eqref{eq:Lyapunov-equation}. We arrive at an optimization problem
\begin{equation}
\begin{split}
\min_{X,K} & \quad \mathrm{tr}(QX) + \mathrm{tr}(K^\top R K X) \\
\mathrm{s.t.}& \quad (A-BK) X + X (A - BK)^\top+ \Omega = 0 \\
& \quad X \succ 0
\end{split},
\label{eq:lqr-directK-toX}
\end{equation}
which is still nonconvex. We do a change of variable \(Y = KX\), so \(K = Y X ^{-1}\) and obtain
\begin{equation}
\begin{split}
\min_{X,Y} & \quad \mathrm{tr}(QX) + \mathrm{tr}(X^{-1}Y^\top R Y) \\
\mathrm{s.t.}& \quad AX - BY + XA^\top- Y^\top B^\top+ \Omega = 0 \\
& \quad X \succ 0
\end{split}.
\label{eq:lqr-directK-toX-1}
\end{equation}
The second term in the objective is still nonconvex, but we can use the Schur complement technique again, and arrive at the final optimization
\begin{equation}
\begin{split}
\min_{X,Y,Z} & \quad \mathrm{tr}(QX) + \mathrm{tr}(Z) \\
\mathrm{s.t.}& \quad AX - BY + XA^\top- Y^\top B^\top+ \Omega = 0 \\
& \quad X \succ 0 \\
& \quad \begin{bmatrix} Z & R^{1/2} Y & \\ Y^\top R^{1/2} & X \end{bmatrix} \succeq 0
\end{split}.
\label{eq:lqr-directK-toX-2}
\end{equation}
Note that the last two matrix inequalities of \eqref{eq:lqr-directK-toX-2} implies, by Schur complement
\[
Z - R^{1/2}Y X^{-1}Y^\top R^{1/2} \succeq 0 \Rightarrow \mathrm{tr}(Z - R^{1/2}Y X^{-1}Y^\top R^{1/2}) \geq 0.
\]
Since the optimization is trying to minimize \(\mathrm{tr}(Z)\), it will push the equality to hold
\[
Z - R^{1/2}Y X^{-1}Y^\top R^{1/2} = 0,
\]
and thus
\[
\mathrm{tr}(Z) = \mathrm{tr}(R^{1/2}Y X^{-1}Y^\top R^{1/2}) = \mathrm{tr}(X^{-1}Y^\top R Y).
\]

\begin{example}[Convex LQR]
\protect\hypertarget{exm:ConvexLQR}{}\label{exm:ConvexLQR}

For the same linear system as in Example \ref{exm:NonconvexStabilizingController}, let \(Q = R = \mathrm{I}_3\).

If we solve the optimal feedback controller \(K\) by solving the ARE, we get the optimal controller is \(K^\star = \mathrm{I}_3\).

If we implement the SDP in \eqref{eq:lqr-directK-toX-2}, we also get \(K^\star = \mathrm{I}_3\), confirming the correctness of the convex parameterization. The implementation is shown below and can be found \href{https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/lqr_sdp.m}{here}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\%\% Show the feasible set is nonconvex}
\VariableTok{A} \OperatorTok{=} \VariableTok{zeros}\NormalTok{(}\FloatTok{3}\OperatorTok{,}\FloatTok{3}\NormalTok{)}\OperatorTok{;}
\VariableTok{B} \OperatorTok{=} \VariableTok{eye}\NormalTok{(}\FloatTok{3}\NormalTok{)}\OperatorTok{;}
\VariableTok{K1} \OperatorTok{=}\NormalTok{ [}\FloatTok{1}\OperatorTok{,} \FloatTok{0}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{10}\OperatorTok{;} \OperatorTok{{-}}\FloatTok{1}\OperatorTok{,} \FloatTok{1}\OperatorTok{,} \FloatTok{0}\OperatorTok{;} \FloatTok{0}\OperatorTok{,} \FloatTok{0}\OperatorTok{,} \FloatTok{1}\NormalTok{]}\OperatorTok{;}
\VariableTok{K2} \OperatorTok{=}\NormalTok{ [}\FloatTok{1}\OperatorTok{,} \OperatorTok{{-}}\FloatTok{10}\OperatorTok{,} \FloatTok{0}\OperatorTok{;} \FloatTok{0}\OperatorTok{,} \FloatTok{1}\OperatorTok{,} \FloatTok{0}\OperatorTok{;} \OperatorTok{{-}}\FloatTok{1}\OperatorTok{,} \FloatTok{0}\OperatorTok{,} \FloatTok{1}\NormalTok{]}\OperatorTok{;}
\VariableTok{K} \OperatorTok{=}\NormalTok{ (}\VariableTok{K1} \OperatorTok{+} \VariableTok{K2}\NormalTok{)}\OperatorTok{/}\FloatTok{2}\OperatorTok{;}

\CommentTok{\%\% get the groundtruth LQR controller}
\VariableTok{Q} \OperatorTok{=} \VariableTok{eye}\NormalTok{(}\FloatTok{3}\NormalTok{)}\OperatorTok{;} \VariableTok{R} \OperatorTok{=} \VariableTok{eye}\NormalTok{(}\FloatTok{3}\NormalTok{)}\OperatorTok{;}
\VariableTok{K\_lqr} \OperatorTok{=} \VariableTok{lqr}\NormalTok{(}\VariableTok{A}\OperatorTok{,}\VariableTok{B}\OperatorTok{,}\VariableTok{Q}\OperatorTok{,}\VariableTok{R}\OperatorTok{,}\VariableTok{zeros}\NormalTok{(}\FloatTok{3}\OperatorTok{,}\FloatTok{3}\NormalTok{))}\OperatorTok{;}
\VariableTok{Omega} \OperatorTok{=} \VariableTok{eye}\NormalTok{(}\FloatTok{3}\NormalTok{)}\OperatorTok{;}

\CommentTok{\%\% solve SDP}
\VariableTok{addpath}\NormalTok{(}\VariableTok{genpath}\NormalTok{(}\SpecialStringTok{\textquotesingle{}../YALMIP\textquotesingle{}}\NormalTok{))}
\VariableTok{addpath}\NormalTok{(}\VariableTok{genpath}\NormalTok{(}\SpecialStringTok{\textquotesingle{}../../../mosek\textquotesingle{}}\NormalTok{))}

\VariableTok{X} \OperatorTok{=} \VariableTok{sdpvar}\NormalTok{(}\FloatTok{3}\OperatorTok{,}\FloatTok{3}\NormalTok{)}\OperatorTok{;}
\VariableTok{Y} \OperatorTok{=} \VariableTok{sdpvar}\NormalTok{(}\FloatTok{3}\OperatorTok{,}\FloatTok{3}\OperatorTok{,}\SpecialStringTok{\textquotesingle{}full\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\VariableTok{Z} \OperatorTok{=} \VariableTok{sdpvar}\NormalTok{(}\FloatTok{3}\OperatorTok{,}\FloatTok{3}\NormalTok{)}\OperatorTok{;}
\VariableTok{M} \OperatorTok{=}\NormalTok{ [}\VariableTok{Z}\OperatorTok{,} \VariableTok{R}\OperatorTok{*}\VariableTok{Y}\OperatorTok{;} \VariableTok{Y}\OperatorTok{\textquotesingle{}*}\VariableTok{R}\OperatorTok{,} \VariableTok{X}\NormalTok{]}\OperatorTok{;}
\VariableTok{F} \OperatorTok{=}\NormalTok{ [}
    \VariableTok{A}\OperatorTok{*}\VariableTok{X} \OperatorTok{{-}} \VariableTok{B}\OperatorTok{*}\VariableTok{Y} \OperatorTok{+} \VariableTok{X}\OperatorTok{*}\VariableTok{A}\OperatorTok{\textquotesingle{}} \OperatorTok{{-}} \VariableTok{Y}\OperatorTok{\textquotesingle{}*}\VariableTok{B}\OperatorTok{\textquotesingle{}} \OperatorTok{+} \VariableTok{Omega} \OperatorTok{==} \FloatTok{0}\OperatorTok{;}
    \VariableTok{M} \OperatorTok{\textgreater{}=} \FloatTok{0}
\NormalTok{]}\OperatorTok{;}
\VariableTok{obj} \OperatorTok{=} \VariableTok{trace}\NormalTok{(}\VariableTok{Q}\OperatorTok{*}\VariableTok{X}\NormalTok{) }\OperatorTok{+} \VariableTok{trace}\NormalTok{(}\VariableTok{Z}\NormalTok{)}\OperatorTok{;}
\VariableTok{optimize}\NormalTok{(}\VariableTok{F}\OperatorTok{,}\VariableTok{obj}\NormalTok{)}\OperatorTok{;}
\VariableTok{K\_sdp} \OperatorTok{=} \VariableTok{value}\NormalTok{(}\VariableTok{Y}\NormalTok{)}\OperatorTok{*}\VariableTok{inv}\NormalTok{(}\VariableTok{value}\NormalTok{(}\VariableTok{X}\NormalTok{))}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\end{example}

\subsection{Domain Adaptation}\label{domain-adaptation}

\citep{mansour09arxiv-domain}

\chapter{Shor's Semidefinite Relaxation}\label{Shor}

In this Chapter, we introduce one of the most important and well-known applications of semidefinite optimization, namely its use in the formulation of \textbf{convex relaxations} of nonconvex optimization problems.

We will focus on the so-called Shor's semidefinite relaxation \citep{shor87sjcss-quadratic}, which is particularly designed for quadratically constrained quadratic programs (QCQPs). Shor's semidefinite relaxation is relatively easy to formulate and understand, and as we will see later, is essentially the first-order relaxation in the moment-SOS hierarchy.

\section{Semidefinite Relaxation of QCQPs}\label{semidefinite-relaxation-of-qcqps}

Consider a quadratically constrained quadratic program (QCQP):
\begin{equation}
\begin{split}
f^\star = \min_{x \in \mathbb{R}^{n}} & \quad x^\top C x \\
\mathrm{s.t.}& \quad x^\top A_i x = b_i, i=1,\dots,m
\end{split}
\label{eq:qcqp}
\end{equation}
where \(C,A_1,\dots,A_m \in \mathbb{S}^{n}\) are given symmetric matrices and \(b = [b_1,\dots,b_m] \in \mathbb{R}^{m}\) is a given vector. We assume the problem \eqref{eq:qcqp} is feasible, solvable, and bounded from below, i.e., \(-\infty < f^\star < +\infty\) and is attained. Many practical problems in optimization, engineering, and applied sciences can be formulated as \eqref{eq:qcqp}. For example, problem \eqref{eq:qcqp} includes binary quadratic optimization (BQP) problems by letting
\[
A_i = e_i e_i^\top, i=1,\dots,n
\]
with \(e_i \in \mathbb{R}^{n}\) the standard Euclidean basis vector, in which case the \(i\)-th constraint becomes
\[
x_i^2 = 1 \Leftrightarrow x_i \in \{+1,-1\},i=1,\dots,n.
\]
We will discuss a particular type of BQP known as the MAXCUT problem in more details later. From this simple example, since QCQP includes BQP, we know in general the problem \eqref{eq:qcqp} is nonconvex and it is NP-hard to compute \(f^\star\) and find a global optimizer.

\subsection{Lagrangian Dual Problem}\label{lagrangian-dual-problem}

Since the original QCQP is hard to solve in general, we turn to computing a \textbf{lower bound} of \eqref{eq:qcqp}. The most natural way to find a lower bound, according to Section \ref{background:convex:optimization:Lagrangian}, is to derive its Lagrangian dual problem. Towards this goal, we associate a Lagrangian multipler \(-y_i\) with each equality constraint and obtain the Lagrangian
\[
L(x,y) = x^\top C x - \sum_{i=1}^m y_i (x^\top A_i x - b_i), \quad x \in \mathbb{R}^{n},y \in \mathbb{R}^{m}.
\]
The Lagrangian dual, by definition, is
\[
\phi(y) = \min_x L(x,y) = \sum_{i=1}^m y_i b_i + \min_{x \in \mathbb{R}^{n}} x^\top\underbrace{\left( C - \sum_{i=1}^m y_i A_i \right)}_{Z} x.
\]
Clearly, if \(Z\) is positive semidefinite, then \(\min_x x^\top Z x = 0\) (by choosing \(x=0\)); otherwise, \(\min_x x^\top Z x = -\infty\). Therefore, the dual function is
\[
\phi(y) = \begin{cases}
\sum_{i=1}^m y_i b_i & \text{if } C - \sum_{i=1}^m y_i A_i \succeq 0 \\
- \infty & \text{otherwise}
\end{cases}.
\]
The Lagrangian dual problem seeks to maximize \(y\), and hence it will make sure \(Z\) is PSD
\begin{equation}
\begin{split}
d^\star = \max_{y \in \mathbb{R}^{m}} & \quad b^\top y \\
\mathrm{s.t.}& \quad C - \mathcal{A}^*(y) \succeq 0.
\end{split}
\label{eq:Lagrangian-dual-qcqp}
\end{equation}
By Lagrangian duality, we have
\[
d^\star \leq f^\star.
\]
Note that problem \eqref{eq:Lagrangian-dual-qcqp} is a convex SDP and can be solved by off-the-shelf solvers.

Another nice property of the dual problem is that it naturally leads to a \textbf{certifier}.

\begin{proposition}[Dual Optimality Certifier]
\protect\hypertarget{prp:DualCertifier}{}\label{prp:DualCertifier}Let \(x_\star\) be a feasible solution to the QCQP \eqref{eq:qcqp}, if there exists \(y_\star \in \mathbb{R}^{m}\) such that
\begin{equation}
C - \mathcal{A}^*(y_\star) \succeq 0, \quad [ C - \mathcal{A}^*(y_\star) ] x_\star = 0,
\label{eq:dual-optimality-condition}
\end{equation}
then \(x_\star\) is a global minimizer of \eqref{eq:qcqp}, and \(y_\star\) is a global maximizer of \eqref{eq:Lagrangian-dual-qcqp}.
\end{proposition}

\begin{proof}
We have zero duality gap
\begin{equation}
\begin{split}
x_\star^\top C x_\star - b^\top y_\star = \langle C, x_\star x_\star^\top \rangle - \langle b, y_\star \rangle = \langle C, x_\star x_\star^\top \rangle - \langle \mathcal{A}(x_\star x_\star^\top), y_\star \rangle \\
= \langle C - \mathcal{A}^*(y_\star),  x_\star x_\star^\top \rangle = x_\star^\top[ C - \mathcal{A}^*(y_\star) ] x_\star = 0.
\end{split}
\end{equation}
and \((x_\star, y_\star)\) is primal-dual feasible. Therefore, \((x_\star, y_\star)\) is primal-dual optimal.
\end{proof}

The reason why Proposition \ref{prp:DualCertifier} can be quite useful is that it gives a very efficient algorithm to certify global optimality of a candidate (potentially locally) optimal solution \(x_\star\). In particular, in several practical applications in computer vision and robotics, the second equation in \eqref{eq:dual-optimality-condition} is a linear system of \(n\) equations in \(m\) variables with \(m\leq n\), and hence it has a unique solution. Therefore, one can first solve the linear system and obtain a candidate \(y_\star\), and then simply check the PSD condition \(C - \mathcal{A}^*(y_\star) \succeq 0\). This leads to optimality certifiers that can run in real time \citep{garcia21ivc-certifiable} \citep{holmes23ral-efficient}.

\subsection{Dual of the Dual (Bidual)}\label{dual-of-the-dual-bidual}

The dual problem \eqref{eq:Lagrangian-dual-qcqp} should appear familiar to us at this moment -- it is simply a standard-form dual SDP \eqref{eq:SDP-D}. Therefore, we can write down the SDP dual of the QCQP dual \eqref{eq:Lagrangian-dual-qcqp}
\begin{equation}
\begin{split}
p^\star = \min_{X \in \mathbb{S}^{n}} & \quad \langle C, X \rangle \\
\mathrm{s.t.}& \quad \mathcal{A}(X) = b \\
& \quad X \succeq 0
\end{split}
\label{eq:qcqp-bidual}
\end{equation}
Under the assumption of SDP strong duality (e.g., both \eqref{eq:qcqp-bidual} and \eqref{eq:Lagrangian-dual-qcqp} are strictly feasible), we have
\[
p^\star = d^\star \leq f^\star.
\]
The weak duality \(d^\star \leq f^\star\) can be interpreted using standard Lagrangian duality. How about the weak duality \(p^\star \leq f^\star\)?
It turns out the dual of the dual (bidual) also has a nice interpretation.

We first observe that the original QCQP \eqref{eq:qcqp} is equivalent to a rank-constrained matrix optimization problem.

\begin{proposition}[Rank-Constrained Matrix Optimization]
\protect\hypertarget{prp:RankConstrainedMatrix}{}\label{prp:RankConstrainedMatrix}

The QCQP \eqref{eq:qcqp} is equivalent to the following rank-constrained matrix optimization
\begin{equation}
\begin{split}
f^\star_m = \min_{X \in \mathbb{S}^{n}} & \quad \langle C, X \rangle \\
\mathrm{s.t.}& \quad \mathcal{A}(X) = b \\
& \quad X \succeq 0 \\
& \quad \mathrm{rank}(X) = 1
\end{split}
\label{eq:rank-constrained-optimization}
\end{equation}
in the sense that

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(f^\star = f^\star_m\)
\item
  For every optimal solution \(x_\star\) of the QCQP \eqref{eq:qcqp}, \(X_\star = x_\star x_\star^\top\) is globally optimal for the matrix optimization \eqref{eq:rank-constrained-optimization}
\item
  Every optimal solution \(X_\star\) of the matrix optimization can be factorized as \(X_\star = x_\star x_\star^\top\) so that \(x_\star\) is optimal for the QCQP \eqref{eq:qcqp}.
\end{enumerate}

\end{proposition}

\begin{proof}
We will show that the feasible set of the QCQP \eqref{eq:qcqp} is the same as the feasible set of \eqref{eq:rank-constrained-optimization}.

Let \(x\) be feasible for the QCQP \eqref{eq:qcqp}, we have \(X=xx^\top\) must be feasible for \eqref{eq:rank-constrained-optimization} because \(X \succeq 0\) by construction, \(\mathrm{rank}(X) = \mathrm{rank}(xx^\top) = \mathrm{rank}(x) = 1\), and
\[
x^\top A_i x = b_i \Rightarrow \mathrm{tr}(x^\top A_i x) = b_i \Rightarrow \mathrm{tr}(A_i x x^\top) = b_i \Rightarrow \langle A_i, X \rangle = b_i, \forall i.
\]

Conversely, let \(X\) be feasible for the matrix optimization \eqref{eq:rank-constrained-optimization}. Since \(X \succeq 0\) and \(\mathrm{rank}(X) = 1\), \(X = xx^\top\) must hold for some \(x \in \mathbb{R}^{n}\). In the meanwhile,
\[
\langle A_i, X \rangle = b_i \Rightarrow \langle A_i, xx^\top \rangle = b_i \Rightarrow x^\top A_i x = b_i, \forall i.
\]
Therefore, \(x\) is feasible for the QCQP \eqref{eq:qcqp}.

Finally, it is easy to observer that
\[
\langle C, X \rangle = \langle C, xx^\top \rangle = x^\top C x,
\]
and the objective is also the same.
\end{proof}

Since the QCQP is equivalent to the matrix optimization \eqref{eq:rank-constrained-optimization}, one should expect the matrix optimization to be NP-hard in general as well. In fact, this is true due to the nonconvex rank constraint \(\mathrm{rank}(X) = 1\). Comparing the nonconvex SDP \eqref{eq:rank-constrained-optimization} and the convex SDP \eqref{eq:qcqp-bidual}, we see the only difference is that we have dropped the nonconvex rank constraint in \eqref{eq:qcqp-bidual} to make it convex, hence the SDP \eqref{eq:qcqp-bidual} is a convex relaxation of the QCQP \eqref{eq:qcqp} and \(p^\star \leq f^\star\).

This convex relaxation perspective also provides a way to certify global optimality, by checking the rank of the optimal solution after solving the convex SDP \eqref{eq:qcqp-bidual}.

\begin{proposition}[Exactness of SDP Relaxation]
\protect\hypertarget{prp:SDPExactness}{}\label{prp:SDPExactness}Let \(X_\star\) be an optimal solution to the SDP \eqref{eq:qcqp-bidual}, if \(\mathrm{rank}(X_\star) = 1\), then \(X_\star\) can be factorized as \(X_\star = x_\star x_\star^\top\) with \(x_\star\) a globally optimal solution to the QCQP \eqref{eq:qcqp}. If so, we say the relaxation \eqref{eq:qcqp-bidual} is exact, or tight.
\end{proposition}

It is worth noting that, even when the relaxation is exact, i.e., \(p^\star = f^\star\), it may not be trivial to numerically certify the exactness, due to several reasons

\begin{itemize}
\item
  If the SDP \eqref{eq:qcqp-bidual} is solved using interior point methods such as MOSEK, then it is well known that they converge to the \emph{maximum-rank solution} \citep{wolkowicz12book-sdp}. This is saying that even if the SDP \eqref{eq:qcqp-bidual} has rank-one solutions, the solvers may not find them. Consider the case where \(x_1\) and \(x_2\) are both optimal solutions to the QCQP \eqref{eq:qcqp} and the relaxation is exact, it is easy to check that
  \[
  X = \lambda_1 x_1 x_1^\top+ \lambda_2 x_2 x_2^\top, \quad \lambda_1, \lambda_2 \geq 0, \lambda_1 + \lambda_2 = 1
  \]
  is globally optimal for the SDP. When \(x_1 x_1^\top\) and \(x_2 x_2^\top\) are linearly independent, \(X\) can have rank equal to two. In this case, interior point methods will not converge to either \(x_1x_1^\top\) or \(x_2 x_2^\top\), but will instead find \(X\) with some unknown coefficients of \(\lambda_1\) and \(\lambda_2\).
\item
  Even if the original QCQP has a unique optimal solution and the relaxation is exact, the SDP solver will converge to a solution that is approximately rank-one (i.e., the second largest sigular value / eigenvalue will still be nonzero) and it may be difficult to draw a conclusion about exactness. Therefore, in practice one can compute a \textbf{relative suboptimality gap} by rounding a feasible point to the QCQP from the SDP (it may or may not be easy to round a feasible point), denoted as \(\hat{x}\), then compute
  \[
  \hat{f} = \hat{x}^\top C \hat{x},
  \]
  which serves as an upper bound
  \[
  p^\star \leq f^\star \leq \hat{f}.
  \]
  The relative suboptimality gap can be computed as
  \[
  \eta = \frac{|\hat{f} - p^\star|}{1 + |\hat{f}| + |p^\star|}.
  \]
  Clearly, \(\eta \approx 0\) certifies exactness of the SDP relaxation.
\end{itemize}

\subsection{MAXCUT}\label{maxcut}

We will now study binary quadratic optimization problems, in particular the MAXCUT problem. The original QCQP reads
\begin{equation}
\begin{split}
\min_{x \in \mathbb{R}^{n}} & \quad x^\top C x \\
\mathrm{s.t.}& \quad x_i^2 = 1, i=1,\dots,n.
\end{split}
\label{eq:bqp}
\end{equation}
For the MAXCUT problem, a standard formulation is
\begin{equation}
\max_{x_i^2 = 1}  \frac{1}{4} \sum_{i,j} w_{ij} (1 - x_i x_j),
\label{eq:maxcut-org}
\end{equation}
where \(w_{ij} \geq 0\) is the weight of the edge between node \(i\) and node \(j\).
It is clear that if \(x_i, x_j\) have the same sign, then \(1- x_i x_j = 0\), otherwise, \(1- x_i x_j = 2\).

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/max_cut} 

}

\caption{MAXCUT seeks to separate the node set of a graph into two disjoint groups such that the separation line cuts as many (weighted) edges as possible. For example, the blue line cuts four edges.}\label{fig:MAXCUT}
\end{figure}

Removing the constant terms in \eqref{eq:maxcut-org}, it is equivalent to the followng BQP
\begin{equation}
\min_{x_i^2 = 1}  \sum_{i,j} w_{ij} x_i x_j.
\label{eq:maxcut-bqp}
\end{equation}

\textbf{Random Rounding}. In general, solving the SDP relaxation of the MAXCUT problem will not produce a certifiably optimal solution. It is therefore interesting to ask if solving the SDP relaxation can produce provably good approximations.

Let \(X\) be the optimal solution of the SDP relaxation, and \(X = V^\top V\) be a rank-\(r\) factorization with \(V \in \mathbb{R}^{r \times n}\)
\[
V = [v_1,\dots,v_n]
\]
and each vector \(v_i \in \mathbb{R}^{r}\). We have \(X_{ij} = v_i^\top v_j\). Since \(X_{ii} = 1\), the vectors \(v_i\)'s lie on the unit sphere. Goemans and Williamson \citep{goemans95jacm-improved} proposed to obtain a feasible point to the orignal BQP by first choosing a random unit direction \(p \in \mathbb{R}^{r}\) and then assign
\[
x_i = \mathrm{sgn}(p^\top v_i), i=1,\dots,n.
\]
The expected value of this solution can be written as
\[
\mathbb{E}_p  \left\{ x^\top C x \right\}  = \sum_{i,j} C_{ij} \mathbb{E}_p  \left\{ x_i x_j \right\}  = \sum_{i,j} C_{ij} \mathbb{E}_p  \left\{ \mathrm{sgn}(p^\top x_i) \mathrm{sgn}(p^\top x_j) \right\} .
\]
This expectation can be computed using geometric intuition. Consider the plane spanned by \(v_i\) and \(v_j\) and let \(\theta_{ij}\) be the angle between them. Then, it is easy to see that the desired expectation is equal to the probability that both points are on the same side of the hyperplane, minus the probability that they are on different sides. These probabilities are \(1- \theta_{ij} / \pi\) and \(\theta_{ij} / \pi\), respectively. Therefore, the expected value of the rounded solution is
\[
\sum_{i,j} C_{ij} \left( 1- \frac{2\theta_{ij}}{\pi} \right) = \sum_{i,j} C_{ij} \left( 1- \frac{2}{\pi} \arccos (v_i^\top v_j)  \right) = \frac{2}{\pi} \sum_{i,j} C_{ij} \arcsin X_{ij},
\]
where we have used
\[
\arccos t + \arcsin t = \frac{\pi}{2}.
\]

\textbf{MAXCUT Bound}. For the MAXCUT problem, there are constant terms involved in the original cost function, which leads to the expected cut of the rounded solution to be
\[
c_{\mathrm{expected}} = \frac{1}{4} \sum_{i,j} w_{ij} \left( 1- \frac{2}{\pi} \arcsin X_{ij} \right) = \frac{1}{4} \frac{2}{\pi} \sum_{ij} w_{ij} \arccos X_{ij}.
\]
On the other hand, the optimal value of the SDP relaxation produces an upper bound on the true MAXCUT
\[
c_{\mathrm{ub}} = \frac{1}{4} \sum_{i,j} w_{ij} (1 - X_{ij}).
\]
We have
\[
c_{\mathrm{expected}} \leq c_{\mathrm{MAXCUT}} \leq c_{\mathrm{ub}}.
\]
We want to find the maximum possible \(\alpha\) such that
\[
\alpha c_{\mathrm{ub}} \leq c_{\mathrm{expected}} \leq c_{\mathrm{MAXCUT}} \leq c_{\mathrm{ub}},
\]
so that \(\alpha\) acts to be the best approximation ratio. To find such \(\alpha\), we need to find the maximum \(\alpha\) such that
\[
\alpha (1 - t) \leq \frac{2}{\pi} \arccos(t), \forall t \in [-1,1].
\]
The best possible \(\alpha\) is \(0.878\), see Fig. \ref{fig:MAXCUTAlpha}.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/maxcut_alpha} 

}

\caption{Best approximation ratio.}\label{fig:MAXCUTAlpha}
\end{figure}

\section{Certifiably Optimal Rotation Averaging}\label{certifiably-optimal-rotation-averaging}

Consider a graph \(\mathcal{G}= (\mathcal{V},\mathcal{E})\) with node set \(\mathcal{V}= [N]\) and edge set \(\mathcal{E}= \{(i,j) \mid i,j \in \mathcal{V}\}\). Each node \(i\) is associated with an unknown rotation matrix \(R_i \in \mathrm{SO}(3)\), and each edge is associated with a relative rotation
\begin{equation}
\tilde{R}_{ij} = R_i^\top R_j \cdot R_{\epsilon},
\label{eq:rotation-averaging-gen-model}
\end{equation}
that measures the relative rotation between \(R_i\) and \(R_j\), up to some small noise corruption \(R_{\epsilon} \in \mathrm{SO}(3)\). See Fig. \ref{fig:RotationAveraging}.

The goal of (multiple) rotation averaging is to estimate the absolute rotations \(\{R_i \}_{i=1}^N\) given the noisy relative rotation measurements on the edges \(\{\tilde{R}_{ij} \}_{(i,j) \in \mathcal{E}}\). This problem is also known as rotation synchronization and it finds applications in computer vision \citep{eriksson18cvpr-rotation}, robotics \citep{rosen19ijrr-sesync}, and medical imaging \citep{wang13ima-exact}.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/rotation_avg} 

}

\caption{Rotation Averaging.}\label{fig:RotationAveraging}
\end{figure}

To synchronize the absolute rotations from relative measurements, it is common practice to formulate the following optimization problem
\begin{equation}
\min_{R_i \in \mathrm{SO}(3), i\in \mathcal{V}} \sum_{(i,j) \in \mathcal{E}} \Vert \tilde{R}_{ij} - R_i^\top R_j \Vert_\mathrm{F}^2,
\label{eq:rotation-averaging}
\end{equation}
to seek the best absolute rotations that fit the relative measurements according to the generative model \eqref{eq:rotation-averaging-gen-model}. It can be shown that when the noise \(R_\epsilon\) satisfies a Langevin distribution, then problem \eqref{eq:rotation-averaging} returns the maximum likelihood estimator. Even when the noise distribution is not Langevin, problem \eqref{eq:rotation-averaging} often produces accurate estimates.

\textbf{QCQP Formulation}. We will first simplify problem \eqref{eq:rotation-averaging} as a QCQP. Note that the objective is equivalent to
\[
\sum_{(i,j) \in \mathcal{E}} \mathrm{tr}\left( (\tilde{R}_{ij} - R_i^\top R_j)^\top(\tilde{R}_{ij} - R_i^\top R_j) \right) = \sum_{(i,j) \in \mathcal{E}} \mathrm{tr}\left( 2 \mathrm{I}_3 - 2 \tilde{R}_{ij}^\top R_i^\top R_j \right).
\]
Therefore, problem \eqref{eq:rotation-averaging} is equivalent to
\begin{equation}
\min_{R_i \in \mathrm{SO}(3), i\in\mathcal{V}} -2\sum_{(i,j)\in\mathcal{E}} \mathrm{tr}(\tilde{R}_{ij}^\top R_i^\top R_j).
\label{eq:rotation-averaging-qcqp}
\end{equation}
This is a QCQP because the objective is quadratic, and \(\mathrm{SO}(3)\) can be described by quadratic equality constraints.

\textbf{Matrix Formulation}. Let
\[
R = \begin{bmatrix} 
R_1^\top\\
\vdots \\
R_N^\top
\end{bmatrix} \in \mathrm{SO}(3)^N,\quad 
RR^\top= \begin{bmatrix}
R_1^\top R_1 & R_1^\top R_2 & \cdots & R_1^\top R_N \\
R_2^\top R_1 & R_2^\top R_2 & \cdots & R_2^\top R_N \\
\vdots & \vdots & \ddots & \vdots \\
R_N^\top R_1 & R_N^\top R_2 & \cdots & R_N^\top R_N
\end{bmatrix} \in \mathbb{S}^{3N}_{+}
\]
and
\begin{equation}
\tilde{R}= \begin{bmatrix}
0 & \tilde{R}_{12} & \cdots & \tilde{R}_{1N} \\
\tilde{R}_{12}^\top& 0 & \cdots & \tilde{R}_{2N}\\
\vdots & \vdots & \ddots & \vdots \\
\tilde{R}_{1N}^\top& \tilde{R}_{2N}^\top& \cdots & 0
\end{bmatrix} \in \mathbb{S}^{3N}
\label{eq:rotation-averaging-tldR}
\end{equation}
Then problem \eqref{eq:rotation-averaging-qcqp} can be compactly written as
\begin{equation}
\min_{R \in \mathrm{SO}(3)^N} - \langle \tilde{R}, RR^\top \rangle
\label{eq:rotation-averaging-matrix}
\end{equation}

\textbf{Semidefinite Relaxation}. Problem \eqref{eq:rotation-averaging-matrix} is nonconvex, so we apply semidefinite relaxation. Observe that, because \(R_i \in \mathrm{SO}(3)\), we have
\[
R_i^\top R_i = \mathrm{I}_3, \forall i=1,\dots,N.
\]
Therefore, the diagonal blocks of \(RR^\top\) are all \(3\times 3\) identity matrices. We have also that \(RR^\top\succeq 0\) by construction. Therefore, the following SDP is a convex relaxation of problem \eqref{eq:rotation-averaging-matrix}
\begin{equation}
\begin{split}
\min_{X \in \mathbb{S}^{3N}} & \quad - \langle \tilde{R}, RR^\top \rangle \\
\mathrm{s.t.}& \quad X \succeq 0 \\
& \quad [X]_{ii} = \mathrm{I}_3, \quad i=1,\dots,N
\end{split}
\label{eq:rotation-averaging-sdp-relax}
\end{equation}
where the last constraint in \eqref{eq:rotation-averaging-sdp-relax} enforces all diagonal blocks to be identity matrices.

How powerful is this SDP relaxation? You may think that it will be quite loose (and hence not very useful) because we have dropped many nonconvex constraints from the original QCQP to the convex SDP (e.g., \(\mathrm{rank}(X) = 3\), \(R_i \in \mathrm{SO}(3)\) but we only used \(R_i \in \mathrm{O}(3)\)), but empirically it is almost always exact.

\begin{example}[Rotation Averaging]
\protect\hypertarget{exm:RotationAveraging}{}\label{exm:RotationAveraging}I will generate a fully connected graph \(\mathcal{G}\) with \(N\) nodes.

\begin{itemize}
\item
  For each node \(i\), I associate a random 3D rotation matrix \(R_i\). For the first node, I always let \(R_1 = \mathrm{I}_3\).
\item
  For each edge \((i,j)\), I generate a noisy measurement
  \[
  \tilde{R}_{ij} = R_i^\top R_j \cdot R_\epsilon,
  \]
  where \(R_\epsilon\) is a rotation matrix with a random rotation axis and a rotation angle uniformally distributed between \(0\) and \(\beta\) degrees.
\end{itemize}

After this graph is generated, I form the \(\tilde{R}\) matrix in \eqref{eq:rotation-averaging-tldR} and solve the SDP \eqref{eq:rotation-averaging-sdp-relax}. This can be easily programmed in Matlab:

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{X} \OperatorTok{=} \VariableTok{sdpvar}\NormalTok{(}\FloatTok{3}\OperatorTok{*}\VariableTok{n}\OperatorTok{,}\FloatTok{3}\OperatorTok{*}\VariableTok{n}\NormalTok{)}\OperatorTok{;}
\VariableTok{F} \OperatorTok{=}\NormalTok{ [}\VariableTok{X} \OperatorTok{\textgreater{}=} \FloatTok{0}\NormalTok{]}\OperatorTok{;}
\KeywordTok{for} \VariableTok{i} \OperatorTok{=} \FloatTok{1}\OperatorTok{:}\VariableTok{n}
    \VariableTok{F} \OperatorTok{=}\NormalTok{ [}\VariableTok{F}\OperatorTok{,}
        \VariableTok{X}\NormalTok{(}\VariableTok{blkIndices}\NormalTok{(}\VariableTok{i}\OperatorTok{,}\FloatTok{3}\NormalTok{)}\OperatorTok{,}\VariableTok{blkIndices}\NormalTok{(}\VariableTok{i}\OperatorTok{,}\FloatTok{3}\NormalTok{)) }\OperatorTok{==} \VariableTok{eye}\NormalTok{(}\FloatTok{3}\NormalTok{)]}\OperatorTok{;}
\KeywordTok{end}
\VariableTok{obj} \OperatorTok{=} \VariableTok{trace}\NormalTok{(}\OperatorTok{{-}}\VariableTok{Rtld}\OperatorTok{*}\VariableTok{X}\NormalTok{)}\OperatorTok{;}
\VariableTok{optimize}\NormalTok{(}\VariableTok{F}\OperatorTok{,}\VariableTok{obj}\NormalTok{)}\OperatorTok{;}
\VariableTok{Xval} \OperatorTok{=} \VariableTok{value}\NormalTok{(}\VariableTok{X}\NormalTok{)}\OperatorTok{;}
\VariableTok{f\_sdp} \OperatorTok{=} \VariableTok{value}\NormalTok{(}\VariableTok{obj}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Note that \texttt{f\_sdp} will be a lower bound.

Let \(X_\star\) be the optimal solution of the SDP. We know that, if the SDP relaxation is tight, then \(X_\star\) will look like \(RR^\top\). Because \(R_1 = \mathrm{I}_3\), we can directly read off the optimal rotation estimations from the first row of blocks. However, if the relaxation is not tight, the blocks there will not be valid rotation matrices, and we can perform a projection onto \(\mathrm{SO}(3)\). Using the estimated rotations, I can compute \texttt{f\_est}, which is an upper bound to the true global optimum.

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{R\_est} \OperatorTok{=}\NormalTok{ []}\OperatorTok{;}
\VariableTok{R\_errs} \OperatorTok{=}\NormalTok{ []}\OperatorTok{;}
\KeywordTok{for} \VariableTok{i} \OperatorTok{=} \FloatTok{1}\OperatorTok{:}\VariableTok{n}
    \KeywordTok{if} \VariableTok{i} \OperatorTok{==} \FloatTok{1}
        \VariableTok{Ri} \OperatorTok{=} \VariableTok{eye}\NormalTok{(}\FloatTok{3}\NormalTok{)}\OperatorTok{;}
    \KeywordTok{else}
        \VariableTok{Ri} \OperatorTok{=} \VariableTok{project2SO3}\NormalTok{(}\VariableTok{Xval}\NormalTok{(}\FloatTok{1}\OperatorTok{:}\FloatTok{3}\OperatorTok{,}\VariableTok{blkIndices}\NormalTok{(}\VariableTok{i}\OperatorTok{,}\FloatTok{3}\NormalTok{)))}\OperatorTok{;}
    \KeywordTok{end}
    \VariableTok{R\_errs} \OperatorTok{=}\NormalTok{ [}\VariableTok{R\_errs}\OperatorTok{,} \VariableTok{getAngularError}\NormalTok{(}\VariableTok{Ri}\OperatorTok{,} \VariableTok{R\_gt}\NormalTok{(}\VariableTok{blkIndices}\NormalTok{(}\VariableTok{i}\OperatorTok{,}\FloatTok{3}\NormalTok{)}\OperatorTok{,:}\NormalTok{))]}\OperatorTok{;}
    \VariableTok{R\_est} \OperatorTok{=}\NormalTok{ [}\VariableTok{R\_est}\OperatorTok{,} \VariableTok{Ri}\NormalTok{]}\OperatorTok{;}
\KeywordTok{end}
\VariableTok{X\_est} \OperatorTok{=} \VariableTok{R\_est}\OperatorTok{\textquotesingle{}*}\VariableTok{R\_est}\OperatorTok{;}
\VariableTok{f\_est} \OperatorTok{=} \VariableTok{trace}\NormalTok{(}\OperatorTok{{-}}\VariableTok{Rtld}\OperatorTok{*}\VariableTok{X\_est}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

With \texttt{f\_est} and \texttt{f\_sdp}, an upper bound and a lower bound, I can compute the relative suboptimality gap \(\eta\). If \(\eta = 0\), then it certifies global optimality.

How does this work?

For \(N=30\) and \(\beta = 10\) (small noise), I got \(\eta = 6.26\times 10^{-13}\). Fig. \ref{fig:MVA-rot-err-30-10} plots the rotation estimation errors at each node compared to the groundtruth rotations.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/mva_rot_err_30_10} 

}

\caption{Rotation estimation errors, 30 nodes, noise bound 10 degrees.}\label{fig:MVA-rot-err-30-10}
\end{figure}

What if I increase the noise bound to \(\beta = 60\)? It turns out the relaxation is still exact with \(\eta = 6.84 \times 10^{-10}\)! Fig. \ref{fig:MVA-rot-err-30-60} plots the rotation estimation errors at each node compared to the groundtruth rotations.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/mva_rot_err_30_60} 

}

\caption{Rotation estimation errors, 30 nodes, noise bound 60 degrees.}\label{fig:MVA-rot-err-30-60}
\end{figure}

What if I set \(\beta = 120\)? The relaxation still remains exact with \(\eta = 9.5 \times 10^{-10}\). Fig. \ref{fig:MVA-rot-err-30-120} plots the rotation estimation errors at each node compared to the groundtruth rotations. Observe that even when the rotation estimates have large errors, they are still the certifiably optimal estimates.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/mva_rot_err_30_120} 

}

\caption{Rotation estimation errors, 30 nodes, noise bound 120 degrees.}\label{fig:MVA-rot-err-30-120}
\end{figure}

Play with the \href{https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/rotation_averaging/example.m}{code} yourself to appreciate the power of this simple SDP relaxation. You can, for example, increase the number of nodes \(N\). What if you make the graph sparse (e.g., fewer edges but still a connected graph)?
\end{example}

\subsection{Dual Optimality Certifier}\label{dual-optimality-certifier}

\section{Stretch to High-Degree Polynomial Optimization}\label{stretch-to-high-degree-polynomial-optimization}

We have seen that Shor's semidefinite relaxation for QCQPs can be derived both using Lagrangian duality, or simply by dropping a rank constraint, both of which are straightforward to understand. When applied to the MAXCUT problem, it produces a provably good approximation ratio. When applied to the rotation averaging problem, it directly gives us the optimal solution without any approximation, and the optimality comes with a certificate.

However, not every optimization problem is a QCQP, right? Is it possible to generalize Shor's semidefinite relaxation to higher-degree polynomial optimization problems? As we will see in the next Chapters, the moment and sums-of-squares (SOS) hierarchy delivers the perfect and principled generalization.

Before going to the moment-SOS hierarchy, let me give you an example of a quartic (degree-4) optimization problem, for which we can still use Shor's relaxation, albeit with some (in my opinion, not so elegant) mathematical massage. This example in fact is from a recent paper in computer vision \citep{briales18cvpr-certifiably}.

\textbf{Two-view Geometry}. Consider the problem of estimating the motion of a camera from two views illustrated in Fig. \ref{fig:two-view}. Let \(C_1\) and \(C_2\) be two cameras (or the same camera but in two different positions) observing the same 3D point \(p \in \mathbb{R}^{3}\). The 3D point will be observed by \(C_1\) and \(C_2\) via its 2D projections on the image plane, respectively. Let \(f_1 \in \mathbb{R}^{3}\) and \(f_2 \in \mathbb{R}^{3}\) be the unit-length bearing vector that emanates from the camera centers to the 2D projections in two cameras, respectively. Our goal is to estimate the relative rotation and translation between the two cameras \(C_1\) and \(C_2\), denoted by \(R \in \mathrm{SO}(3)\) and \(t \in \mathbb{R}^{3}\). The pair of bearing vectors \((f_1,f_2)\) is typically known as a \textbf{correspondence}, or a \textbf{match} in computer vision.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/two_view} 

}

\caption{Two-view Geometry.}\label{fig:two-view}
\end{figure}

It turns out only having one correspondence is insufficient to recover \((R,t)\), and we need at least \(5\) such correspondences \citep{nister04pami-efficient}. See Fig. \ref{fig:two-view-example} for an example I adapted from \href{https://www.mathworks.com/help/vision/ref/estimateessentialmatrix.html}{Mathworks}.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{images/two_view_example_matlab} 

}

\caption{A real two-view motion estimation example. Copyright: Mathworks.}\label{fig:two-view-example}
\end{figure}

Consequently, to formally state our problem, we are given a set of \(N\) correspondences (these correspondences are typically detected by neural networks today \citep{wang20eccv-caps})
\[
\{f_{1,i},f_{2,i} \}_{i=1}^N
\]
between two images taken by two cameras, and our goal is to estimate the relative motion \((R,t)\).

\textbf{Epipolar Constraint}. When the correspondences are noise-free, it is known that they must satisfy the following epipolar constraint \citep{hartley03book-multiple}
\begin{equation}
f_{2,i}^\top[t]_{\times} R f_{1,i} = 0, \quad \forall i=1,\dots,N,
\label{eq:epipolar-constraint}
\end{equation}
where
\[
[t]_{\times} := \begin{bmatrix} 0 & - t_3 & t_2 \\
t_3 & 0 & - t_1 \\
- t_2 & t_1 & 0 \end{bmatrix}
\]
is a linear map such that \(t \times v = [t]_{\times} v\) for any \(v \in \mathbb{R}^{3}\) and \(\times\) denotes cross product in 3D.

\textbf{Nonlinear Least Squares}. Since the correspondences are detected by neural networks, they will be noisy and the epipolar constraint \eqref{eq:epipolar-constraint} will not be perfectly satisfied. Therefore, we formulate the following optimization problem to seek the best estimate that minimize the sum of the squared violations of \eqref{eq:epipolar-constraint}
\begin{equation}
\min_{R \in \mathrm{SO}(3), t \in \mathcal{S}^{2}} \sum_{i=1}^N (f_{2,i}^\top[t]_{\times} R f_{1,i})^2
\label{eq:two-view-estimation-problem}
\end{equation}
Note that I have asked \(t \in \mathcal{S}^{2}\) to lie on the unit sphere, why?

Problem \eqref{eq:two-view-estimation-problem} is not a QCQP anymore, because its objective is a degree-4 polynomial. However, all the constraints of \eqref{eq:two-view-estimation-problem} are quadratic equalities and inequalities. To see this, note that \(t \in \mathcal{S}^{2}\) can be written as
\begin{equation}
1 - t^\top t = 0,
\label{eq:two-view-t-con}
\end{equation}
which is a quadratic polynomial equality.
The constraint \(R \in \mathrm{SO}(3)\) can also be written as quadratic equalities. Let
\[
R = [c_1, c_2, c_3]
\]
where \(c_i\) is the \(i\)-the column. Then \(R\in \mathrm{SO}(3)\) is equivalent to
\begin{equation}
\begin{split}
c_i^\top c_i - 1= 0, & \quad i=1,2,3 \\
c_i^\top c_j = 0, & \quad (i,j) \in \{ (1,2),(2,3),(3,1) \} \\
c_i \times c_j = c_k,& \quad (i,j,k) \in \{ (1,2,3),(2,3,1),(3,1,2) \}. 
\end{split}
\label{eq:two-view-R-con}
\end{equation}
all of which are quadratic polynomial equalities.

Let \(r = \mathrm{vec}(R)\), \(x = [r^\top, t^\top]^\top\in \mathbb{R}^{12}\), we will collectively call all the constraints in \eqref{eq:two-view-t-con} and \eqref{eq:two-view-R-con} as
\[
h_k(x) = 0, k=1,\dots,l, 
\]
with \(l=16\).

\textbf{Semidefinite Relaxation}. Clearly, we cannot directly apply Shor's semidefinite relaxation, because \(X = xx^\top\) only contains monomials in \(x\) of degree up to \(2\), but our objective function is degree \(4\) -- this matrix variable is not powerful enough.

To fix this issue, a natural idea is to create a larger matrix variable
\begin{equation}
\hspace{-16mm}
v = \begin{bmatrix} 
1 \\ r \\ t \\ t_1 r \\ t_2 r \\ t_3 r \end{bmatrix} \in \mathbb{R}^{40}, \quad X = vv^\top= \begin{bmatrix} 1 & * & * & * & * & * \\
r & rr^\top& * & * & * & * \\
t & tr^\top& tt^\top& * & * & * \\
t_1 r & t_1 rr^\top& t_1 r t^\top& t_1^2 rr^\top& * & * \\
t_2 r & t_2 rr^\top& t_2 r t^\top& t_1 t_2 rr^\top& t_2^2 rr^\top& * \\
t_3 r & t_3 rr^\top& t_3 r t^\top& t_3 t_1 rr^\top& t_3 t_2 rr^\top& t_3^2 rr^\top\end{bmatrix} \in \mathbb{S}^{40}_{+}
\label{eq:two-view-larger-X}
\end{equation}
Note that now \(X\) has degree-4 monomials, which allows me to write the objective of the original problem \eqref{eq:two-view-estimation-problem} as
\[
\langle C, X \rangle
\]
with a suitable constant matrix \(C \in \mathbb{S}^{40}\).

I can also write all the original constraints \(h_k(x) = 0,k=1,\dots,l\) as
\[
\langle A_k, X \rangle = 0, k=1,\dots,l,
\]
plus an additional constraint
\[
\langle A_0, X \rangle = 1, 
\]
where \(A_0\) is all zero except its top-left entry is equal to 1.

This seems to be all we need for Shor's relaxation, will this work?

\textbf{``Redundant'' Constraints}. In the original paper \citep{briales18cvpr-certifiably}, the authors found that we are missing some important constraints that we can add to the convex SDP. For example, in the matrix \(X\), we have
\[
t_1^2 rr^\top+ t_2^2 rr^\top+ t_3^2 rr^\top= (t_1^2 + t_2^2 + t_3^2) rr^\top= rr^\top,
\]
which gives us additional linear constraints on the entries of \(X\) (for free)! Essentially, these constraints are generated by multiplying the original constraints \(h_k(x)\) by suitable monomials:
\[
h_k(x) = 0 \Rightarrow h_k(x) \cdot \lambda(x) = 0,
\]
where \(\lambda(x)\) is a monomial such that all the monomials of \(h_k(x) \cdot \lambda(x)\) appear in the big matrix \(X\) (so that the resulting equality constraint can still be written as a linear equality on \(X\)). The authors of \citep{briales18cvpr-certifiably} enumerated all such constraints (by hand) and added them to the SDP relaxation, which led to the relaxation going from loose to tight/exact.

\citep{briales18cvpr-certifiably} called these constraints ``redundant'', are they? We will revisit this after we study the moment-SOS hierarchy!

\chapter{Sums of Squares Relaxation}\label{SOS}

\section{Basic Algebraic Geometry}\label{basic-algebraic-geometry}

We first review several basic concepts in algebraic geometry. We refer to standard textbooks for a more comprehensive treatment \citep{bochnak13book-real}, \citep{cox13book-ideals}, \citep{dummit04book-abstract}, \citep{lang12book-algebra}.

\subsection{Groups, Rings, Fields}\label{groups-rings-fields}

\begin{definition}[Group]
\protect\hypertarget{def:Group}{}\label{def:Group}

A \textbf{group} consists of a set \(G\) and a binary operation ``\(\cdot\)'' defined on \(G\) that satisfies the following conditions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Associative: \((a \cdot b) \cdot c = a \cdot (b \cdot c)\), for all \(a,b,c \in G\).
\item
  Identity: there exists \(1 \in G\) such that \(1 \cdot a = a \cdot 1 = a\), for all \(a \in G\).
\item
  Inverse: Given \(a \in G\), there exists \(b \in G\) such that \(a \cdot b = b \cdot a = 1\).
\end{enumerate}

\end{definition}

For example, the integers \(\mathbb{Z}\) form a group under addition, but not under multiplication; the set \(GL(n,\mathbb{R}^{})\) that contains nonsingular \(n \times n\) matrices forms a group under the usual matrix multiplication. Another example is the set of rotation matrices \(\mathrm{SO}(d):= \{ R \in \mathbb{R}^{d \times d} \mid RR^\top= \mathrm{I}_d, \det(R) = +1 \}\).

In a group we only have one binary operation (``multiplication''). We will introduce another operation (``addition'').

\begin{definition}[Commutative Ring]
\protect\hypertarget{def:Ring}{}\label{def:Ring}

A \textbf{commutative ring} (with identity) consists of a set \(S\) and two binary operations ``\(\cdot\)'' and ``\(+\)'' defined on \(S\) that satisfy the following conditions

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Associative: \((a+b)+c = a + (b+c)\), and \((a \cdot b) \cdot c = a \cdot (b \cdot c)\), for all \(a,b,c \in S\).
\item
  Commutative: \(a+b=b+a\) and \(a\cdot b = b \cdot a\), for all \(a,b \in S\).
\item
  Distributive: \(a \cdot (b+c) = a\cdot b + a \cdot c\) for all \(a,b,c \in S\).
\item
  Identities: there exist \(0, 1 \in S\) such that \(a + 0 = a \cdot 1 = a\), for all \(a \in S\).
\item
  Additive inverse: given \(a \in S\), there exists \(b \in S\) such that \(a + b = 0\).
\end{enumerate}

\end{definition}

A simple example of a ring is the set of integers \(\mathbb{Z}\) under the usual addition and multiplication.

If we add a requirement for the existence of multiplicative inverse, we obtain a field.

\begin{definition}[Field]
\protect\hypertarget{def:Field}{}\label{def:Field}

A \textbf{field} consists of a set \(S\) and two binary operations ``\(\cdot\)'' and ``\(+\)'' defined on \(S\) that satisfy the following conditions

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Associative: \((a+b)+c = a + (b+c)\), and \((a \cdot b) \cdot c = a \cdot (b \cdot c)\), for all \(a,b,c \in S\).
\item
  Commutative: \(a+b=b+a\) and \(a\cdot b = b \cdot a\), for all \(a,b \in S\).
\item
  Distributive: \(a \cdot (b+c) = a\cdot b + a \cdot c\) for all \(a,b,c \in S\).
\item
  Identities: there exist \(0, 1 \in S\), where \(0 \neq 1\), such that \(a + 0 = a \cdot 1 = a\), for all \(a \in S\).
\item
  Additive inverse: given \(a \in S\), there exists \(b \in S\) such that \(a + b = 0\).
\item
  Multiplicative inverse: given \(a \in S\) and \(a \neq 0\), there exists \(c \in S\) such that \(a \cdot c = 1\).
\end{enumerate}

\end{definition}

Any field is obvious a commutative ring. Some commonly used fields are the rationals \(\mathbb{Q}\), the reals \(\mathbb{R}^{}\), and the complex numbers \(\mathbb{C}\). Another important field is given by \(k(x_1,\dots,x_n)\), the set of rational functions with coefficients in the field \(k\), with the natural operations.

\subsection{Polynomials, Ideals, and Varieties}\label{polynomials-ideals-and-varieties}

We will use \(\mathbb{F}= \mathbb{R}\) or \(\mathbb{C}\) to denote the field of real or complex numbers from now on. Let \(x_1,\dots,x_n\) be indeterminates, we can define a polynomial.

\begin{definition}[Polynomial]
\protect\hypertarget{def:Polynomial}{}\label{def:Polynomial}A polynomial \(f\) in \(x_1,\dots,x_n\) with coefficients in a field \(\mathbb{F}\) is a finite linear combination of monomials:
\[
f = \sum_{\alpha} c_\alpha x^\alpha = \sum_{\alpha} c_\alpha x_1^{\alpha_1}\cdots x_n^{\alpha_n}, \quad c_\alpha \in \mathbb{F},
\]
where the sum is over a finite number of \(n\)-tuples (exponents) \(\alpha = (\alpha_1,\dots,\alpha_n)\), \(\alpha_i \in \mathbb{N}\). The set of all polynomials in \(x\) with coefficients in \(\mathbb{F}\) is denoted \(\mathbb{F}[x]\) or \(\mathbb{F}[x_1,\dots,x_n]\).
\end{definition}

The \textbf{degree} of a monomial is the sum of its exponents:
\[
\deg(x^\alpha) = \deg(x_1^{\alpha_1}\cdots x_n^{\alpha_n}) = \sum_{i=1}^n \alpha_i.
\]
The degree of a polynomial is the maximum degree of its monomials:
\[
\deg(f) = \max_{\alpha} \deg(x^\alpha).
\]

It is clear that \(\mathbb{F}[x]\) is a commutative ring with the \(0\) and \(1\) identities.

A \textbf{form} is a polynomial where all the monomials have the same degree. It is also called a \textbf{homogeneous polynomial}. For example,
\[
f = 2 x_1^2 + x_1 x_2 + x_2^2
\]
is a form of degree \(2\). A homogeneous polynomial of degree \(d\) satisfies
\[
f(\lambda x_1,\dots,\lambda x_n) = \lambda^d f(x_1,\dots,x_n).
\]

A polynomial in \(n\) variables of degree \(d\) has
\[
s(n,d) = \begin{pmatrix} n + d \\ d \end{pmatrix}
\]
coefficients. Let \(\mathbb{F}[x]_{d}\) be the set of polynomials in \(n\) variables of degree \(d\), then any \(f \in \mathbb{F}[x]_d\) can be written as
\[
f = c^\top[x]_d, \quad c \in \mathbb{F}^{s(n,d)}
\]
with \([x]_d\) the \textbf{standard monomial basis} in \(x\) of degree up to \(d\). For example, when \(x = (x_1,x_2)\), then
\[
[x]_2 = \begin{bmatrix} 1 \\ x_1 \\ x_2 \\ x_1^2 \\ x_1 x_2 \\ x_2^2 \end{bmatrix}.
\]

Let \(G\) be a set of polynomials, and \(\mathbb{F}[G]\) denote the set of all polynomials that can be written as
\[
\sum_{\alpha} c_\alpha g_1^{\alpha_1} \cdots g_k^{\alpha_k}, \quad c_\alpha \in \mathbb{F}, g_1,\dots,g_k \in G
\]
with finitely many nonzero coefficients. The polynomials in \(G\) are called \textbf{generators} and \(G\) is called a \textbf{generator set} for \(\mathbb{F}[G]\). Clearly, the set
\[
G = \{1, x_1, \dots, x_n\}
\]
is a generator set for \(\mathbb{F}[x]\).

We consider next ideals, which are subrings with an ``absorbent'' property.

\begin{definition}[Ideal]
\protect\hypertarget{def:Ideal}{}\label{def:Ideal}

Let \(R\) be a commutative ring. A subset \(I \subset R\) is an ideal if it satisfies

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(0 \in I\).
\item
  If \(a, b \in I\), then \(a + b \in I\).
\item
  If \(a \in I\) and \(b \in R\), then \(a \cdot b \in I\).
\end{enumerate}

\end{definition}

A simple example of an ideal is the set of even integers, considered as a subset of the integer ring \(\mathbb{Z}\). If the ideal \(I\) contains the multiplicative identity ``\(1\)'', then \(I = R\). For a tuple \(h = (h_1,\dots,h_s)\) of polynomials in \(\mathbb{F}[x]\), \(\mathrm{Ideal}[h]:= \mathrm{Ideal}[h_1,\dots,h_m]\) denotes the smallest ideal containing \(h\), or equivalently
\[
\mathrm{Ideal}[h] = h_1 \cdot \mathbb{F}[x] + \cdots + h_s \cdot \mathbb{F}[x].
\]
The set \(\mathrm{Ideal}[h]\) is called the ideal generated by \(h\). Every ideal of \(\mathbb{F}[x]\) is generated by finitely many polynomials, i.e., every ideal is \textbf{finitely generated}.

\begin{theorem}[Hilbert Basis Theorem]
\protect\hypertarget{thm:HilbertBasisTheorem}{}\label{thm:HilbertBasisTheorem}For every ideal \(I \subseteq \mathbb{F}[x]\), there exist finitely many polynomials \(g_1,\dots,g_m \in I\) such that \(I = \mathrm{Ideal}[g_1,\dots,g_m]\).
\end{theorem}

We define the concept of an \textbf{algebraic variety} as the zero set of a set of polynomial equations.

\begin{definition}[Affine Variety]
\protect\hypertarget{def:AffineVariety}{}\label{def:AffineVariety}Let \(f_1,\dots,f_s \in \mathbb{F}[x_1,\dots,x_n]\) and \(x = (x_1,\dots,x_n)\), and the set \(V\) be
\[
V_{\mathbb{F}}(f_1,\dots,f_s) = \{ x \in \mathbb{F}^{n}\mid f_i(x) = 0, i=1,\dots,s \}.
\]
We call \(V_{\mathbb{F}}(f_1,\dots,f_s)\) the affine variety defined by \(f_1,\dots,f_s\).
\end{definition}

Similarly, let \(I \subset \mathbb{F}[x]\) be an ideal, we denote its zero set as
\[
V_{\mathbb{F}}(I) = \{ x \in \mathbb{F}^n \mid f(x) = 0, \forall f \in I \}.
\]
Since the ideal is finitely generated, we have
\[
V_{\mathbb{F}}(I) = V_{\mathbb{F}}(g_1,\dots,g_m),
\]
where \(g_1,\dots,g_m\) are the generators of \(I\).

The set of polynomials that vanish in a given variety, i.e.,
\[
I(V)= \{ f \in \mathbb{F}[x] \mid f(x) = 0, \forall x \in V \},
\]
is an ideal, called the \textbf{vanishing ideal} of \(V\).

We define the \textbf{radical} of an ideal.

\begin{definition}[Radical]
\protect\hypertarget{def:Radical}{}\label{def:Radical}Let \(I \subset \mathbb{F}[x]\) be an ideal. The radical of \(I\), denoted \(\sqrt{I}\), is the set
\[
\sqrt{I} := \{ f \mid f^k \in I \text{ for some integer }k \}.
\]
\end{definition}

It is clear that \(I \subset \sqrt{I}\), and it can be shown that \(\sqrt{I}\) is also a polynomial ideal.

Given an ideal \(I\) and \(V_{\mathbb{C}}(I)\), it is clear that any \(f \in I\) vanishes on \(V_{\mathbb{C}}(I)\), that is
\[
I \subseteq I(V_{\mathbb{C}}(I)).
\]
However, not all polynomials that vanish on \(V_{\mathbb{C}}(I)\) belong to \(I\).

\begin{theorem}[Hilbert's Nullstellensatz]
\protect\hypertarget{thm:HilbertNull}{}\label{thm:HilbertNull}

Let \(I \subseteq \mathbb{C}[x]\) be an ideal.

\begin{itemize}
\item
  (Weak Nullstellensatz) If \(V_{\mathbb{C}}(I) = \emptyset\), then \(1 \in I\).
\item
  (Strong Nullstellensatz) For \(f \in \mathbb{C}[x]\), if \(f(u) = 0\) for all \(u \in V_{\mathbb{C}}(I)\), then \(f^k \in I\) for some integer \(k \geq 1\), i.e., \(I(V_{\mathbb{C}}(I)) = \sqrt{I}\).
\end{itemize}

\end{theorem}

Let us see an example of Hilbert's Nullstellensatz.

\begin{example}[Hilbert's Nullstellensatz]
\protect\hypertarget{exm:HilbertNullstellensatz}{}\label{exm:HilbertNullstellensatz}Consider the ideal
\[
I=\mathrm{Ideal}[x_1^2 x_2^3, x_1 x_2^4].
\]
The affine variety defined by \(I\) is
\[
V = V_{\mathbb{C}}(I) = \{ (x_1,x_2) \in \mathbb{C}^2 \mid x_1^2 x_2^3 = 0, x_1 x_2^4=0 \}.
\]
It is easy to see that the variety is the union of the two coordinate axes \(x_1=0\) and \(x_2 = 0\).

Therefore, the polynomial \(x_1x_2\) vanishes on the variety \(V\), but \(x_1 x_2\) does not belong to the ideal \(I\) (because the degree is lower).

We claim that
\[
\sqrt{I} = \mathrm{Ideal}[x_1 x_2].
\]
Indeed, \(x_1 x_2 \in \sqrt{I}\) because
\[
(x_1x_2)^3 = x_1^3 x_2^3 = x_1 \cdot x_1^2 x_3^3 \in I.
\]
Conversely, if \(f \in \sqrt{I}\), then \(f^k \in I\) for some integer \(k\), i.e.,
\[
f^k = x_1^2 x_2^3 p(x) + x_1 x_2^4 q(x) = x_1 x_2 r(x)
\]
which implies \(f^k \in \mathrm{Ideal}[x_1 x_2]\). Therefore, all the polynomials that vanish on the variety \(V\) can be generated by \(x_1 x_2\).

As another example, consider the ideal generated by a single univariate polynomial
\[
I = \mathrm{Ideal}[f], \quad f = \prod_{i=1}^{s} (x - a_i)^{n_i}
\]
with \(a_i \neq a_j\) for \(i \neq j\) the unique roots of the polynomial \(f\). Clearly, the affine variety defined by \(I\) is the set of unique roots:
\[
V= V_{\mathbb{C}}(I) = \{a_1,\dots,a_s\}.
\]
The vanishing ideal of \(V\) is
\[
\sqrt{I} = \mathrm{Ideal}[(x-a_1)\cdots (x-a_s)].
\]
\end{example}

\subsection{Grbner Bases}\label{gruxf6bner-bases}

A polynomial ideal can have different ``descriptions'' in terms of its generators. We will now focus on a particular type of description that is better than the others.

Let's first define a monomial ordering.

\begin{definition}[Monomial Ordering]
\protect\hypertarget{def:MonomialOrdering}{}\label{def:MonomialOrdering}

A monomial ordering on \(\mathbb{C}[x]\) is a binary relation \(\succ\) on \(\mathbb{N}^n\), i.e., the exponents of the monomials, that satisfies

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The relation \(\succ\) is a total ordering, i.e., given any two monomials \(x^{\alpha}, x^{\beta}\), we must have either \(x^{\alpha} \succ x^{\beta}\), or \(x^\beta \succ x^\alpha\), or \(x^\alpha = x^\beta\).
\item
  If \(x^\alpha \succ x^\beta\), then \(x^\alpha \cdot x^\gamma \succ x^\beta \cdot x^\gamma\) for any monomial \(x^\gamma\).
\item
  The relation \(\succ\) is well ordered, i.e., every nonempty set has a smallest element under \(\succ\).
\end{enumerate}

\end{definition}

There are several monomial orderings of interest in computational algebra.

\begin{itemize}
\item
  \textbf{Lexicographic} (``dictionary''). Here \(\alpha \succ_{\mathrm{lex}}\beta\) if the left-most nonzero entry of \(\alpha - \beta\) is positive. Note that a particular ordering of the variables is assumed.
\item
  \textbf{Graded lexicographic}. Sort first by total degree, then Lexicographic, i.e., \(\alpha \succ_{\mathrm{grlex}}\beta\) if \(|\alpha| > |\beta|\), or \(|\alpha| = |\beta|\) and \(\alpha \succ_{\mathrm{lex}}\beta\).
\item
  \textbf{Graded reverse lexicographic}. Here \(\alpha \succ_{\mathrm{grevlex}}\beta\) if \(|\alpha| > |\beta|\) or \(|\alpha| = |\beta|\) but the right-most nonzero entry of \(\alpha - \beta\) is negative. This ordering, although somewhat nonintuitive, has some desirable computational properties.
\end{itemize}

\begin{example}[Monomial Ordering]
\protect\hypertarget{exm:MonomialOrdering}{}\label{exm:MonomialOrdering}Consider the polynomial ring \(\mathbb{C}[x,y]\) in two variables. With the lexicographic ordering \(\prec_{\mathrm{lex}}\), we have
\[
1 \prec_{\mathrm{lex}}y \prec_{\mathrm{lex}}y^2 \prec_{\mathrm{lex}}\cdots \prec_{\mathrm{lex}}x \prec_{\mathrm{lex}}xy \prec_{\mathrm{lex}}xy^2 \prec_{\mathrm{lex}}\cdots \prec_{\mathrm{lex}}x^2 \prec_{\mathrm{lex}}x^2 y \prec_{\mathrm{lex}}x^2 y^2 \prec_{\mathrm{lex}}\cdots.
\]
For the other two orderings \(\prec_{\mathrm{grlex}}\) and \(\prec_{\mathrm{grevlex}}\), which in the case of two variables are the same, we have
\[
1 \prec y \prec x \prec y^2 \prec xy \prec x^2 \prec y^3 \prec xy^2 \prec x^2 y \prec x^3 \prec \cdots.
\]

As another example, consider the monomials \(\alpha = x^3 y^2 z^8\) and \(\beta = x^2 y^9 z^2\). If the variables are ordered as \((x,y,z)\), then
\[
\alpha \succ_{\mathrm{lex}}\beta, \quad \alpha \succ_{\mathrm{grlex}}\beta, \quad \alpha \prec_{\mathrm{grevlex}}\beta.
\]
Note that \(x \succ y \succ z\) for all three orderings.
\end{example}

We define a monomial ideal.

\begin{definition}[Monomial Ideal]
\protect\hypertarget{def:MonomialIdeal}{}\label{def:MonomialIdeal}A monomial ideal is a polynomial ideal that can be generated by monomials.
\end{definition}

What are the possible monomials that belong to a given monomial ideal? Since \(x^\alpha \in I \Rightarrow x^{\alpha + \beta} \in I\) for any \(\beta \geq 0\), we have that these sets are ``closed upwards''.

A polynomial belongs to a monomial ideal \(I\) if and only if its terms are in \(I\).

Similarly, we have that every monomial ideal is finitely generated.

\begin{theorem}[Dickson's Lemma]
\protect\hypertarget{thm:Dickson}{}\label{thm:Dickson}Every monomial ideal is finitely generated.
\end{theorem}

We next consider a special monomial ideal, associated with every polynomial ideal. From now on, we assume a fixed monomial ordering (e.g., graded reverse lexicographic), and define the notion of an initial ideal.

\begin{definition}[Initial Ideal]
\protect\hypertarget{def:InitialIdeal}{}\label{def:InitialIdeal}Denote by \(\mathrm{in}(f)\) the ``largest'' (or leading) monomial appearing in the polynomial \(f\neq 0\). Consider an ideal \(I \subset \mathbb{C}[x]\) with a fixed monomial ordering. The initial ideal of \(I\), denoted by \(\mathrm{in}(I)\), is the monomial ideal generated by the leading monomials of all the elements in \(I\), i.e.,
\[
\mathrm{in}(I) = \mathrm{Ideal}[\{ \mathrm{in}(f) \mid f \in I \backslash \{0\} \}].
\]
A monomial \(x^\alpha\) is called \textbf{standard} if it does not belong to the initial ideal \(\mathrm{in}(I)\).
\end{definition}

Given an ideal \(I = \mathrm{Ideal}[f_1,\dots,f_s]\), we can construct two monomial ideals associated with it:

\begin{itemize}
\item
  The initial ideal \(\mathrm{in}(I)\) as defined in Definition \ref{def:InitialIdeal}.
\item
  The monomial ideal generated by the leading monomials of the generators, i.e.,
  \[
  \mathrm{Ideal}[\mathrm{in}(f_1),\dots,\mathrm{in}(f_s)].
  \]
\end{itemize}

Clearly, we have
\[
\mathrm{Ideal}[\mathrm{in}(f_1),\dots,\mathrm{in}(f_s)] \subseteq \mathrm{in}(I).
\]

\begin{example}[Initial Ideal and the Ideal of Initials]
\protect\hypertarget{exm:InitialIdeal}{}\label{exm:InitialIdeal}Consider the ideal
\[
I = \mathrm{Ideal}[x^3 -1, x^2 + 1],
\]
we have \(1 \in I\) due to
\[
1 = \frac{1}{2}(x-1)(x^3 - 1) - \frac{1}{2}(x^2 - x - 1)(x^2 +1).
\]
Therefore, \(\mathrm{in}(I) = I = \mathbb{C}[x]\). On the other hand, the monomial ideal generated by the leading monomials is
\[
\mathrm{Ideal}[x^3, x^2],
\]
and clearly does not contain \(1\).
\end{example}

We have seen that in general these two monomial ideals are not the same. However, is it possible to find a set of generators for which the two monomial ideals are the same? This is exactly the notion of a Grbner basis.

\begin{definition}[Grbner Basis]
\protect\hypertarget{def:GrobnerBasis}{}\label{def:GrobnerBasis}Consider the polynomial ring \(\mathbb{C}[x]\), a fixed monomial ordering, and an ideal \(I\). A finite set of polynomials \(\{ g_1,\dots,g_s \} \subset I\) is a Grbner basis of \(I\) if the initial ideal of \(I\) is generated by the leading terms of the \(g_i\)'s, i.e.,
\[
\mathrm{in}(I) = \mathrm{Ideal}[\mathrm{in}(g_1),\dots,\mathrm{in}(g_s)].
\]
\end{definition}

We have the result that every ideal has a Grobner basis.

\begin{theorem}[Grbner Basis]
\protect\hypertarget{thm:GrobnerBasis}{}\label{thm:GrobnerBasis}Every ideal \(I\) has a Grobner basis. Further, \(I = \mathrm{Ideal}[g_1,\dots,g_s]\).
\end{theorem}

Theorem \ref{thm:GrobnerBasis} indeed proves the Hilbert Basis Theorem \ref{thm:HilbertBasisTheorem}.

Note that the Grobner basis as defined is not unique. It can be fixed to define a so-called \textbf{reduced Grbner Basis}, which is unique when fixing a monomial ordering.

There exist numerical algorithms that can compute the Grobner basis. The most well-known algorithm is called Buchberger's algorithm, developed by Bruno Buchberger around 1965. The algorithm, however, is in general slow because it is double exponential time. Several software packages provide implementations that can compute the Grobner basis, for example Mathematica, Maple, Macaulay2, and Matlab.

\begin{example}[Grobner Basis]
\protect\hypertarget{exm:GrobnerBasis}{}\label{exm:GrobnerBasis}Consider the ideal \(I = \mathrm{Ideal}[x^2+y^2-2, x^2 - y^2]\). The affine variety of \(I\) is finite and only contains four points \((\pm 1, \pm 1)\). It is easy to see that the given generators are not a Grobner basis.

Computing a Grobner basis (e.g., using the \href{https://www.mathworks.com/help/symbolic/sym.gbasis.html}{Matlab \texttt{gbasis} function}) gives us
\[
\{ x^2 - 1, y^2 - 1 \}.
\]
The standard monomials are \(\{ 1,x,y,xy \}\).
\end{example}

We will see that Grobner basis is a powerful tool with many applications in computational algebra. For a brief introduction to Grobner Basis, see \citep{sturmfels05notes-grobner}.

\subsection{Quotient Ring}\label{quotient-ring}

Given an ideal \(I\), we can immediately define a notion of \textbf{equivalence classess}, where we identify two elements in the ring if and only if their difference is in the ideal.

For example, in the ring of integers \(\mathbb{Z}\), the set of even integers is an ideal. We can identify two integers as the same if their difference is even. This effectively divides the ring \(\mathbb{Z}\) into two equivalence classess, the set of odd and even integers.

We can do the same for the ring of polynomials \(\mathbb{C}[x]\) given an ideal \(I\).

\begin{definition}[Congruence]
\protect\hypertarget{def:CongruenceIdeal}{}\label{def:CongruenceIdeal}Let \(I \subset \mathbb{C}[x]\) be an ideal. We are two polynomials \(f,g \in \mathbb{C}[x]\) is \textbf{congruent} modulo \(I\), written as
\[
f \equiv g \quad \text{mod } I,
\]
if \(f - g \in I\).
\end{definition}

It is easy to see that this is an \href{https://en.wikipedia.org/wiki/Equivalence_relation}{equivalence relation}, i.e., it is reflexive, symmetric, and transitive. Therefore, an ideal \(I\) partitions \(\mathbb{C}[x]\) into equivalence classes, where two polynomials are the same if their difference belongs to the ideal. This allows us to define the notion of a quotient ring.

\begin{definition}[Quotient Ring]
\protect\hypertarget{def:QuotientRing}{}\label{def:QuotientRing}The quotient \(\mathbb{C}[x]/I\) is the set of equivalence classes for congruence modulo \(I\).
\end{definition}

The quotient \(\mathbb{C}[x]/I\) inherits the ring structure of \(\mathbb{C}[x]\). With the addition and multiplication operations defined between equivalence classes, \(\mathbb{C}[x]/I\) becomes a ring, known as the quotient ring. Indeed, given a polynomial \(p\), the set of all polynomials equivalent to \(p\) is denoted as
\[
[p]:= \{ p + q \mid q \in I \}.
\]
We have \([p] = [q]\) if and only if \(p - q \in I\). Given two equivalent classes \([p]\) and \([q]\), the addition and multiplication are defined as
\[
[p] + [q] = [p+q], \quad [p] \cdot [q] = [p q].
\]
One can verify that \((\mathbb{C}[x],+,\cdot)\) with \(+\) and \(\cdot\) defined above forms a ring structure.

The quotient ring \(\mathbb{C}[x]/I\) is in fact a vector space, and the Grobner basis gives us a way to find a set of basis in the quotient ring! Let \(G\) be a Grobner basis of the ideal \(I\), and recall from Definition \ref{def:InitialIdeal} that a monomial is standard if it does not belong to the initial ideal \(\mathrm{in}(I)\). This implies that when the Grobner basis is available, the set of all \textbf{standard monomials} can be directly read off from the Grobner basis, as in Example \ref{exm:GrobnerBasis}. Let \(S\) be this set of standard monomials, then the basis of the quotient ring is simply
\[
\{ [s] \mid s\in S \}.
\]
Note that the quotient ring needs not be finite-dimensional as the set of standard monomials can be infinite. Given such a basis of the quotient ring, we can associate every polynomial with a \textbf{normal form} that is a linear combination of the standard monomials.

\begin{definition}[Normal Form]
\protect\hypertarget{def:NormalForm}{}\label{def:NormalForm}

Let \(G\) be a Grobner basis of the ideal \(I \subset \mathbb{C}[x]\). Given any \(p \in \mathbb{C}[x]\), there exists a unique polynomial \(\bar{p}\), called the \textbf{normal form} of \(p\) such that

\begin{itemize}
\item
  \(p\) and \(\bar{p}\) are congruent mod \(I\), i.e., \(p - \bar{p} \in I\).
\item
  Only standard monomials appear in \(\bar{p}\).
\end{itemize}

\end{definition}

Note that since \(p - \bar{p} \in I\), we have
\[
p = \sum_{i}^s\lambda_i g_i + \bar{p}, \quad g_i \in G.
\]
Therefore, the normal form \(\bar{p}\) can be interpreted as the ``reminder'' of \(p\) divided by the ideal \(I\). The unique property of the Grobner basis ensures that the normal form is unique and it is just a \(\mathbb{C}\)-combination of the standard monomials.

As a consequence, we can check the ideal membership of a given polynomial. Indeed, a polynomial \(p\) belongs to the ideal \(I\) if and only if its normal form is the zero polynomial.

See an example of using Grobner basis to compute the normal form in the \href{https://www.maplesoft.com/support/help/maple/view.aspx?path=Groebner\%2FNormalForm}{Maple software}.

\subsection{Zero-dimensional Ideal}\label{ZeroDimIdeal}

In practice, we are often interested in polynomial systems that have only a finite number of solutions, in which case the associated ideal is called zero-dimensional.

\begin{definition}[Zero-Dimensional Ideal]
\protect\hypertarget{def:ZeroDimensional}{}\label{def:ZeroDimensional}An ideal \(I\) is zero-dimensional if the associated affine variety \(V_{\mathbb{C}}(I)\) is a finite set.
\end{definition}

Note that the variety \(V_{\mathbb{C}}(I)\) having a finite number of points is stronger than \(V_{\mathbb{R}}(I)\) have a finite number of points.

The following result characterizes when an ideal is zero-dimensional.

\begin{theorem}[Finiteness Theorem]
\protect\hypertarget{thm:FiniteTheorem}{}\label{thm:FiniteTheorem}

Let \(I \subset \mathbb{C}[x]\) be an ideal. Fix a monomial ordering and let \(G\) be a Grobner basis of \(I\). Then the following statements are equivalent.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The ideal \(I\) is finite-dimensional (i.e., \(V(I)\) is a finite set of points).
\item
  The quotient ring \(\mathbb{C}[x]/I\) is a finite-dimensional vector space (i.e., there are a finite number of standard monomials).
\item
  For each \(x_i, i=1,\dots,n\), there exists an integer \(m_i \in \mathbb{N}\) such that \(x_i^{m_i}\) is the leading monomial of some \(g \in G\).
\end{enumerate}

\end{theorem}

Let us work out an example.

\begin{example}[Zero-dimensional Ideal]
\protect\hypertarget{exm:ZeroDIdeal}{}\label{exm:ZeroDIdeal}Consider the ideal in \(\mathbb{C}[x,y]\):
\[
I = \mathrm{Ideal}[xy^3-x^2, x^3y^2 - y].
\]
Using the graded lexicographic monomial ordering, we obtain the reduced Grobner basis
\[
G = \{ x^3 y^2 - y, x^4 - y^2,  xy^3 - x^2, y^4 - xy \}.
\]
We can see that \(x^4\) is the leading monomial of \(x^4 - y^2\), and \(y^4\) is the leading monomial of \(y^4 - xy\). Therefore, we know \(I\) is zero-dimensional. We can also see this by checking the number of standard monomials. The standard monomials are those that do not belong to the initial ideal \(\mathrm{in}(I)\), which in the case of a Grobner basis, is simply
\[
\mathrm{in}(I) = \mathrm{Ideal}[x^3 y^2, x^4, xy^3, y^4].
\]
This is a monomial ideal and hence is ``closed upwards''. The shaded gray areas in Fig. \ref{fig:ZeroDimensional1} shows all the monomials in the initial ideal, whose boundary forms a ``staircase''. The standard monomials, shown as blue squares in the figure, are those that are below the staircase:
\[
1,x,x^2,x^3,y,xy,x^2 y, x^3 y, y^2, xy^2, x^2 y^2, y^3.
\]

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/zero_dimensional_1} 

}

\caption{Initial ideal and the standard monomials with graded lexicographic monomial ordering.}\label{fig:ZeroDimensional1}
\end{figure}

We can change the monomial ordering and see what happens. Let us use the lexicographic monomial ordering this time. We obtain the reduced Grobner basis
\[
G = \{ x^2-y^6, xy - y^4, y^{11} - y \}.
\]
The monomial \(x^2\) is the leading monomial of \(x^2 - y^6\), and the monomial \(y^{11}\) is the leading monomial of \(y^11 - y\). Hence, the ideal is verified to be zero-dimensional as well. A different monomial ordering does change the set of standard monomials. Fig. \ref{fig:ZeroDimensional2} shows the initial ideal and the standard monomials (blue squares) under the staircase:
\[
1,x,y,y^2,y^3,y^4,y^5,y^6,y^7,y^8,y^9,y^{10}.
\]
Though the set of standard monomials has changed, the number of standard monomials remains to be \(12\). This makes sense because the dimension of the quotient ring \(\mathbb{C}[x]/I\) should not change.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/zero_dimensional_2} 

}

\caption{Initial ideal and the standard monomials with lexicographic monomial ordering.}\label{fig:ZeroDimensional2}
\end{figure}

The code for computing the Grobner basis can be found \href{https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/zero_d_ideal.m}{here}.
\end{example}

If an ideal \(I\) is zero-dimensional, can we find all the points in the affine variety \(V(I)\)? The next result shows that the number of points in \(V(I)\) (counting multiplicity) is precisely the number of standard monomials.

\begin{theorem}[Number of Roots]
\protect\hypertarget{thm:PolySysRoots}{}\label{thm:PolySysRoots}If an ideal \(I \subset \mathbb{C}[x]\) is zero-dimensional, then the number of standard monomials equals to the cardinality of \(V(I)\), counting multiplicities.
\end{theorem}

Once a set of standard monomials is found, we can also design a numerical procedure to compute the roots of the polynomial system of equations. For each \(x_i,\dots,x_n\), define the multiplication mapping
\[
\mathcal{M}_{x_i}: \mathbb{C}[x]/I \rightarrow \mathbb{C}[x]/I, \quad [p] \rightarrow [x_i p].
\]
It can be shown that \(\mathcal{M}_{x_i}\) is a linear mapping. Let \(M_{x_i}\) be the matrix representation of this linear map using \(S\), the set of standard monomials, as the basis of the quotient ring \(\mathbb{C}[x]/I\). \(M_{x_i}\) is called the \textbf{companion matrix} or \textbf{multiplication matrix} of the ideal \(I\) with respect to \(x_i\). The companion matrices \(M_{x_1},\dots,M_{x_n}\) commute with each other and share common eigenvectors. The affine variety \(V_{\mathbb{C}}(I)\) can be determined by eigenvalues of the companion matrices.

\begin{theorem}[Stickelberger's Theorem]
\protect\hypertarget{thm:StickelbergerTheorem}{}\label{thm:StickelbergerTheorem}Let \(I \subset \mathbb{C}[x]\) be a zero-dimensional ideal and let \(M_{x_1},\dots,M_{x_n}\) be the companion matrices, then
\[
V_{\mathbb{C}}(I) = \{ (\lambda_1,\dots,\lambda_n) \mid \exists v \in \mathbb{C}^D \backslash \{0 \}, M_{x_i} v = \lambda_i v, i=1,\dots,n  \},
\]
where \(D\) is the dimension of the quotient ring \(\mathbb{C}[x]/I\).
\end{theorem}

With Stickelberger's Theorem, one can further show that a zero-dimensional ideal \(I\) is radical if and only if the companion matrices \(M_{x_1},\dots,M_{x_n}\) are simultaneously diagonalizable, which occurs if and only if the cardinality \(|V_{\mathbb{C}}(I)| = D\).

Let us make Stickelberger's Theorem concrete through an example.

\begin{example}[Solving Polynomial Equations]
\protect\hypertarget{exm:SolvingPolynomialSystem}{}\label{exm:SolvingPolynomialSystem}Consider the ideal \(I \subset \mathbb{C}[x,y,z]\)
\[
I = \mathrm{Ideal}[xy-z, yz -x, zx - y].
\]
Choosing lexicographic monomial ordering, we get the Groebner basis
\[
G = \{ z - yx, y^2 - x^2, yx^2 - y, x^3 - x \}.
\]
We can see that this ideal is zero-dimensional (due to \(z\), \(y^2\), \(x^3\) being the leading monomials in \(G\)). The standard monomials are
\[
S = \{ 1, x, x^2, y, yx \}.
\]
We now need to form the matrices \(M_x, M_y, M_z\).
This can be done as follows.
\[
\mathrm{NormalForm}\left(
x \cdot \begin{bmatrix}
1 \\
x \\
x^2 \\
y \\
yx 
\end{bmatrix}
\right) = 
\begin{bmatrix}
x \\
x^2 \\
x \\
xy \\
y \end{bmatrix} = 
\underbrace{\begin{bmatrix}
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 1 & 0 
\end{bmatrix}}_{M_x}
\begin{bmatrix}
1 \\
x \\
x^2 \\
y \\
yx 
\end{bmatrix}
\]
\[
\mathrm{NormalForm}\left(
y \cdot \begin{bmatrix}
1 \\
x \\
x^2 \\
y \\
yx 
\end{bmatrix}
\right) = 
\begin{bmatrix}
y \\
xy \\
y \\
x^2 \\
x \end{bmatrix} = 
\underbrace{\begin{bmatrix}
0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 1 & 0 \\
0 & 0 & 1 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 
\end{bmatrix}}_{M_y}
\begin{bmatrix}
1 \\
x \\
x^2 \\
y \\
yx 
\end{bmatrix}
\]
\[
\mathrm{NormalForm}\left(
z \cdot \begin{bmatrix}
1 \\
x \\
x^2 \\
y \\
yx 
\end{bmatrix}
\right) = 
\begin{bmatrix}
yx \\
y \\
xy \\
x \\
x^2 \end{bmatrix} = 
\underbrace{\begin{bmatrix}
0 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 1 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 
\end{bmatrix}}_{M_z}
\begin{bmatrix}
1 \\
x \\
x^2 \\
y \\
yx 
\end{bmatrix}
\]
We can then simultaneously diagonalize \(M_x,M_y,M_z\) using the following matrix
\[
V = \frac{1}{4}\begin{bmatrix}
4 & 0 & -4 & 0 & 0 \\
0 & 1 & 1 & 1 & 1\\
0 & 1 & 1 & -1 & -1 \\
0 & -1 & 1 & 1 & -1 \\
0 & -1 & 1 & -1 & 1
\end{bmatrix}, \quad 
V^{-1}= \begin{bmatrix}
1 & 1 & 1 & 1 & 1\\
0 & 1 & 1 & -1 & -1\\
0 & 1 & 1 & 1 & 1\\
0 & 1 & -1 & 1 & -1 \\
0 & 1 & -1 & -1 & 1
\end{bmatrix}.
\]
The result is
\begin{equation}
\begin{split}
V M_x V^{-1}&= \mathrm{diag}(0 , 1, 1, -1, -1)\\
V M_y V^{-1}&= \mathrm{diag}(0 , 1, -1, 1, -1)\\
V M_z V^{-1}&= \mathrm{diag}(0 , 1, -1, -1, 1)
\end{split}.
\end{equation}
Therefore, the five roots of the polynomial system is
\[
\begin{pmatrix}
x \\ y \\ z 
\end{pmatrix} =
 \left\{ 
    \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix},
    \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix},
    \begin{pmatrix} 1 \\ -1 \\ -1 \end{pmatrix},
    \begin{pmatrix} -1 \\ 1 \\ -1 \end{pmatrix},
    \begin{pmatrix} -1 \\ -1 \\ 1 \end{pmatrix}
 \right\} .
\]
\end{example}

In practice, instead of simultaneously diagonalizing the companion matrices, a Schur decomposition type method is used to compute the roots \citep{corless97-reordered}. We will see that in the homework.

\subsection{Algebraic and Semialgebraic Sets}\label{algebraic-and-semialgebraic-sets}

An \textbf{algebraic set} in \(\mathbb{R}^{n}\) is the set of common \textbf{real} roots of a set of polynomials. For instance, the unit sphere is an algebraic set because it is real zero set of the polynomial \(x_1^2 + \dots + x_n^2 - 1\).

Intersections and unions of finitely many algebraic sets are again algebraic sets. A nonempty algebraic set is said to be \textbf{irreducible} if it cannot be written as a union of two distinct proper algebraic subsets; otherwise it is called reducible. Every algebraic set is the union of finitely many irreducible ones.

More general than algebraic sets are \textbf{semialgebraic sets}.

\begin{definition}[Basic Semialgebraic Set]
\protect\hypertarget{def:BasisSemialgebraic}{}\label{def:BasisSemialgebraic}A set \(S \subset \mathbb{R}^{n}\) defined as
\[
S = \{ x \in \mathbb{R}^{n} \mid f_i(x) \triangleright_i 0, i=1,\dots,\ell  \},
\]
where for each \(i\), \(\triangleright_i\) is one of \(\{ \geq, >, =, \neq \}\) and \(f_i(x) \in \mathbb{R}[x]\), is called a basic semialgebraic set.

A basic closed semialgebraic set is a set of the form
\[
S = \{ x \in \mathbb{R}^{n} \mid f_1\geq 0, \dots f_\ell(x) \geq 0 \}.
\]
\end{definition}

Every basic semialgebraic set can be expressed with polynomial inequalities of the form \(f(x) \geq 0\) and a single inequality \(g \neq 0\).

\begin{definition}[Semialgebraic Set]
\protect\hypertarget{def:SemialgebraicSet}{}\label{def:SemialgebraicSet}A finite union of basic semialgebraic sets in \(\mathbb{R}^{n}\) is called a semialgebraic set, and a finite union of basic closed semialgebraic sets is a closed semialgebraic set.
\end{definition}

Semialgebraic sets are closed under finite unions, finite intersections, and complementation. The following theorem states that they are also closed under projections.

\begin{theorem}[Tarski-Seidenberg Theorem]
\protect\hypertarget{thm:TarskiSeidenberg}{}\label{thm:TarskiSeidenberg}Let \(S \subset \mathbb{R}^{k+n}\) be a semialgebraic set and \(\pi : \mathbb{R}^{k+n} \rightarrow \mathbb{R}^{n}\) be the projection map that sends \((y,x) \mapsto x\). Then \(\pi(S)\) is a semialgebraic set in \(\mathbb{R}^{n}\).
\end{theorem}

Note that an algebraic set is not closed under projection. For example consider the algebraic set defined by \(xy = 1\). The projection of this algebraic set to \(x\) is defined by \(x \neq 0\), which is not an algebraic set, but a semialgebraic set.

Semialgebraic functions are similarly defined. Let \(f: D \rightarrow \mathbb{R}^{}\) be a real-valued function where the domain \(D\) is a semialgebraic set. Then \(f\) is called a \textbf{semialgebraic function} if the graph \(\{ (x,y) \mid x \in D, f(x)=y \}\) is a semialgebraic set.

\section{SOS and Nonnegative Polynomials}\label{sos-and-nonnegative-polynomials}

\subsection{Nonnegative polynomials}\label{nonnegative-polynomials}

Consider polynomials in \(n\) variables with real coefficients, i.e., the set \(\mathbb{R}[x]\). A polynomial \(p(x_1,\dots,x_n)\) is nonnegative if
\[
p(x_1,\dots,x_n) \geq 0, \quad \forall (x_1,\dots,x_n) \in \mathbb{R}^{n}.
\]

Of couse, a natural question is, given a polynomial \(p(x)\), is it possible to efficiently decide whether \(p(x)\) is nonnegative?

\textbf{Univariate Polynomials}. Let us start the discussion on univariate polynomials, i.e., polynomials in a single variable \(x\). A univariate polynomial of degree \(d\) can be written as
\begin{equation}
p(x) = p_d x^d + p_{d-1} x^{d-1} + \cdots + p_1 x + p_0.
\label{eq:univariate-poly}
\end{equation}
Without loss of generality, we can assume \(p_d = 1\), in which case the polynomial is said to be \textbf{monic}. The univariate polynomial can also be written as
\begin{equation}
p(x) = p_d \prod_{i=1}^d (x - x_i),
\label{eq:univariate-poly-root}
\end{equation}
with \(x_i,i=1,\dots,d\) its complex roots that may have multiplicities.

How do we decide if \(p(x)\) is nonnegative? A simple necessary condition is that \(d\) must be even. Otherwise if \(d\) is odd, then either pushing \(x \rightarrow \infty\) or \(x \rightarrow -infinity\) will lead to \(p(x)\) negative.

In certain cases it is easy to derive an explict characterization of nonnegativity.

\begin{example}[Univaraite Quadratic Polynomial]
\protect\hypertarget{exm:NonnegativeQuadratic}{}\label{exm:NonnegativeQuadratic}Let \(p(x) = x^2 + p_1 x + p_0\) be a monic quadratic polynomial. Clearly, \(p(x) \geq 0\) if and only if
\[
\min_{x} p(x) \geq 0.
\]
Since \(p(x)\) is convex, its global minimum can be easily computed by setting its gradient to zero, which gives
\[
x_\star = - \frac{p_1}{2}, \quad p(x_\star) = p_0 - \frac{p_1^2}{4}.
\]
Therefore, \(p(x)\) is nonnegative if and only if
\[
4 p_0 - p_1^2 \geq 0.
\]
\end{example}

For general univariate polynomials, we describe a technique known as the Hermite method for deciding nonnegativity. Consider a monic polynomial as in \eqref{eq:univariate-poly} and \eqref{eq:univariate-poly-root} and define its associated \textbf{Hermite matrix} as the following \(d \times d\) symmetric Hankel matrix
\[
H_1(p) = \begin{bmatrix}
s_0 & s_1 & \cdots & s_{d-1} \\
s_1 & s_2 & \cdots & s_d \\
\vdots & \vdots & \ddots & \vdots \\
s_{d-1} & s_d & \cdots & s_{2d-2}
\end{bmatrix}, \quad s_k = \sum_{j=1}^d x_j^k,
\]
where recall \(x_j,j=1,\dots,d\) are the roots of \(p\). The quantities \(s_k\) are known as the power sums. The follow lemma states that the power sums can be computed without computing the roots.

\begin{lemma}[Newton Identities]
\protect\hypertarget{lem:NewtonIdentity}{}\label{lem:NewtonIdentity}The power sums \(s_k\) satisfy the following recursive equations known as the Newton identities:
\[
s_0 = d, \quad s_k = -1\left(k p_{d-k} + \sum_{i=1}^{k-1} p_{d-i} s_{k-i} \right), k=1,2,\dots.
\]
\end{lemma}

After forming the Hermite matrix, its rank and signature tells us the number of complex and real roots.

\begin{theorem}[Hermite Matrix]
\protect\hypertarget{thm:HermiteMatrix}{}\label{thm:HermiteMatrix}The rank of the Hermite matrix \(H_1(p)\) is equal to the number of distinct complex roots. The signature of \(H_1(p)\) is equal to the number of distinct real roots.
\end{theorem}

Recall that given a symmetric matrix \(A\), its \textbf{inertia}, denoted \(\mathcal{I}(A)\), is the triplet \((n_+, n_0, n_{-})\), where \(n_+,n_0, n_-\) are the number of positive, zero, and negative eigenvalues, respectively. The \textbf{signature} of \(A\) is equal to \(n_+ - n_-\).

With the Hermite matrix, we can decide nonnegativity.

\begin{theorem}[Nonnegativity from Hermite Matrix]
\protect\hypertarget{thm:NonnegativityHermite}{}\label{thm:NonnegativityHermite}

Let \(p(x)\) be a monic polynomial of degree \(2d\). Then the following statements are equivalent.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The polynomial \(p(x)\) is strictly positive.
\item
  The polynomial \(p(x)\) has no real roots.
\item
  The inertia of the Hermite matrix is \(\mathcal{I}(H_1(p)) = (k, 2d-k, k)\) for some \(1 \leq k \leq d\).
\end{enumerate}

\end{theorem}

We can use this result on the quadratic example before.

\begin{example}[Hermite Matrix of A Quadratic Polynomial]
\protect\hypertarget{exm:HermiteQuadratic}{}\label{exm:HermiteQuadratic}Consider the quadratic polynomial \(p(x) = x^2 + p_1 x + p_0\). Using the Newton identifies, we have
\[
s_0 = 2, \quad s_1 = -p_1, \quad s_2 = p_1^2 - 2p_0.
\]
The Hermite matrix is then
\[
H_1(p) = \begin{bmatrix} 2 & - p_1 \\ -p_1 & p_1^2 - 2 p_0 \end{bmatrix}.
\]
Let \(\Delta = \det H_1(p) = p_1^2 - 4p_0\). The inertia of the Hermite matrix is
\[
\mathcal{I}(H_1(p)) = \begin{cases}
(0,0,2) & \text{if } \Delta > 0 \\
(0,1,1) & \text{if } \Delta = 0 \\
(1,0,1) & \text{if } \Delta < 0.
\end{cases}
\]
Thus, \(p\) is strictly positive if and only if \(\Delta < 0\).
\end{example}

\textbf{Multivariate Polynomials}. Let us denote by \(P_{n,2d}\) the set of nonnegative polynomials in \(n\) variables with degree up to \(2d\), i.e.,
\[
P_{n,2d} = \{ f \in \mathbb{R}[x]_{2d} \mid f(x) \geq 0, \forall x \in \mathbb{R}^{n} \}.
\]
There are
\[
s(n,2d) = \begin{pmatrix} n + 2d \\ 2d \end{pmatrix}
\]
coefficients for \(f \in P_{n,2d}\). Notice that the constraint \(f(x) \geq 0\) when fixing \(x\) is an affine constraint in the coefficients of \(p\). Therefore, \(P_{n,2d}\) is in fact a convex set. Further, it is a proper cone.

\begin{theorem}[Cone of Nonnegative Polynomials]
\protect\hypertarget{thm:ConeNonnegative}{}\label{thm:ConeNonnegative}The set of nonnegative polynomials \(P_{n,2d}\) is a proper cone (i.e., closed, convex, pointed, and solid) in \(\mathbb{R}[x]_{2d} \sim \mathbb{R}^{s(n,2d)}\).
\end{theorem}

Let us see an example of quadratic polynomials.

\begin{example}[Cone of Nonnegative Quadratic Polynomials]
\protect\hypertarget{exm:ConeNonnegativeQuadratic}{}\label{exm:ConeNonnegativeQuadratic}Consider the cone \(P_{n,2}\), nonnegative polynomials in \(n\) variables of degree up to \(2\). Such polynomials can be written as
\[
p(x) = x^\top A x + 2 b^\top x + c,
\]
for some \(A \in \mathbb{S}^{n}\), \(b \in \mathbb{R}^{n}\), \(c \in \mathbb{R}^{}\). Observe that we can write
\[
p(x) = \begin{bmatrix} x \\ 1 \end{bmatrix}^\top\begin{bmatrix} A & b \\ b^\top& c \end{bmatrix} \begin{bmatrix} x \\ 1 \end{bmatrix},
\]
therefore \(p(x) \geq 0\) if and only if
\[
\begin{bmatrix} A & b \\ b^\top& c \end{bmatrix} \succeq 0.
\]
Thus, in this case the set \(P_{n,2}\) is isomorphic to the positive semidefinite cone \(\mathbb{S}^{n+1}_{+}\).
\end{example}

One may wonder is it the case that \(P_{n,2d}\), being a convex cone, will always have nice descriptions as in the previous example?

Unfortunately the answer is no. In general the geometry of \(P_{n,2d}\) is extremely complicated. In Example \ref{exm:ConeNonnegativeQuadratic} we showed \(P_{n,2}\) is isomorphic to \(\mathbb{S}^{n+1}_{+}\) and hence it is \textbf{basic semialgebraic} (recall that the PSD cone can be described by a finite number of polynomial constraints). However, in general \(P_{n,2d}\) is semialgebraic but not basic semialgebraic.

\begin{example}[Semialgebraic Set of Nonnegative Polynomials]
\protect\hypertarget{exm:DegreeFourNonnegative}{}\label{exm:DegreeFourNonnegative}Consider the quartic univariate polynomial
\[
p(x) = x^4 + 2ax^2 + b, \quad a,b \in \mathbb{R}^{}.
\]
We are interested in finding conditions on \(a,b\) such that \(p(x) \geq 0\) for any \(x \in \mathbb{R}^{}\).

A formal analysis can be done via the discriminant of \(p(x)\). But here we will leverage a powerful tool known as \textbf{quantifier elimination}, using cylindrical algebraic decomposition, to directly give us the answer. For example, we can use the quantifier elimination function in the Maple software.

Fig. \ref{fig:QuantifierEliminationQuartic} shows my query to Maple. The quantifier elimination algorithm produces me a set of conditions on \(a,b\) such that \(p(x) \geq 0\).

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/quantifier_elimination_quartic} 

}

\caption{Quantifier elimination in Maple.}\label{fig:QuantifierEliminationQuartic}
\end{figure}

Plotting the conditions we get the blue region in Fig. \ref{fig:NonnegativeQuartic}. As we can see, the set of \((a,b)\) such that \(p(x)\) is nonnegative is indeed a convex set, but it is not a basic semialgebraic set in the sense that it cannot be written as the feasible set of a finite number of polynomial constraints. However, it is a semialgebraic set that can be described by the union of several basic semialgebraic sets.

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{images/nonnegative_quartic} 

}

\caption{Set of coefficients such that the polynomial is nonnegative.}\label{fig:NonnegativeQuartic}
\end{figure}

Another issue with the convex set shown in Fig. \ref{fig:NonnegativeQuartic} is that there exists a zero-dimensional face (a vertex) that is not exposed, which is the point \((0,0)\). A non-exposed face is a known obstruction for a convex set to be the feasible set of a semidefinite program \citep{ramana95jgo-some}.
\end{example}

This shows the difficulty of working with nonnegative polynomials.

From the computational complexity perspective, the difficulty of working with nonnegative polynomials is seen by the fact that deciding polynomial nonnegativity for \(2d \geq 4\) is known to be NP-hard in the worst case.

However, we do know very well a special class of nonnegative polynomials, the nonnegative polynomials that can be written as a sum of squares.

\subsection{Sums-of-Squares Polynomials}\label{sums-of-squares-polynomials}

A multivariate polynomial \(p(x)\) is a \textbf{sum of squares} (SOS) if it can be written as the sum of squares of some other polynomials.

\begin{definition}[Sum of Squares Polynomial]
\protect\hypertarget{def:SumOfSquares}{}\label{def:SumOfSquares}A polynomial \(p(x) \in \mathbb{R}[x]_{2d}\) is a sum of squares if there exist \(q_1,\dots,q_m \in \mathbb{R}[x]_d\) such that
\[
p(x) = \sum_{k=1}^m q_k^2(x).
\]
\end{definition}

We will use \(\Sigma_{n,2d}\) to denote the set of SOS polynomials in \(n\) variables of degree up to \(2d\). Clearly, we have
\[
\Sigma_{n,2d} \subseteq P_{n,2d},
\]
because any SOS polynomial is necessarily nonnegative.

Similar to \(P_{n,2d}\), the set of SOS polynomials is also a convex proper cone.

\begin{theorem}[Cone of SOS Polynomials]
\protect\hypertarget{thm:ConeSOSPolynomial}{}\label{thm:ConeSOSPolynomial}The set of SOS polynomials \(\Sigma_{n,2d}\) is a proper cone (i.e., closed, convex, pointed, and solid) in \(\mathbb{R}[x]_{2d}\).
\end{theorem}

One of the central questions in convex algebraic geometry is to understand the relationships between \(P_{n,2d}\) and \(\Sigma_{n,2d}\).

The first question is when is nonnegativity equal to sum of squares? David Hilbert showed that equality between \(\Sigma_{n,2d}\) and \(P_{n,2d}\) happens only in the following three cases:

\begin{itemize}
\item
  Univariate polynomials, \(n=1\)
\item
  Quadratic polynomials, \(2d=2\)
\item
  Bivariate quartics, \(n=2, 2d=4\).
\end{itemize}

For all other cases, there always exist nonnegative polynomials that are not SOS. One of the most famous examples is the \textbf{Motzkin's polynomial} written as
\[
M(x,y) = x^4 y^2 + x^2 y^4 + 1 - 3 x^2 y^2.
\]
One can show that this polynomial is nonnegative but not SOS. Other examples of nonnegative but not SOS polynomials can be found in \citep{reznick00cm-some}.

Let us show that univariate nonnegative polynomials can always be written as a sum of squares.

\begin{theorem}[Univaraite Nonnegative Polynomials are SOS]
\protect\hypertarget{thm:UnivaraiteNonSOS}{}\label{thm:UnivaraiteNonSOS}A univariate polynomial is nonnegative if and only if it is a sum of squares.
\end{theorem}

\begin{proof}
Since \(p(x)\) is univariate, we can factorize it as
\begin{equation}
p(x) = p_n \prod_j (x - r_j)^{n_j} \prod_{k} (x - a_k + i b_k)^{m_k} (x - a_k - i b_k)^{m_k},
\label{eq:proof-univariate-non-sos-factorization}
\end{equation}
where \(r_j\)'s are the real roots and \(a_k \pm i b_k\)'s are the complex roots. Because \(p(x)\) is nonnegative, then \(p_n > 0\) and the multiplicities of the real roots must be even, i.e., \(n_j = 2 s_j\).

Also note that
\[
(x - a + ib)(x - a - ib) = (x-a)^2 + b^2.
\]
Consequently we can write \eqref{eq:proof-univariate-non-sos-factorization} as
\[
p(x) = p_n \prod_j (x - r_j)^{2 s_j} \prod_k ((x-a_k)^2 + b_k^2)^{m_k}.
\]
Since products of sums of squares are still sums of squares and all the factors in the above expression are SOS, it follows that \(p(x)\) is SOS.

Furthermore, the two-squares identify
\[
(\alpha^2 + \beta^2)(\gamma^2 + \delta^2) = (\alpha \gamma - \beta \delta)^2 + (\alpha \delta + \beta \delta)^2
\]
allows us to combine very partial product as a sum of only two squares:
\[
p(x) = q_1^2(x) + q_2^2(x).
\]
Therefore, it suffices to write every nonnegative univariate polynomial as the sum of only two squares.
\end{proof}

In the next section, we focus on how to numerically compute SOS decompositions.

\section{Compute SOS Decompositions}\label{compute-sos-decompositions}

Given a polynomial \(p(x)\), how do we decide if \(p(x)\) is SOS? We knew that deciding if \(p(x)\) is nonnegative is generally NP-hard. The nice thing about SOS polynomials is that the decision problem is tractable and it is a convex semidefinite program.

\subsection{Univaraite Polynomials}\label{univaraite-polynomials}

Consider a univariate polynomial \(p(x)\) of degree \(2d\)
\[
p(x) = p_{2d} x^{2d} + p_{2d-1} x^{2d-1} + \cdots + p_1 x + p_0.
\]
Assume \(p(x)\) is SOS and can be written as
\begin{equation}
p(x) = q_1^2(x) + \dots + q_m^2(x).
\label{eq:univariate-sos}
\end{equation}
Note that the degree of the polynomials \(q_k\) must be at most \(d\) since the leading term of \(q_k^2(x)\) must have positive coefficients and there cannot be any cancellation in the highest power of \(x\). Then, we can write
\begin{equation}
\begin{bmatrix} q_1(x) \\ q_2(x) \\ \vdots \\ q_m(x) \end{bmatrix} = V \begin{bmatrix} 1 \\ x \\ \vdots \\ x^d \end{bmatrix} = V [x]_d,
\label{eq:univariate-q-V}
\end{equation}
where recall \([x]_d\) is the vector of monomials in \(x\) of degree up to \(d\). Plugging \eqref{eq:univariate-q-V} into \eqref{eq:univariate-sos}, we get
\begin{equation}
p(x) = \sum_{k=1}^m q_k^2 (x) = (V [x]_d)^\top(V [x]_d) = [x]_d^\top V^\top V [x]_d = [x]_d^\top Q [x]_d.
\label{eq:univariate-sos-gram-Q}
\end{equation}

This suggests the following characterization of univariate SOS polynomials.

\begin{lemma}[Characterization of Univaraite SOS Polynomials]
\protect\hypertarget{lem:UnivaraiteSOS}{}\label{lem:UnivaraiteSOS}A univariate polynomial \(p(x) \in \mathbb{R}[x]_{2d}\) is SOS if and only if there exists a symmetric matrix \(Q \in \mathbb{S}^{d+1}\) that satisfies
\[
p(x) = [x]_d^\top Q [x]_d, \quad Q \succeq 0.
\]
\end{lemma}

The matrix \(Q\) is typically called the \textbf{Gram matrix} of the SOS representation. Lemma \ref{lem:UnivaraiteSOS} can be easily verified: one direction is clear from \eqref{eq:univariate-sos-gram-Q} and the other direction can be shown by factorizing a positive semidefinite matrix \(Q = V^\top V\).

Although it may not be immediately clear, but the nice property of Lemma \ref{lem:UnivaraiteSOS} is that it says deciding if a univariate polynomial is SOS (and finding its SOS decomposition) is in fact a convex semidefinite program!

To see this, note that the constraint \(Q \succeq 0\) is a convex PSD constraint and the constraint \(p(x) = [x]_d^\top Q [x]_d\) leads to a finite number of affine constraints on the entries of \(Q\) by ``matching coefficients''. In particular, let us index the rows and columns of \(Q\) from \(0\) to \(d\), and expand
\[
[x]_d^\top Q [x]_d = \sum_{k=0}^{2d} \left( \sum_{i+j=k} Q_{ij} \right) x^k.
\]
It now becomes clear that \(p(x) = [x]_d^\top Q [x]_d\) simply askes
\[
\sum_{i+j=k} Q_{ij} = p_k, \quad k = 0, \dots, 2d.
\]

It is easier to work this out via an example.

\begin{example}[SOS Decomposition of Univaraite Polynomials]
\protect\hypertarget{exm:SOSDecompositionUnivariate}{}\label{exm:SOSDecompositionUnivariate}Consider the univariate polynomial
\[
p(x) = x^4 + 4 x^3 + 6 x^2 + 4 x + 5.
\]
To decide if this polynomial is SOS, we write the polynomial equality constraint
\begin{equation}
\begin{split}
p(x) & = \begin{bmatrix} 1 \\ x \\ x^2 \end{bmatrix}^\top\begin{bmatrix} Q_{00} & Q_{01} & Q_{02} \\
Q_{01} & Q_{11} & Q_{12} \\
Q_{02} & Q_{12} & Q_{22} 
\end{bmatrix}  \begin{bmatrix} 1 \\ x \\ x^2 \end{bmatrix} \\
& = Q_{22} x^4 + 2 Q_{12} x^3 + (Q_{11} + 2 Q_{02}) x^2 + 2 Q_{01} x + Q_{00}.
\end{split}
\end{equation}
Matching coefficients, we get the constraints
\begin{equation}
\begin{split}
x^4: & \quad Q_{22} = 1\\
x^3: & \quad 2 Q_{12} = 4\\
x^2: & \quad Q_{11} + 2 Q_{02} = 6\\
x: & \quad 2Q_{01} = 4\\
1: & \quad Q_{00} = 5
\end{split}
\end{equation}
We need to find a \(Q \succeq 0\) that satisfies the above constraints, which is clearly a convex SDP. In this case, the SDP is feasible and we can find a solution
\[
Q = \begin{bmatrix} 5 & 2 & 0 \\ 2 & 6 & 2 \\ 0 & 2 & 1 \end{bmatrix}.
\]
Factorizing \(Q=V^\top V\) with
\[
V = \begin{bmatrix} 0 & 2 & 1 \\ \sqrt{2} & \sqrt{2} & 0 \\ \sqrt{3} & 0 & 0 \end{bmatrix},
\]
we obtain the SOS decomposition
\[
p(x) = (x^2 + 2x)^2 + 2 (1+x)^2 + 3,
\]
\end{example}

\subsection{Multivariate Polynomials}\label{multivariate-polynomials}

Deciding if a multivariate polynomial is SOS is almost identical to what we have shown for univariate polynomials. Consider a multivariate polynomial \(p(x)\) in \(n\) variables of degree \(2d\):
\[
p(x) = \sum_{\alpha} p_{\alpha} x^{\alpha}, \quad \alpha \in \mathcal{F}_{n,2d} := \{ (\alpha_1,\dots,\alpha_n) \in \mathbb{N}^n \mid \alpha_1 + \cdots + \alpha_n \leq 2d \}.
\]
Let
\begin{equation}
[x]_d := \begin{bmatrix} 1 \\ x_1 \\ \vdots \\ x_n \\ x_1^2 \\ x_1 x_2 \\ \vdots \\ x_n^d \end{bmatrix} = [x^\alpha]_{\alpha \in \mathcal{F}_{n,d}}
\label{eq:SOS-standard-basis}
\end{equation}
be the standard basis of monomials with degree up to \(d\). Then in parallel to Lemma \ref{lem:UnivaraiteSOS}, we have that \(p(x)\) is SOS if and only if there exists a positive semidefinite Gram matrix.

\begin{lemma}[Characterization of Multivariate SOS Polynomials]
\protect\hypertarget{lem:MultivariateSOS}{}\label{lem:MultivariateSOS}A multivariate polynomial \(p(x) \in \mathbb{R}[x]_{2d}\) is SOS if and only if there exists a symmetric matrix \(Q \in \mathbb{S}^{s(n,d)}\) that satisfies
\[
p(x) = [x]_d^\top Q [x]_d, \quad Q \succeq 0.
\]
\end{lemma}

Let us index the monomials in the basis \eqref{eq:SOS-standard-basis}, as well as the rows and columns of \(Q\), using their exponents. Then by matching coefficients of the polynomial equation \(p(x) = [x]_d^\top Q [x]_d\), Lemma \ref{lem:MultivariateSOS} is equivalent to finding \(Q \in \mathbb{S}^{s(n,d)}\) that satisfies
\begin{equation}
p_\alpha = \sum_{\beta + \gamma = \alpha} Q_{\beta\gamma}, \forall \alpha \in \mathcal{F}_{n,2d}, \quad Q \succeq 0.
\label{eq:multivariate-SOS-SDP-formulation}
\end{equation}
That is, for every \(\alpha \in \mathcal{F}_{n,2d}\), we search for all possible pairs of \(\beta,\gamma \in \mathcal{F}_{n,d}\) such that \(\beta + \gamma = \alpha\), the sum of \(Q_{\beta \gamma}\) should be equal to \(p_{\alpha}\) by the virtue of matching coefficients. \textbf{Note that \eqref{eq:multivariate-SOS-SDP-formulation} boils down to solving an SDP with matrix size \(s(n,d) \times s(n,d)\) and \(s(n,2d)\) affine constraints.} Therefore, it grows quickly with \(n\) and \(d\).

Let us work out a simple example.

\begin{example}[SOS Decomposition of a Multivariate Polynomial]
\protect\hypertarget{exm:SOSDecompositionMultivariate}{}\label{exm:SOSDecompositionMultivariate}We want to check if the following polynomial in two variables is SOS:
\[
p(x) = 2 x_1^4 + 5 x_2^4 - x_1^2 x_2^2 + 2 x_1^3 x_2 + 2 x_1 + 2.
\]
Since \(\deg(p) = 4\), we pick the standard monomial basis of degree up to \(2\)
\[
[x]_2 = \begin{bmatrix} 1 \\ x_1 \\ x_2 \\ x_1^2 \\ x_1 x_2 \\ x_2^2 \end{bmatrix},
\]
and write down the polynomial equality constraint
\[
p(x) = [x]_2^\top Q [x]_2 = 
[x]_2^\top\begin{bmatrix}
Q_{00,00} & Q_{00,10} & Q_{00,01} & Q_{00,20} & Q_{00,11} & Q_{00,02} \\
* & Q_{10,10} & Q_{10,01} & Q_{10,20} & Q_{10,11} & Q_{10,02} \\
* & * & Q_{01,01} & Q_{01,20} & Q_{01,11} & Q_{01,02} \\
* & * & * & Q_{20,20} & Q_{20,11} & Q_{20,02} \\
* & * & * & * & Q_{11,11} & Q_{11,02} \\
* & * & * & * & * & Q_{02,02}
\end{bmatrix}
[x]_2
\]
By matching coefficients, we obtain
\[
s(n,2d) = s(2,4) = \begin{pmatrix} 2 + 4 \\ 4 \end{pmatrix} = 15
\]
affine constraints on the entries of \(Q\), which has size \(6 \times 6\).

Solving the SDP, we obtain a solution
\[
Q = \frac{1}{3} \begin{bmatrix} 6 & 3 & 0 & -2 & 0 & -2 \\
3 & 4 & 0 & 0 & 0 & 0 \\
0 & 0 & 4 & 0 & 0 & 0 \\
-2 & 0 & 0 & 6 & 3 & -4 \\
0 & 0 & 0 & 3 & 5 & 0 \\
-2 & 0 & 0 & -4 & 0 & 15
\end{bmatrix}.
\]
\end{example}

\textbf{Choice of Basis}. It is worth noting that so far, when computing SOS decompositions, we have been using the standard monomial basis \([x]_d\). This is the most popular choice in practice, but it is not necessarily the only choice. See Chapter 3.1.5 of \citep{blekherman12book-semidefinite} for other basis choices.

\section{SOS Programming}\label{sos-programming}

We have seen that finding SOS decompositions of given polynomials can be written as semidefinite programs. It is clear to see that we can do more than just finding SOS decompositions -- we can also formulate optimization problems subject to SOS constraints, known as SOS programming.

\begin{definition}[SOS Program]
\protect\hypertarget{def:SOSProgram}{}\label{def:SOSProgram}An SOS optimization problem or SOS program is a convex optimization problem of the form
\begin{equation}
\begin{split}
\max_y & \quad b_1 y_1 + \cdots + b_m y_m \\
\mathrm{s.t.}& \quad p_i(x;y) \text{ is SOS in } \mathbb{R}[x], \quad i=1,\dots,k.
\end{split}
\label{eq:SOS-program}
\end{equation}
where \(b = (b_1,\dots,b_m) \in \mathbb{R}^{m}\) is a given constant vector, \(y= (y_1,\dots,y_m)\) is the unknown variable to be optimized, and
\[
p_i(x;y) = a_{i0}(x) + y_1 a_{i1}(x) + \cdots + y_m a_{im}(x), \quad i=1,\dots,k,
\]
are polynomials in \(x\) with coefficientss affine in \(y\), with \(a_{ij}(x),i=1,\dots,k, j=0,\dots,m\) given polynomials.
\end{definition}

For readers seeing SOS programs for the first time, it is critical to realize that \textbf{the variable \(x\) in an SOS program \eqref{eq:SOS-program} is ``dummy''}, in the sense that it is only used to formulate the problem, but not really being optimized. The variable \(y \in \mathbb{R}^{m}\) is the optimization variable.

To see this point more clearly, we will show that the SOS program \eqref{eq:SOS-program} can be reformulated as a convex semidefinite program (or in general a conic optimization problem). Let
\[
d_i = \lceil \deg(p_i)/2 \rceil, \quad i=1,\dots,k,
\]
where importantly, the degree of \(p_i\) is taken w. r. t. \(x\) (but not \(y\)). Then we can clearly see that the constraint ``\(p_i(x;y)\) is SOS in \(\mathbb{R}[x]\)'' is equivalent to
\begin{equation}
p_i(x;y) = [x]_{d_i}^\top Q_i [x]_{d_i}, \quad Q_i \in \mathbb{S}^{s(n,d_i)}_{+}, \quad i=1,\dots,k,
\label{eq:SOS-program-expand}
\end{equation}
where recall \([x]_{d_i}\) is the standard monomial basis in \(x\) of degree up to \(d_i\). By matching coefficients in equation \eqref{eq:SOS-program-expand}, we obtain a set of affine constraints in \(y\) and \(Q_i\), while the variable \(x\) is simply removed! Therefore, the SOS program \eqref{eq:SOS-program} is equivalent to a conic optimization in the variable
\[
(y,Q_1,\dots,Q_k) \in \mathbb{R}^{m} \times \mathbb{S}^{s(n,d_1)}_{+} \times \cdots \times \mathbb{S}^{s(n,d_k)}_{+}.
\]
The number of affine constraints is
\[
s(n,2d_1) + \cdots + s(n,2d_k).
\]

Let us make this observation concrete using a simple example.

\begin{example}[SOS Programming]
\protect\hypertarget{exm:SOSProgram}{}\label{exm:SOSProgram}Consider the following SOS program
\begin{equation}
\begin{split} 
\max_y & \quad y_1 + y_2 \\
\mathrm{s.t.}& \quad x^4 + y_1 x + (2+y_2) \text{ is SOS}\\
& \quad (y_1 - y_2 + 1) x^2 + y_2 x + 1 \text{ is SOS}
\end{split}
\label{eq:SOS-program-example}
\end{equation}
The first SOS constraint is equivalent to
\[
x^4 + y_1 x + (2 + y_2) = [x]_2^\top Q_1 [x]_2 = \begin{bmatrix} 1 \\ x \\ x^2 \end{bmatrix}^\top
\underbrace{\begin{bmatrix}
Q_{1,00} & Q_{1,01} & Q_{1,02} \\
Q_{1,01} & Q_{1,11} & Q_{1,12} \\
Q_{1,02} & Q_{1,12} & Q_{1,22}
\end{bmatrix}}_{Q_1}
\begin{bmatrix} 1 \\ x \\ x^2 \end{bmatrix}.
\]
Matching coefficients, we obtain
\begin{equation}
\begin{split}
x^4: & \quad 1 = Q_{1,22} \\
x^3: & \quad 0 = 2 Q_{1,12} \\
x^2: & \quad 0 = Q_{1,11} + 2 Q_{1,02} \\
x: & \quad y_1 = 2 Q_{1,01} \\
1: & \quad 2 + y_2 = Q_{1,00}
\end{split}
\label{eq:SOS-program-constraint-1}
\end{equation}
The second SOS constraint is equivalent to
\[
(y_1 - y_2 + 1)x^2 + y_2 x + 1 = [x]_1^\top Q_2 [x]_1 = \begin{bmatrix} 1 \\ x \end{bmatrix}^\top
\underbrace{\begin{bmatrix} Q_{2,00} & Q_{2,01} \\
Q_{2,01} & Q_{2,11} \end{bmatrix}}_{Q_2}
\begin{bmatrix} 1 \\ x \end{bmatrix}.
\]
Matching coefficients, we obtain
\begin{equation}
\begin{split}
x^2: & \quad y_1 - y_2 + 1 = Q_{2,11} \\
x: & \quad y_2 = 2 Q_{2,01} \\
1: & \quad 1 = Q_{2,00}
\end{split}
\label{eq:SOS-program-constraint-2}
\end{equation}
Therefore, we obtain a conic optimization in
\[
(y_1,y_2,Q_1,Q_2)
\]
subject to the affine constraints in \eqref{eq:SOS-program-constraint-1} and \eqref{eq:SOS-program-constraint-2}, plus \(Q_1 \succeq 0, Q_2 \succeq 0\).

For this simple example, it is tractable to collect the linear constraints by hand. When the SOS program grows larger, we can use existing software packages to perform the conversion for us.

In the next, we show how to use the software package SOSTOOLS \citep{prajna02cdc-sostools} to implement SOS programming in Matlab.

I first create the dummy polynomial variable \(x\) and the decision variable \(y\).

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{dim\_y} \OperatorTok{=} \FloatTok{2}\OperatorTok{;}
\VariableTok{dim\_x} \OperatorTok{=} \FloatTok{1}\OperatorTok{;}
\VariableTok{x} \OperatorTok{=} \VariableTok{mpvar}\NormalTok{(}\SpecialStringTok{\textquotesingle{}x\textquotesingle{}}\OperatorTok{,}\FloatTok{1}\NormalTok{)}\OperatorTok{;} \CommentTok{\% dummy x }
\VariableTok{prog} \OperatorTok{=} \VariableTok{sosprogram}\NormalTok{(}\VariableTok{x}\NormalTok{)}\OperatorTok{;}
\VariableTok{y\_name} \OperatorTok{=}\NormalTok{ \{\}}\OperatorTok{;} \CommentTok{\% decision variable y}
\KeywordTok{for} \VariableTok{i} \OperatorTok{=} \FloatTok{1}\OperatorTok{:}\VariableTok{dim\_y}
    \VariableTok{y\_name}\NormalTok{\{}\VariableTok{i}\NormalTok{\} }\OperatorTok{=} \VariableTok{sprintf}\NormalTok{(}\SpecialStringTok{\textquotesingle{}y\_\%d\textquotesingle{}}\OperatorTok{,}\VariableTok{i}\NormalTok{)}\OperatorTok{;}
\KeywordTok{end}
\VariableTok{y} \OperatorTok{=} \VariableTok{dpvar}\NormalTok{(}\VariableTok{y\_name}\NormalTok{)}\OperatorTok{;}
\VariableTok{y} \OperatorTok{=} \VariableTok{y}\NormalTok{(}\OperatorTok{:}\NormalTok{)}\OperatorTok{;}
\VariableTok{prog} \OperatorTok{=} \VariableTok{sosdecvar}\NormalTok{(}\VariableTok{prog}\OperatorTok{,}\VariableTok{y}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

I then define the two polynomials in the SOS constraints, two SOS polynomials, and enforce them to the equal.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\% two polynomials}
\VariableTok{p1} \OperatorTok{=} \VariableTok{x}\OperatorTok{\^{}}\FloatTok{4} \OperatorTok{+} \VariableTok{y}\NormalTok{(}\FloatTok{1}\NormalTok{)}\OperatorTok{*}\VariableTok{x} \OperatorTok{+}\NormalTok{ (}\FloatTok{2} \OperatorTok{+} \VariableTok{y}\NormalTok{(}\FloatTok{2}\NormalTok{))}\OperatorTok{;}
\VariableTok{p2} \OperatorTok{=}\NormalTok{ (}\VariableTok{y}\NormalTok{(}\FloatTok{1}\NormalTok{)}\OperatorTok{{-}}\VariableTok{y}\NormalTok{(}\FloatTok{2}\NormalTok{)}\OperatorTok{+}\FloatTok{1}\NormalTok{)}\OperatorTok{*}\VariableTok{x}\OperatorTok{\^{}}\FloatTok{2} \OperatorTok{+} \VariableTok{y}\NormalTok{(}\FloatTok{2}\NormalTok{)}\OperatorTok{*}\VariableTok{x} \OperatorTok{+} \FloatTok{1}\OperatorTok{;}
\CommentTok{\% two SOS polynomials}
\NormalTok{[}\VariableTok{prog}\OperatorTok{,} \VariableTok{sig1}\NormalTok{] }\OperatorTok{=} \VariableTok{sossosvar}\NormalTok{(}\VariableTok{prog}\OperatorTok{,}\VariableTok{monomials}\NormalTok{(}\VariableTok{x}\OperatorTok{,}\FloatTok{0}\OperatorTok{:}\FloatTok{2}\NormalTok{))}\OperatorTok{;}
\NormalTok{[}\VariableTok{prog}\OperatorTok{,} \VariableTok{sig2}\NormalTok{] }\OperatorTok{=} \VariableTok{sossosvar}\NormalTok{(}\VariableTok{prog}\OperatorTok{,}\VariableTok{monomials}\NormalTok{(}\VariableTok{x}\OperatorTok{,}\FloatTok{0}\OperatorTok{:}\FloatTok{1}\NormalTok{))}\OperatorTok{;}
\CommentTok{\% matching coefficients}
\VariableTok{prog} \OperatorTok{=} \VariableTok{soseq}\NormalTok{(}\VariableTok{prog}\OperatorTok{,}\VariableTok{p1}\OperatorTok{{-}}\VariableTok{sig1}\NormalTok{)}\OperatorTok{;}
\VariableTok{prog} \OperatorTok{=} \VariableTok{soseq}\NormalTok{(}\VariableTok{prog}\OperatorTok{,}\VariableTok{p2}\OperatorTok{{-}}\VariableTok{sig2}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Finally, I set the objective function, choose a solver, and solve the SOS program.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\% objective}
\VariableTok{prog} \OperatorTok{=} \VariableTok{sossetobj}\NormalTok{(}\VariableTok{prog}\OperatorTok{,{-}}\NormalTok{(}\VariableTok{y}\NormalTok{(}\FloatTok{1}\NormalTok{)}\OperatorTok{+}\VariableTok{y}\NormalTok{(}\FloatTok{2}\NormalTok{)))}\OperatorTok{;}
\CommentTok{\% choose solver}
\VariableTok{options}\NormalTok{.}\VariableTok{solver} \OperatorTok{=} \SpecialStringTok{\textquotesingle{}mosek\textquotesingle{}}\OperatorTok{;}
\VariableTok{prog} \OperatorTok{=} \VariableTok{sossolve}\NormalTok{(}\VariableTok{prog}\OperatorTok{,}\VariableTok{options}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

After solving the SOS program, I extract the optimal solution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\% get solution}
\VariableTok{ystar} \OperatorTok{=} \VariableTok{double}\NormalTok{(}\VariableTok{sosgetsol}\NormalTok{(}\VariableTok{prog}\OperatorTok{,}\VariableTok{y}\NormalTok{))}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

which produces
\[
y_{\star} = (6.6189, 3.8716).
\]

How do I get the solutions to \(Q_1\) and \(Q_2\)? If I go to the field \texttt{prog.solinfo.x}, I see a vector of dimension \(15\), which is \(2 + 3^2 + 2^2\). Therefore, I can extract \(Q_{1\star}\) and \(Q_{2\star}\) with

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{Q1star} \OperatorTok{=} \VariableTok{reshape}\NormalTok{(}\VariableTok{prog}\NormalTok{.}\VariableTok{solinfo}\NormalTok{.}\VariableTok{x}\NormalTok{(}\FloatTok{2}\OperatorTok{+}\FloatTok{1}\OperatorTok{:}\FloatTok{2}\OperatorTok{+}\FloatTok{9}\NormalTok{)}\OperatorTok{,}\FloatTok{3}\OperatorTok{,}\FloatTok{3}\NormalTok{)}\OperatorTok{;}
\VariableTok{Q2star} \OperatorTok{=} \VariableTok{reshape}\NormalTok{(}\VariableTok{prog}\NormalTok{.}\VariableTok{solinfo}\NormalTok{.}\VariableTok{x}\NormalTok{(}\FloatTok{2}\OperatorTok{+}\FloatTok{9}\OperatorTok{+}\FloatTok{1}\OperatorTok{:}\KeywordTok{end}\NormalTok{)}\OperatorTok{,}\FloatTok{2}\OperatorTok{,}\FloatTok{2}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

which produces
\[
Q_{1\star} = \begin{bmatrix} 5.8716 & 3.3095 & -1.3990 \\
3.3095 & 2.7980 & 0 \\-1.3990 & 0 & 1 \end{bmatrix}, \quad 
Q_{2\star} = \begin{bmatrix} 1 & 1.9358 \\ 1.9358 & 3.7473 \end{bmatrix}.
\]

The implementation can be found \href{https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/sos_program_example_sostools.m}{here}.

The implementation in SOSTOOLS is a bit unsatisfying because (i) one needs to separately define \(x\) and \(y\), (ii) the extraction of \(Q_1\) and \(Q_2\) is not very intuitive. The following implementation shows how to solve the same SOS program using YALMIP \citep{lofberg04icra-yalmip}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\% define all variables}
\VariableTok{x} \OperatorTok{=} \VariableTok{sdpvar}\NormalTok{(}\FloatTok{1}\NormalTok{)}\OperatorTok{;}
\VariableTok{y} \OperatorTok{=} \VariableTok{sdpvar}\NormalTok{(}\FloatTok{2}\OperatorTok{,}\FloatTok{1}\NormalTok{)}\OperatorTok{;}
\VariableTok{Q1} \OperatorTok{=} \VariableTok{sdpvar}\NormalTok{(}\FloatTok{3}\OperatorTok{,}\FloatTok{3}\NormalTok{)}\OperatorTok{;}
\VariableTok{Q2} \OperatorTok{=} \VariableTok{sdpvar}\NormalTok{(}\FloatTok{2}\OperatorTok{,}\FloatTok{2}\NormalTok{)}\OperatorTok{;}
\CommentTok{\% define polynomials}
\VariableTok{p1} \OperatorTok{=} \VariableTok{x}\OperatorTok{\^{}}\FloatTok{4} \OperatorTok{+} \VariableTok{y}\NormalTok{(}\FloatTok{1}\NormalTok{)}\OperatorTok{*}\VariableTok{x} \OperatorTok{+}\NormalTok{ (}\FloatTok{2} \OperatorTok{+} \VariableTok{y}\NormalTok{(}\FloatTok{2}\NormalTok{))}\OperatorTok{;}
\VariableTok{p2} \OperatorTok{=}\NormalTok{ (}\VariableTok{y}\NormalTok{(}\FloatTok{1}\NormalTok{)}\OperatorTok{{-}}\VariableTok{y}\NormalTok{(}\FloatTok{2}\NormalTok{)}\OperatorTok{+}\FloatTok{1}\NormalTok{)}\OperatorTok{*}\VariableTok{x}\OperatorTok{\^{}}\FloatTok{2} \OperatorTok{+} \VariableTok{y}\NormalTok{(}\FloatTok{2}\NormalTok{)}\OperatorTok{*}\VariableTok{x} \OperatorTok{+} \FloatTok{1}\OperatorTok{;}
\CommentTok{\% SOS polynomials}
\VariableTok{sig1} \OperatorTok{=} \VariableTok{monolist}\NormalTok{(}\VariableTok{x}\OperatorTok{,}\FloatTok{2}\NormalTok{)}\OperatorTok{\textquotesingle{}} \OperatorTok{*} \VariableTok{Q1} \OperatorTok{*} \VariableTok{monolist}\NormalTok{(}\VariableTok{x}\OperatorTok{,}\FloatTok{2}\NormalTok{)}\OperatorTok{;}
\VariableTok{sig2} \OperatorTok{=} \VariableTok{monolist}\NormalTok{(}\VariableTok{x}\OperatorTok{,}\FloatTok{1}\NormalTok{)}\OperatorTok{\textquotesingle{}} \OperatorTok{*} \VariableTok{Q2} \OperatorTok{*} \VariableTok{monolist}\NormalTok{(}\VariableTok{x}\OperatorTok{,}\FloatTok{1}\NormalTok{)}\OperatorTok{;}
\CommentTok{\% define all constraints}
\VariableTok{F} \OperatorTok{=}\NormalTok{ [}\VariableTok{Q1}\OperatorTok{\textgreater{}=}\FloatTok{0}\OperatorTok{,} \VariableTok{Q2}\OperatorTok{\textgreater{}=}\FloatTok{0}\OperatorTok{,...}
    \VariableTok{coefficients}\NormalTok{(}\VariableTok{p1}\OperatorTok{{-}}\VariableTok{sig1}\OperatorTok{,}\VariableTok{x}\NormalTok{)}\OperatorTok{==}\FloatTok{0}\OperatorTok{,...}
    \VariableTok{coefficients}\NormalTok{(}\VariableTok{p2}\OperatorTok{{-}}\VariableTok{sig2}\OperatorTok{,}\VariableTok{x}\NormalTok{)}\OperatorTok{==}\FloatTok{0}\NormalTok{]}\OperatorTok{;}
\CommentTok{\% objective}
\VariableTok{obj} \OperatorTok{=} \OperatorTok{{-}}\NormalTok{(}\VariableTok{y}\NormalTok{(}\FloatTok{1}\NormalTok{)}\OperatorTok{+}\VariableTok{y}\NormalTok{(}\FloatTok{2}\NormalTok{))}\OperatorTok{;}
\CommentTok{\% solve}
\VariableTok{options} \OperatorTok{=} \VariableTok{sdpsettings}\NormalTok{(}\SpecialStringTok{\textquotesingle{}solver\textquotesingle{}}\OperatorTok{,}\SpecialStringTok{\textquotesingle{}mosek\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\VariableTok{optimize}\NormalTok{(}\VariableTok{F}\OperatorTok{,}\VariableTok{obj}\OperatorTok{,}\VariableTok{options}\NormalTok{)}\OperatorTok{;}
\CommentTok{\% extract solution}
\VariableTok{ystar} \OperatorTok{=} \VariableTok{value}\NormalTok{(}\VariableTok{y}\NormalTok{)}\OperatorTok{;}
\VariableTok{Q1star} \OperatorTok{=} \VariableTok{value}\NormalTok{(}\VariableTok{Q1}\NormalTok{)}\OperatorTok{;}
\VariableTok{Q2star} \OperatorTok{=} \VariableTok{value}\NormalTok{(}\VariableTok{Q2}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

We get the same solution as using SOSTOOLS. The implementation in YALMIP can be found \href{https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/sos_program_example_yalmip.m}{here}.
\end{example}

\section{Positivstellensatz}\label{positivstellensatz}

We have seen that in the univariate case, a polynomial is nonnegative if and only if it is SOS; while in the multivariate case, being SOS is a sufficient but not necessary condition for nonnegativity in general (e.g., think of the Motzkin's polynomial). Those characterizations are stated with respect to \(\mathbb{R}^{n}\). What if we are interested in nonnegativity over only a subset of \(\mathbb{R}^{n}\)?

\subsection{Univaraite Intervals}\label{univaraite-intervals}

The first result we present here is w.r.t. univariate intervals.

\begin{theorem}[Nonnegativity Over Univaraite Intervals]
\protect\hypertarget{thm:SOSUnivariateInterval}{}\label{thm:SOSUnivariateInterval}A univariate polynomial \(p(x)\) is nonnegative on \([0,\infty]\) if and only if it can be written as
\begin{equation}
p(x) = s(x) + x \cdot t(x)
\label{eq:SOS-univariate-interval-1}
\end{equation}
where \(s(x)\) and \(t(x)\) are both SOS polynomials. If \(\deg(p) = 2d\), then we have \(\deg(s) \leq 2d\) and \(\deg(t) \leq 2d -2\), while if \(\deg(p) = 2d+1\), then \(\deg(s) \leq 2d, \deg(t) \leq 2d\).

Similarly, a univariate polynomial \(p(x)\) is nonnegative on the interval \([a,b]\) with \(a < b\) if and only if it can be written as
\begin{equation}
\begin{cases}
p(x) = s(x) + (x-a)(b-x) \cdot t(x) & \text{if } \deg(p) = 2d, \\
p(x) = (x-a)\cdot s(x) + (b-x) \cdot t(x) & \text{if } \deg(p) = 2d + 1
\end{cases}
\label{eq:SOS-univariate-interval-2}
\end{equation}
where both \(s(x),t(x)\) are SOS polynomials. In the first case, \(\deg(s) \leq 2d\), \(\deg(t) \leq 2d -2\). In the second case, \(\deg(s) \leq 2d, \deg(t) \leq 2d\).
\end{theorem}

A simple example of the above theorem is that the polynomial \(p(x)=x^3\) is nonnegative on the interval \([0,\infty]\) (but not on \(\mathbb{R}^{}\)) because we can write \(p(x) = x \cdot x^2\) where \(x^2\) is SOS.

It should be noted that the ``if'' direction is clear, i.e., when \(p(x)\) can be written as in \eqref{eq:SOS-univariate-interval-1} and \eqref{eq:SOS-univariate-interval-2}, it certifies nonnegativity because the polynomials \(x, x-a, b-x, (x-a)(b-x)\) are all nonnegative on the respective intervals. The ``only if'' direction is nontrivial and it states that it is sufficient to consider the decompositions in \eqref{eq:SOS-univariate-interval-1} and \eqref{eq:SOS-univariate-interval-2} with bounded degrees on \(s(x)\) and \(t(x)\). It should also be noted that finding \(s(x)\) and \(t(x)\) can be done using SOS programming as introduced above.

\subsection{Affine Variety}\label{affine-variety}

Consider now the case where we are interested in deciding if a polynomial \(p(x)\) is nonnegative on the set defined by a finite number of polynomial equalities
\[
I = \mathrm{Ideal}[h_1,\dots,h_\ell], \quad V(I) = V_{\mathbb{R}}(I) = \{ x \in \mathbb{R}^{n} \mid h_i(x) = 0, i=1,\dots,\ell \}.
\]
This is an algebraic set. Clearly, if we can decompose \(p(x)\) as
\[
p(x) = \sigma_0(x) + \sum_{i=1}^{\ell} \lambda_i(x) h_i(x),
\]
with \(\sigma_0(x)\) SOS and \(\lambda_i(x)\) arbitrary polynomials, then it verifies nonnegativity on \(V(I)\). To see this, for any \(x \in V(I)\), we have \(h_i(x) = 0,i=1,\dots,\ell\) and hence
\[
p(x) = \sigma_0(x) + \sum_{i=1}^{\ell} \lambda_i(x) \cdot h_i(x) = \sigma_0(x) \geq 0.
\]
The following result states that it is also a necessary condition under additional assumptions.

\begin{theorem}[SOS on Affine Variety]
\protect\hypertarget{thm:SOSonVaritty}{}\label{thm:SOSonVaritty}Let \(I\) be a radical ideal. Then \(p(x)\) is nonnegative on \(V(I)\) if and only if
\begin{equation}
p(x) = \sigma_0(x) + \sum_{i=1}^{\ell} \lambda_i(x) h_i(x)
\label{eq:SOS-variety-decomposition}
\end{equation}
for \(\sigma_0(x)\) that is SOS and \(\lambda_1(x),\dots,\lambda_{\ell}(x)\) that are arbitrary polynomials.
\end{theorem}

Note that the assumption that \(I\) is radical is necessary when \(p(x)\) is nonnegative but not strictly positive. For example, the polynomial \(p(x)=x\) is nonnegative on the variety defined by the non-radical ideal \(\mathrm{Ideal}[x^2]\), but no decomposition of the form \(x = \sigma_0(x) + \lambda(x) x^2\) can possibly exist.

It is also worth noting that, in stark contrast with the Positivstellensatz conditions we stated so far, the degrees of \(\sigma_0(x)\) and \(\lambda_i(x)\) are not bounded in the decomposition \eqref{eq:SOS-variety-decomposition}! Therefore, one may need to search for nonnegativity certifcates with infinite degrees. To make the decomposition tractable, it is often done in practice to limit the degrees of \(\sigma_0(x)\) and \(\lambda_i(x)\) to bound the computational complexity.

It is clear that finding a decomposition of the form \eqref{eq:SOS-variety-decomposition} with bounded degrees on \(\sigma_0(x)\) and \(\lambda_i(x)\) is an instance of SOS programming.

When a Grobner basis of the ideal \(I\) is available, we can leverage the structure of the problem to formulate a more efficient type of SOS program.

Define the quotient ring \(\mathbb{R}[x]/I\), a different perspective to look at \eqref{eq:SOS-variety-decomposition} is that
\[
p(x) \text{ is SOS on } \mathbb{R}[x]/I.
\]
With this perspective, we can formulate an SOS program not with the standard monomial basis, but instead with the \textbf{standard monomials}. Let us see an example.

\begin{example}[SOS on Quotient Ring]
\protect\hypertarget{exm:SOSonQuotientRing}{}\label{exm:SOSonQuotientRing}Consider the problem of deciding if the polynomial
\[
p(x,y) = 10 - x^2 - y
\]
is nonnegative on the affine variety \(V(I)\) with
\[
I = \mathrm{Ideal}[x^2 + y^2 - 1].
\]
Clearly, \(V(I)\) is the unit circle. Since the ideal is generated by a single polynomial, we know that \(h(x,y):= x^2 + y^2 - 1\) is already a Grobner basis. With the graded lexicographic monomial ordering and \(x \prec y\), the corresponding set of standard monomials is
\[
S = \{ 1,x,y,x^2, xy, x^3, x^2 y, \dots \}.
\]
We pick a partial basis of the quotient ring, \(\{ 1,x,y \}\). Then we write
\begin{equation}
\begin{split}
10 - x^2 - y = &  \begin{bmatrix} 1 \\ x \\ y \end{bmatrix}^\top\begin{bmatrix} Q_{11} & Q_{12} & Q_{13} \\ Q_{12} & Q_{22} & Q_{23} \\ Q_{13} & Q_{23} & Q_{33} \end{bmatrix} \begin{bmatrix} 1 \\ x \\ y \end{bmatrix} \\
= & Q_{11} + 2 Q_{12}x + 2 Q_{13} y + Q_{22} x^2 + 2 Q_{23} xy + Q_{33} y^2 \\
\equiv & (Q_{11} + Q_{33}) + (Q_{22} - Q_{33}) x^2 + 2 Q_{12} x + 2 Q_{13} y + 2 Q_{23} xy \quad \text{mod }I 
\end{split}
\end{equation}
where in the last equation we used the normal form of \(y^2\) to write everything using the standard monomials. We can then do the same procedure of matching coefficients and solving the SDP, which gives us a solution
\[
Q = \begin{bmatrix} 9 & 0 & -\frac{1}{2} \\
0 & 0 & 0 \\
- \frac{1}{2} & 0 & 1 
\end{bmatrix}.
\]
Finding a factorization of \(Q\) gives us
\[
10 - x^2 - y \equiv \left( 3 - \frac{y}{6} \right)^2 + 
\frac{35}{36} y^2 \quad \text{mod }I,
\]
and shows that it is SOS on the quotient ring.

What if we do not want to use the Grobner basis and standard monomials? We can directly search for the certificate of the form \eqref{eq:SOS-variety-decomposition} using SOSTOOLS, as shown below

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{x} \OperatorTok{=} \VariableTok{mpvar}\NormalTok{(}\SpecialStringTok{\textquotesingle{}x\textquotesingle{}}\OperatorTok{,}\FloatTok{2}\OperatorTok{,}\FloatTok{1}\NormalTok{)}\OperatorTok{;} \CommentTok{\% dummy x }
\VariableTok{p} \OperatorTok{=} \FloatTok{10} \OperatorTok{{-}} \VariableTok{x}\NormalTok{(}\FloatTok{1}\NormalTok{)}\OperatorTok{\^{}}\FloatTok{2} \OperatorTok{{-}} \VariableTok{x}\NormalTok{(}\FloatTok{2}\NormalTok{)}\OperatorTok{;}
\VariableTok{h} \OperatorTok{=} \VariableTok{x}\NormalTok{(}\FloatTok{1}\NormalTok{)}\OperatorTok{\^{}}\FloatTok{2} \OperatorTok{+} \VariableTok{x}\NormalTok{(}\FloatTok{2}\NormalTok{)}\OperatorTok{\^{}}\FloatTok{2} \OperatorTok{{-}} \FloatTok{1}\OperatorTok{;}
\VariableTok{prog} \OperatorTok{=} \VariableTok{sosprogram}\NormalTok{(}\VariableTok{x}\NormalTok{)}\OperatorTok{;}
\VariableTok{kappa} \OperatorTok{=} \FloatTok{1}\OperatorTok{;} \CommentTok{\% bound of degree}
\NormalTok{[}\VariableTok{prog}\OperatorTok{,} \VariableTok{sig0}\NormalTok{] }\OperatorTok{=} \VariableTok{sossosvar}\NormalTok{(}\VariableTok{prog}\OperatorTok{,}\VariableTok{monomials}\NormalTok{(}\VariableTok{x}\OperatorTok{,}\FloatTok{0}\OperatorTok{:}\VariableTok{kappa}\NormalTok{))}\OperatorTok{;}
\NormalTok{[}\VariableTok{prog}\OperatorTok{,} \VariableTok{lam}\NormalTok{] }\OperatorTok{=} \VariableTok{sospolyvar}\NormalTok{(}\VariableTok{prog}\OperatorTok{,}\VariableTok{monomials}\NormalTok{(}\VariableTok{x}\OperatorTok{,}\FloatTok{0}\OperatorTok{:}\NormalTok{(}\FloatTok{2}\OperatorTok{*}\VariableTok{kappa}\OperatorTok{{-}}\FloatTok{2}\NormalTok{)))}\OperatorTok{;}
\VariableTok{prog} \OperatorTok{=} \VariableTok{soseq}\NormalTok{(}\VariableTok{prog}\OperatorTok{,}\VariableTok{p}\OperatorTok{{-}}\VariableTok{sig0}\OperatorTok{{-}}\VariableTok{lam}\OperatorTok{*}\VariableTok{h}\NormalTok{)}\OperatorTok{;}
\VariableTok{options}\NormalTok{.}\VariableTok{solver} \OperatorTok{=} \SpecialStringTok{\textquotesingle{}mosek\textquotesingle{}}\OperatorTok{;}
\VariableTok{prog} \OperatorTok{=} \VariableTok{sossolve}\NormalTok{(}\VariableTok{prog}\OperatorTok{,}\VariableTok{options}\NormalTok{)}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Note that the variable \texttt{kappa} is used to bound the degree of SOS polynomials. Solving the above SOS program, I get a solution
\[
\sigma_0 = 2.8808 x^2 + 3.8808 y ^2 - y + 6.1192, \quad \lambda = -3.8808.
\]
It is easy to verify that \(p = \sigma_0 + \lambda h\).

Note that the decomposition in \eqref{eq:SOS-variety-decomposition} needs not be unique. If we increase \(\kappa\) to be \(2\), we get the solution
\begin{equation}
\begin{split}
\sigma_0 = 2.3716 x^4 + 4.8085 x^2 y^2 + 2.4369 y^4 - 0.14344 x^2 y \\ - 0.14344 y^3 + 1.3059 x^2 + 2.2406 y^2 - 0.85656 y + 5.3225,
\end{split}
\end{equation}
\[
\lambda = -2.3716 x^2 - 2.4369 y^2 + 0.14344 y - 4.6775.
\]
You can play with the code \href{https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/sos_quotient_ring.m}{here}.
\end{example}

\subsection{Basic Semialgebraic Sets}\label{basic-semialgebraic-sets}

We are ready to bring SOS nonnegativity certifcates to full generality. In optimization, usually we are faced with a constraint set defined by finitely many polynomial equalities and inequalities:
\begin{equation}
S = \{ x \in \mathbb{R}^{n} \mid h_i(x)=0, i=1,\dots,\ell_h, g_i(x) \geq 0, i = 1,\dots,\ell_g \},
\label{eq:basic-semialgebraic-set}
\end{equation}
where \(h_i\) and \(g_i\) are polynomials in \(x\). \(S\) is a basic closed semialgebraic set. Often times we are interested in minimizing another polynomial \(p(x)\) over \(S\). Before talking about this optimization problem, let us discuss how we can certify nonnegativity of \(p(x)\) over \(S\), because minimizing \(p(x)\) can be equivalently written as certifying nonnegativity.

\subsubsection{Quadratic Module and Preorder}\label{quadratic-module-and-preorder}

Given a set of polynomials \(h_1,\dots,h_{\ell_h}\), we have seen that the ideal generated by them is
\[
I=\mathrm{Ideal}[h_1,\dots,h_{\ell_h}] =  \left\{ \sum_{i=1}^{\ell_h} \lambda_i(x) h_i(x) \ \middle\vert\ \lambda_i(x) \in \mathbb{R}[x],i=1,\dots,\ell_h  \right\} .
\]
Every polynomial in the ideal vanishes on \(V_{\mathbb{R}}(I)\), i.e., the algebraic set defined by \(I\).

What is the corresponding notion of an ideal when we have inequalities \(g_1,\dots,g_{\ell_g}\)? That is to say, we can try to generate many other polynomials that are also nonnegative on the basic semialgebraic set defined by the inequalities.

\begin{definition}[Quadratic Module]
\protect\hypertarget{def:QuadraticModule}{}\label{def:QuadraticModule}Given a set of multivariate polynomials \(\{ g_1(x),\dots,g_{\ell_g}(x) \}\), the quadratic module generated by them is the set
\[
\mathrm{Qmodule}[g_1,\dots,g_{\ell_g}] =  \left\{  \sigma_0(x) + \sigma_1(x)g_1(x) + \cdots + \sigma_{\ell_g}(x) g_{\ell_g}(x) \mid \sigma_0,\dots,\sigma_{\ell_g} \text{ are SOS}  \right\} .
\]

The \(2d\)-th order truncated quadratic module is
\begin{equation}
\begin{split}
\mathrm{Qmodule}[g_1,\dots,g_{\ell_g}]_{2d} = \\
 \left\{  \sigma_0(x) + \sum_{i=1}^{\ell_g} \sigma_i(x)g_i(x) \mid \sigma_0,\dots,\sigma_{\ell_g} \text{ are SOS}, \deg(\sigma_0) \leq 2d, \deg(\sigma_i g_i) \leq 2d,i=1,\dots,\ell_g \right\} .
\end{split}
\end{equation}
\end{definition}

For any polynomial \(g\) in the quadratic module, and any \(x\) such that \(g_i(x) \geq 0,i=1,\dots,\ell_g\), we have \(g(x) \geq 0\) due to the fact that \(\sigma_i(x)\) are SOS polynomials.

This is not the only way to generate valid inequality constraints given the existing inequalities \(\{ g_1(x),\dots,g_{\ell_g}(x) \}\). More general than the quadratic module is the notion of a preorder.

\begin{definition}[Preorder]
\protect\hypertarget{def:Preorder}{}\label{def:Preorder}Given a set of multivariate polynomials \(\{ g_1(x),\dots,g_{\ell_g}(x) \}\), the preorder generated by them is the set
\begin{equation}
\begin{split}
\mathrm{Preorder}[g_1,\dots,g_{\ell_g}] = \{ \sigma_0(x) + \sum_{i} \sigma_i(x) g_i(x) +  \sum_{i,j} \sigma_{ij}(x) g_i(x) g_j(x) \\
 + \sum_{i,j,k} \sigma_{ijk}(x) g_i(x) g_j(x) g_k(x) + \cdots \mid \sigma_0(x),\sigma_i(x),\sigma_{ij}(x),\sigma_{ijk}(x)\dots \text{ are SOS} \}
\end{split}
\end{equation}
\end{definition}

Comparing the preorder with the quadratic module, we see that when forming the preorder, it is allowed to take arbitrary products of the given polynomials. For this reason, it is clear to observe that
\[
\mathrm{Qmodule}[g_1,\dots,g_{\ell_g}] \subset \mathrm{Preorder}[g_1,\dots,g_{\ell_g}].
\]
Moreover, for any \(g \in \mathrm{Preorder}[g_1,\dots,g_{\ell_g}]\), and any \(x\) such that \(g_i \geq 0, i=1,\dots,\ell_g\), we have that \(g(x) \geq 0\) must also hold.

Now the question is, consider the set
\[
S_{\geq 0} := \{ x \in \mathbb{R}^{n} \mid g_i(x) \geq 0, i=1,\dots,\ell_g \},
\]
do the quadratic module and the preorder generate \textbf{all possible} polynomials that are nonnegative on the set \(S_{\geq 0}\)? The answer is no, as shown by the following exercise.

\begin{exercise}
\leavevmode

\begin{itemize}
\item
  Let \(S = \{ x \in \mathbb{R}^{} \mid x^3 \geq 0 \}\). Show that the polynomial \(x\) is nonnegative on \(S\) but it is not in \(\mathrm{Preorder}[x^3]\) (and thus is also not in \(\mathrm{Qmodule}[x^3]\)).
\item
  Let \(S = \{ x \in \mathbb{R}^{}\mid x\geq 0, y\geq 0 \}\). Show that the polynomial \(xy\) is nonnegative on the feasible set but is not in \(\mathrm{Qmodule}[x,y]\) (but it is in \(\mathrm{Preorder}[x,y]\)).
\end{itemize}

\end{exercise}

\subsubsection{The Positivstellensatz}\label{the-positivstellensatz}

With the introduction of the quadratic module and the preorder, we can state one of the cornerstone results in real algebraic geometry, the Positivstellensatz, due to \citep{stengle74ma-nullstellensatz} and presented in the following form due to \citep{bochnak13book-real}.

\begin{theorem}[Positivstellensatz]
\protect\hypertarget{thm:Positivstellensatz}{}\label{thm:Positivstellensatz}Consider the set \(S\) in \eqref{eq:basic-semialgebraic-set} that is defined by polynomial equalities and inequalities. The set \(S\) is empty (i.e., the polynomial equalities and inequalities have no solutions in \(\mathbb{R}^{n}\)) if and only if
\[
\exists H(x), G(x) \in \mathbb{R}[x] \quad \mathrm{s.t.}\quad \begin{cases}
H(x) + G(x) = -1 \\
H(x) \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}] \\
G(x) \in \mathrm{Preorder}[g_1,\dots,g_{\ell_g}]
\end{cases}.
\]
\end{theorem}

Let us parse the Positivstellensatz result a bit.

\begin{itemize}
\item
  The if direction should be clear. If \(S\) is nonempty, then pick \(x \in S\), we have
  \[
  H(x) = 0, \quad G(x) \geq 0
  \]
  for any \(H(x)\) in the ideal and \(G(x)\) in the preorder. However, \(H(x) + G(x) = -1\) exists for some \(H\) and \(G\), creating a contradiction. The only if direction is not easy to prove but it states that as long as \(S\) is empty, there exists \(H(x)\) and \(G(x)\) that will serve as \textbf{certificates of infeasibility}.
\item
  The Positivstellensatz holds \textbf{without any assumptions} on the defining polynomials \(h_1,\dots,h_{\ell_h}\) and \(g_1,\dots,g_{\ell_g}\). They need not be convex.
\item
  There is no guarantee that the degrees of the polynomials \(H(x)\) and \(G(x)\) are bounded. However, once we bound the degrees of \(H(x)\) and \(G(x)\) (more precisely bound the degrees of the polynomial and SOS multipliers in the ideal and the preorder), then seaching for such certificates is a \textbf{convex optimization} problem! In particular, they are SOS programs that we have seen before.
\end{itemize}

Let us see an example.

\begin{example}[Positivstellensatz]
\protect\hypertarget{exm:Positivstellensatz}{}\label{exm:Positivstellensatz}Consider the following polynomial system:
\begin{equation}
\begin{split}
h_1 & := x_1^2 + x_2^2 -1 = 0 \\
g_1 & := 3x_2 - x_1^3 -2 \geq 0 \\
g_2 & := x_1 - 8 x_2^3 \geq 0
\end{split}
\end{equation}

We will use the Positivstellensatz to prove that this system has no real solutions. To do so, according to the Positivstellensatz, the system is infeasible if and only if
\[
\underbrace{\lambda_1(x) h_1(x)}_{\mathrm{Ideal}[h_1]} + \underbrace{\sigma_0(x) + \sigma_1(x) g_1(x) + \sigma_2(x) g_2(x) + \sigma_{12}(x) g_1(x) g_2(x)}_{\mathrm{Preorder}[g_1,g_2]} = -1.
\]
where \(\lambda_1\) is an arbitrary polynomial and \(\sigma_0,\sigma_1,\sigma_2,\sigma_{12}\) are SOS polynomials.

We will use SOS programming to find such certificates. In particular, we will search for certifcates with bounded degree \(2\kappa\), where \(\kappa \in \mathbb{N}\) is the degree of choice. Solving the SOS program with \(\kappa=4\), we found an infeasibility certifcate. The code can be found \href{https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/example_infeasibility.m}{here}.
\end{example}

We can use the Positivstellensatz to induce a positivity certificate. Given the set \(S\) defined in \eqref{eq:basic-semialgebraic-set}, and another polynomial \(p(x)\), how can we certify that \(p(x)\) is \textbf{strictly positive} on \(S\)? This is equivalent to showing that the following polynomial system has no real solutions:
\begin{equation}
\begin{cases}
h_i(x) = 0, i=1,\dots,\ell_h \\
g_i(x) \geq 0, i=1,\dots, \ell_g \\
p(x) \leq 0 \Leftrightarrow -p(x) \geq 0
\end{cases}.
\label{eq:Positivstellensatz-positivity}
\end{equation}
By the Positivstellensatz, the polynomial system in \eqref{eq:Positivstellensatz-positivity} has no real solutions if and only if
\[
\underbrace{\sum_{i}^{\ell_h} \lambda_i h_i}_{\mathrm{Ideal}[h_1,\dots,h_{\ell_h}]} + \underbrace{\sigma_0 + \sigma_{p} (-p) + \sum_{i=1}^{\ell_g} \sigma_i g_i + \sum_{i,j} \sigma_{ij} g_i g_j + \sum_{i,p} \sigma_{ip} g_i (-p) + \cdots}_{\mathrm{Preorder}[-p,g_1,\dots,g_{\ell_g}]} = -1
\]
Rearranging terms we get
\[
p\underbrace{\left( \sigma_p + \sum_{i,p} \sigma_{ip} g_i  + \cdots \right)}_{\mathrm{Preorder}[g_1,\dots,g_{\ell_g}]} = 1 + \underbrace{\sum_{i=1}^{\ell_h}}_{\mathrm{Ideal}[h_1,\dots,h_{\ell_h}]} + \underbrace{\sigma_0 + \sum_{i=1}^{\ell_g} \sigma_i g_i + \sum_{i,j} \sigma_{ij} g_i g_j + \cdots}_{\mathrm{Preorder}[g_1,\dots,g_{\ell_g}]}.
\]
Consequently, we have the following corollary.

\begin{corollary}[Positivstellensatz]
\protect\hypertarget{cor:Positivstellensatz}{}\label{cor:Positivstellensatz}Consider the set \(S\) defined in \eqref{eq:basic-semialgebraic-set}. A polynomial \(p(x)\) is strictly positive on \(S\) if and only if there exist \(G_1(x),G_2(x),H(x) \in \mathbb{R}[x]\) such that
\[
p(x) = \frac{1 + H(x) + G_1(x)}{G_2(x)}, \quad H(x) \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}], G_1(x),G_2(x) \in \mathrm{Preorder}[g_1,\dots,g_{\ell_g}].
\]
\end{corollary}

\subsubsection{Schmudgen's and Putinar's Positivity Certificates}\label{schmudgens-and-putinars-positivity-certificates}

The positivity certifcate in Corollay \ref{cor:Positivstellensatz} holds without any assumptions on the set \(S\). However, when the set \(S\) is compact, the positivity certifcate can be simplified.

The first simplification is due to Schmudgen \citep{Schmudgen91ma-moment}.

\begin{theorem}[Schmudgen's Positivstellensatz]
\protect\hypertarget{thm:Schmudgen}{}\label{thm:Schmudgen}Let \(S\) defined in \eqref{eq:basic-semialgebraic-set} be compact. A polynomial \(p(x)\) is strictly positive on \(S\) if and only if
\[
p(x) \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}] + \mathrm{Preorder}[g_1,\dots,g_{\ell_g}].
\]
\end{theorem}

The second simplification, due to Putinar \citep{putinar93-positive} adds a further assumption that the set \(S\) is compact with a certifcate.

\begin{definition}[Archimedean]
\protect\hypertarget{def:Archimedean}{}\label{def:Archimedean}The set \(S\) is said to be Archimedean if there exists \(N \in \mathbb{N}\) such that
\[
N - \sum_{i=1}^n x_i^2 \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}] + \mathrm{Qmodule}[g_1,\dots,g_{\ell_g}].
\]
\end{definition}

In practice, if we know the set \(S\) is compact, then we might as well just add a constraint \(g:=N - \sum_{i=1}^{n} x_i^2\) to the set \(S\) to make the Archimedean condition trivially satisfied. Under the Archimedean condition, we have the simpler Positivstellensatz.

\begin{theorem}[Putinar's Positivstellensatz]
\protect\hypertarget{thm:Putinar}{}\label{thm:Putinar}Let \(S\) defined in \eqref{eq:basic-semialgebraic-set} be Archimedean. A polynomial \(p(x)\) is strictly positive on \(S\) if and only if
\[
p(x) \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}] + \mathrm{Qmodule}[g_1,\dots,g_{\ell_g}].
\]
\end{theorem}

It is important to recognize that searching for positivity certifcates in the form of Schmudgen or Putinar with \textbf{bounded degrees} is a convex optimization problem.

\section{Applications}\label{applications-1}

The Positivstellensatz results stated above are extremely powerful tools and they have a broad set of applications due to their connections with semidefinite programming.

\subsection{Polynomial Optimization}\label{SOS:POP}

Consider the polynomial optimization problem (POP)
\begin{equation}
\begin{split}
p^\star = \min_{x \in \mathbb{R}^{n}} & \quad p(x) \\
\mathrm{s.t.}& \quad h_i(x) = 0, i=1,\dots,\ell_h \\
& \quad g_i(x) \geq 0, i=1,\dots,\ell_g
\end{split}
\label{eq:pop}
\end{equation}
We denote the feasible set of \eqref{eq:pop} as \(S\) and we assume \(S\) is nonempty. The POP is a very general modelling language and in general it is NP-hard to solve it to global optimality. To connect it with the QCQP formulation we introduced before, we clearly see that POP subsumes QCQP.

We will show that the Positivstellensatz provides a way to use convex optimization to approximately solve POP to global optimality. To see this, note that the original POP formulation \eqref{eq:pop} is equivalent to
\begin{equation}
\max \quad \gamma \quad \mathrm{s.t.}\quad p(x) - \gamma \text{ is nonnegative on } S. 
\label{eq:pop-gamma-nonnegative}
\end{equation}
Since it is challenging to handle the nonnegativity constraint, we can relax it using the Positivstellensatz results before. For example, assuming the set \(S\) is Archimedean, we can invoke Putinar's Positivstellensatz and equivalently write \eqref{eq:pop-gamma-nonnegative} as
\begin{equation}
\max \quad \gamma \quad \mathrm{s.t.}\quad p(x) - \gamma \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}] + \mathrm{Qmodule}[g_1,\dots,g_{\ell_g}]. 
\label{eq:pop-gamma-nonnegative-Putinar}
\end{equation}
To make \eqref{eq:pop-gamma-nonnegative-Putinar} computationally tractable, we can bound the degree of the terms and formulate the following optimization problem
\begin{equation}
\max \quad \gamma \quad \mathrm{s.t.}\quad p(x) - \gamma \in \mathrm{Ideal}[h_1,\dots,h_{\ell_h}]_{2\kappa} + \mathrm{Qmodule}[g_1,\dots,g_{\ell_g}]_{2\kappa},
\label{eq:pop-gamma-nonnegative-Putinar-truncated}
\end{equation}
where the subscript \(2\kappa\) indicates the ideal and the quadratic module are truncated at degree \(2\kappa\). Problem \eqref{eq:pop-gamma-nonnegative-Putinar-truncated} can be explicitly written as
\begin{equation}
\begin{split}
\gamma^\star_{\kappa}=\max & \quad \gamma\\
\mathrm{s.t.}& \quad p(x) - \gamma = \sum_{i}^{\ell_h} \lambda_i(x) h_i(x) + \sum_{i=0}^{\ell_g} \sigma_i(x) g_i(x) \\
& \quad \deg(\lambda_i(x) h_i(x)) \leq 2\kappa, i=1,\dots,\ell_h \\
& \quad \deg(\sigma_i(x) g_i(x)) \leq 2\kappa, i=1,\dots,\ell_g \\
& \quad \lambda_i(x) \in \mathbb{R}[x], i=1,\dots,\ell_h, \quad \sigma_i(x) \in \Sigma[x], i=1,\dots,\ell_g.
\end{split}
\label{eq:pop-gamma-nonnegative-Putinar-bound}
\end{equation}
where I have added \(g_0:=1\) as a dummy constraint, \(\Sigma[x]\) denotes the set of SOS polynomials, and \(\kappa\) is called the \textbf{relaxation order}. We have
\[
\gamma^\star_{\kappa} \leq p^\star.
\]

\textbf{Problem \eqref{eq:pop-gamma-nonnegative-Putinar-bound} is convex!} In fact, it is an instance of an SOS program. Note, again, \textbf{the decision variable of \eqref{eq:pop-gamma-nonnegative-Putinar-bound} is not \(x\)!} The decision variable is \(\gamma\), the coefficients of \(\lambda_i\), and the coefficients (Gram matrix) of \(\sigma_i\).

Let us use a simple example to illustrate this.

\begin{example}[SOS Relaxation of Polynomial Optimization]
\protect\hypertarget{exm:SOSRelaxation}{}\label{exm:SOSRelaxation}Consider the optimization problem
\[
\min_{x_1,x_2} \quad 4 x_1^3 + 6 x_2  \quad \mathrm{s.t.}\quad x_1^2 = x_2^2 = 1, x_1 \geq 0.
\]
This is a POP we can solve by hand. The optimal solution is
\[
x_\star = (1,-1),
\]
with the optimal value \(p^\star = -2\).
The feasible set is Archimedean. Therefore, we can solve \eqref{eq:pop-gamma-nonnegative-Putinar-bound} to obtain a lower bound to \(p^\star\).

Solving \eqref{eq:pop-gamma-nonnegative-Putinar-bound} at \(\kappa=2\), we obtain \(\gamma_{2}^\star = -2\), which is actually the true global optimum!

Make sure you check out the \href{https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/example_pop.m}{code}.
\end{example}

\subsection{Lyapunov Certificates}\label{lyapunov-certificates}

In Chapter \ref{LyapunovLinearSystem} we have seen the application of SDP in certifying stability of linear systems via the notion of a Lyapunov function. With sums of squares, we can generalize Lyapunov certifcates to nonlinear systems, in particular systems whose dynamics can be written as polynomials. You can \href{https://hankyang.seas.harvard.edu/OptimalControlEstimation/stability.html\#computing-lyapunov-certificates}{find more information in this webpage}.

\chapter{Moment Relaxation}\label{Moment}

In the last Chapter, we have learned a lot about polynomials, and in particular, the cone of nonnegative polynomials \(P_{n,2d}\), and the cone of SOS polynomials \(\Sigma_{n,2d}\), with the key inclusion relationship
\[
\Sigma_{n,2d} \subseteq P_{n,2d}.
\]

A natural question is then to characterize the dual of \(P_{n,2d}\) and \(\Sigma_{n,2d}\). Let me first restate the dual of a convex set here from Definition \ref{def:Dual}.

\begin{definition}[Dual Cone]
\protect\hypertarget{def:DualConeRestate}{}\label{def:DualConeRestate}The dual of a convex cone \(S\) is
\[
S^* := \{ y \mid \langle y, x \rangle \geq 0, \forall x \in S \}.
\]
\end{definition}

\section{Dual Cones of Polynomials}\label{dual-cones-of-polynomials}

What are the dual cones of \(P_{n,2d}\) and \(\Sigma_{n,2d}\)?

For a cone of polynomials, we will first need to define the notion of an inner product in Definition \ref{def:DualConeRestate}, i.e., a map that takes in a polynomial and returns a real number. The space of all such maps is the dual space of \(\mathbb{R}[x]_{2d}\), which we denote \(\mathbb{R}[x]^*_{2d}\). The elements of this vector space are \textbf{linear functionals of polynomials}
\begin{equation}
\ell: \mathbb{R}[x]_{2d} \rightarrow \mathbb{R}^{}.
\label{eq:linear-functional-poly}
\end{equation}
There are many such functionals and they can superficially look quite different. Given \(p(x) \in \mathbb{R}[x]_{2d}\), here are some examples of linear functionals:

\begin{itemize}
\item
  Evaluation of \(p(x)\) at a point \(x_0 \in \mathbb{R}^{n}\), i.e., \(p \mapsto p(x_0)\)
\item
  Integration of \(p(x)\) over a subset \(S \subset \mathbb{R}^{n}\), i.e., \(p \mapsto \int_S p(x) dx\)
\item
  Evaluation of derivatives of \(p\) at a point \(x_0 \in \mathbb{R}^{n}\), i.e., \(p \mapsto \frac{\partial p}{\partial x_i \cdots \partial x_k} (x_0)\)
\item
  Extraction of coefficients, i.e., \(p \mapsto p_{\alpha}\), where \(p_{\alpha}\) is the coefficient corresponding to the monomial \(x^{\alpha}\)
\end{itemize}

For all the examples above, it is easy to verify linearity
\[
\ell(p_1 + p_2) = \ell(p_1) + \ell(p_2), \quad \langle \ell, p_1 + p_2 \rangle = \langle \ell, p_1 \rangle + \langle \ell, p_2 \rangle.
\]

A distinguished class of linear functionals are the point evaluations (our first example above): given any point \(v \in \mathbb{R}^{n}\), we can generate a linear functional
\[
\ell_v \in \mathbb{R}[x]^*_{2d}: \ell_v(p) = p(x), \forall p \in \mathbb{R}[x]_{2d}.
\]
Then, we can generate additional linear functionals by taking linear combinations of point evaluations, i.e., maps of the form
\[
p \mapsto \sum_{i} \lambda_i \ell_{v_i} (p) = \sum_{i} \lambda_i p(v_i), \quad \lambda_i \in \mathbb{R}^{}, v_i \in \mathbb{R}^{n}, \forall i.
\]
It turns out that \emph{all} linear functionals can be generated in such form.

\begin{theorem}[Dual Space of Polynomials]
\protect\hypertarget{thm:DualSpacePoly}{}\label{thm:DualSpacePoly}Every linear functional in \(\mathbb{R}[x]^*_{2d}\) is a linear combination of point evaluations, i.e., for any \(\ell \in \mathbb{R}[x]^*_{2d}\), there exists \(\lambda_1,\dots,\lambda_K\) and \(v_1,\dots,v_K\) such that
\[
\ell_{p} = \sum_{i=1}^K \lambda_i p(v_i).
\]
\end{theorem}

\textbf{Truncated Multi-Sequence (TMS)}. The above characterization of \(\mathbb{R}[x]^*_{2d}\) is purely geometric and coordinate-free. Now we are going to fix the basis of \(\mathbb{R}[x]_{2d}\) to be the standard monomial basis \([x]_{2d}\) with length \(s(n,2d)\). In this coordinate, any linear functional \(\ell\) in \eqref{eq:linear-functional-poly} can be equivalently identified by its values at the monomial basis, this is
\[
\ell: \mathbb{R}[x]_{2d} \rightarrow \mathbb{R}^{}, \quad x^{\alpha} \mapsto y_{\alpha}, \alpha \in \mathcal{F}_{n,2d}.
\]
This set of real numbers
\[
y:=(y_\alpha)_{\alpha \in \mathcal{F}_{n,2d}} \in \mathbb{R}^{s(n,2d)}
\] is called a \textbf{truncated multi-sequences} (TMS) of degree \(2d\). Using this TMS \(y\), and denote the linear functional associated with \(y\) as \(\ell_y \in \mathbb{R}[x]^*_{2d}\), then applying \(\ell_y\) to any polynomial \(p \in \mathbb{R}[x]_{2d}\) is simply
\[
\ell_y(p) = \langle \ell_y, p \rangle = \langle y, \mathrm{vec}(p) \rangle = \sum_{\alpha \in \mathcal{F}_{n,2d}} p_\alpha y_\alpha
\]
i.e., the inner product between the TMS \(y\) and the vector of coefficients of \(p\):
\[
\mathrm{vec}(p) = (p_\alpha)_{\alpha \in \mathcal{F}_{n,2d}}.
\]

\textbf{Moment Matrix}. We now assemble the TMS \(y \in \mathbb{R}^{s(n,2d)}\) into symmetric matrices. In particular, for any nonnegative integer \(\kappa \in [0,d]\), the \textbf{\(\kappa\)-th order moment matrix} of the TMS \(y\) is a symmetric matrix
\[
M_\kappa[y]:= [y_{\alpha + \beta}]_{\alpha,\beta \in \mathcal{F}_{n,\kappa}} \in \mathbb{S}^{s(n,\kappa)},
\]
whose rows and columns are indexed by the exponents \(\alpha\) and \(\beta\), according to the graded lexicographic monomial ordering. Clearly, if \(\kappa_1 \leq \kappa_2\), then \(M_{\kappa_1}[y]\) is a leading principal submatrix of \(M_{\kappa_2}[y]\). Another perspective for looking at the moment matrix is that
\[
M_{\kappa}[y] = \ell_y ([x]_{\kappa} [x]_{\kappa}^\top) = \langle \ell_y, [x]_{\kappa} [x]_{\kappa}^\top \rangle,
\]
where applying the linear functional \(\ell_y\) to the polynomial matrix \([x]_{\kappa} [x]_{\kappa}^\top\) is equivalent to element-wise application.

Let's see some examples.

\begin{example}[Moment Matrix]
\protect\hypertarget{exm:MomentMatrix}{}\label{exm:MomentMatrix}Consider the univariate case \(n=1\), and a TMS
\[
y = (y_0,y_1,\dots,y_{2d}),
\]
the \(d\)-th order moment matrix of \(y\) is the following matrix
\[
M_d[y] = \begin{bmatrix}
y_0 & y_1 & y_2 & y_3 & \cdots & y_d \\
y_1 & y_2 & y_3 & y_4 & \cdots & y_{d+1} \\
y_2 & y_3 & y_4 & y_5 & \cdots & y_{d+2} \\
y_3 & y_4 & y_5 & y_6 & \cdots & y_{d+3} \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
y_d & y_{d+1} & y_{d+2} & y_{d+3} & \cdots & y_{2d}
\end{bmatrix},
\]
which is also a Hankel matrix.

For the binary case \(n=2\) and \(d=2\), we have
\[
\mathcal{F}_{2,2} = \{ (00),(10),(01),(20),(11),(02) \},
\]
and hence the second-order moment matrix is
\[
M_2[y] = [y_{\alpha + \beta}]_{\alpha,\beta \in \mathcal{F}_{2,2}} = \begin{bmatrix}
y_{00} & y_{10} & y_{01} & y_{20} & y_{11} & y_{02} \\
y_{10} & y_{20} & y_{11} & y_{30} & y_{21} & y_{12} \\
y_{01} & y_{11} & y_{02} & y_{21} & y_{12} & y_{03} \\
y_{20} & y_{30} & y_{21} & y_{40} & y_{31} & y_{22} \\
y_{11} & y_{21} & y_{12} & y_{31} & y_{22} & y_{13} \\
y_{02} & y_{12} & y_{03} & y_{22} & y_{13} & y_{04}
\end{bmatrix}.
\]
Equivalently, one can check that \(M_2[y]\) is equivalent to applying \(\ell_y\) to the polynomial matrix \([x]_2 [x]_2^\top\).
\end{example}

In general, the moment matrix \(M_d[y]\) (given a TMS \(y \in \mathbb{R}^{s(n,2d)}\)) defines a \textbf{bilinear form} \(\langle \cdot, \cdot \rangle_y\) on \(\mathbb{R}[x]_d\). In particular, given any two polynomials \(p,q \in \mathbb{R}[x]_d\), we have
\begin{equation}
\langle p, q \rangle_y := \ell_y(p q) = \langle \mathrm{vec}(p), M_d[y] \mathrm{vec}(q) \rangle = \mathrm{vec}(p)^\top M_d[y] \mathrm{vec}(q).
\label{eq:moment-matrix-bilinear}
\end{equation}
To see why the equation above is true, note that \(p(x) = \mathrm{vec}(p)^\top[x]_d\), \(q(x) = \mathrm{vec}(q)^\top[x]_d\), so
\[
\ell_y(pq) = \ell_y(\mathrm{vec}(p)^\top[x]_d [x]_d^\top\mathrm{vec}(q)) = \mathrm{vec}(p)^\top\left( \ell_y ([x]_d [x]_d^\top) \right) \mathrm{vec}(q) = \mathrm{vec}(p)^\top M_d[y] \mathrm{vec}(q).
\]

\textbf{Dual Cone of SOS Polynomials}. With the moment matrix, we can characterize the dual cone of SOS polynomials. Recall that every SOS polynomial of degree up to \(2d\) can be written as
\[
p = [x]_d^\top Q [x]_d,
\]
where \(Q \in \mathbb{S}^{s(n,d)}_{+}\) is the associated gram matrix. The dual cone of \(\Sigma_{n,d}\) is therefore
\[
\Sigma_{n,d}^* =  \left\{ y \in \mathbb{R}^{s(n,2d)} \mid \ell_y (p) \geq 0, \forall p \in \Sigma_{n,2d} \right\} .
\]
Now observe that
\[
\ell_y (p) \geq 0, \forall p \in \Sigma_{n,2d} \Leftrightarrow \ell_y ([x]_d^\top Q [x]_d) \geq 0, \forall Q \succeq 0 \Leftrightarrow \langle Q, M_d[y] \rangle \geq 0, \forall Q \succeq 0 \Leftrightarrow M_d[y] \succeq 0.
\]
Therefore, we conclude that the dual cone to \(\Sigma_{n,2d}\) is the moment cone.

\begin{theorem}[Moment Cone]
\protect\hypertarget{thm:MomentCone}{}\label{thm:MomentCone}The dual cone to the cone of SOS polynomials is the moment cone
\[
\Sigma_{n,2d}^* = \mathcal{M}_{n,2d} :=  \left\{ y \in \mathbb{R}^{s(n,2d)} \mid M_d[y] \succeq 0 \right\} .
\]
\end{theorem}

\textbf{Dual Cone of Nonnegative Polynomials}. The dual cone to the cone of nonnegative polynomials is
\[
P_{n,2d}^* =  \left\{ y \in \mathbb{R}^{s(n,2d)} \mid \langle \mathrm{vec}(p), y \rangle \geq 0, \forall p \in P_{n,2d} \right\} .
\]
To describe the dual cone, we consider the conic hull
\begin{equation}
\mathcal{R}_{n,2d} =  \left\{  \sum_{i=1}^K \lambda_i [v_i]_{2d} \mid \lambda_i \geq 0, v_i \in \mathbb{R}^{n}, K \in \mathbb{N} \right\} .
\label{eq:dual-cone-nonnegative}
\end{equation}
We can clearly see that
\[
\mathcal{R}_{n,2d} \subseteq P_{n,2d}^*,
\]
because for any \(p \in P_{n,2d}\), we have
\[
\left\langle \mathrm{vec}(p), \sum_{i=1}^K \lambda_i [v_i]_{2d} \right\rangle = \sum_{i=1}^K \lambda_i \langle \mathrm{vec}(p), [v_i]_{2d} \rangle = \sum_{i=1}^K \lambda_i p(v_i) \geq 0.
\]
It turns out the closure of \(\mathcal{R}_{n,2d}\) is the dual cone of nonnegative polynomials.

\begin{theorem}[Dual Cone of Nonnegative Polynomials]
\protect\hypertarget{thm:DualConeNonnegative}{}\label{thm:DualConeNonnegative}The dual cone of \(P_{n,2d}\) is the closure of \(\mathcal{R}_{n,2d}\):
\[
P_{n,2d}^* = \mathrm{cl}(\mathcal{R}_{n,2d}), \quad \mathcal{R}_{n,2d}^* = P_{n,2d}.
\]
\end{theorem}

The closure is needed can be seen from the following exercise.

\begin{exercise}

Consider the vector space of univariate quadratic polynomials
\[
\mathbb{R}[x]_2 =  \left\{ p_2 x^2 + p_1 x + p_0 \mid (p_2,p_1,p_0) \in \mathbb{R}^{3} \right\} .
\]

\begin{itemize}
\item
  Express the linear functional
  \[
  p_2 x^2 + p_1 x + p_0 \mapsto p_2
  \]
  as a linear combination of point evaluations. (Hint: consider \(p(0) = p_0\), \(p(1)=p_2 + p_1 + p_0\), \(p(-1) = p_2 - p_1 + p_0\). )
\item
  Show that this linear functional is in the dual cone \(P^*_{1,2}\) but cannot be written as a conic combination of point evaluations.
\end{itemize}

\end{exercise}

\section{Dual of Quadratic Modules and Ideals}\label{dual-of-quadratic-modules-and-ideals}

\textbf{Localizing Matrix}. Let \(y \in \mathbb{R}^{s(n,2d)}\) be a truncated multi-sequence (TMS) and \(g(x) \in \mathbb{R}[x]_{2d}\) be a given polynomial. Let \(s\) be the maximum integer such that \(2s + \deg(g) \leq 2d\), then the \(d\)-th order \textbf{localizing matrix} of \(g\) generated by \(y\) is the following symmetric matrix
\begin{equation}
L_{g}^d [y] = \ell_y\left( g(x)\cdot [x]_s [x]_s^\top\right),
\label{eq:localizing-matrix}
\end{equation}
where the application of the linear functional \(\ell_y\) to the symmetric polynomial matrix \(g(x) \cdot [x]_s [x]_s^\top\) is element-wise. For example, let \(g = 1- x_1^2 - x_2^2\), then
\begin{equation}
\begin{split}
g\cdot [x]_1 [x]_1^\top=&  (1-x_1^2 - x_2^2) \begin{bmatrix} 1 & x_1 & x_2 \\ 
x_1 & x_1^2 & x_1 x_2 \\
x_2 & x_1 x_2 & x_2^2 \end{bmatrix} \\
= & \begin{bmatrix} 1 - x_1^2 - x_2^2 & x_1 - x_1^3 - x_1 x_2^2 & x_2 - x_1^2 x_2 - x_2^3 \\
x_1 - x_1^3 - x_1 x_2^2 & x_1^2 - x_1^4 - x_1^2 x_2^2 & x_1 x_2 - x_1^3 x_2 - x_1 x_2^3 \\
x_2 - x_1^2 x_2 - x_2^3 & x_1 x_2 - x_1^3 x_2 - x_1 x_2^3 & x_2^2 - x_1^2 x_2^2 - x_2^4
\end{bmatrix}
\end{split}
\end{equation}
and
\[
L_g^d[y] = \ell_y (g\cdot [x]_1 [x]_1^\top) = \begin{bmatrix}
1 - y_{20} - y_{02} & y_{10} - y_{30} - y_{12} & y_{01} - y_{21} - y_{03} \\
y_{10} - y_{30} - y_{12} & y_{20} - y_{40} - y_{22} & y_{11} - y_{31} - y_{13} \\
y_{01} - y_{21} - y_{03} &  y_{11} - y_{31} - y_{13} & y_{02} - y_{22} - y_{04}
\end{bmatrix}.
\]
A key observation is that the entries of \(L_g^d[y]\) are affine functions of the TMS \(y\).

\textbf{Dual of Quadratic Module}. Given a tuple of polynomials \(g = (g_1,\dots,g_{l_g})\), recall (from Definition \ref{def:QuadraticModule}) that the quadratic module associated with \(g\) is
\[
\mathrm{Qmodule}[g] :=  \left\{  \sum_{i=0}^{l_g} \sigma_i g_i \mid \sigma_i \in \Sigma[x],i=0,\dots,l_g  \right\} 
\]
where \(g_0(x):=1\) and \(\Sigma[x]\) denotes the set of SOS polynomials. The degree-\(2d\) truncation of the quadratic module is
\begin{equation}
\mathrm{Qmodule}[g]_{2d} :=  \left\{  \sum_{i=0}^{l_g} \sigma_i g_i \mid \sigma_i \in \Sigma[x], \deg(\sigma_i g_i) \leq 2d, i=0,\dots,l_g  \right\} .
\label{eq:quadratic-module-truncated}
\end{equation}
Now consider the convex cone defined by the PSD conditions of the localizing matrices:
\begin{equation}
\mathcal{M}[g]_{2d} :=  \left\{  y \in \mathbb{R}^{s(n,2d)} \mid M_d[y] \succeq 0, L_{g_i}^d[y] \succeq 0, i=1,\dots,l_g \right\} .
\label{eq:tms-cone-dual-qmodule}
\end{equation}
The following result shows that \(\mathcal{M}[g]_{2d}\) is the dual cone of \(\mathrm{Qmodule}[g]_{2d}\).

\begin{theorem}[Dual of Quadratic Module]
\protect\hypertarget{thm:DualQuadratedModule}{}\label{thm:DualQuadratedModule}

Given a set of polynomials \(g=(g_1,\dots,g_{l_g})\), we have

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The cone \(\mathcal{M}[g]_{2d}\) is closed and convex, and it is dual to \(\mathrm{Qmodule}[g]_{2d}\), i.e.,
  \[
  \langle f, y \rangle \geq 0, \quad \forall f \in \mathrm{Qmodule}[g]_{2d}, y \in \mathcal{M}[g]_{2d}.
  \]
\item
  If the set \(S_{\geq 0} := \{ x \in \mathbb{R}^{n} \mid g_i(x) \geq 0, i=1,\dots,l_g \}\) has nonempty interior, then both \(\mathcal{M}[g]_{2d}\) and \(\mathrm{Qmodule}[g]_{2d}\) are proper cones (i.e., closed and convex) and they are dual to each other.
  \[
  (\mathcal{M}[g]_{2d})^* = \mathrm{Qmodule}[g]_{2d}, \quad (\mathrm{Qmodule}[g]_{2d})^* = \mathcal{M}[g]_{2d}.
  \]
\end{enumerate}

\end{theorem}

To see 1 of Theorem \ref{thm:DualQuadratedModule}, pick any \(f \in \mathrm{Qmodule}[g]_{2d}\) from \eqref{eq:quadratic-module-truncated}, and any \(y \in \mathcal{M}[g]_{2d}\) from \eqref{eq:tms-cone-dual-qmodule}, we have
\begin{equation}
\begin{split}
\langle f, y \rangle = & \langle \sigma_0, y \rangle + \sum_{i=1}^{l_g} \langle \sigma_i g_i, y \rangle \\
= & \left\langle [x]_d^\top Q_0 [x]_d, y \right\rangle + \sum_{i=1}^{l_g} \left\langle g_i \cdot [x]_{s_i}^\top Q_i [x]_{s_i}, y \right\rangle \\
= & \left\langle M_d[y], Q_0 \right\rangle + \sum_{i=1}^{l_g} \left\langle L^d_{g_i}[y], Q_i \right\rangle \geq 0
\end{split}
\end{equation}
where \(Q_0,Q_1,\dots,Q_{l_g}\) are the Gram matrices associated with the SOS multipliers \(\sigma_0,\sigma_1,\dots,\sigma_{l_g}\), and \(s_i\) is the maximum integer such that \(2 s_i + \deg (g_i) \leq 2d\). The equation above also shows that, in order for any TMS \(y\) to be in the dual cone of \(\mathrm{Qmodule}[y]_{2d}\), it must hold that \(M_d[y] \succeq 0, L^d_{g_i}[y] \succeq 0,i=1,\dots,l_g\), and hence \(y\) must belong to \(\mathcal{M}_d[y]\).

To see 2 of Theorem \ref{thm:DualQuadratedModule}, note that when \(S_{\geq 0}\) has empty interior, the cone \(\mathrm{Qmodule}[g]_{2d}\) may not be closed. For example, consider \(g = -x^2\), the set \(S_{\geq 0}\) is the singleton \(\{ 0 \}\) and has empty interior. The polynomial \(x + \epsilon\), for any \(\epsilon > 0\), is in \(\mathrm{Qmodule}[g]_2\) because
\[
x + \epsilon = \left( \sqrt{\epsilon} + \frac{x}{2 \sqrt{\epsilon}} \right)^2 + (-x^2) \left( \frac{1}{2 \sqrt{\epsilon}} \right)^2.
\]
However, when \(\epsilon = 0\), the polynomial \(x \not\in \mathrm{Qmodule}[x]_{2}\).

\textbf{Dual of the Sum of Ideal and Quadratic Module}. Recall that given a tuple of polynomials \(h=(h_1,\dots,h_{l_h})\), the ideal generated by \(h\) is
\[
\mathrm{Ideal}[h] =  \left\{ \sum_{i=1}^{l_h} \lambda_i h_i \mid \lambda_i \in \mathbb{R}[x],i=1,\dots,l_h \right\} ,
\]
where \(\lambda_i\) are the polynomial multipliers. Similarly, the degree-\(2d\) truncation of \(\mathrm{Ideal}[h]\) is
\begin{equation}
\mathrm{Ideal}[h]_{2d} =  \left\{  \sum_{i=1}^{l_h} \lambda_i h_i \mid \lambda_i \in \mathbb{R}[x], \deg(\lambda_i h_i) \leq 2d,i=1,\dots,l_h \right\} .
\label{eq:ideal-truncated-2d}
\end{equation}
For each \(\lambda_i \in \mathbb{R}[x]_{2d - \deg(h_i)}\) such that \(\deg(\lambda_i h_i) \leq 2d\), the coefficients of \((\lambda_i h_i\) are linear in that of \(\lambda_i\)
\[
\mathrm{vec}(\lambda_i h_i) = H_i^{2d} \mathrm{vec}(\lambda_i),
\]
where \(\mathrm{vec}(\cdot)\) denotes the coefficients vector of a polynomial. For example, suppose \(h = x^2-1\) and \(d = 2\), then \(\lambda(x) = \lambda_2 x^2 + \lambda_1 x + \lambda_0\), and
\[
\lambda(x) h(x) = (\lambda_2 x^2 + \lambda_1 x + \lambda_0)(x^2 - 1) = \lambda_2 x^4 + \lambda_1 x^3 + (\lambda_0 - \lambda_2) x^2 - \lambda_1 x - \lambda_0.
\]
Then,
\[
\mathrm{vec}(\lambda h) = \begin{bmatrix}
- \lambda_0 \\
- \lambda_1 \\
\lambda_0 - \lambda_2 \\
\lambda_1 \\
\lambda_2 \end{bmatrix} = 
\underbrace{\begin{bmatrix}
-1 & 0 & 0 \\
0 & -1 & 0 \\
1 & 0 & -1 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}}_{H^4}
\begin{bmatrix}
\lambda_0 \\ \lambda_1 \\ \lambda_2 \end{bmatrix}
\]

\textbf{Localizing Vector}. Given a TMS \(y \in \mathbb{R}^{s(n,2d)}\) and its associated linear functional \(\ell_y\), applying \(\ell_y\) to \(\lambda_i h_i\) with \(\deg(\lambda_i h_i) \leq 2d\) can be written as
\[
\ell_y(\lambda_i h_i) = \langle y, \mathrm{vec}(\lambda_i h_i) \rangle = \langle y, H_i^{2d} \mathrm{vec}(\lambda_i) \rangle = \left\langle (H_i^{2d})^\top y, \mathrm{vec}(\lambda_i) \right\rangle,
\]
and the vector
\begin{equation}
L_{h_i}^{2d}[y] := (H_i^{2d})^\top y
\label{eq:localizing-vector}
\end{equation}
is called the \textbf{localizing vector} of \(h_i\) generated by the TMS \(y\). We are interested in linear functionals that vanish on \(\mathrm{Ideal}[h]_{2d}\). Clearly, this is the subspace
\begin{equation}
\mathcal{Z}[h]_{2d} :=  \left\{ y \in \mathbb{R}^{s(n,2d)} \mid L_{h_i}^{2d}[y] = 0,i=1,\dots,l_h  \right\} .
\label{eq:linear-subspace-tms}
\end{equation}

The next result gives the dual of the sum of ideal and quadratic module.

\begin{theorem}[Dual of the Sum of Ideal and Quadratic Module]
\protect\hypertarget{thm:DualSumIdealQuadraticModule}{}\label{thm:DualSumIdealQuadraticModule}Let \(g=(g_1,\dots,g_{l_g})\) and \(h=(h_1,\dots,l_h)\) be tuples of polynomials, for any \(2d > 0\), we have
\[
\left( \mathrm{Ideal}[h]_{2d} + \mathrm{Qmodule}[g]_{2d} \right)^* = \mathcal{Z}[h]_{2d} \cap \mathcal{M}[g]_{2d}
\]
where \(\mathcal{Z}[h]_{2d}\) is the linear subspace in \eqref{eq:linear-subspace-tms} and \(\mathcal{M}[g]_{2d}\) is the convex cone in \eqref{eq:tms-cone-dual-qmodule}.
\end{theorem}

To see this, pick any element \(f \in \mathrm{Ideal}[h]_{2d} + \mathrm{Qmodule}[g]_{2d}\) and any element \(y \in \mathcal{Z}[h]_{2d} \cap \mathcal{M}[g]_{2d}\), perform the inner product
\begin{equation}
\begin{split}
\langle f, \ell_y \rangle = \left\langle \sum_{i=1}^{l_h} \lambda_i h_i + \sum_{i=0}^{l_g} \sigma_i g_i , \ell_y \right\rangle = \sum_{i=1}^{l_h} \langle \mathrm{vec}(\lambda_i h_i), y \rangle + \sum_{i=1}^{l_g} \langle g_i \cdot [x]_{s_i}^\top Q_i [x]_{s_i}, \ell_y \rangle \\
= \sum_{i=1}^{l_h} \langle L_{h_i}^{2d}[y], \mathrm{vec}(\lambda_i) \rangle + \sum_{i=0}^{l_g} \langle L_{g_i}^d[y], Q_i \rangle
\end{split}.
\end{equation}
This is clearly nonnegative since \(L_{h_i}^{2d}[y] = 0\) and \(L_{g_i}^d[y] \succeq 0\) is implied by \(y \in \mathcal{Z}[h]_{2d} \cap \mathcal{M}[g]_{2d}\).

\section{The Moment-SOS Hierarchy}\label{the-moment-sos-hierarchy}

In Chapter \ref{SOS:POP}, we introduced an SOS relaxation for solving polynomial optimization problems (POPs). In particular, we consider the following POP, restated from \eqref{eq:pop}
\begin{equation}
\begin{split}
p^\star = \min_{x \in \mathbb{R}^{n}} & \quad p(x) \\
\mathrm{s.t.}& \quad h_i(x) = 0, i=1,\dots,l_h \\
& \quad g_i(x) \geq 0, i=1,\dots,l_g
\end{split}
\label{eq:pop-restate}
\end{equation}
Using Putinar's Positivstellensatz, for any \(\kappa \in \mathbb{N}\), we have the following SOS program
\begin{equation}
\boxed{
\begin{split}
\gamma_{\kappa}^\star = \max & \quad \gamma \\
 \mathrm{s.t.}& \quad p(x) - \gamma \in \mathrm{Ideal}[h]_{2\kappa} + \mathrm{Qmodule}[g]_{2\kappa}
\end{split}
}
\label{eq:SOS-Putinar-restate}
\end{equation}
whose optimal value produces a lower bound to \(p^\star\), i.e., \(\gamma_{\kappa}^\star \leq p^\star\).

With the machinery introduced above on the dual of the cone of polynomials, we can write down the dual problem of the SOS program \eqref{eq:SOS-Putinar-restate}
\begin{equation}
\boxed{
\begin{split}
\beta_{\kappa}^\star = \min_{y \in \mathbb{R}^{s(n,2d)}} & \quad \langle \ell_y, p \rangle \\
\mathrm{s.t.}& \quad y \in \mathcal{Z}[h]_{2\kappa} \cap \mathcal{M}[g]_{2\kappa} \\
& \quad \langle \ell_y, 1 \rangle = 1
\end{split}
}
\label{eq:moment-Putinar}
\end{equation}
In problem \eqref{eq:moment-Putinar}, \(\langle \ell_y, p \rangle\) and \(\langle \ell_y, 1 \rangle\) should be interpreted as applying the linear functional associated with the TMS \(y\) to the polynomial \(p\) and the polynomial ``\(1\)''. As a result, the constraint \(\langle \ell_y, 1 \rangle=1\) implies \(y_0 = 1\). To see why \eqref{eq:moment-Putinar} is the dual of \eqref{eq:SOS-Putinar-restate}, pick any \(\gamma\) that is feasible for \eqref{eq:SOS-Putinar-restate} and any \(y\) that is feasible for \eqref{eq:moment-Putinar}, we have
\[
\langle \ell_y, p \rangle - \gamma = \langle \ell_y, p \rangle - \langle \ell_y, \gamma \rangle = \langle \ell_y, p - \gamma \rangle \geq 0,
\]
where, again, \(\langle \ell_y, \gamma \rangle\) should be interpreted as applying \(\ell_y\) to the degree-\(0\) polynomial ``\(\gamma\)''. The last inequality holds because \(y\) and \(p - \gamma\) live in two cones that are dual to each other. Consequently, we have the weak duality
\[
\gamma_{\kappa}^\star \leq \beta_{\kappa}^\star, \quad \forall \kappa \in \mathbb{N}.
\]
The pair of SDPs \eqref{eq:moment-Putinar} and \eqref{eq:SOS-Putinar-restate} is called the moment-SOS hierarchy and is first proposed in \citep{lasserre01siopt-global}.

One may wonder how to directly write down the primal problem \eqref{eq:moment-Putinar} given the dual problem \eqref{eq:SOS-Putinar-restate}, or vice versa? In the next we give a brief discussion about general conic duality, from which the primal-dual relationship shall be clear.

Conic Duality

Let \(V\) be a vector space and \(\mathcal{K}\subset V\) be a proper cone. On the dual side, let \(V^*\) be the dual space of \(V\) and \(\mathcal{K}^*\) be the dual cone of \(\mathcal{K}\). Note that \(V^*\), the dual space to \(V\), is the vector space of real-valued linear functionals. For example,

\begin{itemize}
\item
  if \(V=\mathbb{R}^{n}\) (think of this as the space of points), then \(V^* = \mathbb{R}^{n}\) (think of this as the space of linear functionals on points).
\item
  if \(V = \mathbb{R}[x]_{2d}\) is the space of polynomials of degree up to \(2d\) (which is isomorphic to just \(\mathbb{R}^{s(n,2d)}\) after identifying each polynomial \(f\) with its vector of coefficients \(\mathrm{vec}(f)\)), then \(V^* = \mathbb{R}[x]_{2d}^*\) is the space of linear functionals (which, again, is isomorphic to just \(\mathbb{R}^{s(n,2d)}\) after identifying each linear functional with its associated truncated muti-sequence \(y\)).
\end{itemize}

For any \(x \in V\) and \(f \in V^*\), we can define an inner product \(\langle f, x \rangle = f(x)\), which is simply applying the linear functional \(f\) to the point \(x\) and returning a real number.

We then consider a linear map \(\mathcal{A}: V \rightarrow T\) where \(T\) is another vector space. The adjoint map \(\mathcal{A}^*: T^* \rightarrow V^*\) is defined via
\[
\langle x, \mathcal{A}^* y \rangle_V = \langle y, \mathcal{A}x \rangle_T, \quad \forall x \in V, y \in T^*,
\]
where the subscript \(V,T\) implies the inner product is written in their respective primal-dual vector spaces.

We can then define the general primal-dual conic pair
\begin{equation}
\boxed{
\begin{split}
\min_{x \in V} & \quad \langle c, x \rangle_V \\
\mathrm{s.t.}& \quad \mathcal{A}x = b \\
& \quad x \in \mathcal{K}
\end{split}}
\label{eq:conic-primal}
\end{equation}
and
\begin{equation}
\boxed{
\begin{split}
\max_{y \in T^*} & \quad \langle b, y \rangle_T \\
\mathrm{s.t.}& \quad c - \mathcal{A}^* y \in \mathcal{K}^*
\end{split}}
\label{eq:conic-dual}
\end{equation}
where \(b \in T\) and \(c \in V^*\) are given. The proof of weak duality can be done by picking any \(x\) feasible for the primal and \(y\) feasible for the dual, leading to
\begin{equation}
\begin{split}
\langle c, x \rangle_V - \langle b, y \rangle_T & = \langle c, x \rangle_V - \langle \mathcal{A}x, y \rangle_T \\
& = \langle c, x \rangle_V - \langle x, \mathcal{A}^* y \rangle_V \\
& = \langle c - \mathcal{A}^* y, x \rangle_V \\
& \geq 0
\end{split}
\end{equation}
where the last inequality holds because \(x \in \mathcal{K}\) and \(c - \mathcal{A}^* y \in \mathcal{K}^*\).

We have seen three instantiations of \eqref{eq:conic-primal} and \eqref{eq:conic-dual} so far in the class.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Linear programming} (Chapter \ref{background:linear:optimization}). With \(V = V^* = \mathbb{R}^{n}\), \(T = T^* = \mathbb{R}^{m}\), \(\mathcal{K}= \mathcal{K}^* = \mathbb{R}^{n}_{+}\), we recover the standard LP pair \eqref{eq:primal-lp} and \eqref{eq:dual-lp}.
\item
  \textbf{Semidefinite programming} (Chapter \ref{sdp}). With \(V = V^* = \mathbb{S}^{n}\), \(T = T^* = \mathbb{R}^{m}\), \(\mathcal{K}= \mathcal{K}^* = \mathbb{S}^{n}_{+}\), we recover the standard SDP pair \eqref{eq:SDP-P} and \eqref{eq:SDP-D}.
\item
  \textbf{Moment-SOS hierarchy}. With
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \(V^* = \mathbb{R}[x]_{2\kappa}\), \(V = \mathbb{R}[x]_{2\kappa}^*\)
\item
  \(T = T^* = \mathbb{R}^{}\)
\item
  \(\mathcal{K}= \mathcal{Z}[h]_{2\kappa} \cap \mathcal{M}[g]_{2\kappa}\), and \(\mathcal{K}^* = \mathrm{Ideal}[h]_{2\kappa} + \mathrm{Qmodule}[g]_{2\kappa}\)
\end{itemize}

From LP to SDP to the moment-SOS hierarchy, this is a (in my opinion, beautiful) sequence of generalizations in conic duality. As we seek higher level of generalization, we have more modelling power (i.e., we can solve harder optimization problems), but we also face more computational challenges (i.e., the convex optimization problems become more expensive to solve).

The next theorem collects some known results about the moment-SOS hierarchy in terms of asymptotic convergence and strong duality.

\begin{theorem}[Moment-SOS Hierarchy]
\protect\hypertarget{thm:MomentSOSHierarchy}{}\label{thm:MomentSOSHierarchy}

Consider the POP \eqref{eq:pop-restate} and the primal-dual pair \eqref{eq:moment-Putinar} and \eqref{eq:SOS-Putinar-restate}, we have
\[
\gamma_{\kappa}^\star \leq \beta_{\kappa}^\star \leq p^\star, \quad \forall \kappa \in \mathbb{N},
\]
and both sequences \(\{ \gamma_{\kappa}^\star \}_{\kappa=1}^{\infty}\), \(\{ \beta_{\kappa}^\star \}_{\kappa=1}^{\infty}\) are monotonically increasing. Moreover, let the feasible set of the POP \eqref{eq:pop-restate} be \(S\),

\begin{itemize}
\item
  Suppose all equality constraints are linear or there are no equality constraints. If there exists \(x_0 \in S\) such that \(g_i(x_0) > 0, i=1,\dots,l_g\), then \(\gamma_{\kappa}^\star = \beta_{\kappa}^\star\) for any \(\kappa\), and the dual problem \eqref{eq:SOS-Putinar-restate} is solvable (i.e., the maximum is attained).
\item
  Suppose there exists a scalar \(R > 0\) such that
  \[
  R - \Vert x \Vert^{2\kappa_0} \in \mathrm{Ideal}[h]_{2\kappa_0} + \mathrm{Qmodule}[g]_{2\kappa_0}
  \]
  for some \(\kappa_0 \in \mathbb{N}\). For any \(\kappa \geq \kappa_0\), if the moment relaxation \eqref{eq:moment-Putinar} is feasible, then it is solvable (i.e., the minimum is attained).
\item
  If the constraint set is Archimedean, then the moment-SOS hierarchy has asymptotic convergence, i.e.,
  \[
  \lim_{\kappa \rightarrow \infty} \gamma_{\kappa}^\star = \lim_{\kappa \rightarrow \infty} \beta_{\kappa}^\star = p^\star.
  \]
\item
  If \(g\) includes a ball constraint \(R - \Vert x \Vert^2\), and the POP feasible set \(S\) is nonempty, then \(\gamma_{\kappa}^\star = \beta_{\kappa}^\star\) for any \(\kappa\), and the moment relaxation \eqref{eq:moment-Putinar} is solvable (i.e., the minimum is attained).
\end{itemize}

\end{theorem}

The last point in Theorem \ref{thm:MomentSOSHierarchy} is particularly useful for numerical computation. It suggests that adding a redundant ball constraint is always encouraged for strong duality to hold. In addition, an appropriate scaling technique is needed so that all scaled variables belong to the unit ball. Without scaling, numerical troubles can occur.

Without these assumptions and conditions, it is possible that strong duality fails.

\begin{example}[Failure of Strong Duality in Moment-SOS Hierarchy]
\protect\hypertarget{exm:FailureStrongDualityMomentSOS}{}\label{exm:FailureStrongDualityMomentSOS}Consider the following POP
\begin{equation}
\begin{split}
p^\star = \min_{x \in \mathbb{R}^{2}} & \quad x_1 x_2 \\
\mathrm{s.t.}& \quad -1 \leq x_1 \leq 1 \\
& \quad x_2^2 \leq 0
\end{split}
\end{equation}
Clearly, the global minimum \(p^\star = 0\) and it is attained at \((\alpha,0)\) for any \(\alpha \in [-1,1]\). We now implement the moment-SOS hierarchy and see if strong duality holds.

As shown in Example \ref{exm:SOSRelaxation}, the SOS relaxation can be implemented in SOSTOOLS, see \href{https://github.com/ComputationalRobotics/Semidefinite-Examples/blob/main/example_pop_no_strong_duality.m}{this code}. Running the code at \(\kappa = 1\), we obtain the following output from MOSEK:

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{ITE} \VariableTok{PFEAS}    \VariableTok{DFEAS}    \VariableTok{GFEAS}    \VariableTok{PRSTATUS}   \VariableTok{POBJ}              \VariableTok{DOBJ}              \VariableTok{MU}       \VariableTok{TIME}  
\FloatTok{0}   \FloatTok{1.0e+00}  \FloatTok{1.0e+00}  \FloatTok{1.0e+00}  \FloatTok{0.00e+00}   \FloatTok{0.000000000e+00}   \FloatTok{0.000000000e+00}   \FloatTok{1.0e+00}  \FloatTok{0.00}  
\FloatTok{1}   \FloatTok{1.5e{-}01}  \FloatTok{1.5e{-}01}  \FloatTok{7.9e{-}02}  \FloatTok{5.56e{-}01}   \FloatTok{3.088172318e{-}01}   \FloatTok{4.050011330e{-}01}   \FloatTok{1.5e{-}01}  \FloatTok{0.00}  
\FloatTok{2}   \FloatTok{4.1e{-}02}  \FloatTok{4.1e{-}02}  \FloatTok{2.1e{-}02}  \FloatTok{3.13e{-}01}   \FloatTok{5.858768891e{-}01}   \FloatTok{7.658826639e{-}01}   \FloatTok{4.1e{-}02}  \FloatTok{0.00}  
\FloatTok{3}   \FloatTok{1.1e{-}02}  \FloatTok{1.1e{-}02}  \FloatTok{4.5e{-}03}  \FloatTok{2.25e{-}01}   \FloatTok{4.180497936e{-}01}   \FloatTok{5.431122321e{-}01}   \FloatTok{1.1e{-}02}  \FloatTok{0.00}  
\FloatTok{4}   \FloatTok{4.2e{-}03}  \FloatTok{4.2e{-}03}  \FloatTok{2.2e{-}03}  \OperatorTok{{-}}\FloatTok{7.15e{-}02}  \FloatTok{7.821867345e{-}01}   \FloatTok{1.021805063e+00}   \FloatTok{4.2e{-}03}  \FloatTok{0.00}  
\FloatTok{5}   \FloatTok{8.7e{-}04}  \FloatTok{8.7e{-}04}  \FloatTok{3.1e{-}04}  \FloatTok{8.58e{-}02}   \FloatTok{3.753027688e{-}01}   \FloatTok{4.921723327e{-}01}   \FloatTok{8.7e{-}04}  \FloatTok{0.00}  
\FloatTok{6}   \FloatTok{2.0e{-}04}  \FloatTok{2.0e{-}04}  \FloatTok{1.1e{-}04}  \OperatorTok{{-}}\FloatTok{3.30e{-}02}  \FloatTok{8.469613700e{-}01}   \FloatTok{1.114348467e+00}   \FloatTok{2.0e{-}04}  \FloatTok{0.00}  
\FloatTok{7}   \FloatTok{3.6e{-}05}  \FloatTok{3.6e{-}05}  \FloatTok{1.5e{-}05}  \FloatTok{6.62e{-}02}   \FloatTok{5.132062526e{-}01}   \FloatTok{6.764418357e{-}01}   \FloatTok{3.6e{-}05}  \FloatTok{0.00}  
\FloatTok{8}   \FloatTok{8.5e{-}06}  \FloatTok{8.5e{-}06}  \FloatTok{3.9e{-}06}  \FloatTok{2.07e{-}02}   \FloatTok{6.478873186e{-}01}   \FloatTok{8.551888421e{-}01}   \FloatTok{8.5e{-}06}  \FloatTok{0.00}  
\FloatTok{9}   \FloatTok{2.3e{-}06}  \FloatTok{2.3e{-}06}  \FloatTok{9.1e{-}07}  \FloatTok{6.40e{-}02}   \FloatTok{5.033974907e{-}01}   \FloatTok{6.654248395e{-}01}   \FloatTok{2.3e{-}06}  \FloatTok{0.00}  
\FloatTok{10}  \FloatTok{8.0e{-}07}  \FloatTok{8.0e{-}07}  \FloatTok{4.2e{-}07}  \OperatorTok{{-}}\FloatTok{1.66e{-}01}  \FloatTok{8.695267485e{-}01}   \FloatTok{1.150524931e+00}   \FloatTok{8.0e{-}07}  \FloatTok{0.00}  
\FloatTok{11}  \FloatTok{1.7e{-}07}  \FloatTok{1.7e{-}07}  \FloatTok{6.1e{-}08}  \FloatTok{8.16e{-}02}   \FloatTok{3.666850704e{-}01}   \FloatTok{4.865006085e{-}01}   \FloatTok{1.7e{-}07}  \FloatTok{0.00}  
\FloatTok{12}  \FloatTok{3.8e{-}08}  \FloatTok{3.8e{-}08}  \FloatTok{2.2e{-}08}  \OperatorTok{{-}}\FloatTok{1.05e{-}01}  \FloatTok{1.019156252e+00}   \FloatTok{1.353211111e+00}   \FloatTok{3.8e{-}08}  \FloatTok{0.00}  
\FloatTok{13}  \FloatTok{5.8e{-}09}  \FloatTok{5.8e{-}09}  \FloatTok{2.6e{-}09}  \FloatTok{3.57e{-}02}   \FloatTok{5.915896244e{-}01}   \FloatTok{7.859525244e{-}01}   \FloatTok{5.8e{-}09}  \FloatTok{0.00}  
\FloatTok{14}  \FloatTok{1.4e{-}09}  \FloatTok{1.4e{-}09}  \FloatTok{5.8e{-}10}  \FloatTok{9.40e{-}02}   \FloatTok{5.523832993e{-}01}   \FloatTok{7.340489667e{-}01}   \FloatTok{1.4e{-}09}  \FloatTok{0.00}  
\FloatTok{15}  \FloatTok{4.3e{-}10}  \FloatTok{4.3e{-}10}  \FloatTok{2.3e{-}10}  \OperatorTok{{-}}\FloatTok{1.39e{-}01}  \FloatTok{8.826739207e{-}01}   \FloatTok{1.173406707e+00}   \FloatTok{4.3e{-}10}  \FloatTok{0.00}  
\FloatTok{16}  \FloatTok{1.1e{-}10}  \FloatTok{1.1e{-}10}  \FloatTok{3.7e{-}11}  \FloatTok{1.31e{-}01}   \FloatTok{3.711852473e{-}01}   \FloatTok{4.939043249e{-}01}   \FloatTok{1.1e{-}10}  \FloatTok{0.00}  
\FloatTok{17}  \FloatTok{7.0e{-}11}  \FloatTok{2.6e{-}11}  \FloatTok{1.5e{-}11}  \OperatorTok{{-}}\FloatTok{1.55e{-}01}  \FloatTok{1.056341629e+00}   \FloatTok{1.406000814e+00}   \FloatTok{2.6e{-}11}  \FloatTok{0.00}  
\FloatTok{18}  \FloatTok{7.1e{-}12}  \FloatTok{4.6e{-}12}  \FloatTok{2.1e{-}12}  \OperatorTok{{-}}\FloatTok{2.75e{-}03}  \FloatTok{6.282269209e{-}01}   \FloatTok{8.364103066e{-}01}   \FloatTok{4.6e{-}12}  \FloatTok{0.00}  
\FloatTok{19}  \FloatTok{1.5e{-}12}  \FloatTok{9.9e{-}13}  \FloatTok{4.1e{-}13}  \FloatTok{1.33e{-}01}   \FloatTok{5.056202080e{-}01}   \FloatTok{6.732103175e{-}01}   \FloatTok{9.9e{-}13}  \FloatTok{0.00}  
\FloatTok{20}  \FloatTok{4.2e{-}13}  \FloatTok{2.7e{-}13}  \FloatTok{1.5e{-}13}  \OperatorTok{{-}}\FloatTok{1.07e{-}01}  \FloatTok{8.738865371e{-}01}   \FloatTok{1.163743093e+00}   \FloatTok{2.7e{-}13}  \FloatTok{0.00}  
\FloatTok{21}  \FloatTok{9.4e{-}14}  \FloatTok{6.1e{-}14}  \FloatTok{2.3e{-}14}  \FloatTok{1.05e{-}01}   \FloatTok{4.311662782e{-}01}   \FloatTok{5.743514027e{-}01}   \FloatTok{6.1e{-}14}  \FloatTok{0.00}  
\FloatTok{22}  \FloatTok{2.4e{-}14}  \FloatTok{1.6e{-}14}  \FloatTok{8.5e{-}15}  \OperatorTok{{-}}\FloatTok{1.21e{-}01}  \FloatTok{8.898674342e{-}01}   \FloatTok{1.185531234e+00}   \FloatTok{1.6e{-}14}  \FloatTok{0.00}  
\FloatTok{23}  \FloatTok{7.1e{-}15}  \FloatTok{5.8e{-}15}  \FloatTok{2.2e{-}15}  \OperatorTok{{-}}\FloatTok{3.77e{-}02}  \FloatTok{6.963438000e{-}01}   \FloatTok{9.278150049e{-}01}   \FloatTok{4.3e{-}15}  \FloatTok{0.00}  
\FloatTok{24}  \FloatTok{1.2e{-}15}  \FloatTok{7.6e{-}16}  \FloatTok{3.3e{-}16}  \FloatTok{1.78e{-}01}   \FloatTok{5.434018296e{-}01}   \FloatTok{7.241064462e{-}01}   \FloatTok{8.9e{-}16}  \FloatTok{0.00}  
\FloatTok{25}  \FloatTok{8.9e{-}16}  \FloatTok{1.8e{-}15}  \FloatTok{1.0e{-}16}  \OperatorTok{{-}}\FloatTok{1.35e{-}01}  \FloatTok{6.204719258e{-}01}   \FloatTok{8.268596881e{-}01}   \FloatTok{2.4e{-}16}  \FloatTok{0.00}  
\FloatTok{26}  \FloatTok{2.2e{-}16}  \FloatTok{4.4e{-}16}  \FloatTok{2.2e{-}17}  \FloatTok{7.87e{-}02}   \FloatTok{5.651101237e{-}01}   \FloatTok{7.531366036e{-}01}   \FloatTok{6.0e{-}17}  \FloatTok{0.00}  
\FloatTok{27}  \FloatTok{4.4e{-}16}  \FloatTok{2.7e{-}15}  \FloatTok{1.9e{-}17}  \OperatorTok{{-}}\FloatTok{1.32e{-}01}  \FloatTok{5.677222556e{-}01}   \FloatTok{7.566247465e{-}01}   \FloatTok{5.1e{-}17}  \FloatTok{0.00}  
\FloatTok{28}  \FloatTok{6.5e{-}17}  \FloatTok{3.6e{-}15}  \FloatTok{1.8e{-}17}  \OperatorTok{{-}}\FloatTok{8.42e{-}02}  \FloatTok{5.674944086e{-}01}   \FloatTok{7.563223512e{-}01}   \FloatTok{4.9e{-}17}  \FloatTok{0.00}  
\FloatTok{29}  \FloatTok{6.0e{-}17}  \FloatTok{2.7e{-}15}  \FloatTok{1.7e{-}17}  \OperatorTok{{-}}\FloatTok{8.28e{-}02}  \FloatTok{5.669921471e{-}01}   \FloatTok{7.556553290e{-}01}   \FloatTok{4.5e{-}17}  \FloatTok{0.00}  
\FloatTok{30}  \FloatTok{4.4e{-}16}  \FloatTok{2.7e{-}15}  \FloatTok{1.7e{-}17}  \OperatorTok{{-}}\FloatTok{6.79e{-}02}  \FloatTok{5.669663151e{-}01}   \FloatTok{7.556209582e{-}01}   \FloatTok{4.5e{-}17}  \FloatTok{0.00}  
\FloatTok{31}  \FloatTok{4.4e{-}16}  \FloatTok{2.7e{-}15}  \FloatTok{1.4e{-}17}  \OperatorTok{{-}}\FloatTok{6.99e{-}02}  \FloatTok{5.652526235e{-}01}   \FloatTok{7.533411196e{-}01}   \FloatTok{3.8e{-}17}  \FloatTok{0.00}  
\FloatTok{32}  \FloatTok{3.0e{-}17}  \FloatTok{8.9e{-}16}  \FloatTok{8.5e{-}18}  \OperatorTok{{-}}\FloatTok{4.43e{-}02}  \FloatTok{5.579125501e{-}01}   \FloatTok{7.435651031e{-}01}   \FloatTok{2.4e{-}17}  \FloatTok{0.00}  
\FloatTok{33}  \FloatTok{3.0e{-}17}  \FloatTok{8.9e{-}16}  \FloatTok{8.5e{-}18}  \OperatorTok{{-}}\FloatTok{8.34e{-}03}  \FloatTok{5.579035284e{-}01}   \FloatTok{7.435530824e{-}01}   \FloatTok{2.4e{-}17}  \FloatTok{0.00}  
\FloatTok{34}  \FloatTok{3.0e{-}17}  \FloatTok{8.9e{-}16}  \FloatTok{8.5e{-}18}  \OperatorTok{{-}}\FloatTok{8.34e{-}03}  \FloatTok{5.579035284e{-}01}   \FloatTok{7.435530824e{-}01}   \FloatTok{2.4e{-}17}  \FloatTok{0.00}  
\FloatTok{35}  \FloatTok{2.5e{-}17}  \FloatTok{1.6e{-}17}  \FloatTok{6.8e{-}18}  \OperatorTok{{-}}\FloatTok{1.15e{-}02}  \FloatTok{5.529270780e{-}01}   \FloatTok{7.369224772e{-}01}   \FloatTok{1.9e{-}17}  \FloatTok{0.00}  
\FloatTok{36}  \FloatTok{2.5e{-}17}  \FloatTok{2.2e{-}15}  \FloatTok{6.8e{-}18}  \OperatorTok{{-}}\FloatTok{1.79e{-}03}  \FloatTok{5.529095013e{-}01}   \FloatTok{7.368990567e{-}01}   \FloatTok{1.9e{-}17}  \FloatTok{0.00}  
\FloatTok{37}  \FloatTok{2.5e{-}17}  \FloatTok{2.2e{-}15}  \FloatTok{6.8e{-}18}  \OperatorTok{{-}}\FloatTok{1.79e{-}03}  \FloatTok{5.529095013e{-}01}   \FloatTok{7.368990567e{-}01}   \FloatTok{1.9e{-}17}  \FloatTok{0.00}  
\FloatTok{38}  \FloatTok{2.5e{-}17}  \FloatTok{2.2e{-}15}  \FloatTok{6.8e{-}18}  \OperatorTok{{-}}\FloatTok{1.76e{-}03}  \FloatTok{5.529007155e{-}01}   \FloatTok{7.368873498e{-}01}   \FloatTok{1.9e{-}17}  \FloatTok{0.00}  
\FloatTok{39}  \FloatTok{1.1e{-}17}  \FloatTok{4.4e{-}15}  \FloatTok{4.0e{-}18}  \OperatorTok{{-}}\FloatTok{1.74e{-}03}  \FloatTok{5.409849593e{-}01}   \FloatTok{7.210098998e{-}01}   \FloatTok{1.1e{-}17}  \FloatTok{0.01}  
\FloatTok{40}  \FloatTok{1.1e{-}17}  \FloatTok{4.9e{-}15}  \FloatTok{4.0e{-}18}  \FloatTok{1.44e{-}02}   \FloatTok{5.408403061e{-}01}   \FloatTok{7.208171399e{-}01}   \FloatTok{1.1e{-}17}  \FloatTok{0.01}  
\FloatTok{41}  \FloatTok{1.1e{-}17}  \FloatTok{4.9e{-}15}  \FloatTok{4.0e{-}18}  \FloatTok{1.44e{-}02}   \FloatTok{5.408403061e{-}01}   \FloatTok{7.208171399e{-}01}   \FloatTok{1.1e{-}17}  \FloatTok{0.01}  
\FloatTok{42}  \FloatTok{1.1e{-}17}  \FloatTok{4.9e{-}15}  \FloatTok{4.0e{-}18}  \FloatTok{1.44e{-}02}   \FloatTok{5.408403061e{-}01}   \FloatTok{7.208171399e{-}01}   \FloatTok{1.1e{-}17}  \FloatTok{0.01}  
\VariableTok{Optimizer} \VariableTok{terminated}\NormalTok{. }\VariableTok{Time}\OperatorTok{:} \FloatTok{0.01}    


\VariableTok{Interior}\OperatorTok{{-}}\VariableTok{point} \VariableTok{solution} \VariableTok{summary}
  \VariableTok{Problem} \VariableTok{status}  \OperatorTok{:} \VariableTok{UNKNOWN}
  \VariableTok{Solution} \VariableTok{status} \OperatorTok{:} \VariableTok{UNKNOWN}
  \VariableTok{Primal}\NormalTok{.  }\VariableTok{obj}\OperatorTok{:} \FloatTok{5.4084030611e{-}01}    \VariableTok{nrm}\OperatorTok{:} \FloatTok{3e+08}    \VariableTok{Viol}\NormalTok{.  }\VariableTok{con}\OperatorTok{:} \FloatTok{1e{-}09}    \VariableTok{var}\OperatorTok{:} \FloatTok{0e+00}    \VariableTok{barvar}\OperatorTok{:} \FloatTok{0e+00}  
  \VariableTok{Dual}\NormalTok{.    }\VariableTok{obj}\OperatorTok{:} \FloatTok{7.2081713987e{-}01}    \VariableTok{nrm}\OperatorTok{:} \FloatTok{4e+08}    \VariableTok{Viol}\NormalTok{.  }\VariableTok{con}\OperatorTok{:} \FloatTok{0e+00}    \VariableTok{var}\OperatorTok{:} \FloatTok{1e{-}09}    \VariableTok{barvar}\OperatorTok{:} \FloatTok{7e{-}07} 
\end{Highlighting}
\end{Shaded}

which shows that the solver did not converge.

If instead, we add a redundant ball constraint \(4 - x_1^2 - x_2^2 \geq 0\) and solve again at \(\kappa=1\), we see the following result:

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{ITE} \VariableTok{PFEAS}    \VariableTok{DFEAS}    \VariableTok{GFEAS}    \VariableTok{PRSTATUS}   \VariableTok{POBJ}              \VariableTok{DOBJ}              \VariableTok{MU}       \VariableTok{TIME}  
\FloatTok{0}   \FloatTok{1.0e+00}  \FloatTok{1.0e+00}  \FloatTok{1.0e+00}  \FloatTok{0.00e+00}   \FloatTok{0.000000000e+00}   \FloatTok{0.000000000e+00}   \FloatTok{1.0e+00}  \FloatTok{0.00}  
\FloatTok{1}   \FloatTok{1.8e{-}01}  \FloatTok{1.8e{-}01}  \FloatTok{1.4e{-}01}  \FloatTok{3.28e{-}01}   \FloatTok{2.041575331e{-}01}   \FloatTok{5.267481899e{-}01}   \FloatTok{1.8e{-}01}  \FloatTok{0.00}  
\FloatTok{2}   \FloatTok{3.5e{-}02}  \FloatTok{3.5e{-}02}  \FloatTok{1.4e{-}02}  \FloatTok{9.46e{-}01}   \FloatTok{4.043057656e{-}01}   \FloatTok{4.966964156e{-}01}   \FloatTok{3.5e{-}02}  \FloatTok{0.00}  
\FloatTok{3}   \FloatTok{1.3e{-}02}  \FloatTok{1.3e{-}02}  \FloatTok{3.8e{-}03}  \FloatTok{5.26e{-}01}   \FloatTok{2.214064092e{-}01}   \FloatTok{2.805094594e{-}01}   \FloatTok{1.3e{-}02}  \FloatTok{0.00}  
\FloatTok{4}   \FloatTok{3.5e{-}03}  \FloatTok{3.5e{-}03}  \FloatTok{6.1e{-}04}  \FloatTok{7.62e{-}01}   \FloatTok{1.925510959e{-}01}   \FloatTok{2.134013995e{-}01}   \FloatTok{3.5e{-}03}  \FloatTok{0.00}  
\FloatTok{5}   \FloatTok{1.1e{-}03}  \FloatTok{1.1e{-}03}  \FloatTok{1.7e{-}04}  \FloatTok{4.01e{-}01}   \FloatTok{1.154109271e{-}01}   \FloatTok{1.350598297e{-}01}   \FloatTok{1.1e{-}03}  \FloatTok{0.00}  
\FloatTok{6}   \FloatTok{2.9e{-}04}  \FloatTok{2.9e{-}04}  \FloatTok{2.8e{-}05}  \FloatTok{7.10e{-}01}   \FloatTok{8.188641629e{-}02}   \FloatTok{8.975466685e{-}02}   \FloatTok{2.9e{-}04}  \FloatTok{0.00}  
\FloatTok{7}   \FloatTok{9.1e{-}05}  \FloatTok{9.1e{-}05}  \FloatTok{8.2e{-}06}  \FloatTok{4.07e{-}01}   \FloatTok{5.245561798e{-}02}   \FloatTok{5.978149022e{-}02}   \FloatTok{9.1e{-}05}  \FloatTok{0.00}  
\FloatTok{8}   \FloatTok{2.7e{-}05}  \FloatTok{2.7e{-}05}  \FloatTok{1.6e{-}06}  \FloatTok{6.84e{-}01}   \FloatTok{3.727529406e{-}02}   \FloatTok{4.054196962e{-}02}   \FloatTok{2.7e{-}05}  \FloatTok{0.00}  
\FloatTok{9}   \FloatTok{9.9e{-}06}  \FloatTok{9.9e{-}06}  \FloatTok{6.1e{-}07}  \FloatTok{3.09e{-}01}   \FloatTok{2.492316391e{-}02}   \FloatTok{2.855972552e{-}02}   \FloatTok{9.9e{-}06}  \FloatTok{0.00}  
\FloatTok{10}  \FloatTok{2.5e{-}06}  \FloatTok{2.5e{-}06}  \FloatTok{9.4e{-}08}  \FloatTok{6.93e{-}01}   \FloatTok{1.662754698e{-}02}   \FloatTok{1.801019802e{-}02}   \FloatTok{2.5e{-}06}  \FloatTok{0.00}  
\FloatTok{11}  \FloatTok{7.4e{-}07}  \FloatTok{7.4e{-}07}  \FloatTok{2.7e{-}08}  \FloatTok{3.57e{-}01}   \FloatTok{1.066174340e{-}02}   \FloatTok{1.199307778e{-}02}   \FloatTok{7.4e{-}07}  \FloatTok{0.00}  
\FloatTok{12}  \FloatTok{2.2e{-}07}  \FloatTok{2.2e{-}07}  \FloatTok{5.4e{-}09}  \FloatTok{6.43e{-}01}   \FloatTok{7.435651393e{-}03}   \FloatTok{8.053182585e{-}03}   \FloatTok{2.2e{-}07}  \FloatTok{0.00}  
\FloatTok{13}  \FloatTok{7.8e{-}08}  \FloatTok{7.8e{-}08}  \FloatTok{2.1e{-}09}  \FloatTok{2.63e{-}01}   \FloatTok{5.027346675e{-}03}   \FloatTok{5.735405751e{-}03}   \FloatTok{7.8e{-}08}  \FloatTok{0.00}  
\FloatTok{14}  \FloatTok{1.9e{-}08}  \FloatTok{1.9e{-}08}  \FloatTok{3.1e{-}10}  \FloatTok{6.78e{-}01}   \FloatTok{3.274376941e{-}03}   \FloatTok{3.539771530e{-}03}   \FloatTok{1.9e{-}08}  \FloatTok{0.00}  
\FloatTok{15}  \FloatTok{5.4e{-}09}  \FloatTok{5.4e{-}09}  \FloatTok{8.6e{-}11}  \FloatTok{3.51e{-}01}   \FloatTok{2.090217524e{-}03}   \FloatTok{2.340150880e{-}03}   \FloatTok{5.4e{-}09}  \FloatTok{0.00}  
\FloatTok{16}  \FloatTok{1.6e{-}09}  \FloatTok{1.6e{-}09}  \FloatTok{1.8e{-}11}  \FloatTok{6.25e{-}01}   \FloatTok{1.460073639e{-}03}   \FloatTok{1.580348192e{-}03}   \FloatTok{1.6e{-}09}  \FloatTok{0.00}  
\FloatTok{17}  \FloatTok{6.0e{-}10}  \FloatTok{6.0e{-}10}  \FloatTok{7.2e{-}12}  \FloatTok{2.35e{-}01}   \FloatTok{1.000023643e{-}03}   \FloatTok{1.142129878e{-}03}   \FloatTok{6.0e{-}10}  \FloatTok{0.00}  
\FloatTok{18}  \FloatTok{1.4e{-}10}  \FloatTok{1.4e{-}10}  \FloatTok{1.0e{-}12}  \FloatTok{6.79e{-}01}   \FloatTok{6.400941650e{-}04}   \FloatTok{6.913204662e{-}04}   \FloatTok{1.4e{-}10}  \FloatTok{0.00}  
\FloatTok{19}  \FloatTok{1.0e{-}10}  \FloatTok{3.9e{-}11}  \FloatTok{2.7e{-}13}  \FloatTok{3.56e{-}01}   \FloatTok{4.051653495e{-}04}   \FloatTok{4.517858240e{-}04}   \FloatTok{3.9e{-}11}  \FloatTok{0.00}  
\FloatTok{20}  \FloatTok{1.2e{-}11}  \FloatTok{1.2e{-}11}  \FloatTok{5.8e{-}14}  \FloatTok{6.05e{-}01}   \FloatTok{2.840240254e{-}04}   \FloatTok{3.074642454e{-}04}   \FloatTok{1.2e{-}11}  \FloatTok{0.00}  
\FloatTok{21}  \FloatTok{4.6e{-}12}  \FloatTok{4.5e{-}12}  \FloatTok{2.4e{-}14}  \FloatTok{2.10e{-}01}   \FloatTok{1.967647207e{-}04}   \FloatTok{2.251266137e{-}04}   \FloatTok{4.5e{-}12}  \FloatTok{0.00}  
\FloatTok{22}  \FloatTok{1.0e{-}12}  \FloatTok{1.0e{-}12}  \FloatTok{3.3e{-}15}  \FloatTok{6.81e{-}01}   \FloatTok{1.242068557e{-}04}   \FloatTok{1.340389165e{-}04}   \FloatTok{1.0e{-}12}  \FloatTok{0.00}  
\FloatTok{23}  \FloatTok{2.7e{-}13}  \FloatTok{2.7e{-}13}  \FloatTok{8.0e{-}16}  \FloatTok{3.56e{-}01}   \FloatTok{7.772043572e{-}05}   \FloatTok{8.646338802e{-}05}   \FloatTok{2.7e{-}13}  \FloatTok{0.00}  
\FloatTok{24}  \FloatTok{8.5e{-}14}  \FloatTok{8.5e{-}14}  \FloatTok{1.8e{-}16}  \FloatTok{5.92e{-}01}   \FloatTok{5.463905229e{-}05}   \FloatTok{5.916694930e{-}05}   \FloatTok{8.5e{-}14}  \FloatTok{0.00}  
\FloatTok{25}  \FloatTok{3.3e{-}14}  \FloatTok{3.3e{-}14}  \FloatTok{7.7e{-}17}  \FloatTok{1.91e{-}01}   \FloatTok{3.813146090e{-}05}   \FloatTok{4.367749095e{-}05}   \FloatTok{3.3e{-}14}  \FloatTok{0.00}  
\FloatTok{26}  \FloatTok{7.5e{-}15}  \FloatTok{7.5e{-}15}  \FloatTok{1.0e{-}17}  \FloatTok{6.82e{-}01}   \FloatTok{2.388667090e{-}05}   \FloatTok{2.575875793e{-}05}   \FloatTok{7.5e{-}15}  \FloatTok{0.00}  
\FloatTok{27}  \FloatTok{9.5e{-}13}  \FloatTok{6.1e{-}15}  \FloatTok{8.2e{-}18}  \FloatTok{3.63e{-}01}   \FloatTok{2.249020870e{-}05}   \FloatTok{2.430458202e{-}05}   \FloatTok{6.1e{-}15}  \FloatTok{0.00}  
\FloatTok{28}  \FloatTok{2.7e{-}13}  \FloatTok{1.3e{-}15}  \FloatTok{1.5e{-}18}  \FloatTok{3.14e{-}01}   \FloatTok{1.318081011e{-}05}   \FloatTok{1.456985641e{-}05}   \FloatTok{1.3e{-}15}  \FloatTok{0.00}  
\FloatTok{29}  \FloatTok{7.4e{-}13}  \FloatTok{1.2e{-}15}  \FloatTok{1.4e{-}18}  \FloatTok{1.00e+00}   \FloatTok{1.295450582e{-}05}   \FloatTok{1.429001140e{-}05}   \FloatTok{1.2e{-}15}  \FloatTok{0.00}  
\FloatTok{30}  \FloatTok{9.7e{-}13}  \FloatTok{1.2e{-}15}  \FloatTok{1.4e{-}18}  \FloatTok{1.00e+00}   \FloatTok{1.283897715e{-}05}   \FloatTok{1.414828202e{-}05}   \FloatTok{1.2e{-}15}  \FloatTok{0.00}  
\FloatTok{31}  \FloatTok{1.0e{-}12}  \FloatTok{1.2e{-}15}  \FloatTok{1.4e{-}18}  \FloatTok{1.00e+00}   \FloatTok{1.280983848e{-}05}   \FloatTok{1.411266897e{-}05}   \FloatTok{1.2e{-}15}  \FloatTok{0.00}  
\FloatTok{32}  \FloatTok{1.0e{-}12}  \FloatTok{1.2e{-}15}  \FloatTok{1.4e{-}18}  \FloatTok{1.00e+00}   \FloatTok{1.280618882e{-}05}   \FloatTok{1.410821245e{-}05}   \FloatTok{1.2e{-}15}  \FloatTok{0.00}  
\FloatTok{33}  \FloatTok{1.0e{-}12}  \FloatTok{1.2e{-}15}  \FloatTok{1.4e{-}18}  \FloatTok{1.00e+00}   \FloatTok{1.280436352e{-}05}   \FloatTok{1.410598387e{-}05}   \FloatTok{1.2e{-}15}  \FloatTok{0.00}  
\FloatTok{34}  \FloatTok{7.1e{-}13}  \FloatTok{3.3e{-}16}  \FloatTok{2.8e{-}19}  \FloatTok{4.71e{-}01}   \FloatTok{8.481144013e{-}06}   \FloatTok{9.212971618e{-}06}   \FloatTok{3.3e{-}16}  \FloatTok{0.00}  
\FloatTok{35}  \FloatTok{7.2e{-}13}  \FloatTok{3.3e{-}16}  \FloatTok{2.8e{-}19}  \FloatTok{1.00e+00}   \FloatTok{8.474714028e{-}06}   \FloatTok{9.205554497e{-}06}   \FloatTok{3.3e{-}16}  \FloatTok{0.00}  
\FloatTok{36}  \FloatTok{7.3e{-}13}  \FloatTok{3.3e{-}16}  \FloatTok{2.8e{-}19}  \FloatTok{1.00e+00}   \FloatTok{8.473094330e{-}06}   \FloatTok{9.203686456e{-}06}   \FloatTok{3.3e{-}16}  \FloatTok{0.01}  
\FloatTok{37}  \FloatTok{4.4e{-}14}  \FloatTok{1.2e{-}16}  \FloatTok{1.1e{-}19}  \FloatTok{1.73e{-}01}   \FloatTok{5.812012110e{-}06}   \FloatTok{6.610489568e{-}06}   \FloatTok{1.2e{-}16}  \FloatTok{0.01}  
\FloatTok{38}  \FloatTok{3.2e{-}13}  \FloatTok{7.8e{-}17}  \FloatTok{5.6e{-}20}  \FloatTok{1.00e+00}   \FloatTok{4.907525789e{-}06}   \FloatTok{5.428890141e{-}06}   \FloatTok{8.3e{-}17}  \FloatTok{0.01}  
\FloatTok{39}  \FloatTok{3.9e{-}13}  \FloatTok{7.1e{-}17}  \FloatTok{4.9e{-}20}  \FloatTok{1.00e+00}   \FloatTok{4.737143451e{-}06}   \FloatTok{5.216312950e{-}06}   \FloatTok{7.7e{-}17}  \FloatTok{0.01}  
\FloatTok{40}  \FloatTok{1.0e{-}13}  \FloatTok{1.9e{-}17}  \FloatTok{9.0e{-}21}  \FloatTok{5.68e{-}01}   \FloatTok{3.163202225e{-}06}   \FloatTok{3.391803637e{-}06}   \FloatTok{2.0e{-}17}  \FloatTok{0.01}  
\FloatTok{41}  \FloatTok{2.1e{-}13}  \FloatTok{1.8e{-}17}  \FloatTok{8.3e{-}21}  \FloatTok{1.00e+00}   \FloatTok{3.079800819e{-}06}   \FloatTok{3.297015112e{-}06}   \FloatTok{2.0e{-}17}  \FloatTok{0.01}  
\FloatTok{42}  \FloatTok{3.0e{-}13}  \FloatTok{1.7e{-}17}  \FloatTok{7.7e{-}21}  \FloatTok{1.00e+00}   \FloatTok{2.985096669e{-}06}   \FloatTok{3.190159883e{-}06}   \FloatTok{2.0e{-}17}  \FloatTok{0.01}  
\FloatTok{43}  \FloatTok{3.1e{-}13}  \FloatTok{1.7e{-}17}  \FloatTok{7.6e{-}21}  \FloatTok{1.00e+00}   \FloatTok{2.972167540e{-}06}   \FloatTok{3.175652455e{-}06}   \FloatTok{2.0e{-}17}  \FloatTok{0.01}  
\FloatTok{44}  \FloatTok{1.2e{-}13}  \FloatTok{3.9e{-}18}  \FloatTok{1.6e{-}21}  \FloatTok{1.93e{-}01}   \FloatTok{1.802355527e{-}06}   \FloatTok{1.972166368e{-}06}   \FloatTok{4.4e{-}18}  \FloatTok{0.01}  
\FloatTok{45}  \FloatTok{1.7e{-}13}  \FloatTok{1.5e{-}18}  \FloatTok{3.7e{-}22}  \FloatTok{1.00e+00}   \FloatTok{1.272549881e{-}06}   \FloatTok{1.334918948e{-}06}   \FloatTok{1.7e{-}18}  \FloatTok{0.01}  
\FloatTok{46}  \FloatTok{1.7e{-}13}  \FloatTok{1.5e{-}18}  \FloatTok{3.7e{-}22}  \FloatTok{1.00e+00}   \FloatTok{1.272549881e{-}06}   \FloatTok{1.334918948e{-}06}   \FloatTok{1.7e{-}18}  \FloatTok{0.01}  
\FloatTok{47}  \FloatTok{1.7e{-}13}  \FloatTok{1.5e{-}18}  \FloatTok{3.7e{-}22}  \FloatTok{1.00e+00}   \FloatTok{1.272549881e{-}06}   \FloatTok{1.334918948e{-}06}   \FloatTok{1.7e{-}18}  \FloatTok{0.01}  
\VariableTok{Optimizer} \VariableTok{terminated}\NormalTok{. }\VariableTok{Time}\OperatorTok{:} \FloatTok{0.01}    


\VariableTok{Interior}\OperatorTok{{-}}\VariableTok{point} \VariableTok{solution} \VariableTok{summary}
  \VariableTok{Problem} \VariableTok{status}  \OperatorTok{:} \VariableTok{PRIMAL\_AND\_DUAL\_FEASIBLE}
  \VariableTok{Solution} \VariableTok{status} \OperatorTok{:} \VariableTok{OPTIMAL}
\end{Highlighting}
\end{Shaded}

which shows the solver converged and the optimal value is numerically close to zero. This shows the correctness of the last point in the Theorem above.

We can also write the constraint \(x_2^2 \leq 0\) equivalently as \(x_2 = 0\), in which case the POP will satisfy the first point of Theorem \ref{thm:MomentSOSHierarchy} and strong duality holds. Implementing this in code, MOSEK produces the following outut

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{ITE} \VariableTok{PFEAS}    \VariableTok{DFEAS}    \VariableTok{GFEAS}    \VariableTok{PRSTATUS}   \VariableTok{POBJ}              \VariableTok{DOBJ}              \VariableTok{MU}       \VariableTok{TIME}  
\FloatTok{0}   \FloatTok{1.0e+00}  \FloatTok{1.0e+00}  \FloatTok{1.0e+00}  \FloatTok{0.00e+00}   \FloatTok{0.000000000e+00}   \FloatTok{0.000000000e+00}   \FloatTok{1.0e+00}  \FloatTok{0.00}  
\FloatTok{1}   \FloatTok{2.8e{-}01}  \FloatTok{2.8e{-}01}  \FloatTok{1.7e{-}01}  \FloatTok{6.80e{-}01}   \FloatTok{1.784287181e{-}01}   \FloatTok{2.250737385e{-}01}   \FloatTok{2.8e{-}01}  \FloatTok{0.00}  
\FloatTok{2}   \FloatTok{1.6e{-}02}  \FloatTok{1.6e{-}02}  \FloatTok{2.4e{-}03}  \FloatTok{1.10e+00}   \OperatorTok{{-}}\FloatTok{1.896781377e{-}02}  \OperatorTok{{-}}\FloatTok{1.421782353e{-}02}  \FloatTok{1.6e{-}02}  \FloatTok{0.00}  
\FloatTok{3}   \FloatTok{1.8e{-}04}  \FloatTok{1.8e{-}04}  \FloatTok{2.7e{-}06}  \FloatTok{1.00e+00}   \OperatorTok{{-}}\FloatTok{2.173561193e{-}04}  \OperatorTok{{-}}\FloatTok{1.728424914e{-}04}  \FloatTok{1.8e{-}04}  \FloatTok{0.00}  
\FloatTok{4}   \FloatTok{1.0e{-}06}  \FloatTok{1.0e{-}06}  \FloatTok{1.2e{-}09}  \FloatTok{1.00e+00}   \OperatorTok{{-}}\FloatTok{1.291256020e{-}06}  \OperatorTok{{-}}\FloatTok{1.041546182e{-}06}  \FloatTok{1.0e{-}06}  \FloatTok{0.00}  
\FloatTok{5}   \FloatTok{1.9e{-}08}  \FloatTok{1.9e{-}08}  \FloatTok{3.0e{-}12}  \FloatTok{1.00e+00}   \OperatorTok{{-}}\FloatTok{2.316455946e{-}08}  \OperatorTok{{-}}\FloatTok{1.858439993e{-}08}  \FloatTok{1.9e{-}08}  \FloatTok{0.00}  
\VariableTok{Optimizer} \VariableTok{terminated}\NormalTok{. }\VariableTok{Time}\OperatorTok{:} \FloatTok{0.00}    


\VariableTok{Interior}\OperatorTok{{-}}\VariableTok{point} \VariableTok{solution} \VariableTok{summary}
  \VariableTok{Problem} \VariableTok{status}  \OperatorTok{:} \VariableTok{PRIMAL\_AND\_DUAL\_FEASIBLE}
  \VariableTok{Solution} \VariableTok{status} \OperatorTok{:} \VariableTok{OPTIMAL}
\end{Highlighting}
\end{Shaded}

with optimal value numerically zero.

In all three cases, the geometry of the feasible set never changes, what changed was the algebraic description of the same geometric set. This shows that the moment-SOS hierarchy can be sensitive to how the user describes the problem.
\end{example}

\subsection{Conversion to Standard SDP}\label{conversion-to-standard-sdp}

\section{Measure-Theoretic Interpretation}\label{measure-theoretic-interpretation}

Let us zoom out a bit and see what we have done. We started with Putinar's Positivstellensatz, applied it to polynomial optimization (POP) and obtained the SOS relaxation of POPs. Then, by taking the dual of \(\mathbb{R}[x]_{2d}\) and \(\mathrm{Ideal}[h] + \mathrm{Qmodule}[g]\), and applying standard conic duality, we obtained the primal moment relaxation, which is an optimization over the truncated multi-sequence \(y\).

However, recall in the discussion of Shor's SDP relaxation, the dual of the dual can be directly obtained by first writing the QCQP as a rank-constrained matrix optimization problem and then dropping the rank constraint -- an approach that gives us the primal relaxation without needing to go through the dual relaxation. Can we do the same for POPs, i.e., obtaining the moment relaxation without needing to go through the SOS relaxation? The answer is affirmative.

Consider the polynomial optimization (POP) in \eqref{eq:pop-restate} and denote its feasible set as
\[
S = \{ x \in \mathbb{R}^{n} \mid h_i(x)=0,i=1,\dots,l_h, g_i(x)\geq 0, i=1,\dots,l_g \}.
\]
We assume \(S\) is compact and Archimedean (e.g., there is a ball constraint \(R - x^\top x \geq 0\) in \(g\)). The POP \eqref{eq:pop-restate} is equivalent to
\begin{equation}
p^\star = \min_{x \in S} \quad p(x).
\label{eq:pop-with-S}
\end{equation}

A key observation is that problem \eqref{eq:pop-with-S} is equivalent to an \textbf{infinite-dimensional convex optimization problem}! Let \(\mathcal{P}(S)\) be the space of all possible measures supported on \(S\), the following result shows that the POP \eqref{eq:pop-with-S} is equivalent to a linear optimization over \(\mathcal{P}(S)\).

\begin{theorem}[Optimization over Measures]
\protect\hypertarget{thm:MeasureOpt}{}\label{thm:MeasureOpt}The following optimization
\begin{equation}
\begin{split}
\rho^\star = \min_{ \mu \in \mathcal{P}(S)} & \quad \int_S p(x) d \mu(x) \\
\mathrm{s.t.}& \quad \int_S 1 d \mu(x) = 1.
\end{split}
\label{eq:measure-opt}
\end{equation}
is equivalent to the POP \eqref{eq:pop-with-S}, i.e., \(p^\star = \rho^\star\).
\end{theorem}

\begin{proof}
To see this, note that if \(p^\star = -\infty\), then trivially \(\rho^\star = -\infty\) (this is left as an exercise for you). We focus on the case \(p^\star > - \infty\) is finite. Since \(p^\star\) is the global minimum, we have
\[
p(x) \geq p^\star, \forall x \in S.
\]
Therefore,
\[
\int_S p(x) d\mu(x) \geq \int_S p^\star d \mu(x) \geq p^\star, \quad \forall \mu \in \mathcal{P}(S), \int_S 1 d\mu(x) = 1.
\]
This shows that
\[
\rho^\star \geq p^\star.
\]
Conversely, for any \(x \in S\), let \(\delta_{x}\) be the Dirac measure. We have \(\delta_{x}\) is feasible for problem \eqref{eq:measure-opt} and attains the same cost as \(x\) for the POP. This shows that
\[
\rho^\star \leq p^\star.
\]
As a result, \(\rho^\star = p^\star\).
\end{proof}

The proof shows that, if \(x_\star\) is a global optimizer of the POP, then the Dirac measure \(\mu_\star = \delta_{x_\star}\) is an optimal solution to \eqref{eq:measure-opt}.

Now let us inspect the objective function of \eqref{eq:measure-opt}. Suppose \(p(x) \in \mathbb{R}[x]_{2d}\), then
\[
p(x) = \sum_{\alpha \in \mathcal{F}_{n,2d}} p_{\alpha} x^{\alpha} = \langle \mathrm{vec}(p), [x]_{2d} \rangle.
\]
Plugging this to the objective function, we see
\[
\int_S p(x) d \mu(x) = \int_S \left(\sum_{\alpha} p_{\alpha} x^{\alpha}\right) d \mu(x) = \sum_{\alpha} p_{\alpha} \left(\int_S x^{\alpha} d \mu(x)\right).
\]
Denoting
\[
y_{\alpha} = \int_S x^{\alpha} d \mu(x), 
\]
as the \(\alpha\) moment of \(\mu\) on \(S\), and
\begin{equation}
y = (y_\alpha)_{\alpha \in \mathcal{F}_{n,2d}} = \int_S [x]_{2d} d \mu(x)
\label{eq:representing-measure}
\end{equation}
as the truncated moment sequence of degree up to \(2d\), we can see that problem \eqref{eq:measure-opt} is a linear optimization over the moments of \(\mu\):
\begin{equation}
\begin{split}
\min_{\mu \in \mathcal{P}(S)} & \quad \langle \mathrm{vec}(p), y \rangle \\
\mathrm{s.t.}& \quad y_0 = 1
\end{split}
\label{eq:measure-opt-moments}
\end{equation}
where \(y_0\) is the zero-order moment.

Now in order to solve problem \eqref{eq:measure-opt-moments}, the key question boils down to: given a TMS \(y = (y_{\alpha})\), under what conditions can we ensure that \(y\) has a \textbf{representing measure} supported on \(S\), i.e., equation \eqref{eq:representing-measure} holds for some measure \(\mu\)?

As we will introduce soon, we will derive \textbf{necessary conditions} on the TMS \(y\) for it to admit a representing measure, which surprisingly and not surprisingly, is exactly the dual conic constraint \(y \in \mathcal{Z}[h]_{2d} \cap \mathcal{M}[g]_{2d}\) we introduced in Theorem \ref{thm:DualSumIdealQuadraticModule}! Therefore, the moment relaxation can be derived by solving \eqref{eq:measure-opt-moments} with necessary conditions on \(y\) admitting a representing measure.

However, the measure-theoretic perspective will give us one advantage, i.e., via checkable \textbf{sufficient conditions} for \(y\) to admit a representing measure, we can \textbf{certify} convergence of the moment-SOS hierarchy and extract global minimizers of the original POP!

\section{Truncated Moment Problem}\label{truncated-moment-problem}

Given a truncated multi-sequence \(y = (y_\alpha)_{\alpha \in \mathcal{F}_{n,2d}}\), it is said to admit a Borel measure if \eqref{eq:representing-measure} holds for some measure \(\mu\) supported on \(S\) (the support of a measure on \(\mathbb{R}^{n}\) is the smallest closed set \(T \subseteq \mathbb{R}^{n}\) such that \(\mu(\mathbb{R}^{n} \backslash T) = 0\)), in which case \(\mu\) is called a \textbf{\(S\)-representing measure} of \(y\).

A measure \(\mu\) whose support is a finite set is called \textbf{finitely atomic}. A measure is called \(r\)-atomic if its support has cardinality \(r\).

The following result, due to \citep{bayer06ams-proof}, shows that a representing measure can always be chosen to be finitely atomic if it exists.

\begin{theorem}[Representing Measure]
\protect\hypertarget{thm:RepresentingMeasure}{}\label{thm:RepresentingMeasure}If a TMS \(y \in \mathbb{R}^{s(n,2d)}\) admits a representing measure, then it also admits a
finitely atomic representing measure \(\nu\) such that
\[
\mathrm{supp}(\nu) \subseteq \mathrm{supp}(\mu), \quad \left\vert \mathrm{supp}(\nu) \right\vert \leq s(n,2d).
\]
\end{theorem}

The \textbf{truncated \(S\)-moment problem} concerns the following: given a TMS \(y\), does it admit a representing measure \(\mu\) supported on \(S\)?

To answer this question, let us pick any polynomial \(p(x) \in \mathbb{R}[x]_{2d}\) that is SOS, then it is easy to see that, for any measure \(\mu\),
\[
\int_S p(x) d\mu(x) \geq 0
\]
must hold. Using the fact that \(p(x)\) is SOS, we can write
\[
p(x) = [x]_d^\top Q [x]_d = \left\langle Q, [x]_d [x]_d^\top \right\rangle, \quad Q \succeq 0
\]
and therefore
\begin{equation}
\int_S p(x) d\mu(x) = \int_S \left\langle Q, [x]_d [x]_d^\top \right\rangle d \mu(x) = \left\langle Q,  \int_S [x]_d [x]_d^\top d \mu(x)  \right\rangle = \langle Q, M_d[y] \rangle
\label{eq:integral-to-moment-matrix}
\end{equation}
where \(M_d[y] \in \mathbb{S}^{s(n,d)}\) is the moment matrix of \(\mu\)'s truncated moment sequence \(y \in \mathbb{R}^{s(n,2d)}\). In order for \eqref{eq:integral-to-moment-matrix} to be nonnegative for any \(Q \succeq 0\), the moment matrix \(M_d[y]\) must be positive semidefinite.

We can keep doing this using the defining polynomials of \(S\). Pick any \(g_i(x) \geq 0\) constraint that defines \(S\), and any SOS polynomial \(\sigma_i(x)\) whose degree \(2s_i\) is chosen such that \(2 s_i + \deg(g) \leq 2d\), then
\[
\int_S g_i(x) \sigma_i(x) d\mu(x) \geq 0
\]
must hold. Since \(\sigma_i(x)\) is SOS, it can be written as \(\sigma_i(x) = [x]_{s_i}^\top Q_i [x]_{s_i}\) for some \(Q_i \succeq 0\). Then we have
\[
\int_S g_i(x) \sigma_i(x) d\mu(x) = \int_S g_i(x) [x]_{s_i}^\top Q_i [x]_{s_i} d\mu(x) = \left\langle Q_i,  \int_S g_i(x) [x]_{s_i}[x]_{s_i}^\top d\mu(x)  \right\rangle = \langle Q_i,  L_{g_i}^d[y] \rangle
\]
where \(L_{g_i}^d [y]\) is the localizing matrix of \(g_i(x)\) generated by the moment vector \(y\). In order for the above equation to be nonnegative for any \(Q_i \succeq 0\), we must have \(L_{g_i}^d[y] \succeq 0\) for any \(g_i\).

Similarly, we can pick any equality constraint \(h_i(x) = 0\) that defines \(S\) and any polynomial \(\lambda_i(x)\) whose degree is chosen such that \(\deg(\lambda_i) + \deg(h_i) \leq 2d\), then
\[
\int_S h_i(x) \lambda_i(x) d\mu(x) = 0.
\]
In order for this equation to hold for any multiplier \(\lambda_i(x)\), one can verify that we must have the localizing vector \(L_{h_i}^{2d}[y] = 0\). This gives us a set of necessary conditions for \(y\) to admit a representing measure.

\begin{proposition}[Necessary Condition for Existence of Representing Measure]
\protect\hypertarget{prp:NecessaryConditionRepresentingMeasure}{}\label{prp:NecessaryConditionRepresentingMeasure}Let \(y \in \mathbb{R}^{s(n,2d)}\) be a truncated multi-sequence. If \(y\) admits an \(S\)-representing measure, i.e., \eqref{eq:representing-measure} holds for some measure \(\mu\) supported on \(S\), then \(y\) must satisfy
\[
M_d[y] \succeq 0, \quad L_{g_i}^d[y] \succeq 0, i=1,\dots,l_g, \quad L_{h_i}^{2d}[y] = 0, i=1,\dots,l_h.
\]
This is equivalent to \(y \in \mathcal{Z}[h]_{2d} \cap \mathcal{M}[g]_{2d}\).
\end{proposition}

The first corollary of Proposition \ref{prp:NecessaryConditionRepresentingMeasure} is that problem \eqref{eq:moment-Putinar} is a convex relaxation for the infinite-dimensional problem \eqref{eq:measure-opt}.

\begin{corollary}[Moment Relaxation]
\protect\hypertarget{cor:MomentRelaxation}{}\label{cor:MomentRelaxation}The convex optimization problem \eqref{eq:moment-Putinar} is a convex relaxation of problem \eqref{eq:measure-opt} (and hence is also a relaxation of the original POP):
\[
\beta^\star_\kappa \leq \rho^\star = p^\star.
\]
\end{corollary}

The second corollary of Proposition \ref{prp:NecessaryConditionRepresentingMeasure}, which is the extra advantage offered via this measure-theoretic interpretation, is that if we solve the moment relaxation \eqref{eq:moment-Putinar} and obtain an optimal solution \(y_\star\) that indeed admits a representing measure \(\mu_\star\), then \(\mu_\star\) is in fact a global optimal solution to problem \eqref{eq:measure-opt}. Moreover, if \(y_\star\) admits a representing measure \(\mu_\star\), then by Theorem \ref{thm:RepresentingMeasure} it also admits a finitely atomic measure \(\nu_\star\) and every point in the support of \(\nu_\star\) is a global optimal solution to the POP. In this case, we say the moment-SOS relaxation is \textbf{exact} or \textbf{tight}.

\begin{corollary}[Exactness of Moment Relaxation]
\protect\hypertarget{cor:ExactnessOfRelaxation}{}\label{cor:ExactnessOfRelaxation}Let the moment relaxation \eqref{eq:moment-Putinar} be solvable and \(y_\star\) be an optimal solution. If \(y_\star\) admits an \(r\)-atomic representing measure \(\nu_\star\) supported on \(S\), then every point \(x_\star \in \mathrm{supp}(\nu_\star)\) is a globally optimal solution to the POP \eqref{eq:pop-with-S}.
\end{corollary}

\begin{proof}
Since \(y_\star\) admits an \(r\)-atomic representing measure \(\nu_\star\) we have
\[
\nu_\star = \lambda_1 \delta_{u_1} + \dots + \lambda_r \delta_{u_r}, \quad \lambda_i \geq 0, i=1,\dots,r,
\]
where \(\mathrm{supp}(\nu_\star) = \{ u_1,\dots,u_r \} \subset S\). This is equivalent to
\[
y_\star = \lambda_1 [u_1]_{2\kappa} + \cdots + \lambda_r [u_r]_{2\kappa}, \quad \lambda_i \geq 0, i=1,\dots,r.
\]
The fact that \(y_\star\) needs to satisfy the constraint \(y_0 = 1\) implies \(\sum_{i=1}^r \lambda_i = 1\).

By the nature of relaxation,
\begin{equation}
\langle \ell_{y_\star}, p(x) \rangle \leq p^\star \Rightarrow \sum_{i=1}^r \lambda_i p(u_i) \leq p^\star.
\label{eq:measure-proof-lower-bound}
\end{equation}
However, since each \(u_i\) is a feasible point to the POP, we have
\begin{equation}
p(u_i) \geq p^\star \Rightarrow \sum_{i=1}^r \lambda_i p(u_i) \geq p^\star.
\label{eq:measure-proof-upper-bound}
\end{equation}
Combing \eqref{eq:measure-proof-lower-bound} and \eqref{eq:measure-proof-upper-bound}, we have
\[
p(u_i) = p^\star, \quad \forall i=1,\dots,r,
\]
and every \(u_i\) is globally optimal for the POP.
\end{proof}

This is an extremely powerful result. It shows that, if given a TMS \(y\) one can check sufficient conditions on \(y\) admitting an \(r\)-atomic representing measure \(\nu_\star\), then it \textbf{certifies convergence and exactness of the moment-SOS hierarchy}. Moreover, every point in the support of \(\nu_\star\) is a globally optimal solution of the original POP.

\section{Flat Extension: Detecting Global Optimality and Extracting Solutions}\label{flat-extension-detecting-global-optimality-and-extracting-solutions}

Fortunately, there exist sufficient conditions for a TMS \(y \in \mathbb{R}^{s(n,2d)}\) to admit an \(r\)-atomic representing measure.
Suppose we solve the moment relaxation at order \(\kappa\) and let \(y_\star = (y_\alpha)_{\alpha \in \mathcal{F}_{n,2\kappa}}\) be an optimal solution. Denote
\[
d_c := \max  \left\{ 1, \lceil \frac{\deg(h_i)}{2} \rceil,i=1,\dots,l_h, \lceil \frac{\deg(g_i)}{2} \rceil,i=1,\dots,l_g \right\} 
\]
and
\[
d_0 := \max  \left\{ d_c, \lceil  \frac{\deg(f)}{2}  \rceil \right\} .
\]
Clearly we have \(\kappa \geq d_0\), because otherwise the TMS \(y\) does not have enough degree to include all monomials in the objective and constraint polynomials.

The following result gives a sufficient condition for the exactness of the moment-SOS relaxation.

\begin{theorem}[Flat Truncation]
\protect\hypertarget{thm:FlatTruncation}{}\label{thm:FlatTruncation}Suppose there exists \(t \in [d_0, \kappa]\) such that
\begin{equation}
\mathrm{rank}(M_t[y_\star]) = \mathrm{rank}(M_{t-d_c}[y_\star]) = r,
\label{eq:flat-extension}
\end{equation}
then the truncated optimal solution \(y_{\star,2t}:=(y_\alpha)_{\alpha \in \mathcal{F}_{n,2t}}\) admits an \(r\)-atomic representing measure \(\nu\) such that each point in \(\mathrm{supp}(\nu)\) is a global optimizer of the original POP.
\end{theorem}

Condition \eqref{eq:flat-extension} is called \textbf{flat extension} for the truncated TMS \(y_{\star,2t}\). The proof that the flat extension condition is sufficient for an \(r\)-atomic representing measure is due to \citep{curto05jot-truncated}. The proof of exactness given an \(r\)-atomic representing measure of \(y_{\star,2t}\) is given by Corollary \ref{cor:ExactnessOfRelaxation}.

In the next, we will present an algorithm that can find the \(r\)-atomic representing measure of \(y_{\star,2t}\) when it satisfies the flat extension condition \eqref{eq:flat-extension}, which was first proposed in \citep{henrion05ppc-detecting}. For ease of notation, I will remove the ``\(\star\)'' subscript in the TMS \(y_{\star,2t}\). Given \(y \in \mathbb{R}^{s(n,2t)}\), the goal is to extract \(r = \mathrm{rank}(M_t[y])\) optimal solutions of the POP.

Since \(y\) admits an \(r\)-atomic representing measure \(\nu\), we have
\[
\nu = \lambda_1 \delta_{x_1} + \dots + \lambda_r \delta_{x_r}, \quad \lambda_i \geq 0, x_i \in S, i=1,\dots,r.
\]
This implies
\begin{equation}
\begin{split}
M_t[y] & = \lambda_1 [x_1]_t [x_1]_t^\top+ \dots + \lambda_r [x_r]_t [x_r]_t^\top\\
& = \underbrace{\begin{pmatrix} [x_1]_t & \dots & [x_r]_t \end{pmatrix}}_{:= V_\star \in \mathbb{R}^{s(n,t) \times r}}
\underbrace{\begin{pmatrix} \lambda_1 &  &  \\
 & \ddots & \\
 &  & \lambda_r \end{pmatrix}}_{\in \mathbb{R}^{r \times r}}
\underbrace{\begin{pmatrix}
[x_1]_t^\top\\
\vdots \\
[x_r]_t^\top
 \end{pmatrix}}_{:= V_\star^\top\in \mathbb{R}^{r \times s(n,t)}}
\end{split}
\end{equation}

A polynomial \(p \in \mathbb{R}[x]_t\) such that \(p \equiv 0\) on \(\mathrm{supp}(\nu)\) if and only if \(M_t[y] \mathrm{vec}(p) = 0\) because
\[
0 = \int p(x)^2 d\nu(x) = \mathrm{vec}(p)^\top M_t[y] \mathrm{vec}(p).
\]
We now look for polynomials from the null space (or kernel) of \(M_t[y]\), for which we denote \(\mathrm{ker}(M_t[y])\). Consider the ideal
\[
I := \mathrm{Ideal}[ \{ p \in \mathbb{R}[x]_t \mid \mathrm{vec}(p) \in \mathrm{ker}(M_t[y]) \} ].
\]
We will show that we can construct a basis for the quotient space \(\mathbb{R}[x] / I\).

Let the spectral decomposition of \(M_t[y]\) be
\[
M_t[y] = V \Lambda V^\top, \quad V \in \mathbb{R}^{s(n,t) \times r}.
\]
Clearly, the kernel of \(M_t[y]\) is the same as the null space of \(V^\top\):
\[
\mathrm{ker}(M_t[y]) = \mathrm{ker}(V^\top).
\]
Therefore, to get the kernel of \(M_t[y]\), we can first put \(V^\top\) into \href{https://en.wikipedia.org/wiki/Row_echelon_form\#:~:text=row\%20echelon\%20form-,A\%20matrix\%20is\%20in\%20row\%20echelon\%20form\%20if,entry\%20of\%20every\%20row\%20above.}{reduced row echelon form} (RREF, for a square matrix, the RREF can be thought of as the upper triangular form), e.g., using the Matlab \href{https://www.mathworks.com/help/matlab/ref/rref.html}{\texttt{rref}} function:
\[
U = \begin{bmatrix}
1 & * & 0 & 0 & * & \cdots & 0 & * & * & * \\
 & & 1 & 0 & * & \cdots & 0 & * & * & * \\
  & & & 1 & * & \cdots & 0 & * & * & * \\
    & & &  &  & \cdots & 0 & * & * & * \\
      & & &  &  & \ddots & 0 & * & * & * \\
      & & &  &  &  & 1 & * & * & * 
\end{bmatrix} \in \mathbb{R}^{r \times s(n,t)}.
\]
The columns of \(U\) are labeled by the standard monomials \(x^{\alpha}, \alpha \in \mathcal{F}_{n,t}\). The RREF \(U\) has \(r\) pivot columns (columns having the first nonzero element in each row), say labelled by
\[
B_0 = \{ \beta_1, \dots, \beta_r \}, \quad \beta_i \in \mathcal{F}_{n,t}, i=1,\dots,t.
\]
Let \(e_i\) be the standard basis vector with all zeros except \(1\) at the \(i\)-th row, form the new set
\[
B_1 := (e_1 + B_0) \cup \dots \cup (e_n + B_0) \backslash B_0.
\]

The following result shows that we can obtain all the solutions \(x_1,\dots,x_r\) by solving a system of polynomial equations.

\begin{lemma}[Extracting Solutions]
\protect\hypertarget{lem:ExtractingSolutions}{}\label{lem:ExtractingSolutions}Suppose the flat extension condition holds for \(y \in \mathbb{R}^{s(n,2t)}\), then,
\[
\mathbb{R}[x]/I = \mathrm{span}\{ [x^{\beta_1}], \dots, [x^{\beta_r}] \},
\]
and the points \(x_1,\dots,x_r\) in \(\mathrm{supp}(\nu)\) are precisely solutions to the following polynomial system of equations
\begin{equation}
p_{\alpha}(x) = x^{\alpha} - \sum_{j=1}^r U(j,\alpha) x^{\beta_j} = 0, \quad \alpha \in B_1.
\label{eq:extract-solution-polynomial-system}
\end{equation}
\end{lemma}

The fact that all the polynomials \(p_{\alpha}(x), \alpha \in B_1\) are in the null space of \(M_t[y]\) can be deduced from the RREF \(U\), e.g., you can see \href{https://people.math.carleton.ca/~kcheung/math/notes/MATH1107/wk09/09_basis_for_nullspace.html}{this webpage about how to find the null space of an RREF}.

Our goal now becomes to find all the roots of the system \eqref{eq:extract-solution-polynomial-system}. This is something we learned how to solve in Chapter \ref{ZeroDimIdeal}! Specifically, the basic strategy is to first find the multiplication matrices, and then simultaneously diagonalize them, or use a more robust procedure suggested in \citep{corless1997reordered}, which I asked you to practice in one of the problem sets.

Let us make this solution extraction procedure concrete by going through an example.

\begin{example}[Solution Extraction from Moment Matrix]
\protect\hypertarget{exm:SolutionExtraction}{}\label{exm:SolutionExtraction}Consider the polynomial optimization problem
\begin{equation}
\begin{split}
\min_{x \in \mathbb{R}^{2}} & \quad (x_1 - 1)^2 + (x_1 - x_2)^2 + (x_2 - 3)^2 \\
\mathrm{s.t.}& \quad 1 - (x_1 - 1)^2 \geq 0 \\
& \quad 1 - (x_1 - x_2)^2 \geq 0 \\
& \quad 1 - (x_2 - 3)^2 \geq 0
\end{split}
\end{equation}
Solving the moment relaxation with \(\kappa =2\), we obtain
\[
\mathrm{rank}(M_1[y]) = \mathrm{rank}(M_2[y]) = 3.
\]
Therefore, there exist three global optimizers. The moment matrix reads
\[
M_2[y] = \begin{bmatrix}
1.0000 & 1.5868 & 2.2477 & 2.7603 & 3.6690 & 5.2387 \\
1.5868 & 2.7603 & 3.6690 & 5.1073 & 6.5115 & 8.8245 \\
2.2477 & 3.6690 & 5.2387 & 6.5115 & 8.8245 & 12.7072 \\
2.7603 & 5.1073 & 6.5115 & 9.8013 & 12.1965 & 15.9960 \\
3.6690 & 6.5115 & 8.8245 & 12.1965 & 15.9960 & 22.1084 \\
5.2387 & 8.8245 & 12.7072 & 15.9960 & 22.1084 & 32.1036
\end{bmatrix}
\]
whose rows and columns are indexed by the standard monomial basis
\[
[x]_2 = \begin{bmatrix}
1 \\ x_1 \\ x_2 \\ x_1^2 \\ x_1 x_2 \\ x_2^2 
\end{bmatrix}.
\]
We can factorize \(M_2[y]\) as \(VV^\top\) with
\[
V = \begin{bmatrix}
-0.9384 & - 0.0247 & 0.3447 \\
-1.6188 & 0.3036 & 0.2182 \\
-2.2486 & -0.1822 & 0.3864 \\
-2.9796 & 0.9603 & -0.0348 \\
-3.9813 & 0.3417 & -0.1697 \\
-5.6128 & -0.7627 & -0.1365
\end{bmatrix}.
\]
Reduce \(V\) to column echelon form (which is equivalent to reduce \(V^\top\) to row echelon form)
\[
U = \begin{bmatrix}
1 & & \\
0 & 1 & \\
0 & 0 & 1 \\
-2 & 3 & 0 \\
-4 & 2 & 2 \\
-6 & 0 & 5 
\end{bmatrix}.
\]
Pivot entries of \(U\) correspond to the following monomial basis
\[
w(x) = \begin{bmatrix} 1\\ x_1 \\ x_2 \end{bmatrix}.
\]
The polynomial system of equations \([x]_2 = U w(x)\) reads
\begin{equation}
\begin{split}
x_1^2 &= -2 + 3x_1 \\
x_1 x_2 &= -4 + 2x_1 + 2x_2 \\
x_2^2 &= -6 + 5x_2
\end{split}
\end{equation}
Multiplication matrices, by \(x_1\) and \(x_2\), can be extracted from \(U\):
\[
x_1 \cdot w(x) = \begin{bmatrix}
0 & 1 & 0 \\
-2 & 3 & 0 \\
-4 & 2 & 2
\end{bmatrix} w(x) = M_1 w(x)
\]
\[
x_2 \cdot w(x) = \begin{bmatrix}
0 & 0 & 1 \\
-4 & 2 & 2\\
-6 & 0 & 5
\end{bmatrix} w(x) = M_2 w(x).
\]
Perform a generic linear combination of \(M_1\) and \(M_2\):
\[
M = 3 M_1 + 4 M_2,
\]
and then find its Schur decomposition
\[
U^* M U = T = \begin{bmatrix}
18.0000  & -36.3731  & -30.0892\\
0   & 11.0000   & -0.8018 \\
0         & 0   & 14.0000
\end{bmatrix}, \quad U = \begin{bmatrix}
-0.2673   & -0.7715   & -0.5774\\
-0.5345    & 0.6172   & -0.5774\\
-0.8018   &-0.1543    & 0.5774
\end{bmatrix}.
\]
Then we perform
\[
U^* M_1 U = \begin{bmatrix}
2.0000  &  -5.1962   & -1.3887 \\
    0.0000    & 1.0000   & -0.2673\\
   0.0000    & 0.0000   & 2.0000
\end{bmatrix}, \quad 
U^* M_2 U = \begin{bmatrix}
3.0000   & -5.1962   & -6.4807\\
    0.0000    & 2.0000    & 0.0000\\
    0.0000   & -0.0000    & 2.0000
\end{bmatrix}
\]
from which the three global optimizers can be found:
\[
x(1) = \begin{bmatrix} 2 \\ 3 \end{bmatrix}, \quad 
x(2) = \begin{bmatrix} 1 \\ 2 \end{bmatrix}, \quad 
x(3) = \begin{bmatrix} 2 \\ 2 \end{bmatrix}.
\]
\end{example}

  \bibliography{book.bib}

\end{document}
